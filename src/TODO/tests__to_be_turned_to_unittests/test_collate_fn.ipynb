{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.nn.utils.rnn import pad_sequence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CollateFnV2:\n",
    "    def __init__(self, batch_first: bool, word_pad_idx: int, \n",
    "                 swipe_pad_idx: int = 0) -> None:\n",
    "        self.word_pad_idx = word_pad_idx\n",
    "        self.batch_first = batch_first\n",
    "        self.swipe_pad_idx = swipe_pad_idx\n",
    "\n",
    "    def _assert_encoder_in_type_and_shape(self, encoder_in_example):\n",
    "        assert len(encoder_in_example) == 2\n",
    "        for el in encoder_in_example:\n",
    "            assert isinstance(el, torch.Tensor), \\\n",
    "                f\"Expected torch.Tensor, got {type(el)}\"\n",
    "        \n",
    "    def _is_encoder_input_tuple(self, batch):\n",
    "        encoder_in_example = batch[0][0][0]\n",
    "        if isinstance(encoder_in_example, tuple):\n",
    "            self._assert_encoder_in_type_and_shape(encoder_in_example)\n",
    "            return True\n",
    "        elif isinstance(encoder_in_example, torch.Tensor):\n",
    "            return False\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown type of encoder input {type(batch[0][0])}\")\n",
    "    \n",
    "    def __call__(self, batch: list):\n",
    "        \"\"\"\n",
    "        Given a List where each row is \n",
    "        ((encoder_in_sample, decoder_in_sample), decoder_out_sample) \n",
    "        returns a tuple of two elements:\n",
    "        1. (encoder_in, decoder_in, swipe_pad_mask, word_pad_mask)\n",
    "        2. decoder_out\n",
    "\n",
    "        Arguments:\n",
    "        ----------\n",
    "        batch: list of tuples:\n",
    "            ((encoder_in, dec_in_char_seq), dec_out_char_seq),\n",
    "            where encoder_in may be a tuple of torch tensors\n",
    "            (ex. ```(traj_feats, nearest_kb_tokens)```)\n",
    "            or a single tensor (ex. ```nearest_kb_tokens```)\n",
    "\n",
    "\n",
    "        Returns:\n",
    "        --------\n",
    "        transformer_in: tuple of torch tensors:\n",
    "            1. (enc_in, dec_in, swipe_pad_mask, word_pad_mask),\n",
    "                where enc_in can be either a single tensor or a tuple\n",
    "                of two tensors (depends on type of input)\n",
    "                Each element is a torch tensor of shape:\n",
    "                - enc_in: either (curve_len, batch_size, n_feats) or\n",
    "                    ((curve_len, batch_size, n_feats1), (curve_len, batch_size, n_feats2))\n",
    "                - dec_in: (chars_seq_len - 1, batch_size)\n",
    "                - swipe_pad_mask: (batch_size, curve_len)\n",
    "                - word_pad_mask: (batch_size, chars_seq_len - 1, )\n",
    "        \"\"\"\n",
    "        is_encoder_input_tuple = self._is_encoder_input_tuple(batch)\n",
    "        dec_in_no_pad = []\n",
    "        dec_out_no_pad = []\n",
    "\n",
    "        encoder_in_no_pad = ([], []) if is_encoder_input_tuple else []\n",
    "\n",
    "        for row in batch:\n",
    "            x_smpl, decoder_out_smpl = row\n",
    "            encoder_in_smpl, decoder_in_smpl = x_smpl\n",
    "            if is_encoder_input_tuple:\n",
    "                for i in range(2):\n",
    "                    encoder_in_no_pad[i].append(encoder_in_smpl[i])\n",
    "            else:\n",
    "                encoder_in_no_pad.append(encoder_in)\n",
    "\n",
    "            dec_in_no_pad.append(decoder_in_smpl)\n",
    "            dec_out_no_pad.append(decoder_out_smpl)\n",
    "\n",
    "        if is_encoder_input_tuple:\n",
    "            encoder_in = tuple(pad_sequence(encoder_in_no_pad_i, batch_first=self.batch_first, \n",
    "                                       padding_value=self.swipe_pad_idx)\n",
    "                          for encoder_in_no_pad_i in encoder_in_no_pad)\n",
    "        else:\n",
    "            encoder_in = pad_sequence(encoder_in_no_pad, batch_first=self.batch_first,\n",
    "                                      padding_value=self.swipe_pad_idx)\n",
    "\n",
    "        dec_out = pad_sequence(dec_out_no_pad, batch_first=self.batch_first,\n",
    "                                        padding_value=self.word_pad_idx)\n",
    "        \n",
    "        dec_in = pad_sequence(dec_in_no_pad, batch_first=self.batch_first,\n",
    "                                        padding_value=self.word_pad_idx)\n",
    "        \n",
    "        word_pad_mask = dec_in == self.word_pad_idx\n",
    "        if not self.batch_first:\n",
    "            word_pad_mask = word_pad_mask.T  # word_pad_mask is always batch first\n",
    "\n",
    "        encoder_in_el = encoder_in[0] if is_encoder_input_tuple else encoder_in\n",
    "        max_curve_len = encoder_in_el.shape[1] if self.batch_first else encoder_in_el.shape[0]\n",
    "        encoder_in_no_pad_el = encoder_in_no_pad[0] if is_encoder_input_tuple else encoder_in_no_pad\n",
    "        encoder_lens = torch.tensor([len(x) for x in encoder_in_no_pad_el])\n",
    "\n",
    "        # Берем матрицу c len(encoder_lens) строками вида\n",
    "        # [0, 1, ... , max_curve_len - 1].  Каждый элемент i-ой строки\n",
    "        # сравниваем с длиной i-ой траектории.  Получится матрица, где True\n",
    "        # только на позициях, больших, чем длина соответствующей траектории.\n",
    "        # (batch_size, max_curve_len)\n",
    "        encoder_pad_mask = torch.arange(max_curve_len).expand(\n",
    "            len(encoder_lens), max_curve_len) >= encoder_lens.unsqueeze(1)\n",
    "        \n",
    "        transformer_in = (encoder_in, dec_in, encoder_pad_mask, word_pad_mask)\n",
    "        \n",
    "        return transformer_in, dec_out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CollateFnV3:\n",
    "    def __init__(self, batch_first: bool, word_pad_idx: int, swipe_pad_idx: int = 0) -> None:\n",
    "        self.word_pad_idx = word_pad_idx\n",
    "        self.batch_first = batch_first\n",
    "        self.swipe_pad_idx = swipe_pad_idx\n",
    "\n",
    "    def _assert_encoder_in_type_and_shape(self, encoder_in_example):\n",
    "        assert len(encoder_in_example) == 2\n",
    "        for el in encoder_in_example:\n",
    "            assert isinstance(el, torch.Tensor), f\"Expected torch.Tensor, got {type(el)}\"\n",
    "        \n",
    "    def _is_encoder_input_tuple(self, batch):\n",
    "        encoder_in_example = batch[0][0][0]\n",
    "        if isinstance(encoder_in_example, tuple):\n",
    "            self._assert_encoder_in_type_and_shape(encoder_in_example)\n",
    "            return True\n",
    "        elif isinstance(encoder_in_example, torch.Tensor):\n",
    "            return False\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown type of encoder input {type(batch[0][0])}\")\n",
    "    \n",
    "    def __call__(self, batch: list):\n",
    "        \"\"\"\n",
    "        Given a List where each row is \n",
    "        ((encoder_in_sample, decoder_in_sample), decoder_out_sample) \n",
    "        returns a tuple of two elements:\n",
    "        1. (encoder_in, decoder_in, swipe_pad_mask, word_pad_mask)\n",
    "        2. decoder_out\n",
    "\n",
    "        Arguments:\n",
    "        ----------\n",
    "        batch: list of tuples:\n",
    "            ((encoder_in, dec_in_char_seq), dec_out_char_seq),\n",
    "            where encoder_in may be a tuple of torch tensors\n",
    "            (ex. ```(traj_feats, nearest_kb_tokens)```)\n",
    "            or a single tensor (ex. ```nearest_kb_tokens```)\n",
    "\n",
    "\n",
    "        Returns:\n",
    "        --------\n",
    "        transformer_in: tuple of torch tensors:\n",
    "            1. (enc_in, dec_in, swipe_pad_mask, word_pad_mask),\n",
    "                where enc_in can be either a single tensor or a tuple\n",
    "                of two tensors (depends on type of input)\n",
    "                Each element is a torch tensor of shape:\n",
    "                - enc_in: either (curve_len, batch_size, n_feats) or\n",
    "                    ((curve_len, batch_size, n_feats1), (curve_len, batch_size, n_feats2))\n",
    "                - dec_in: (chars_seq_len - 1, batch_size)\n",
    "                - swipe_pad_mask: (batch_size, curve_len)\n",
    "                - word_pad_mask: (batch_size, chars_seq_len - 1, )\n",
    "        \"\"\"\n",
    "        is_encoder_input_tuple = self._is_encoder_input_tuple(batch)\n",
    "\n",
    "        encoder_in_samples, dec_in_samples, dec_out_samples = zip(*((x_smpl[0], x_smpl[1], decoder_out_smpl) for x_smpl, decoder_out_smpl in batch))\n",
    "\n",
    "        if is_encoder_input_tuple:\n",
    "            encoder_in_samples_0, encoder_in_samples_1 = zip(*encoder_in_samples)\n",
    "            encoder_in_no_pad = (\n",
    "                list(encoder_in_samples_0),\n",
    "                list(encoder_in_samples_1)\n",
    "            )\n",
    "        else:\n",
    "            encoder_in_no_pad = encoder_in_samples\n",
    "\n",
    "        encoder_in = (\n",
    "            tuple(\n",
    "                pad_sequence(enc_in_no_pad_i, batch_first=self.batch_first, padding_value=self.swipe_pad_idx)\n",
    "                for enc_in_no_pad_i in encoder_in_no_pad\n",
    "            )\n",
    "            if is_encoder_input_tuple else\n",
    "            pad_sequence(encoder_in_no_pad, batch_first=self.batch_first, padding_value=self.swipe_pad_idx)\n",
    "        )\n",
    "\n",
    "        dec_in = pad_sequence(list(dec_in_samples), batch_first=self.batch_first, padding_value=self.word_pad_idx)\n",
    "        dec_out = pad_sequence(list(dec_out_samples), batch_first=self.batch_first, padding_value=self.word_pad_idx)\n",
    "\n",
    "        word_pad_mask = dec_in == self.word_pad_idx\n",
    "        if not self.batch_first:\n",
    "            word_pad_mask = word_pad_mask.T  # word_pad_mask is always batch first\n",
    "\n",
    "        encoder_in_el = encoder_in[0] if is_encoder_input_tuple else encoder_in\n",
    "        max_curve_len = encoder_in_el.shape[1] if self.batch_first else encoder_in_el.shape[0]\n",
    "        encoder_in_no_pad_el = encoder_in_no_pad[0] if is_encoder_input_tuple else encoder_in_no_pad\n",
    "        encoder_lens = torch.tensor([len(x) for x in encoder_in_no_pad_el])\n",
    "\n",
    "        # Берем матрицу c len(encoder_lens) строками вида\n",
    "        # [0, 1, ... , max_curve_len - 1].  Каждый элемент i-ой строки\n",
    "        # сравниваем с длиной i-ой траектории.  Получится матрица, где True\n",
    "        # только на позициях, больших, чем длина соответствующей траектории.\n",
    "        # (batch_size, max_curve_len)\n",
    "        encoder_pad_mask = torch.arange(max_curve_len).expand(\n",
    "            len(encoder_lens), max_curve_len) >= encoder_lens.unsqueeze(1)\n",
    "                \n",
    "        transformer_in = (encoder_in, dec_in, encoder_pad_mask, word_pad_mask)\n",
    "        \n",
    "        return transformer_in, dec_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_batch(is_encoder_in_tuple: bool,\n",
    "                   batch_size = 7,\n",
    "                    min_swipe_len = 8,\n",
    "                    max_swipe_len = 16,\n",
    "                    min_word_len = 1,\n",
    "                    max_word_len = 10) -> list:\n",
    "    \n",
    "    swipe_lens = torch.randint(min_swipe_len, max_swipe_len, (batch_size,))\n",
    "    word_lens = torch.randint(min_word_len, max_word_len, (batch_size,))\n",
    "\n",
    "\n",
    "    batch = []\n",
    "    for i in range(batch_size):\n",
    "        if is_encoder_in_tuple:\n",
    "            encoder_in = tuple(torch.tensor(range(swipe_lens[i])) for _ in range (2))\n",
    "        else:\n",
    "            encoder_in = torch.tensor(range(swipe_lens))\n",
    "        decoder_in, decoder_out = [torch.tensor(range(word_lens[i])) for _ in range(2)]\n",
    "\n",
    "        batch.append(((encoder_in, decoder_in), decoder_out))\n",
    "\n",
    "    return batch\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CollateFnV4:\n",
    "    def __init__(self, batch_first: bool, word_pad_idx: int, \n",
    "                 swipe_pad_idx: int = 0) -> None:\n",
    "        self.word_pad_idx = word_pad_idx\n",
    "        self.batch_first = batch_first\n",
    "        self.swipe_pad_idx = swipe_pad_idx\n",
    "\n",
    "    def _assert_encoder_in_type_and_shape(self, encoder_in_example):\n",
    "        assert len(encoder_in_example) == 2\n",
    "        for el in encoder_in_example:\n",
    "            assert isinstance(el, torch.Tensor), \\\n",
    "                f\"Expected torch.Tensor, got {type(el)}\"\n",
    "        \n",
    "    def _is_encoder_input_tuple(self, batch):\n",
    "        encoder_in_example = batch[0][0][0]\n",
    "        if isinstance(encoder_in_example, tuple):\n",
    "            self._assert_encoder_in_type_and_shape(encoder_in_example)\n",
    "            return True\n",
    "        elif isinstance(encoder_in_example, torch.Tensor):\n",
    "            return False\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown type of encoder input {type(batch[0][0])}\")\n",
    "    \n",
    "    def __call__(self, batch: list):\n",
    "        \"\"\"\n",
    "        Given a List where each row is \n",
    "        ((encoder_in_sample, decoder_in_sample), decoder_out_sample) \n",
    "        returns a tuple of two elements:\n",
    "        1. (encoder_in, decoder_in, swipe_pad_mask, word_pad_mask)\n",
    "        2. decoder_out\n",
    "\n",
    "        Arguments:\n",
    "        ----------\n",
    "        batch: list of tuples:\n",
    "            ((encoder_in, dec_in_char_seq), dec_out_char_seq),\n",
    "            where encoder_in may be a tuple of torch tensors\n",
    "            (ex. ```(traj_feats, nearest_kb_tokens)```)\n",
    "            or a single tensor (ex. ```nearest_kb_tokens```)\n",
    "\n",
    "\n",
    "        Returns:\n",
    "        --------\n",
    "        transformer_in: tuple of torch tensors:\n",
    "            1. (enc_in, dec_in, swipe_pad_mask, word_pad_mask),\n",
    "                where enc_in can be either a single tensor or a tuple\n",
    "                of two tensors (depends on type of input)\n",
    "                Each element is a torch tensor of shape:\n",
    "                - enc_in: either (curve_len, batch_size, n_feats) or\n",
    "                    ((curve_len, batch_size, n_feats1), (curve_len, batch_size, n_feats2))\n",
    "                - dec_in: (chars_seq_len - 1, batch_size)\n",
    "                - swipe_pad_mask: (batch_size, curve_len)\n",
    "                - word_pad_mask: (batch_size, chars_seq_len - 1, )\n",
    "        \"\"\"\n",
    "        is_encoder_input_tuple = self._is_encoder_input_tuple(batch)\n",
    "        dec_in_no_pad = []\n",
    "        dec_out_no_pad = []\n",
    "\n",
    "        encoder_in_no_pad = ([], []) if is_encoder_input_tuple else ([],)\n",
    "\n",
    "        for row in batch:\n",
    "            x_smpl, decoder_out_smpl = row\n",
    "            encoder_in_smpl, decoder_in_smpl = x_smpl\n",
    "            if isinstance(encoder_in_smpl, torch.Tensor):\n",
    "                encoder_in_smpl = (encoder_in_smpl,)\n",
    "            # assert isinstance(encoder_in_smpl, tuple)\n",
    "            for enc_in_smlp_i, enc_in_no_pad_i in zip(encoder_in_smpl, encoder_in_no_pad):\n",
    "                enc_in_no_pad_i.append(enc_in_smlp_i)\n",
    "\n",
    "            dec_in_no_pad.append(decoder_in_smpl)\n",
    "            dec_out_no_pad.append(decoder_out_smpl)\n",
    "\n",
    "        encoder_in = tuple(pad_sequence(encoder_in_no_pad_i, batch_first=self.batch_first, \n",
    "                                    padding_value=self.swipe_pad_idx)\n",
    "                        for encoder_in_no_pad_i in encoder_in_no_pad)\n",
    "        if len(encoder_in) == 1:\n",
    "            encoder_in = encoder_in[0]\n",
    "\n",
    "        dec_out = pad_sequence(dec_out_no_pad, batch_first=self.batch_first,\n",
    "                                        padding_value=self.word_pad_idx)\n",
    "        \n",
    "        dec_in = pad_sequence(dec_in_no_pad, batch_first=self.batch_first,\n",
    "                                        padding_value=self.word_pad_idx)\n",
    "        \n",
    "        word_pad_mask = dec_in == self.word_pad_idx\n",
    "        if not self.batch_first:\n",
    "            word_pad_mask = word_pad_mask.T  # word_pad_mask is always batch first\n",
    "\n",
    "        encoder_in_el = encoder_in[0] if is_encoder_input_tuple else encoder_in\n",
    "        max_curve_len = encoder_in_el.shape[1] if self.batch_first else encoder_in_el.shape[0]\n",
    "        encoder_in_no_pad_el = encoder_in_no_pad[0] if is_encoder_input_tuple else encoder_in_no_pad\n",
    "        encoder_lens = torch.tensor([len(x) for x in encoder_in_no_pad_el])\n",
    "\n",
    "        # Берем матрицу c len(encoder_lens) строками вида\n",
    "        # [0, 1, ... , max_curve_len - 1].  Каждый элемент i-ой строки\n",
    "        # сравниваем с длиной i-ой траектории.  Получится матрица, где True\n",
    "        # только на позициях, больших, чем длина соответствующей траектории.\n",
    "        # (batch_size, max_curve_len)\n",
    "        encoder_pad_mask = torch.arange(max_curve_len).expand(\n",
    "            len(encoder_lens), max_curve_len) >= encoder_lens.unsqueeze(1)\n",
    "        \n",
    "        transformer_in = (encoder_in, dec_in, encoder_pad_mask, word_pad_mask)\n",
    "        \n",
    "        return transformer_in, dec_out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12]), tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12]))\n",
      "tensor([0, 1, 2, 3, 4, 5, 6, 7])\n",
      "tensor([0, 1, 2, 3, 4, 5, 6, 7])\n"
     ]
    }
   ],
   "source": [
    "batch = generate_batch(True)\n",
    "(encoder_in, decoder_in), decoder_out = batch[0]\n",
    "\n",
    "print(encoder_in, decoder_in, decoder_out, sep='\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "isinstance(encoder_in[0], torch.Tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "collate_fn = CollateFnV2(batch_first=False, word_pad_idx=-1, swipe_pad_idx = -1)\n",
    "\n",
    "(encoder_in, dec_in, encoder_pad_mask, word_pad_mask), dec_out =  collate_fn(batch)\n",
    "\n",
    "assert torch.equal(encoder_in[0]==-1 , encoder_pad_mask.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "collate_fn = CollateFnV2(batch_first=True, word_pad_idx=-1, swipe_pad_idx = -1)\n",
    "\n",
    "(encoder_in, dec_in, encoder_pad_mask, word_pad_mask), dec_out =  collate_fn(batch)\n",
    "\n",
    "assert torch.equal(encoder_in[0]==-1 , encoder_pad_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "collate_fn = CollateFnV3(batch_first=False, word_pad_idx=-1, swipe_pad_idx = -1)\n",
    "\n",
    "(encoder_in, dec_in, encoder_pad_mask, word_pad_mask), dec_out =  collate_fn(batch)\n",
    "\n",
    "assert torch.equal(encoder_in[0]==-1 , encoder_pad_mask.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "collate_fn = CollateFnV3(batch_first=True, word_pad_idx=-1, swipe_pad_idx = -1)\n",
    "\n",
    "(encoder_in, dec_in, encoder_pad_mask, word_pad_mask), dec_out =  collate_fn(batch)\n",
    "\n",
    "assert torch.equal(encoder_in[0]==-1 , encoder_pad_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "collate_fn = CollateFnV4(batch_first=False, word_pad_idx=-1, swipe_pad_idx = -1)\n",
    "\n",
    "(encoder_in, dec_in, encoder_pad_mask, word_pad_mask), dec_out =  collate_fn(batch)\n",
    "\n",
    "assert torch.equal(encoder_in[0]==-1 , encoder_pad_mask.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "collate_fn = CollateFnV4(batch_first=True, word_pad_idx=-1, swipe_pad_idx = -1)\n",
    "\n",
    "(encoder_in, dec_in, encoder_pad_mask, word_pad_mask), dec_out =  collate_fn(batch)\n",
    "\n",
    "assert torch.equal(encoder_in[0]==-1 , encoder_pad_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "630 µs ± 87.1 µs per loop (mean ± std. dev. of 3 runs, 10,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -r 3 -n 10000\n",
    "\n",
    "collate_fn = CollateFnV4(batch_first=True, word_pad_idx=-1, swipe_pad_idx = -1)\n",
    "\n",
    "(encoder_in, dec_in, encoder_pad_mask, word_pad_mask), dec_out =  collate_fn(batch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "527 µs ± 26.3 µs per loop (mean ± std. dev. of 3 runs, 10,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -r 3 -n 10000\n",
    "collate_fn = CollateFnV3(batch_first=True, word_pad_idx=-1, swipe_pad_idx = -1)\n",
    "\n",
    "(encoder_in, dec_in, encoder_pad_mask, word_pad_mask), dec_out =  collate_fn(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "510 µs ± 2.58 µs per loop (mean ± std. dev. of 3 runs, 10,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -r 3 -n 10000\n",
    "\n",
    "collate_fn = CollateFnV2(batch_first=True, word_pad_idx=-1, swipe_pad_idx = -1)\n",
    "\n",
    "(encoder_in, dec_in, encoder_pad_mask, word_pad_mask), dec_out =  collate_fn(batch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "538 µs ± 11.2 µs per loop (mean ± std. dev. of 3 runs, 10,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -r 3 -n 10000\n",
    "\n",
    "collate_fn = CollateFnV4(batch_first=False, word_pad_idx=-1, swipe_pad_idx = -1)\n",
    "\n",
    "(encoder_in, dec_in, encoder_pad_mask, word_pad_mask), dec_out =  collate_fn(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "533 µs ± 11.5 µs per loop (mean ± std. dev. of 3 runs, 10,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -r 3 -n 10000\n",
    "collate_fn = CollateFnV3(batch_first=False, word_pad_idx=-1, swipe_pad_idx = -1)\n",
    "\n",
    "(encoder_in, dec_in, encoder_pad_mask, word_pad_mask), dec_out =  collate_fn(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "554 µs ± 53 µs per loop (mean ± std. dev. of 3 runs, 10,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -r 3 -n 10000\n",
    "collate_fn = CollateFnV2(batch_first=False, word_pad_idx=-1, swipe_pad_idx = -1)\n",
    "\n",
    "(encoder_in, dec_in, encoder_pad_mask, word_pad_mask), dec_out =  collate_fn(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "555 µs ± 21 µs per loop (mean ± std. dev. of 3 runs, 10,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -r 3 -n 10000\n",
    "collate_fn = CollateFnV2(batch_first=False, word_pad_idx=-1, swipe_pad_idx = -1)\n",
    "\n",
    "(encoder_in, dec_in, encoder_pad_mask, word_pad_mask), dec_out =  collate_fn(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'word_char_tokenizer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[83], line 6\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Протестируем корректность collate_fn (вызывается неявно в DataLoader)\u001b[39;00m\n\u001b[0;32m      3\u001b[0m batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m6\u001b[39m\n\u001b[1;32m----> 6\u001b[0m PAD_CHAR_TOKEN \u001b[38;5;241m=\u001b[39m \u001b[43mword_char_tokenizer\u001b[49m\u001b[38;5;241m.\u001b[39mchar_to_idx[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m<pad>\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m      9\u001b[0m train_dataloader \u001b[38;5;241m=\u001b[39m DataLoader(train_dataset, batch_size\u001b[38;5;241m=\u001b[39mbatch_size, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m     10\u001b[0m                               num_workers\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, collate_fn\u001b[38;5;241m=\u001b[39mcollate_fn)\n\u001b[0;32m     13\u001b[0m dataset_els \u001b[38;5;241m=\u001b[39m [train_dataset[i] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(batch_size)]\n",
      "\u001b[1;31mNameError\u001b[0m: name 'word_char_tokenizer' is not defined"
     ]
    }
   ],
   "source": [
    "# Протестируем корректность collate_fn (вызывается неявно в DataLoader)\n",
    "\n",
    "batch_size = 6\n",
    "\n",
    "\n",
    "PAD_CHAR_TOKEN = word_char_tokenizer.char_to_idx[\"<pad>\"]\n",
    "\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=False,\n",
    "                              num_workers=0, collate_fn=collate_fn)\n",
    "\n",
    "\n",
    "dataset_els = [train_dataset[i] for i in range(batch_size)]\n",
    "unproc_batch_x, unproc_batch_y = zip(*dataset_els)\n",
    "\n",
    "batch_x, batch_y = next(iter(train_dataloader))\n",
    "\n",
    "\n",
    "############### Проверка корректности batch_y ###################\n",
    "max_out_seq_len = max([len(y) for y in unproc_batch_y])\n",
    "\n",
    "assert batch_y.shape == (max_out_seq_len, batch_size)\n",
    "\n",
    "\n",
    "for i in range(batch_size):\n",
    "    assert (batch_y[:len(unproc_batch_y[i]), i] == unproc_batch_y[i]).all()\n",
    "    assert (batch_y[len(unproc_batch_y[i]):, i] == PAD_CHAR_TOKEN).all()\n",
    "\n",
    "print(\"batch_y is correct\")\n",
    "\n",
    "\n",
    "\n",
    "############### Проверка корректности batch_x ###################\n",
    "unproc_batch_traj_feats, unproc_batch_kb_tokens, unproc_batch_dec_in_char_seq = zip(*unproc_batch_x)\n",
    "\n",
    "(traj_feats, kb_tokens, dec_in_char_seq, traj_pad_mask, word_pad_mask) = batch_x\n",
    "\n",
    "\n",
    "# каждая сущность, полученная выше из unpoc_batch_x - это tuple длины batch_size.\n",
    "# Например, unproc_batch_traj_feats[i] = train_dataset[i][0][0]\n",
    "\n",
    "N_TRAJ_FEATS = 6\n",
    "max_curve_len = max([el.shape[0] for el in unproc_batch_traj_feats]) \n",
    "\n",
    "assert max_curve_len == max([el.shape[0] for el in unproc_batch_kb_tokens])\n",
    "\n",
    "assert traj_feats.shape == (max_curve_len, batch_size, N_TRAJ_FEATS)\n",
    "assert kb_tokens.shape == (max_curve_len, batch_size)\n",
    "assert dec_in_char_seq.shape == (max_out_seq_len, batch_size)\n",
    "assert traj_pad_mask.shape == (batch_size, max_curve_len)\n",
    "assert word_pad_mask.shape == (batch_size, max_out_seq_len)\n",
    "\n",
    "\n",
    "for i in range(batch_size):\n",
    "    assert (traj_feats[:len(unproc_batch_traj_feats[i]), i] == unproc_batch_traj_feats[i]).all()\n",
    "    assert (kb_tokens[:len(unproc_batch_kb_tokens[i]), i] == unproc_batch_kb_tokens[i]).all()\n",
    "\n",
    "    assert (dec_in_char_seq[:len(unproc_batch_dec_in_char_seq[i]), i] == unproc_batch_dec_in_char_seq[i]).all()\n",
    "    assert (dec_in_char_seq[len(unproc_batch_dec_in_char_seq[i]):, i] == PAD_CHAR_TOKEN).all()\n",
    "\n",
    "    assert (traj_pad_mask[i, :len(unproc_batch_traj_feats[i])] == False).all()\n",
    "    assert (traj_pad_mask[i, len(unproc_batch_traj_feats[i]):] == True).all()\n",
    "    \n",
    "    assert (word_pad_mask[i, :len(unproc_batch_dec_in_char_seq[i])] == False).all()\n",
    "    assert (word_pad_mask[i, len(unproc_batch_dec_in_char_seq[i]):] == True).all()\n",
    "\n",
    "print(\"batch_x is correct\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
