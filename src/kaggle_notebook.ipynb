{"cells":[{"cell_type":"markdown","metadata":{},"source":["Я вижу два решения:\n","\n","Для простоты я бы сделал 2 класса датасета\n","Если нужно кодировать лишь последовательность букв, он и хранит последовательности букв сразу и не хранит коордианты\n","\n","В обоих случаях декодер оперирует эмбеддингами букв текста\n","\n","<h3>1. На вход энкодера x, y, t, dx/dt, dy/st, x'', y'', keybard_key_embedding</h3>\n","\n","**Что делать, если ближайшая клавиша неалфавитная (пунктуация, клавиши-действия)?**\n","\n","Добавлю для всех неалфавитных клавиш один специальный токен. Хотя, возможно,\n","лучше добавить отдельный токен для каждой клавиши. Кажется, в кавиатуре схожесть\n","клавиш определяется тем, насколько часто они встречаются рядом друг с другом.\n","Тогда может быть важно отличать enter, который близок к бкве `э`, например,\n","от `caps lock`, который близок к `ф`. Отмечу, что схожесть в данном случае - это\n","не просто физическое расстояние между клавишами (хотя отчасти и так), но скорее, похожесть\n","клавиш `a` и `b` означает, что для последовательностей вида `letter1`, `letter2` ... `letterX`, `letterN`\n","если вероятность, что `letterX` = `a` велика, то вероятность, что `letterX` = `b` тоже велика.\n","\n","\n","**Где происходит инициализация токенизатора?**\n","я бы вынес токенезатор вне датасета и передавал бы его в конструктор датасета.\n","\n","\n","для каждой раскладки свои instance'ы датасета и модели.\n","\n","\n","\n","<h3> 2. На вход энкодера последовательность клавиш клавиатуры </h3>\n","\n","Если ближайшая клавиша неалфавитная **пропускать**\n","\n","**Где происходит инициализация токенизатора?**\n","\n","\n","один instance датасета и одна модель для всех раскладок.\n"]},{"cell_type":"markdown","metadata":{},"source":[]},{"cell_type":"markdown","metadata":{},"source":["Реализовывать ли для каждого варианта отдельный токенизатор:\n","\n","У нас может быть различное количество токенов: в некотоорых раскладках отсутствует символ \"ъ\", например\n","\n","Когда датасет содержит лишь одну раскладку, токенизатор должен учесть символы из одной раскладки. Когда датасет содержит несколько раскладок, токенизатор должен учесть символы из всех раскладок.\n","\n","Кажется, что варьируется только наличие 'ъ' и 'ё'. Во-первых, не ясно нужны ли эти символы. Есть желание заменять 'ё' на 'е', а 'ъ' на 'ь'. "]},{"cell_type":"markdown","metadata":{},"source":[]},{"cell_type":"markdown","metadata":{},"source":["Кажется, нас совершенно устраивает токенизатор, содержащий все буквы русского языка, включая 'ё' и 'ъ'. Наличие пары лишних токенов незначительно увеличит размер эмбеддинг-матрицы, но не повлияет на обучение модели."]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2023-11-01T19:48:33.678825Z","iopub.status.busy":"2023-11-01T19:48:33.678295Z","iopub.status.idle":"2023-11-01T19:48:33.684426Z","shell.execute_reply":"2023-11-01T19:48:33.683359Z","shell.execute_reply.started":"2023-11-01T19:48:33.678792Z"},"trusted":true},"outputs":[],"source":["import os\n","\n","import torch\n","import torch.nn as nn\n","from torch.utils.data import Dataset, DataLoader, IterableDataset\n","\n","# from model import SwipeCurveEncoderTransformer"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2023-11-01T19:48:35.951358Z","iopub.status.busy":"2023-11-01T19:48:35.950535Z","iopub.status.idle":"2023-11-01T19:48:35.955869Z","shell.execute_reply":"2023-11-01T19:48:35.954642Z","shell.execute_reply.started":"2023-11-01T19:48:35.951322Z"},"trusted":true},"outputs":[],"source":["data_root = \"/kaggle/input/neuroswipe-defualt-only-v1\""]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2023-11-01T20:09:37.662729Z","iopub.status.busy":"2023-11-01T20:09:37.662403Z","iopub.status.idle":"2023-11-01T20:09:37.668337Z","shell.execute_reply":"2023-11-01T20:09:37.667221Z","shell.execute_reply.started":"2023-11-01T20:09:37.662701Z"},"trusted":true},"outputs":[],"source":["def init_random_seed(value=42):\n","    # random.seed(value)\n","    np.random.seed(value)\n","    torch.manual_seed(value)\n","    torch.cuda.manual_seed(value)\n","    # torch.backends.cudnn.deterministic = True"]},{"cell_type":"code","execution_count":13,"metadata":{"execution":{"iopub.execute_input":"2023-11-01T20:09:37.672479Z","iopub.status.busy":"2023-11-01T20:09:37.672105Z","iopub.status.idle":"2023-11-01T20:09:37.684604Z","shell.execute_reply":"2023-11-01T20:09:37.683603Z","shell.execute_reply.started":"2023-11-01T20:09:37.672436Z"},"trusted":true},"outputs":[],"source":["init_random_seed()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2023-11-01T19:48:45.055028Z","iopub.status.busy":"2023-11-01T19:48:45.054626Z","iopub.status.idle":"2023-11-01T19:48:45.071412Z","shell.execute_reply":"2023-11-01T19:48:45.070241Z","shell.execute_reply.started":"2023-11-01T19:48:45.054995Z"},"trusted":true},"outputs":[],"source":["from typing import List, Optional\n","\n","class CharLevelTokenizerv1:\n","    \"\"\"\n","    Tokenizes a word into a list of integers.\n","\n","    Toknized word is padded to the max_word_len.\n","\n","    Guarantees that <sos> and <pad> are tokens with `vocab_len - 1`\n","    and `vocab_len - 2` indices respectively.\n","    This is useful because model never generates <sos> and <pad> tokens.\n","    \"\"\"\n","    def __init__(self, vocab_path):\n","        self.char_to_idx = {}\n","        self.idx_to_char = {}\n","        self.max_word_len = None  # is set in _build_vocab\n","        self._build_vocab(vocab_path)\n","\n","    def _build_vocab(self, vocab_path):\n","        self.max_word_len = 0\n","        special_tokens = [\"<eos>\", \"<pad>\", \"<unk>\", \"<sos>\"]\n","        unique_chars = set()\n","\n","        with open(vocab_path, \"r\", encoding=\"utf-8\") as f:\n","            vocab = f.read().split(\"\\n\")\n","            for word in vocab:\n","                self.max_word_len = max(self.max_word_len, len(word) + 2)  # + <sos> and <eos>\n","                for char in word:\n","                    unique_chars.add(char)\n","                    \n","        unique_chars_list = sorted(list(unique_chars)) + special_tokens\n","        self.char_to_idx = {char: idx for idx, char in enumerate(unique_chars_list)}\n","        self.idx_to_char = {idx: char for idx, char in enumerate(unique_chars_list)}\n","\n","    def _tokenize_word(self, word):\n","        \"\"\"\n","        Tokenizes a word into a list of integers.\n","        \"\"\"\n","        tokenized_word = []\n","        tokenized_word.append(self.char_to_idx[\"<sos>\"])\n","        for char in word:\n","            default: int = self.char_to_idx['<unk>']\n","            tokenized_word.append(self.char_to_idx.get(char, default))\n","        tokenized_word.append(self.char_to_idx[\"<eos>\"])\n","        return tokenized_word\n","    \n","    def _pad(self, tokenized_word):\n","        \"\"\"\n","        Pads a word to the max_word_len.\n","        \"\"\"\n","        return tokenized_word + [self.char_to_idx[\"<pad>\"]] * (self.max_word_len - len(tokenized_word))\n","    \n","    def tokenize(self, word):\n","        \"\"\"\n","        Tokenizes a word and pads it to the max_word_len.\n","        \"\"\"\n","        token_seq = torch.tensor(self._pad(self._tokenize_word(word)))\n","        mask = torch.ones(self.max_word_len, dtype=torch.bool)\n","        mask[:len(word)+2] = False\n","        return token_seq, mask\n","    \n","    def decode(self, token_seq):\n","        \"\"\"\n","        Decodes a tokenized word into a string.\n","        \"\"\"\n","        return \"\".join([self.idx_to_char[int(idx)] for idx in token_seq])"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2023-11-01T19:48:51.331203Z","iopub.status.busy":"2023-11-01T19:48:51.330772Z","iopub.status.idle":"2023-11-01T19:48:52.515628Z","shell.execute_reply":"2023-11-01T19:48:52.514653Z","shell.execute_reply.started":"2023-11-01T19:48:51.331153Z"},"trusted":true},"outputs":[],"source":["import pickle\n","\n","word_char_tokenizer = CharLevelTokenizerv1(os.path.join(data_root, \"voc.txt\"))\n","\n","# word_char_tokenizer_save_path = \"../data/data_separated_grid/word_char_tokenizer.pkl\"\n","\n","# with open(word_char_tokenizer_save_path, 'wb') as f:\n","#     pickle.dump(word_char_tokenizer, f, protocol=pickle.HIGHEST_PROTOCOL)\n","\n","# with open(word_char_tokenizer_save_path, 'rb') as f:\n","#     word_char_tokenizer = pickle.load(f)"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2023-11-01T19:48:53.490556Z","iopub.status.busy":"2023-11-01T19:48:53.490146Z","iopub.status.idle":"2023-11-01T19:48:53.496720Z","shell.execute_reply":"2023-11-01T19:48:53.495568Z","shell.execute_reply.started":"2023-11-01T19:48:53.490525Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["{0: '-', 1: 'а', 2: 'б', 3: 'в', 4: 'г', 5: 'д', 6: 'е', 7: 'ж', 8: 'з', 9: 'и', 10: 'й', 11: 'к', 12: 'л', 13: 'м', 14: 'н', 15: 'о', 16: 'п', 17: 'р', 18: 'с', 19: 'т', 20: 'у', 21: 'ф', 22: 'х', 23: 'ц', 24: 'ч', 25: 'ш', 26: 'щ', 27: 'ъ', 28: 'ы', 29: 'ь', 30: 'э', 31: 'ю', 32: 'я', 33: '<eos>', 34: '<pad>', 35: '<unk>', 36: '<sos>'}\n"]}],"source":["print(word_char_tokenizer.idx_to_char)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2023-11-01T19:48:55.231878Z","iopub.status.busy":"2023-11-01T19:48:55.231511Z","iopub.status.idle":"2023-11-01T19:48:55.238861Z","shell.execute_reply":"2023-11-01T19:48:55.237601Z","shell.execute_reply.started":"2023-11-01T19:48:55.231848Z"},"trusted":true},"outputs":[],"source":["class KeyboardTokenizerv1:\n","    \n","    i2t = ['а', 'б', 'в', 'г', 'д', 'е', 'ë', 'ж', 'з', 'и', 'й',\n","           'к', 'л', 'м', 'н', 'о', 'п', 'р', 'с', 'т', 'у', 'ф',\n","           'х', 'ц', 'ч', 'ш', 'щ', 'ъ', 'ы', 'ь', 'э', 'ю', 'я',\n","           '-', '<unk>', '<pad>']\n","    \n","    t2i = {t: i for i, t in enumerate(i2t)}\n","\n","    def get_token(self, char):\n","        return self.t2i.get(char, self.t2i['<unk>'])"]},{"cell_type":"code","execution_count":57,"metadata":{"execution":{"iopub.execute_input":"2023-11-01T21:12:42.211903Z","iopub.status.busy":"2023-11-01T21:12:42.211523Z","iopub.status.idle":"2023-11-01T21:12:42.253216Z","shell.execute_reply":"2023-11-01T21:12:42.252245Z","shell.execute_reply.started":"2023-11-01T21:12:42.211873Z"},"trusted":true},"outputs":[],"source":["import json\n","from typing import Optional, List, Tuple, Dict\n","import array\n","import numpy as np\n","\n","import torch\n","from torch.utils.data import Dataset\n","from tqdm import tqdm\n","\n","\n","class NeuroSwipeDatasetv1(Dataset):\n","    \"\"\"\n","    Dataset class for NeuroSwipe dataset.\n","    The dataset file weights over 3 GB and contains over 6 million swipe gestures.\n","    \"\"\"\n","\n","    def __init__(self,\n","                 data_path: str,\n","                 grid: dict,\n","                 kb_tokenizer: KeyboardTokenizerv1,\n","                 max_traj_len: int,\n","                 word_char_tokenizer: CharLevelTokenizerv1,  # should contain max word len\n","                 include_time: bool = True,\n","                 include_velocities: bool = True,\n","                 include_accelerations: bool = True,\n","                 total: Optional[int] = None):\n","        \"\"\"\n","        Argsuments:\n","        -----------\n","        data_path (string): Path to the NeuroSwipe dataset in JSON format.\n","            A custom version of the dataset is used:\n","            \"grid\" property is replaced with \"grid_name\" property.\n","        \"\"\"\n","        if include_accelerations and not include_velocities:\n","\n","            raise ValueError(\"Accelerations are supposed \\\n","                             to be an addition to velocities. Add velocities.\")\n","\n","        self.max_traj_len = max_traj_len\n","        self.include_velocities = include_velocities\n","        self.include_accelerations = include_accelerations\n","        self.include_time = include_time\n","\n","        self.word_char_tokenizer = word_char_tokenizer\n","\n","        self.kb_width = grid['width']\n","        self.kb_height = grid['height']\n","\n","        self._coord_to_kb_label = self._get_coord_to_kb_label(grid)\n","\n","        self.data_list = []\n","        self._set_data(data_path, grid, kb_tokenizer, self.data_list, total = total)\n","    \n","\n","    def _get_key_center(self, hitbox: Dict[str, int]) -> Tuple[int, int]:\n","        x = hitbox['x'] + hitbox['w'] / 2\n","        y = hitbox['y'] + hitbox['h'] / 2\n","        return x, y\n","\n","    def _get_kb_label_without_map(self, x, y, grid: dict) -> str:\n","        nearest_kb_label = None\n","        min_dist = float(\"inf\")\n","        for key in grid['keys']:\n","            key_x, key_y = self._get_key_center(key['hitbox'])\n","            dist = (x - key_x)**2 + (y - key_y)**2\n","            if dist < min_dist:\n","                min_dist = dist\n","                if 'label' in key:\n","                    nearest_kb_label = key['label']\n","                elif 'action' in key:\n","                    nearest_kb_label = key['action']  # tokenizer will covert it to <unk>\n","                else:\n","                    raise ValueError(\"Key has no label or action\")\n","        return nearest_kb_label\n","\n","\n","    def _get_coord_to_kb_label(self, grid: dict) -> np.array:\n","        coord_to_kb_label = np.chararray((grid['width'], grid['height']), unicode=True) # 1080 x 640 in our case\n","        coord_to_kb_label.fill('')\n","\n","        for key in grid['keys']:\n","            x_left = key['hitbox']['x']\n","            x_right = x_left + key['hitbox']['w']\n","            y_top = key['hitbox']['y']\n","            y_bottom = y_top + key['hitbox']['h']\n","\n","            # tokenizer will covert actions to <unk>\n","            label = key['label'] if 'label' in key else key['action']\n","\n","            if len(label) > 1:\n","                print(f\"Warning: label '{label}' is substituted with {label[0]}\")\n","\n","            coord_to_kb_label[x_left:x_right, y_top:y_bottom] = label\n","\n","\n","        for x in range(grid['width']):\n","            for y in range(grid['height']):\n","                if coord_to_kb_label[x, y] != '':\n","                    continue\n","                        \n","                coord_to_kb_label[x, y] = self._get_kb_label_without_map(x, y, grid)\n","\n","        return coord_to_kb_label\n","    \n","    def coord_to_kb_label(self, x, y, grid: dict) -> str:\n","        if x < 0 or x >= self.kb_width or y < 0 or y >= self.kb_height:\n","            return self._get_kb_label_without_map(x, y, grid)\n","        else:\n","            return self._coord_to_kb_label[x, y]\n","            \n","\n","    def _set_data(self,\n","                  data_path: str,\n","                  kb_keys: str,\n","                  kb_tokenizer,\n","                  data_list: list,\n","                  total: Optional[int] = None):\n","        with open(data_path, \"r\", encoding=\"utf-8\") as json_file:\n","            for line in tqdm(json_file, total = total):\n","                data_list.append(self._get_data_from_json_line(line, kb_keys, kb_tokenizer))\n","\n","\n","    def _get_dx_dt(self,\n","                   X: torch.tensor,\n","                   T: torch.tensor,\n","                   len: int) -> List[float]:\n","        \"\"\"\n","        Calculates dx/dt for a list of x coordinates and a list of t coordinates.\n","\n","        Arguments:\n","        ----------\n","        X : torch.tensor\n","            x (position) coordinates.\n","        T : torch.tensor\n","            T[i] = time from the beginning of the swipe corresponding to X[i].\n","        len : int\n","            Length of the swipe trajectory. Indexes greater than len are ignored.\n","        \"\"\"\n","        dx_dt = torch.zeros_like(X)\n","        # dx_dt[1:-1] = (X[2:] - X[:-2]) / (T[2:] - T[:-2])\n","        dx_dt[1:len-1] = (X[2:len] - X[:len-2]) / (T[2:len] - T[:len-2])\n","\n","        # Example:\n","        # x0 x1 x2 x3\n","        # t0 t1 t2 t3\n","        # dx_dt[0] = 0\n","        # dx_dt[1] = (x2 - x0) / (t2 - t0)\n","        # dx_dt[2] = (x3 - x1) / (t3 - t1)\n","        # dx_dt[3] = 0\n","\n","\n","        # if True in torch.isnan(dx_dt):\n","        #     print(dx_dt)\n","        #     raise ValueError(\"dx_dt contains NaNs\")\n","\n","        return dx_dt\n","    \n","    def _get_data_from_json_line(self, line, grid, kb_tokenizer) -> Tuple[list, list, list, str]:\n","        \"\"\"\n","        Parses a JSON line and returns a dictionary with data.\n","        \"\"\"\n","        data = json.loads(line)\n","        word: str = data['word']\n","\n","        X = array.array('h', data['curve']['x'])\n","        Y = array.array('h', data['curve']['y'])\n","        T = array.array('h', data['curve']['t'])        \n","\n","        kb_labels = [self.coord_to_kb_label(x, y, grid) for x, y in zip(X, Y)]\n","        kb_tokens = [kb_tokenizer.get_token(label) for label in kb_labels]\n","        kb_tokens += [kb_tokenizer.get_token('<pad>')] * (self.max_traj_len - len(kb_labels))\n","        kb_tokens = array.array('h', kb_tokens)\n","\n","        return X, Y, T, word, kb_tokens\n","\n","    def __len__(self):\n","        return len(self.data_list)\n","    \n","    def __getitem__(self, idx):\n","        X_list, Y_list, T_list, word, kb_tokens = self.data_list[idx]\n","\n","        X = torch.zeros(self.max_traj_len, dtype=torch.float32)\n","        Y = torch.zeros(self.max_traj_len, dtype=torch.float32)\n","        T = torch.zeros(self.max_traj_len, dtype=torch.float32)\n","        \n","        X[:len(X_list)] = torch.tensor(X_list, dtype=torch.float32) / self.kb_width\n","        Y[:len(Y_list)] = torch.tensor(Y_list, dtype=torch.float32) / self.kb_height\n","        T[:len(T_list)] = torch.tensor(T_list, dtype=torch.float32)\n","\n","        xyt = torch.cat(\n","            (\n","                X.reshape(-1, 1),\n","                Y.reshape(-1, 1),\n","            ),\n","            axis = 1\n","        )\n","\n","        if self.include_time:\n","            xyt = torch.cat(\n","                (\n","                    xyt,\n","                    T.reshape(-1, 1)\n","                ),\n","                axis = 1\n","            )\n","\n","        traj_len = len(X_list)\n","\n","        if self.include_velocities:\n","            dx_dt = self._get_dx_dt(X, T, traj_len)\n","            dy_dt = self._get_dx_dt(Y, T, traj_len)\n","            xyt = torch.cat(\n","                [\n","                    xyt,\n","                    dx_dt.reshape(-1, 1),\n","                    dy_dt.reshape(-1, 1)\n","                ],\n","                axis = 1\n","            )\n","\n","        if self.include_accelerations:\n","            d2x_dt2 = self._get_dx_dt(dx_dt, T, traj_len)\n","            d2y_dt2 = self._get_dx_dt(dy_dt, T, traj_len)\n","            xyt = torch.cat(\n","                [\n","                    xyt,\n","                    d2x_dt2.reshape(-1, 1),\n","                    d2y_dt2.reshape(-1, 1)\n","                ],\n","                axis = 1\n","            )\n","\n","        traj_pad_mask = torch.ones(self.max_traj_len, dtype=torch.bool)\n","        traj_pad_mask[:len(X_list)] = False\n","\n","        char_seq, word_mask = self.word_char_tokenizer.tokenize(word)\n","        \n","        word_mask = word_mask[:-1]\n","\n","        decoder_in_char_seq = char_seq[:-1]\n","        decoder_out_char_seq = char_seq[1:]\n","\n","        kb_tokens = torch.tensor(kb_tokens, dtype=torch.int64)\n","    \n","        return (xyt, kb_tokens, decoder_in_char_seq, traj_pad_mask, word_mask), decoder_out_char_seq"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2023-11-01T19:48:58.319076Z","iopub.status.busy":"2023-11-01T19:48:58.318662Z","iopub.status.idle":"2023-11-01T19:48:58.324155Z","shell.execute_reply":"2023-11-01T19:48:58.323243Z","shell.execute_reply.started":"2023-11-01T19:48:58.319043Z"},"trusted":true},"outputs":[],"source":["def get_grid(grid_name: str, grids_path: str) -> dict:\n","    with open(grids_path, \"r\", encoding=\"utf-8\") as f:\n","        return json.load(f)[grid_name]"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2023-11-01T19:50:22.662149Z","iopub.status.busy":"2023-11-01T19:50:22.661358Z","iopub.status.idle":"2023-11-01T20:09:37.660522Z","shell.execute_reply":"2023-11-01T20:09:37.659329Z","shell.execute_reply.started":"2023-11-01T19:50:22.662116Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Warning: label 'shift' is substituted with s\n","Warning: label 'backspace' is substituted with b\n","Warning: label 'toNumberState' is substituted with t\n","Warning: label 'globe' is substituted with g\n","Warning: label 'space' is substituted with s\n","Warning: label 'enter' is substituted with e\n"]},{"name":"stderr","output_type":"stream","text":[" 87%|████████▋ | 5237584/6000000 [19:03<02:46, 4581.05it/s]  \n"]},{"name":"stdout","output_type":"stream","text":["Warning: label 'shift' is substituted with s\n","Warning: label 'backspace' is substituted with b\n","Warning: label 'toNumberState' is substituted with t\n","Warning: label 'globe' is substituted with g\n","Warning: label 'space' is substituted with s\n","Warning: label 'enter' is substituted with e\n"]},{"name":"stderr","output_type":"stream","text":[" 94%|█████████▍| 9416/10000 [00:02<00:00, 4615.10it/s]\n"]}],"source":["grid_path =  os.path.join(data_root, \"gridname_to_grid.json\")\n","grid_name = \"default\"\n","\n","grid = get_grid(grid_name, grid_path)\n","kb_tokenizer = KeyboardTokenizerv1()\n","word_char_tokenizer = CharLevelTokenizerv1(os.path.join(data_root, \"voc.txt\"))\n","\n","\n","train_path = os.path.join(data_root, \"train__default_only_no_errors__2023_10_31__03_26_16.jsonl\")\n","\n","train_dataset = NeuroSwipeDatasetv1(\n","    data_path = train_path,\n","    grid = grid,\n","    kb_tokenizer = kb_tokenizer,\n","    max_traj_len = 299,\n","    word_char_tokenizer = word_char_tokenizer,\n","    include_time = False,\n","    include_velocities = True,\n","    include_accelerations = True,\n","    total = 6_000_000\n",")\n","\n","\n","val_path = os.path.join(data_root, \"valid__in_train_format__default_only.jsonl\")\n","\n","val_dataset = NeuroSwipeDatasetv1(\n","    data_path = val_path,\n","    grid = grid,\n","    kb_tokenizer = kb_tokenizer,\n","    max_traj_len = 299,\n","    word_char_tokenizer = word_char_tokenizer,\n","    include_time = False,\n","    include_velocities = True,\n","    include_accelerations = True,\n","    total = 10_000\n",")"]},{"cell_type":"code","execution_count":14,"metadata":{"execution":{"iopub.execute_input":"2023-11-01T20:17:01.127119Z","iopub.status.busy":"2023-11-01T20:17:01.126682Z","iopub.status.idle":"2023-11-01T20:17:01.132331Z","shell.execute_reply":"2023-11-01T20:17:01.131165Z","shell.execute_reply.started":"2023-11-01T20:17:01.127084Z"},"trusted":true},"outputs":[],"source":["# full train dataset before adding nearest_kb_label:\n","# ----------------------------------\n","# 16.2GB RAM (when data stored as torch tensors)\n","# when stored as lists 17Gb is 61%\n","# when data stored as python arrays with dtype short: 4.8GB RAM\n","\n","\n","# Now:\n","# ----\n","# 9.3 Gb RAM"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":27,"metadata":{"execution":{"iopub.execute_input":"2023-11-01T20:38:06.496709Z","iopub.status.busy":"2023-11-01T20:38:06.496216Z","iopub.status.idle":"2023-11-01T20:38:06.538082Z","shell.execute_reply":"2023-11-01T20:38:06.536879Z","shell.execute_reply.started":"2023-11-01T20:38:06.496669Z"},"trusted":true},"outputs":[],"source":["from typing import Callable\n","import math\n","\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","\n","class SwipeCurveTransformerEncoderv1(nn.Module):\n","    \"\"\"\n","    Transformer-based Curve encoder takes in a sequence of vectors and creates a representation\n","    of a swipe gesture on a samrtphone keyboard.\n","    Each vector contains information about finger trajectory at a time step.\n","    It contains:\n","    * x coordinate\n","    * y coordinate\n","    * Optionally: t\n","    * Optionally: dx/dt\n","    * Optionally: dy/dt\n","    * Optionally: keyboard key that has x and y coordinates within its boundaries\n","    \"\"\"\n","\n","    def __init__(self,\n","                 input_size: int,\n","                 d_model: int,\n","                 dim_feedforward: int,\n","                 num_layers: int,\n","                 num_heads_first: int,\n","                 num_heads_other: int,\n","                 dropout: float = 0.1,\n","                 device = None):\n","        \"\"\"\n","        Arguments:\n","        ----------\n","        input_size: int\n","            Size of input vectors.\n","        d_model: int\n","            Size of the embeddings (output vectors).\n","            Should be equal to char embedding size of the decoder.\n","        dim_feedforward: int\n","        num_layers: int\n","            Number of encoder layers including the first layer.\n","\n","        \"\"\"\n","        super().__init__()\n","\n","        device = device or torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","        self.first_encoder_layer = nn.TransformerEncoderLayer(\n","            input_size, num_heads_first, dim_feedforward, dropout, device=device)\n","        self.liner = nn.Linear(input_size, d_model, device=device)  # to convert embedding to d_model size\n","        num_layer_after_first = num_layers - 1\n","        if num_layer_after_first > 0:\n","            encoder_layer = nn.TransformerEncoderLayer(\n","                d_model, num_heads_other, dim_feedforward, dropout, device=device)\n","            self.transformer_encoder = nn.TransformerEncoder(encoder_layer, num_layers)\n","        else:\n","            self.transformer_encoder = None\n","    \n","\n","    def forward(self, x, pad_mask: torch.tensor):\n","        x = self.first_encoder_layer(x, src_key_padding_mask=pad_mask)\n","        x = self.liner(x)\n","        if self.transformer_encoder:\n","            x = self.transformer_encoder(x, src_key_padding_mask=pad_mask)\n","        return x\n","\n","\n","\n","class SwipeCurveTransformerDecoderv1(nn.Module):\n","    \"\"\"\n","    Decodes a swipe gesture representation into a sequence of characters.\n","\n","    Uses decoder transformer with masked attention to prevent the model from cheating.\n","    \"\"\"\n","\n","    def __init__(self,\n","                 char_emb_size,\n","                 n_classes,\n","                 nhead,\n","                 num_decoder_layers,\n","                 dim_feedforward,\n","                 dropout,\n","                 activation = F.relu,\n","                 device = None):\n","        super().__init__()\n","\n","        device = device or torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","        self.decoder_layer = nn.TransformerDecoderLayer(\n","            char_emb_size, nhead, dim_feedforward, dropout, activation, device = device)\n","        self.transformer_decoder = nn.TransformerDecoder(self.decoder_layer, num_decoder_layers)\n","        self.out = nn.Linear(char_emb_size, n_classes, device = device)\n","        # self.softmax = nn.LogSoftmax(dim=2)\n","    \n","    def forward(self, x, memory, tgt_mask, memory_key_padding_mask, tgt_key_padding_mask):\n","        x = self.transformer_decoder(x,\n","                                     memory,\n","                                     tgt_mask=tgt_mask,\n","                                     memory_key_padding_mask=memory_key_padding_mask,\n","                                     tgt_key_padding_mask=tgt_key_padding_mask)\n","        x = self.out(x)\n","        # x = self.softmax(x)\n","        return x\n","\n","\n","class PositionalEncoding(nn.Module):\n","    def __init__(self, d_model: int, max_len: int, device, dropout: float = 0.0):\n","        super().__init__()\n","        self.dropout = nn.Dropout(p=dropout)\n","\n","        position = torch.arange(max_len).unsqueeze(1)\n","        div_term = torch.exp(torch.arange(0, d_model, 2) * (-math.log(10000.0) / d_model))\n","        pe = torch.zeros(max_len, 1, d_model)\n","        pe[:, 0, 0::2] = torch.sin(position * div_term)\n","        pe[:, 0, 1::2] = torch.cos(position * div_term)\n","        pe = pe.to(device=device)\n","        self.register_buffer('pe', pe)\n","\n","    def forward(self, x: torch.Tensor) -> torch.Tensor:\n","        \"\"\"\n","        Arguments:\n","        ----------\n","        x: Tensor, shape ``[seq_len, batch_size, embedding_dim]``\n","        \"\"\"\n","        x = x + self.pe[:x.size(0)]\n","        return self.dropout(x)\n","\n","\n","class SwipeCurveTransformer(nn.Module):\n","    \"\"\"\n","    Seq2seq model. Encodes a sequence of points of a\n","    swipe-keyboard-typing gesture into a sequence of characters.\n","\n","    n_output_classes = char_vocab_size - 2 because <pad> and <sos>\n","    tokens are never predicted.\n","    \"\"\"\n","\n","    def _get_mask(self, max_seq_len: int):\n","        \"\"\"\n","        Returns a mask for the decoder transformer.\n","        \"\"\"\n","        mask = torch.triu(torch.ones(max_seq_len, max_seq_len), diagonal=1)\n","        mask = mask.masked_fill(mask == 1, float('-inf'))\n","        return mask\n","\n","    def __init__(self,\n","                 n_coord_feats: int,\n","                 char_emb_size: int,\n","                 char_vocab_size: int,\n","                 key_emb_size: int,\n","                 num_encoder_layers: int,\n","                 num_decoder_layers: int,\n","                 dim_feedforward: int,\n","                 num_heads_encoder_1: int,\n","                 num_heads_encoder_2: int,\n","                 num_heads_decoder: int,\n","                 dropout:float,\n","                 char_embedding_dropout: float,\n","                 key_embedding_dropout: float,\n","                 max_out_seq_len: int,\n","                 max_curves_seq_len: int,\n","                 activation: Callable = F.relu,\n","                 device: str = None):\n","        super().__init__()\n","\n","        device = device or torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","        input_feats_size = n_coord_feats + key_emb_size\n","\n","        d_model = char_emb_size\n","\n","        self.char_embedding_dropout = nn.Dropout(char_embedding_dropout)\n","        self.key_embedding_dropout = nn.Dropout(key_embedding_dropout)\n","        \n","        self.char_embedding = nn.Embedding(char_vocab_size, char_emb_size, device=device)\n","        self.key_embedding = nn.Embedding(char_vocab_size, key_emb_size, device=device)\n","\n","        self.encoder = SwipeCurveTransformerEncoderv1(\n","            input_feats_size, d_model, dim_feedforward,\n","            num_encoder_layers, num_heads_encoder_1,\n","            num_heads_encoder_2, dropout, device=device)\n","        \n","        self.char_pos_encoder = PositionalEncoding(\n","            char_emb_size, max_out_seq_len, device=device)\n","        \n","        self.key_pos_encoder = PositionalEncoding(\n","            key_emb_size, max_curves_seq_len, device=device)\n","        \n","        n_classes = char_vocab_size - 2  # <sos> and <pad> are not predicted\n","        self.decoder = SwipeCurveTransformerDecoderv1(\n","            char_emb_size, n_classes, num_heads_decoder,\n","            num_decoder_layers, dim_feedforward, dropout, activation, device=device)\n","\n","        self.mask = self._get_mask(max_out_seq_len).to(device=device)\n","\n","    def forward(self, x, kb_tokens, y, x_pad_mask, y_pad_mask):\n","        kb_k_emb = self.key_embedding(kb_tokens)  # keyboard key\n","        kb_k_emb = self.key_embedding_dropout(kb_k_emb)\n","        kb_k_emb = self.key_pos_encoder(kb_k_emb)\n","        x = torch.cat((x, kb_k_emb), axis = -1)\n","        x = self.encoder(x, x_pad_mask)\n","        y = self.char_embedding(y)\n","        y = self.char_embedding_dropout(y)\n","        y = self.char_pos_encoder(y)\n","        y = self.decoder(y, x, self.mask, x_pad_mask, y_pad_mask)\n","        return y"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":16,"metadata":{"execution":{"iopub.execute_input":"2023-11-01T20:17:16.567758Z","iopub.status.busy":"2023-11-01T20:17:16.567350Z","iopub.status.idle":"2023-11-01T20:17:16.596110Z","shell.execute_reply":"2023-11-01T20:17:16.594988Z","shell.execute_reply.started":"2023-11-01T20:17:16.567727Z"},"trusted":true},"outputs":[],"source":["device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":28,"metadata":{"execution":{"iopub.execute_input":"2023-11-01T20:38:20.665526Z","iopub.status.busy":"2023-11-01T20:38:20.665113Z","iopub.status.idle":"2023-11-01T20:38:20.694136Z","shell.execute_reply":"2023-11-01T20:38:20.693185Z","shell.execute_reply.started":"2023-11-01T20:38:20.665494Z"},"trusted":true},"outputs":[],"source":["max_out_seq_len = word_char_tokenizer.max_word_len - 1\n","\n","transformer = SwipeCurveTransformer(\n","    n_coord_feats=6,\n","    char_emb_size=128,\n","    char_vocab_size=len(word_char_tokenizer.char_to_idx),\n","    key_emb_size=54,\n","    num_encoder_layers=3,\n","    num_decoder_layers=3,\n","    dim_feedforward=128,\n","    num_heads_encoder_1=4,\n","    num_heads_encoder_2=4,\n","    num_heads_decoder=4,\n","    dropout=0.1,\n","    char_embedding_dropout=0.1,\n","    key_embedding_dropout=0.1,\n","    max_out_seq_len=max_out_seq_len,\n","    max_curves_seq_len=299,\n","    device = device)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":29,"metadata":{"execution":{"iopub.execute_input":"2023-11-01T20:38:23.100625Z","iopub.status.busy":"2023-11-01T20:38:23.100244Z","iopub.status.idle":"2023-11-01T20:38:23.108800Z","shell.execute_reply":"2023-11-01T20:38:23.107543Z","shell.execute_reply.started":"2023-11-01T20:38:23.100597Z"},"trusted":true},"outputs":[],"source":["def prepare_batch(x, y, device):\n","    (xyt, kb_tokens, dec_in_char_seq, traj_pad_mask, word_pad_mask), dec_out_char_seq = x, y\n","\n","    xyt = xyt.transpose_(0, 1).to(device)  # (curves_seq_len, batch_size, n_coord_feats)\n","    kb_tokens = kb_tokens.transpose_(0, 1).to(device) # (curves_seq_len, batch_size)\n","    dec_in_char_seq = dec_in_char_seq.transpose_(0, 1).to(device)  # (chars_seq_len - 1, batch_size)\n","    dec_out_char_seq = dec_out_char_seq.transpose_(0, 1).to(device)  # (chars_seq_len - 1, batch_size)\n","\n","    traj_pad_mask = traj_pad_mask.to(device)  # (batch_size, curves_seq_len)\n","    word_pad_mask = word_pad_mask.to(device)  # (batch_size, chars_seq_len - 1)\n","\n","    return (xyt, kb_tokens, dec_in_char_seq, traj_pad_mask, word_pad_mask), dec_out_char_seq"]},{"cell_type":"code","execution_count":30,"metadata":{"execution":{"iopub.execute_input":"2023-11-01T20:38:25.664096Z","iopub.status.busy":"2023-11-01T20:38:25.663699Z","iopub.status.idle":"2023-11-01T20:38:25.670657Z","shell.execute_reply":"2023-11-01T20:38:25.669364Z","shell.execute_reply.started":"2023-11-01T20:38:25.664065Z"},"trusted":true},"outputs":[],"source":["def cross_entropy_with_reshape(pred, target):\n","    \"\"\"\n","    pred - BatchSize x TargetLen x VocabSize\n","    target - BatchSize x TargetLen\n","    \"\"\"\n","    pred_flat = pred.view(-1, pred.shape[-1])  # BatchSize*TargetLen x VocabSize\n","    target_flat = target.reshape(-1)  # BatchSize*TargetLen\n","    return F.cross_entropy(pred_flat, target_flat, ignore_index=0)"]},{"cell_type":"code","execution_count":31,"metadata":{"execution":{"iopub.execute_input":"2023-11-01T20:38:33.608060Z","iopub.status.busy":"2023-11-01T20:38:33.607655Z","iopub.status.idle":"2023-11-01T20:38:34.342372Z","shell.execute_reply":"2023-11-01T20:38:34.341229Z","shell.execute_reply.started":"2023-11-01T20:38:33.608029Z"},"trusted":true},"outputs":[],"source":["# from torch.utils.data import DataLoader\n","\n","loader = DataLoader(train_dataset, batch_size=10, shuffle=True)\n","\n","\n","for x, y in loader:\n","    x, y = prepare_batch(x, y, device)\n","\n","    char_seq_pred = transformer(*x)\n","    cross_entropy_with_reshape(char_seq_pred, y)\n","    break"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":32,"metadata":{"execution":{"iopub.execute_input":"2023-11-01T20:38:39.290107Z","iopub.status.busy":"2023-11-01T20:38:39.289013Z","iopub.status.idle":"2023-11-01T20:38:39.295479Z","shell.execute_reply":"2023-11-01T20:38:39.294079Z","shell.execute_reply.started":"2023-11-01T20:38:39.290065Z"},"trusted":true},"outputs":[],"source":["def lr_scheduler(optimizer):\n","    return torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer,\n","                                                      patience=20,\n","                                                      factor=0.5,\n","                                                      verbose=True)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2023-11-01T21:11:17.255458Z","iopub.status.busy":"2023-11-01T21:11:17.255041Z","iopub.status.idle":"2023-11-01T21:11:17.280055Z","shell.execute_reply":"2023-11-01T21:11:17.278936Z","shell.execute_reply.started":"2023-11-01T21:11:17.255425Z"},"trusted":true},"outputs":[{"ename":"SyntaxError","evalue":"invalid syntax (1428022237.py, line 67)","output_type":"error","traceback":["\u001b[1;36m  Cell \u001b[1;32mIn[1], line 67\u001b[1;36m\u001b[0m\n\u001b[1;33m    best_model =\u001b[0m\n\u001b[1;37m                ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"]}],"source":["import traceback\n","import datetime\n","import copy\n","\n","from typing import Callable\n","\n","\n","def train_eval_loop(model, train_dataset, val_dataset, criterion,\n","                    lr=1e-4, epoch_n=10, batch_size=32,\n","                    device=None, early_stopping_patience=10, l2_reg_alpha=0,\n","                    max_batches_per_epoch_train=10000,\n","                    max_batches_per_epoch_val=1000,\n","                    data_loader_ctor=DataLoader,\n","                    optimizer_ctor=None,\n","                    lr_scheduler_ctor=None,\n","                    shuffle_train=True,\n","                    dataloader_workers_n=0,\n","                    prepare_batch: Callable = lambda x, y: (x, y)):\n","    \"\"\"\n","    Цикл для обучения модели. После каждой эпохи качество модели оценивается по отложенной выборке.\n","    :param model: torch.nn.Module - обучаемая модель\n","    :param train_dataset: torch.utils.data.Dataset - данные для обучения\n","    :param val_dataset: torch.utils.data.Dataset - данные для оценки качества\n","    :param criterion: функция потерь для настройки модели\n","    :param lr: скорость обучения\n","    :param epoch_n: максимальное количество эпох\n","    :param batch_size: количество примеров, обрабатываемых моделью за одну итерацию\n","    :param device: cuda/cpu - устройство, на котором выполнять вычисления\n","    :param early_stopping_patience: наибольшее количество эпох, в течение которых допускается\n","        отсутствие улучшения модели, чтобы обучение продолжалось.\n","    :param l2_reg_alpha: коэффициент L2-регуляризации\n","    :param max_batches_per_epoch_train: максимальное количество итераций на одну эпоху обучения\n","    :param max_batches_per_epoch_val: максимальное количество итераций на одну эпоху валидации\n","    :param data_loader_ctor: функция для создания объекта, преобразующего датасет в батчи\n","        (по умолчанию torch.utils.data.DataLoader)\n","    :return: кортеж из двух элементов:\n","        - среднее значение функции потерь на валидации на лучшей эпохе\n","        - лучшая модель\n","    \"\"\"\n","    if device is None:\n","        device =  torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","    model.to(device)\n","\n","    if optimizer_ctor is None:\n","        optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=l2_reg_alpha)\n","    else:\n","        optimizer = optimizer_ctor(model.parameters(), lr=lr)\n","\n","    if lr_scheduler_ctor is not None:\n","        lr_scheduler = lr_scheduler_ctor(optimizer)\n","    else:\n","        lr_scheduler = None\n","\n","    train_dataloader = data_loader_ctor(train_dataset, batch_size=batch_size, shuffle=shuffle_train,\n","                                        num_workers=dataloader_workers_n)\n","    val_dataloader = data_loader_ctor(val_dataset, batch_size=batch_size, shuffle=False,\n","                                      num_workers=dataloader_workers_n)\n","\n","    best_val_loss = float('inf')\n","    best_epoch_i = 0\n","\n","    best_model_path = \"best_model.pt\"\n","    best_model = copy.deepcopy(model)\n","\n","    if os.path.exists(best_model_path):\n","        best_model.load_state_dict(best_model_path)\n","\n","    for epoch_i in tqdm(range(epoch_n), position = 0):\n","        try:\n","            model.train()\n","            mean_train_loss = 0\n","            train_batches_n = 0\n","            for batch_i, (batch_x, batch_y) in tqdm(enumerate(train_dataloader), total = min(max_batches_per_epoch_train, len(train_dataset) // batch_size), position=1, leave = False):\n","                if batch_i > max_batches_per_epoch_train:\n","                    break\n","\n","                batch_x, batch_y = prepare_batch(batch_x, batch_y, device)\n","\n","                pred = model(*batch_x)\n","                loss = criterion(pred, batch_y)\n","\n","                model.zero_grad()\n","                loss.backward()\n","\n","                optimizer.step()\n","\n","                mean_train_loss += float(loss)\n","                train_batches_n += 1\n","\n","            mean_train_loss /= train_batches_n\n","            \n","            print('Среднее значение функции потерь на обучении', mean_train_loss)\n","\n","\n","\n","            model.eval()\n","            mean_val_loss = 0\n","            val_batches_n = 0\n","\n","            with torch.no_grad():\n","                for batch_i, (batch_x, batch_y) in enumerate(val_dataloader):\n","                    if batch_i > max_batches_per_epoch_val:\n","                        break\n","\n","                    batch_x, batch_y = prepare_batch(batch_x, batch_y, device)\n","\n","                    pred = model(*batch_x)\n","                    loss = criterion(pred, batch_y)\n","\n","                    mean_val_loss += float(loss)\n","                    val_batches_n += 1\n","\n","            mean_val_loss /= val_batches_n\n","            print('Среднее значение функции потерь на валидации', mean_val_loss)\n","\n","            if mean_val_loss < best_val_loss:\n","                best_epoch_i = epoch_i\n","                best_val_loss = mean_val_loss\n","                best_model = copy.deepcopy(model)\n","                torch.save(model.state_dict(), best_model_path)\n","                print('Новая лучшая модель!')\n","            elif epoch_i - best_epoch_i > early_stopping_patience:\n","                print('Модель не улучшилась за последние {} эпох, прекращаем обучение'.format(\n","                    early_stopping_patience))\n","                break\n","\n","            if lr_scheduler is not None:\n","                lr_scheduler.step(mean_val_loss)\n","\n","            print()\n","        except KeyboardInterrupt:\n","            print('Досрочно остановлено пользователем')\n","            break\n","        except Exception as ex:\n","            print('Ошибка при обучении: {}\\n{}'.format(ex, traceback.format_exc()))\n","            break\n","\n","    return best_val_loss, best_model\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":60,"metadata":{"execution":{"iopub.execute_input":"2023-11-01T21:13:36.854043Z","iopub.status.busy":"2023-11-01T21:13:36.853208Z","iopub.status.idle":"2023-11-01T21:13:36.858549Z","shell.execute_reply":"2023-11-01T21:13:36.857465Z","shell.execute_reply.started":"2023-11-01T21:13:36.854009Z"},"trusted":true},"outputs":[],"source":["from tqdm.notebook import tqdm\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-01T21:13:39.842527Z","iopub.status.busy":"2023-11-01T21:13:39.841719Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"78d3d39dd4d545fdb943d04ada03db41","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1000 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"269468f837c349189b3d9d6145493597","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/500 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Эпоха: 501 итераций, 228.90 сек\n","Среднее значение функции потерь на обучении 0.06695280402541874\n","Среднее значение функции потерь на валидации 0.06767147096494834\n","Новая лучшая модель!\n","\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"265f65c2918d4fd59dd02eab05de4534","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/500 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"}],"source":["best_val_loss, best_model = train_eval_loop(\n","    transformer, train_dataset, val_dataset, cross_entropy_with_reshape,\n","    lr=1e-4, epoch_n=1000, batch_size=320,\n","    device=device, early_stopping_patience=10, l2_reg_alpha=0,\n","    max_batches_per_epoch_train=500,\n","    max_batches_per_epoch_val=1000,\n","    data_loader_ctor=DataLoader,\n","    optimizer_ctor=None,\n","    lr_scheduler_ctor=lr_scheduler,\n","    shuffle_train=True,\n","    dataloader_workers_n=0,\n","    prepare_batch=prepare_batch\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.10"}},"nbformat":4,"nbformat_minor":4}
