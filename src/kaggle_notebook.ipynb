{"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":7299591,"sourceType":"datasetVersion","datasetId":4234577}],"dockerImageVersionId":30665,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"%load_ext autoreload\n%autoreload 2","metadata":{"execution":{"iopub.status.busy":"2024-02-28T16:55:16.548961Z","iopub.execute_input":"2024-02-28T16:55:16.549326Z","iopub.status.idle":"2024-02-28T16:55:16.602125Z","shell.execute_reply.started":"2024-02-28T16:55:16.549299Z","shell.execute_reply":"2024-02-28T16:55:16.601021Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"The autoreload extension is already loaded. To reload it, use:\n  %reload_ext autoreload\n","output_type":"stream"}]},{"cell_type":"code","source":"# !git clone https://github.com/proshian/yandex-cup-2023-ml-neuroswipe.git\n# %cd yandex-cup-2023-ml-neuroswipe\n# ! git checkout remake_after_finals ","metadata":{"execution":{"iopub.status.busy":"2024-02-28T16:55:16.604717Z","iopub.execute_input":"2024-02-28T16:55:16.605240Z","iopub.status.idle":"2024-02-28T16:55:16.652857Z","shell.execute_reply.started":"2024-02-28T16:55:16.605202Z","shell.execute_reply":"2024-02-28T16:55:16.651935Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"# !pip install dvc --quiet\n# !pip install dvc_gdrive --quiet","metadata":{"execution":{"iopub.status.busy":"2024-02-28T16:55:16.654340Z","iopub.execute_input":"2024-02-28T16:55:16.655030Z","iopub.status.idle":"2024-02-28T16:55:16.701769Z","shell.execute_reply.started":"2024-02-28T16:55:16.654994Z","shell.execute_reply":"2024-02-28T16:55:16.700965Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"%cd /kaggle/working/yandex-cup-2023-ml-neuroswipe/src","metadata":{"execution":{"iopub.status.busy":"2024-02-28T16:55:16.703087Z","iopub.execute_input":"2024-02-28T16:55:16.703900Z","iopub.status.idle":"2024-02-28T16:55:16.750794Z","shell.execute_reply.started":"2024-02-28T16:55:16.703850Z","shell.execute_reply":"2024-02-28T16:55:16.749772Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"/kaggle/working/yandex-cup-2023-ml-neuroswipe/src\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport json\nimport typing as tp\nimport traceback\nfrom datetime import datetime\nimport copy\n\nimport torch\n# import torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import DataLoader\nfrom tqdm.notebook import tqdm\nimport numpy as np\nfrom torch.utils.tensorboard import SummaryWriter\n\n\nfrom model import SwipeCurveTransformer, get_m1_bigger_model\nfrom tokenizers import CharLevelTokenizerv2, KeyboardTokenizerv1\nfrom tokenizers import ALL_CYRILLIC_LETTERS_ALPHABET_ORD\nfrom dataset import NeuroSwipeDatasetv3, collate_fn\nfrom word_generators import GreedyGenerator\n","metadata":{"execution":{"iopub.status.busy":"2024-02-28T16:55:16.754125Z","iopub.execute_input":"2024-02-28T16:55:16.754647Z","iopub.status.idle":"2024-02-28T16:55:22.780183Z","shell.execute_reply.started":"2024-02-28T16:55:16.754612Z","shell.execute_reply":"2024-02-28T16:55:22.779022Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"############# Script arguments emulation #############\n\nGRID_NAME = \"default\"\nBATCH_SIZE = 320\nIN_KAGGLE = False\nRANDOM_SEED = 12\n\n# keyboard_selection_set is a set of labels of keys that will be\n# considered when finding the nearest keyboard label.  In this\n# case only cyrillic letters are considered. This means that\n# all action keys like \"shift\", \"backspace\", \"enter\", etc. are excluded.\nDS_KWARGS = dict(\n    include_time = False,\n    include_velocities = True,\n    include_accelerations = True,\n    has_target=True,\n    has_one_grid_only=True,\n    include_grid_name=False,\n    keyboard_selection_set=set(ALL_CYRILLIC_LETTERS_ALPHABET_ORD)\n)\n\nDATA_ROOT = \"../data/data_separated_grid\"\nMODELS_DIR = \"../data/trained_models/m1\"","metadata":{"execution":{"iopub.status.busy":"2024-02-28T16:55:49.642371Z","iopub.execute_input":"2024-02-28T16:55:49.642737Z","iopub.status.idle":"2024-02-28T16:55:49.718230Z","shell.execute_reply.started":"2024-02-28T16:55:49.642709Z","shell.execute_reply":"2024-02-28T16:55:49.717244Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"################ Other constants ####################\nGRID_NAME_TO_DS_PATHS = {\n    \"extra\": {\n        \"train\": os.path.join(DATA_ROOT, \"train__extra_only_no_errors__2023_11_01__19_49_14.jsonl\"),\n        \"val\": os.path.join(DATA_ROOT, \"valid__in_train_format__extra_only.jsonl\")\n    },\n    \"default\": {\n        \"train\": os.path.join(DATA_ROOT, \"train__default_only_no_errors__2023_10_31__03_26_16.jsonl\"),\n        \"val\": os.path.join(DATA_ROOT, \"valid__in_train_format__default_only.jsonl\")\n    }\n}","metadata":{"execution":{"iopub.status.busy":"2024-02-28T16:55:49.881360Z","iopub.execute_input":"2024-02-28T16:55:49.881724Z","iopub.status.idle":"2024-02-28T16:55:49.956175Z","shell.execute_reply.started":"2024-02-28T16:55:49.881697Z","shell.execute_reply":"2024-02-28T16:55:49.955153Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# if IN_KAGGLE:\n#     DATA_ROOT = \"/kaggle/input/neuroswipe-defualt-only-v1\"\n#     MODELS_DIR = \"\"","metadata":{"execution":{"iopub.status.busy":"2024-02-28T16:55:50.591297Z","iopub.execute_input":"2024-02-28T16:55:50.592270Z","iopub.status.idle":"2024-02-28T16:55:50.663595Z","shell.execute_reply.started":"2024-02-28T16:55:50.592225Z","shell.execute_reply":"2024-02-28T16:55:50.662682Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def init_random_seed(value=42):\n    # random.seed(value)\n    np.random.seed(value)\n    torch.manual_seed(value)\n    torch.cuda.manual_seed(value)\n    # torch.backends.cudnn.deterministic = True","metadata":{"execution":{"iopub.status.busy":"2024-02-28T16:55:51.710946Z","iopub.execute_input":"2024-02-28T16:55:51.711350Z","iopub.status.idle":"2024-02-28T16:55:51.784405Z","shell.execute_reply.started":"2024-02-28T16:55:51.711317Z","shell.execute_reply":"2024-02-28T16:55:51.783417Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"def get_grid(grid_name: str, grids_path: str) -> dict:\n    with open(grids_path, \"r\", encoding=\"utf-8\") as f:\n        return json.load(f)[grid_name]","metadata":{"execution":{"iopub.status.busy":"2024-02-28T16:55:51.907976Z","iopub.execute_input":"2024-02-28T16:55:51.908366Z","iopub.status.idle":"2024-02-28T16:55:51.983961Z","shell.execute_reply.started":"2024-02-28T16:55:51.908336Z","shell.execute_reply":"2024-02-28T16:55:51.982875Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"def get_datasets(grid_name: str, grid_name_to_grid_path: str,\n                 train_data_path: str, val_data_path: str,\n                 ds_kwargs: dict, kb_tokenizer: KeyboardTokenizerv1,\n                 word_char_tokenizer: CharLevelTokenizerv2\n                 ) -> tuple[NeuroSwipeDatasetv3, NeuroSwipeDatasetv3]:\n    \n    gridname_to_grid  = {grid_name: get_grid(grid_name, grid_name_to_grid_path)}\n\n    train_ds = NeuroSwipeDatasetv3(\n        data_path=train_data_path,\n        gridname_to_grid = gridname_to_grid,\n        kb_tokenizer=kb_tokenizer,\n        word_tokenizer =word_char_tokenizer,\n        total = 5_237_584,  # 349_172 for extra\n        **ds_kwargs\n    )\n\n    val_ds = NeuroSwipeDatasetv3(\n        data_path=val_data_path,\n        gridname_to_grid =gridname_to_grid,\n        kb_tokenizer=kb_tokenizer,\n        word_tokenizer =word_char_tokenizer,\n        total = 9_416,\n        **ds_kwargs\n    )\n\n    return train_ds, val_ds","metadata":{"execution":{"iopub.status.busy":"2024-02-28T16:55:52.334346Z","iopub.execute_input":"2024-02-28T16:55:52.335246Z","iopub.status.idle":"2024-02-28T16:55:52.414986Z","shell.execute_reply.started":"2024-02-28T16:55:52.335211Z","shell.execute_reply":"2024-02-28T16:55:52.413791Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"init_random_seed(RANDOM_SEED)","metadata":{"execution":{"iopub.status.busy":"2024-02-28T16:55:52.709824Z","iopub.execute_input":"2024-02-28T16:55:52.710213Z","iopub.status.idle":"2024-02-28T16:55:52.786022Z","shell.execute_reply.started":"2024-02-28T16:55:52.710183Z","shell.execute_reply":"2024-02-28T16:55:52.784936Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"# Pickling the dataset would be great to not waste\n# around 20 minutes creating train_dataset.\n\nkb_tokenizer = KeyboardTokenizerv1()\nvoc_path=os.path.join(DATA_ROOT, \"voc.txt\")\nword_char_tokenizer = CharLevelTokenizerv2(voc_path)\n\ntrain_dataset, val_dataset = get_datasets(\n    grid_name=GRID_NAME,\n    grid_name_to_grid_path=os.path.join(DATA_ROOT, \"gridname_to_grid.json\"),\n    train_data_path = GRID_NAME_TO_DS_PATHS[GRID_NAME]['train'],\n    val_data_path = GRID_NAME_TO_DS_PATHS[GRID_NAME]['val'],\n    ds_kwargs=DS_KWARGS,\n    kb_tokenizer=kb_tokenizer,\n    word_char_tokenizer=word_char_tokenizer,\n)","metadata":{"execution":{"iopub.status.busy":"2024-02-28T16:55:52.871015Z","iopub.execute_input":"2024-02-28T16:55:52.871396Z","iopub.status.idle":"2024-02-28T17:08:21.791189Z","shell.execute_reply.started":"2024-02-28T16:55:52.871367Z","shell.execute_reply":"2024-02-28T17:08:21.790171Z"},"trusted":true},"execution_count":26,"outputs":[{"name":"stderr","text":"5237584it [11:49, 7379.66it/s]                           \n 94%|█████████▍| 9416/10000 [00:01<00:00, 7286.24it/s]\n","output_type":"stream"}]},{"cell_type":"code","source":"device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')","metadata":{"execution":{"iopub.status.busy":"2024-02-28T17:08:21.792859Z","iopub.execute_input":"2024-02-28T17:08:21.793213Z","iopub.status.idle":"2024-02-28T17:08:21.889011Z","shell.execute_reply.started":"2024-02-28T17:08:21.793188Z","shell.execute_reply":"2024-02-28T17:08:21.888009Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"transformer = get_m1_bigger_model(device)","metadata":{"execution":{"iopub.status.busy":"2024-02-28T17:08:21.890272Z","iopub.execute_input":"2024-02-28T17:08:21.890728Z","iopub.status.idle":"2024-02-28T17:08:22.324239Z","shell.execute_reply.started":"2024-02-28T17:08:21.890693Z","shell.execute_reply":"2024-02-28T17:08:22.323160Z"},"trusted":true},"execution_count":28,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/transformer.py:282: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def cross_entropy_with_reshape(pred, target, ignore_index=-100, label_smoothing=0.0):\n    \"\"\"\n    pred - BatchSize x TargetLen x VocabSize\n    target - BatchSize x TargetLen\n    \"\"\"\n    pred_flat = pred.view(-1, pred.shape[-1])  # BatchSize*TargetLen x VocabSize\n    target_flat = target.reshape(-1)  # BatchSize*TargetLen\n    return F.cross_entropy(pred_flat,\n                           target_flat,\n                           ignore_index=ignore_index,\n                           label_smoothing=label_smoothing)","metadata":{"execution":{"iopub.status.busy":"2024-02-28T17:08:22.327128Z","iopub.execute_input":"2024-02-28T17:08:22.327456Z","iopub.status.idle":"2024-02-28T17:08:22.403214Z","shell.execute_reply.started":"2024-02-28T17:08:22.327429Z","shell.execute_reply":"2024-02-28T17:08:22.402083Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"def lr_scheduler(optimizer):\n    return torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer,\n                                                      patience=20,\n                                                      factor=0.5,\n                                                      verbose=True)","metadata":{"execution":{"iopub.status.busy":"2024-02-28T17:08:22.404760Z","iopub.execute_input":"2024-02-28T17:08:22.405076Z","iopub.status.idle":"2024-02-28T17:08:22.482693Z","shell.execute_reply.started":"2024-02-28T17:08:22.405050Z","shell.execute_reply":"2024-02-28T17:08:22.481546Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"def move_all_to_device(x, device):\n    if torch.is_tensor(x):\n        return x.to(device)\n    elif not isinstance(x, (list, tuple)):\n        raise ValueError(f'Unexpected data type {type(x)}')\n    new_x = []\n    for el in x:\n        if not torch.is_tensor(el):\n            raise ValueError(f'Unexpected data type {type(el)}')\n        new_x.append(el.to(device))\n    return new_x","metadata":{"execution":{"iopub.status.busy":"2024-02-28T17:08:22.484025Z","iopub.execute_input":"2024-02-28T17:08:22.484311Z","iopub.status.idle":"2024-02-28T17:08:22.561355Z","shell.execute_reply.started":"2024-02-28T17:08:22.484287Z","shell.execute_reply":"2024-02-28T17:08:22.560182Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Протестируем корректность collate_fn (вызывается неявно в DataLoader)\n\nbatch_size = 6\n\n\nPAD_CHAR_TOKEN = word_char_tokenizer.char_to_idx[\"<pad>\"]\n\n\ntrain_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=False,\n                                        num_workers=0, collate_fn=collate_fn)\n\n\ndataset_els = [train_dataset[i] for i in range(batch_size)]\nunproc_batch_x, unproc_batch_y = zip(*dataset_els)\n\nbatch_x, batch_y = next(iter(train_dataloader))\n\n\n############### Проверка корректности batch_y ###################\nmax_out_seq_len = max([len(y) for y in unproc_batch_y])\n\nassert batch_y.shape == (max_out_seq_len, batch_size)\n\n\nfor i in range(batch_size):\n    assert (batch_y[:len(unproc_batch_y[i]), i] == unproc_batch_y[i]).all()\n    assert (batch_y[len(unproc_batch_y[i]):, i] == PAD_CHAR_TOKEN).all()\n\nprint(\"batch_y is correct\")\n\n\n\n############### Проверка корректности batch_x ###################\nunproc_batch_traj_feats, unproc_batch_kb_tokens, unproc_batch_dec_in_char_seq, \\\n    unproc_batch_word_pad_mask = zip(*unproc_batch_x)\n\n(traj_feats, kb_tokens, dec_in_char_seq, traj_pad_mask, word_pad_mask) = batch_x\n\n\n# каждая сущность, полученная выше из unpoc_batch_x - это tuple длины batch_size.\n# Например, unproc_batch_traj_feats[i] = train_dataset[i][0][0]\n\nN_TRAJ_FEATS = 6\nmax_curve_len = max([el.shape[0] for el in unproc_batch_traj_feats]) \n\nassert max_curve_len == max([el.shape[0] for el in unproc_batch_kb_tokens])\n\nassert traj_feats.shape == (max_curve_len, batch_size, N_TRAJ_FEATS)\nassert kb_tokens.shape == (max_curve_len, batch_size)\nassert dec_in_char_seq.shape == (max_out_seq_len, batch_size)\nassert traj_pad_mask.shape == (batch_size, max_curve_len)\nassert word_pad_mask.shape == (batch_size, max_out_seq_len)\n\n\nfor i in range(batch_size):\n    assert (traj_feats[:len(unproc_batch_traj_feats[i]), i] == unproc_batch_traj_feats[i]).all()\n    assert (kb_tokens[:len(unproc_batch_kb_tokens[i]), i] == unproc_batch_kb_tokens[i]).all()\n\n    assert (dec_in_char_seq[:len(unproc_batch_dec_in_char_seq[i]), i] == unproc_batch_dec_in_char_seq[i]).all()\n    assert (dec_in_char_seq[len(unproc_batch_dec_in_char_seq[i]):, i] == PAD_CHAR_TOKEN).all()\n\n    assert (traj_pad_mask[i, :len(unproc_batch_traj_feats[i])] == False).all()\n    assert (traj_pad_mask[i, len(unproc_batch_traj_feats[i]):] == True).all()\n    \n    assert (word_pad_mask[i, :len(unproc_batch_dec_in_char_seq[i])] == unproc_batch_word_pad_mask[i]).all()\n\nprint(\"batch_x is correct\")","metadata":{"execution":{"iopub.status.busy":"2024-02-28T17:08:22.563021Z","iopub.execute_input":"2024-02-28T17:08:22.563350Z","iopub.status.idle":"2024-02-28T17:08:22.672446Z","shell.execute_reply.started":"2024-02-28T17:08:22.563324Z","shell.execute_reply":"2024-02-28T17:08:22.671501Z"},"trusted":true},"execution_count":32,"outputs":[{"name":"stdout","text":"batch_y is correct\nbatch_x is correct\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from typing import List\n\ndef predict_greedy_raw(dataset,\n                       greedy_word_generator: GreedyGenerator,\n                      ) -> List[List[str]]:\n    \"\"\"\n    Creates predictions using greedy generation.\n\n    Supposed to be used with a dataset of a single grid\n    \n    Arguments:\n    ----------\n    dataset: NeuroSwipeDatasetv2\n    grid_name_to_greedy_generator: dict\n        Dict mapping grid names to GreedyGenerator objects.\n    \"\"\"\n    preds = [None] * len(dataset)\n\n    for data in tqdm(enumerate(dataset), total=len(dataset)):\n#         i, ((xyt, kb_tokens, _, traj_pad_mask, _), _, grid_name) = data\n        i, ((xyt, kb_tokens, _, _), _) = data\n\n        pred = greedy_word_generator.generate_word_only(xyt, kb_tokens)\n        pred = pred.removeprefix(\"<sos>\")\n#         preds[i] = [pred]\n        preds[i] = pred\n\n    return preds","metadata":{"execution":{"iopub.status.busy":"2024-02-28T17:08:22.673557Z","iopub.execute_input":"2024-02-28T17:08:22.673829Z","iopub.status.idle":"2024-02-28T17:08:22.743947Z","shell.execute_reply.started":"2024-02-28T17:08:22.673806Z","shell.execute_reply":"2024-02-28T17:08:22.743063Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"###################### протестируем predict_greedy_raw ######################\n\nMODEL_TO_TEST_GREEDY_GEN__PATH = \"/kaggle/input/m1-bigger-v2-0-13413-extra-l2-0-ls0-switch-1-pt/\" \\\n    \"m1_bigger_v2__2023_11_12__02_27_14__0.13413_extra_l2_0_ls0_switch_1.pt\"\n\n\ndef get_targets(dataset: NeuroSwipeDatasetv3) -> tp.List[str]:\n    targets = []\n    for (_, _, _, word_pad_mask), target_tokens in dataset:\n        target_len = int(torch.sum(~word_pad_mask)) - 1\n        target = word_char_tokenizer.decode(target_tokens[:target_len])\n        targets.append(target)\n    return targets\n\n\ndef get_accuracy(preds, targets) -> float:\n    return sum(pred == target for pred, target \n               in zip(preds, targets)) / len(targets)\n\n\ndef get_greedy_generator_accuracy(val_dataset, model, \n                                  word_char_tokenizer, device) -> float:\n    val_targets = get_targets(val_dataset)\n    greedy_generator = GreedyGenerator(model, word_char_tokenizer, device)\n    greedy_preds = predict_greedy_raw(val_dataset, greedy_generator)\n    return get_accuracy(greedy_preds, val_targets)\n    \n\ndef test_greedy_generator(val_dataset, model_getter, word_char_tokenizer, device) -> float:\n    \n    model = model_getter(device, MODEL_TO_TEST_GREEDY_GEN__PATH)\n\n    return get_greedy_generator_accuracy(val_dataset, model, word_char_tokenizer, device)\n\n\n\ntest_greedy_generator(val_dataset, get_m1_bigger_model, word_char_tokenizer, device)","metadata":{"execution":{"iopub.status.busy":"2024-02-28T17:08:22.745439Z","iopub.execute_input":"2024-02-28T17:08:22.746352Z","iopub.status.idle":"2024-02-28T17:12:35.071418Z","shell.execute_reply.started":"2024-02-28T17:08:22.746315Z","shell.execute_reply":"2024-02-28T17:12:35.070492Z"},"trusted":true},"execution_count":34,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/9416 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6356b99a02eb415eb089fbccccdd3f1c"}},"metadata":{}},{"execution_count":34,"output_type":"execute_result","data":{"text/plain":"0.8263593882752761"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def train_eval_loop(model, train_dataset, val_dataset, criterion,\n                    tb, epoch_start, lr=1e-4, epoch_n=10, batch_size=32,\n                    collate_fn = None,\n                    device=None, early_stopping_patience=20, l2_reg_alpha=0,\n                    max_batches_per_epoch_train=10000,\n                    max_batches_per_epoch_val=1000,\n                    optimizer_ctor=None,\n                    lr_scheduler_ctor=None,\n                    shuffle_train=True,\n                    label_smoothing = 0.0,\n                    dataloader_workers_n=0,\n                    criterion_ignore_index = -100,\n                    model_name_postfix = \"\",\n                    model_save_root = \".\",\n                    ):\n    \"\"\"\n    Цикл для обучения модели. После каждой эпохи качество модели оценивается по отложенной выборке.\n    :param model: torch.nn.Module - обучаемая модель\n    :param train_dataset: torch.utils.data.Dataset - данные для обучения\n    :param val_dataset: torch.utils.data.Dataset - данные для оценки качества\n    :param criterion: функция потерь для настройки модели\n    :param lr: скорость обучения\n    :param epoch_n: максимальное количество эпох\n    :param batch_size: количество примеров, обрабатываемых моделью за одну итерацию\n    :param device: cuda/cpu - устройство, на котором выполнять вычисления\n    :param early_stopping_patience: наибольшее количество эпох, в течение которых допускается\n        отсутствие улучшения модели, чтобы обучение продолжалось.\n    :param l2_reg_alpha: коэффициент L2-регуляризации\n    :param max_batches_per_epoch_train: максимальное количество итераций на одну эпоху обучения\n    :param max_batches_per_epoch_val: максимальное количество итераций на одну эпоху валидации\n    :return: кортеж из двух элементов:\n        - среднее значение функции потерь на валидации на лучшей эпохе\n        - лучшая модель\n    \"\"\"\n    if device is None:\n        device =  torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n\n    model.to(device)\n\n    if optimizer_ctor is None:\n        optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=l2_reg_alpha)\n    else:\n        optimizer = optimizer_ctor(model.parameters(), lr=lr)\n\n    if lr_scheduler_ctor is not None:\n        lr_scheduler = lr_scheduler_ctor(optimizer)\n    else:\n        lr_scheduler = None\n\n    train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=shuffle_train,\n                                        num_workers=dataloader_workers_n, collate_fn=collate_fn)\n    val_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False,\n                                      num_workers=dataloader_workers_n, collate_fn=collate_fn)\n\n    best_val_loss = float('inf')\n    best_epoch_i = 0\n\n    best_model_path = \"m1_bigger_v2.pt\"\n    best_model = copy.deepcopy(model)\n    \n    n_train_examples_in_epoch = (batch_size * max_batches_per_epoch_train \n                                 if max_batches_per_epoch_train < len(train_dataset) // batch_size\n                                 else len(train_dataset))\n\n    if os.path.exists(best_model_path):\n        best_model.load_state_dict(torch.load(best_model_path))\n        print(f\"Загружено состояние модели {best_model_path}\")\n\n    for epoch_i in tqdm(range(epoch_start, epoch_start + epoch_n), position = 0):\n        try:\n            model.train()\n            mean_train_loss = 0\n            train_batches_n = 0\n            for batch_i, (batch_x, batch_y) in tqdm(enumerate(train_dataloader), total = min(max_batches_per_epoch_train, len(train_dataset) // batch_size), position=1, leave = False):\n                if batch_i > max_batches_per_epoch_train:\n                    break\n                    \n\n                batch_x, batch_y = [move_all_to_device(el, device) for el in (batch_x, batch_y)]\n\n                pred = model(*batch_x)\n                loss = criterion(pred, batch_y, ignore_index = criterion_ignore_index, \n                                 label_smoothing=label_smoothing)\n\n                model.zero_grad()\n                loss.backward()\n\n                optimizer.step()\n\n                mean_train_loss += float(loss)\n                train_batches_n += 1\n\n            mean_train_loss /= train_batches_n\n            \n            print('Среднее значение функции потерь на обучении', mean_train_loss)\n\n            tb.add_scalar('mean_loss/train', mean_train_loss, epoch_i)\n\n\n\n            model.eval()\n            mean_val_loss = 0\n            val_batches_n = 0\n\n            with torch.no_grad():\n                for batch_i, (batch_x, batch_y) in enumerate(val_dataloader):\n                    if batch_i > max_batches_per_epoch_val:\n                        break\n\n                    batch_x, batch_y = [move_all_to_device(el, device) for el in (batch_x, batch_y)]\n\n                    pred = model(*batch_x)\n                    loss = criterion(pred, batch_y, \n                                     ignore_index = criterion_ignore_index, \n                                     label_smoothing=label_smoothing)\n\n                    mean_val_loss += float(loss)\n                    val_batches_n += 1\n\n            mean_val_loss /= val_batches_n\n            print('Среднее значение функции потерь на валидации', mean_val_loss)\n            tb.add_scalar('mean_loss/val', mean_val_loss, epoch_i * n_train_examples_in_epoch)\n\n            if mean_val_loss < best_val_loss:\n                best_epoch_i = epoch_i\n                best_val_loss = mean_val_loss\n                best_model = copy.deepcopy(model)\n                torch.save(model.state_dict(), os.path.join(model_save_root, best_model_path))\n                \n                cur_time = \"{:%Y_%m_%d__%H_%M_%S}\".format(datetime.now())\n                \n               \n                greedy_accuracy = get_greedy_generator_accuracy(val_dataset, model, word_char_tokenizer, device)\n                tb.add_scalar('greedy_accuracy/val', greedy_accuracy, epoch_i * n_train_examples_in_epoch)\n                \n                torch.save(model.state_dict(), os.path.join(model_save_root, f\"m1_bigger_v2__{cur_time}__{mean_val_loss:.5f}__greed_acc_{greedy_accuracy:.5f}__{model_name_postfix}__epoch_i{epoch_i}.pt\"))\n                print(f\"Greedy accuracy = {greedy_accuracy}\")\n                print('Новая лучшая модель!')\n            elif epoch_i - best_epoch_i > early_stopping_patience:\n                print('Модель не улучшилась за последние {} эпох, прекращаем обучение'.format(\n                    early_stopping_patience))\n                break\n\n            if lr_scheduler is not None:\n                lr_scheduler.step(mean_val_loss)\n\n            print()\n        except KeyboardInterrupt:\n            print('Досрочно остановлено пользователем')\n            break\n        except Exception as ex:\n            print('Ошибка при обучении: {}\\n{}'.format(ex, traceback.format_exc()))\n            break\n\n    return best_val_loss, best_model\n","metadata":{"execution":{"iopub.status.busy":"2024-02-28T17:18:16.895159Z","iopub.execute_input":"2024-02-28T17:18:16.895587Z","iopub.status.idle":"2024-02-28T17:18:16.992326Z","shell.execute_reply.started":"2024-02-28T17:18:16.895555Z","shell.execute_reply":"2024-02-28T17:18:16.991092Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"EXPERIMENT_NAME = f\"m1_bigger_model__{GRID_NAME}__from_random_weights__/SEED_{RANDOM_SEED}__run1\"\nTENSORBOARD_LOG_PATH = f\"/kaggle/working/tensorboard_log/{EXPERIMENT_NAME}\"\n\ntb = SummaryWriter(TENSORBOARD_LOG_PATH)\n","metadata":{"execution":{"iopub.status.busy":"2024-02-28T17:18:31.644853Z","iopub.execute_input":"2024-02-28T17:18:31.645724Z","iopub.status.idle":"2024-02-28T17:18:31.720340Z","shell.execute_reply.started":"2024-02-28T17:18:31.645691Z","shell.execute_reply":"2024-02-28T17:18:31.719352Z"},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"code","source":"l2_reg_alpha =  0 #5e-5\nlabel_smoothing=  0 #0.045\nepoch_start = 0\n\nbest_val_loss, best_model = train_eval_loop(\n    transformer, train_dataset, val_dataset, cross_entropy_with_reshape, tb, epoch_start,\n    lr=1e-4, epoch_n=10000, batch_size=BATCH_SIZE, collate_fn = collate_fn,\n    device=device, early_stopping_patience=20, l2_reg_alpha=l2_reg_alpha,\n    max_batches_per_epoch_train=2000,\n    max_batches_per_epoch_val=1000,\n    optimizer_ctor=None,\n    lr_scheduler_ctor=lr_scheduler,\n    shuffle_train=True,\n    dataloader_workers_n=0,\n    criterion_ignore_index = word_char_tokenizer.char_to_idx['<pad>'],\n    model_name_postfix = f'{GRID_NAME}_l2_{l2_reg_alpha}_ls{label_smoothing}',\n    model_save_root = \"../..\",\n    label_smoothing=label_smoothing,\n)","metadata":{"execution":{"iopub.status.busy":"2024-02-28T17:19:09.932192Z","iopub.execute_input":"2024-02-28T17:19:09.933030Z"},"trusted":true},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/10000 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7cbd74f72f36408bb91a00d0a825ed6e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/2000 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7b7cb58f7a364fd6a3de5a85ecad7608"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/nn/functional.py:5076: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.\n  warnings.warn(\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}