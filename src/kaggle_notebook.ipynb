{"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":7299591,"sourceType":"datasetVersion","datasetId":4234577}],"dockerImageVersionId":30665,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"%load_ext autoreload\n%autoreload 2","metadata":{"execution":{"iopub.status.busy":"2024-02-28T14:35:18.217217Z","iopub.execute_input":"2024-02-28T14:35:18.217509Z","iopub.status.idle":"2024-02-28T14:35:18.245790Z","shell.execute_reply.started":"2024-02-28T14:35:18.217483Z","shell.execute_reply":"2024-02-28T14:35:18.244979Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"# !git clone https://github.com/proshian/yandex-cup-2023-ml-neuroswipe.git\n# %cd yandex-cup-2023-ml-neuroswipe\n# ! git checkout remake_after_finals ","metadata":{"execution":{"iopub.status.busy":"2024-02-28T14:35:18.247365Z","iopub.execute_input":"2024-02-28T14:35:18.247697Z","iopub.status.idle":"2024-02-28T14:35:18.263434Z","shell.execute_reply.started":"2024-02-28T14:35:18.247665Z","shell.execute_reply":"2024-02-28T14:35:18.262713Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"# !pip install dvc --quiet\n# !pip install dvc_gdrive --quiet","metadata":{"execution":{"iopub.status.busy":"2024-02-28T14:35:18.264483Z","iopub.execute_input":"2024-02-28T14:35:18.264780Z","iopub.status.idle":"2024-02-28T14:35:18.280505Z","shell.execute_reply.started":"2024-02-28T14:35:18.264756Z","shell.execute_reply":"2024-02-28T14:35:18.279627Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"%cd /kaggle/working/yandex-cup-2023-ml-neuroswipe/src","metadata":{"execution":{"iopub.status.busy":"2024-02-28T14:36:26.483340Z","iopub.execute_input":"2024-02-28T14:36:26.484063Z","iopub.status.idle":"2024-02-28T14:36:26.514237Z","shell.execute_reply.started":"2024-02-28T14:36:26.484026Z","shell.execute_reply":"2024-02-28T14:36:26.513358Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"/kaggle/working/yandex-cup-2023-ml-neuroswipe/src\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport json\nimport typing as tp\nimport traceback\nfrom datetime import datetime\nimport copy\n\nimport torch\n# import torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import DataLoader\nfrom tqdm.notebook import tqdm\nimport numpy as np\n\nfrom model import SwipeCurveTransformer, get_m1_bigger_model\nfrom tokenizers import CharLevelTokenizerv2, KeyboardTokenizerv1\nfrom tokenizers import ALL_CYRILLIC_LETTERS_ALPHABET_ORD\nfrom dataset import NeuroSwipeDatasetv3, collate_fn\nfrom word_generators import GreedyGenerator\nfrom utils import prepare_batch\n","metadata":{"execution":{"iopub.status.busy":"2024-02-28T14:36:27.135309Z","iopub.execute_input":"2024-02-28T14:36:27.135798Z","iopub.status.idle":"2024-02-28T14:36:27.189838Z","shell.execute_reply.started":"2024-02-28T14:36:27.135750Z","shell.execute_reply":"2024-02-28T14:36:27.189093Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"############# Script arguments emulation #############\n\nGRID_NAME = \"extra\"\nBATCH_SIZE = 320\nIN_KAGGLE = False\nRANDOM_SEED = 12\n\n# keyboard_selection_set is a set of labels of keys that will be\n# considered when finding the nearest keyboard label.  In this\n# case only cyrillic letters are considered. This means that\n# all action keys like \"shift\", \"backspace\", \"enter\", etc. are excluded.\nDS_KWARGS = dict(\n    include_time = False,\n    include_velocities = True,\n    include_accelerations = True,\n    has_target=True,\n    has_one_grid_only=True,\n    include_grid_name=False,\n    keyboard_selection_set=set(ALL_CYRILLIC_LETTERS_ALPHABET_ORD)\n)\n\nDATA_ROOT = \"../data/data_separated_grid\"\nMODELS_DIR = \"../data/trained_models/m1\"","metadata":{"execution":{"iopub.status.busy":"2024-02-28T14:36:27.283411Z","iopub.execute_input":"2024-02-28T14:36:27.284019Z","iopub.status.idle":"2024-02-28T14:36:27.314747Z","shell.execute_reply.started":"2024-02-28T14:36:27.283987Z","shell.execute_reply":"2024-02-28T14:36:27.313947Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"################ Other constants ####################\nGRID_NAME_TO_DS_PATHS = {\n    \"extra\": {\n        \"train\": os.path.join(DATA_ROOT, \"train__extra_only_no_errors__2023_11_01__19_49_14.jsonl\"),\n        \"val\": os.path.join(DATA_ROOT, \"valid__in_train_format__extra_only.jsonl\")\n    },\n    \"default\": {\n        \"train\": os.path.join(DATA_ROOT, \"train__default_only_no_errors__2023_10_31__03_26_16.jsonl\"),\n        \"val\": os.path.join(DATA_ROOT, \"valid__in_train_format__default_only.jsonl\")\n    }\n}","metadata":{"execution":{"iopub.status.busy":"2024-02-28T14:36:27.544397Z","iopub.execute_input":"2024-02-28T14:36:27.545240Z","iopub.status.idle":"2024-02-28T14:36:27.574996Z","shell.execute_reply.started":"2024-02-28T14:36:27.545205Z","shell.execute_reply":"2024-02-28T14:36:27.573996Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# if IN_KAGGLE:\n#     DATA_ROOT = \"/kaggle/input/neuroswipe-defualt-only-v1\"\n#     MODELS_DIR = \"\"","metadata":{"execution":{"iopub.status.busy":"2024-02-28T14:36:27.860065Z","iopub.execute_input":"2024-02-28T14:36:27.860867Z","iopub.status.idle":"2024-02-28T14:36:27.890023Z","shell.execute_reply.started":"2024-02-28T14:36:27.860834Z","shell.execute_reply":"2024-02-28T14:36:27.889140Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def init_random_seed(value=42):\n    # random.seed(value)\n    np.random.seed(value)\n    torch.manual_seed(value)\n    torch.cuda.manual_seed(value)\n    # torch.backends.cudnn.deterministic = True","metadata":{"execution":{"iopub.status.busy":"2024-02-28T14:36:28.269417Z","iopub.execute_input":"2024-02-28T14:36:28.269759Z","iopub.status.idle":"2024-02-28T14:36:28.300358Z","shell.execute_reply.started":"2024-02-28T14:36:28.269732Z","shell.execute_reply":"2024-02-28T14:36:28.299518Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"def get_grid(grid_name: str, grids_path: str) -> dict:\n    with open(grids_path, \"r\", encoding=\"utf-8\") as f:\n        return json.load(f)[grid_name]","metadata":{"execution":{"iopub.status.busy":"2024-02-28T14:36:28.422848Z","iopub.execute_input":"2024-02-28T14:36:28.423200Z","iopub.status.idle":"2024-02-28T14:36:28.452756Z","shell.execute_reply.started":"2024-02-28T14:36:28.423171Z","shell.execute_reply":"2024-02-28T14:36:28.451846Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"def get_datasets(grid_name: str, grid_name_to_grid_path: str,\n                 train_data_path: str, val_data_path: str,\n                 ds_kwargs: dict, kb_tokenizer: KeyboardTokenizerv1,\n                 word_char_tokenizer: CharLevelTokenizerv2\n                 ) -> tuple[NeuroSwipeDatasetv3, NeuroSwipeDatasetv3]:\n    \n    gridname_to_grid  = {grid_name: get_grid(grid_name, grid_name_to_grid_path)}\n\n    train_ds = NeuroSwipeDatasetv3(\n        data_path=train_data_path,\n        gridname_to_grid = gridname_to_grid,\n        kb_tokenizer=kb_tokenizer,\n        word_tokenizer =word_char_tokenizer,\n        total = 349_172,\n        **ds_kwargs\n    )\n\n    val_ds = NeuroSwipeDatasetv3(\n        data_path=val_data_path,\n        gridname_to_grid =gridname_to_grid,\n        kb_tokenizer=kb_tokenizer,\n        word_tokenizer =word_char_tokenizer,\n        total = 10_000,\n        **ds_kwargs\n    )\n\n    return train_ds, val_ds","metadata":{"execution":{"iopub.status.busy":"2024-02-28T14:36:28.498695Z","iopub.execute_input":"2024-02-28T14:36:28.499001Z","iopub.status.idle":"2024-02-28T14:36:28.529635Z","shell.execute_reply.started":"2024-02-28T14:36:28.498951Z","shell.execute_reply":"2024-02-28T14:36:28.528769Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"init_random_seed(RANDOM_SEED)","metadata":{"execution":{"iopub.status.busy":"2024-02-28T14:36:28.829914Z","iopub.execute_input":"2024-02-28T14:36:28.830286Z","iopub.status.idle":"2024-02-28T14:36:28.862873Z","shell.execute_reply.started":"2024-02-28T14:36:28.830257Z","shell.execute_reply":"2024-02-28T14:36:28.861947Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"# Pickling the dataset would be great to not waste\n# around 20 minutes creating train_dataset.\n\nkb_tokenizer = KeyboardTokenizerv1()\nvoc_path=os.path.join(DATA_ROOT, \"voc.txt\")\nword_char_tokenizer = CharLevelTokenizerv2(voc_path)\n\ntrain_dataset, val_dataset = get_datasets(\n    grid_name=GRID_NAME,\n    grid_name_to_grid_path=os.path.join(DATA_ROOT, \"gridname_to_grid.json\"),\n    train_data_path = GRID_NAME_TO_DS_PATHS[GRID_NAME]['train'],\n    val_data_path = GRID_NAME_TO_DS_PATHS[GRID_NAME]['val'],\n    ds_kwargs=DS_KWARGS,\n    kb_tokenizer=kb_tokenizer,\n    word_char_tokenizer=word_char_tokenizer,\n)","metadata":{"execution":{"iopub.status.busy":"2024-02-28T14:36:29.000828Z","iopub.execute_input":"2024-02-28T14:36:29.001376Z","iopub.status.idle":"2024-02-28T14:37:51.878905Z","shell.execute_reply.started":"2024-02-28T14:36:29.001337Z","shell.execute_reply":"2024-02-28T14:37:51.878064Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stderr","text":"100%|██████████| 349172/349172 [00:43<00:00, 8059.65it/s]\n  6%|▌         | 584/10000 [00:00<00:01, 8725.37it/s]\n","output_type":"stream"}]},{"cell_type":"code","source":"device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')","metadata":{"execution":{"iopub.status.busy":"2024-02-28T14:37:51.880494Z","iopub.execute_input":"2024-02-28T14:37:51.880780Z","iopub.status.idle":"2024-02-28T14:37:51.929506Z","shell.execute_reply.started":"2024-02-28T14:37:51.880755Z","shell.execute_reply":"2024-02-28T14:37:51.928540Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"transformer = get_m1_bigger_model(device)","metadata":{"execution":{"iopub.status.busy":"2024-02-28T14:37:51.930693Z","iopub.execute_input":"2024-02-28T14:37:51.930995Z","iopub.status.idle":"2024-02-28T14:37:52.283874Z","shell.execute_reply.started":"2024-02-28T14:37:51.930946Z","shell.execute_reply":"2024-02-28T14:37:52.282880Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/transformer.py:282: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def cross_entropy_with_reshape(pred, target, ignore_index=-100, label_smoothing=0.0):\n    \"\"\"\n    pred - BatchSize x TargetLen x VocabSize\n    target - BatchSize x TargetLen\n    \"\"\"\n    pred_flat = pred.view(-1, pred.shape[-1])  # BatchSize*TargetLen x VocabSize\n    target_flat = target.reshape(-1)  # BatchSize*TargetLen\n    return F.cross_entropy(pred_flat,\n                           target_flat,\n                           ignore_index=ignore_index,\n                           label_smoothing=label_smoothing)","metadata":{"execution":{"iopub.status.busy":"2024-02-28T14:37:52.286091Z","iopub.execute_input":"2024-02-28T14:37:52.286376Z","iopub.status.idle":"2024-02-28T14:37:52.316005Z","shell.execute_reply.started":"2024-02-28T14:37:52.286352Z","shell.execute_reply":"2024-02-28T14:37:52.315004Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"def lr_scheduler(optimizer):\n    return torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer,\n                                                      patience=20,\n                                                      factor=0.5,\n                                                      verbose=True)","metadata":{"execution":{"iopub.status.busy":"2024-02-28T14:37:52.317227Z","iopub.execute_input":"2024-02-28T14:37:52.317554Z","iopub.status.idle":"2024-02-28T14:37:52.347985Z","shell.execute_reply.started":"2024-02-28T14:37:52.317521Z","shell.execute_reply":"2024-02-28T14:37:52.347221Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"def move_all_to_device(x, device):\n    if torch.is_tensor(x):\n        return x.to(device)\n    elif not isinstance(x, (list, tuple)):\n        raise ValueError(f'Unexpected data type {type(x)}')\n    new_x = []\n    for el in x:\n        if not torch.is_tensor(el):\n            raise ValueError(f'Unexpected data type {type(el)}')\n        new_x.append(el.to(device))\n    return new_x","metadata":{"execution":{"iopub.status.busy":"2024-02-28T14:37:52.349058Z","iopub.execute_input":"2024-02-28T14:37:52.349319Z","iopub.status.idle":"2024-02-28T14:37:52.379302Z","shell.execute_reply.started":"2024-02-28T14:37:52.349296Z","shell.execute_reply":"2024-02-28T14:37:52.378387Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Протестируем корректность collate_fn (вызывается неявно в DataLoader)\n\nbatch_size = 6\n\n\nPAD_CHAR_TOKEN = word_char_tokenizer.char_to_idx[\"<pad>\"]\n\n\ntrain_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=False,\n                                        num_workers=0, collate_fn=collate_fn)\n\n\ndataset_els = [train_dataset[i] for i in range(batch_size)]\nunproc_batch_x, unproc_batch_y = zip(*dataset_els)\n\nbatch_x, batch_y = next(iter(train_dataloader))\n\n\n############### Проверка корректности batch_y ###################\nmax_out_seq_len = max([len(y) for y in unproc_batch_y])\n\nassert batch_y.shape == (max_out_seq_len, batch_size)\n\n\nfor i in range(batch_size):\n    assert (batch_y[:len(unproc_batch_y[i]), i] == unproc_batch_y[i]).all()\n    assert (batch_y[len(unproc_batch_y[i]):, i] == PAD_CHAR_TOKEN).all()\n\nprint(\"batch_y is correct\")\n\n\n\n############### Проверка корректности batch_x ###################\nunproc_batch_traj_feats, unproc_batch_kb_tokens, unproc_batch_dec_in_char_seq, \\\n    unproc_batch_word_pad_mask = zip(*unproc_batch_x)\n\n(traj_feats, kb_tokens, dec_in_char_seq, traj_pad_mask, word_pad_mask) = batch_x\n\n\n# каждая сущность, полученная выше из unpoc_batch_x - это tuple длины batch_size.\n# Например, unproc_batch_traj_feats[i] = train_dataset[i][0][0]\n\nN_TRAJ_FEATS = 6\nmax_curve_len = max([el.shape[0] for el in unproc_batch_traj_feats]) \n\nassert max_curve_len == max([el.shape[0] for el in unproc_batch_kb_tokens])\n\nassert traj_feats.shape == (max_curve_len, batch_size, N_TRAJ_FEATS)\nassert kb_tokens.shape == (max_curve_len, batch_size)\nassert dec_in_char_seq.shape == (max_out_seq_len, batch_size)\nassert traj_pad_mask.shape == (batch_size, max_curve_len)\nassert word_pad_mask.shape == (batch_size, max_out_seq_len)\n\n\nfor i in range(batch_size):\n    assert (traj_feats[:len(unproc_batch_traj_feats[i]), i] == unproc_batch_traj_feats[i]).all()\n    assert (kb_tokens[:len(unproc_batch_kb_tokens[i]), i] == unproc_batch_kb_tokens[i]).all()\n\n    assert (dec_in_char_seq[:len(unproc_batch_dec_in_char_seq[i]), i] == unproc_batch_dec_in_char_seq[i]).all()\n    assert (dec_in_char_seq[len(unproc_batch_dec_in_char_seq[i]):, i] == PAD_CHAR_TOKEN).all()\n\n    assert (traj_pad_mask[i, :len(unproc_batch_traj_feats[i])] == False).all()\n    assert (traj_pad_mask[i, len(unproc_batch_traj_feats[i]):] == True).all()\n    \n    assert (word_pad_mask[i, :len(unproc_batch_dec_in_char_seq[i])] == unproc_batch_word_pad_mask[i]).all()\n\nprint(\"batch_x is correct\")","metadata":{"execution":{"iopub.status.busy":"2024-02-28T14:37:52.380636Z","iopub.execute_input":"2024-02-28T14:37:52.380902Z","iopub.status.idle":"2024-02-28T14:37:52.438551Z","shell.execute_reply.started":"2024-02-28T14:37:52.380878Z","shell.execute_reply":"2024-02-28T14:37:52.437702Z"},"trusted":true},"execution_count":21,"outputs":[{"name":"stdout","text":"batch_y is correct\nbatch_x is correct\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from typing import List\n\ndef predict_greedy_raw(dataset,\n                       greedy_word_generator: GreedyGenerator,\n                      ) -> List[List[str]]:\n    \"\"\"\n    Creates predictions using greedy generation.\n\n    Supposed to be used with a dataset of a single grid\n    \n    Arguments:\n    ----------\n    dataset: NeuroSwipeDatasetv2\n    grid_name_to_greedy_generator: dict\n        Dict mapping grid names to GreedyGenerator objects.\n    \"\"\"\n    preds = [None] * len(dataset)\n\n    for data in tqdm(enumerate(dataset), total=len(dataset)):\n#         i, ((xyt, kb_tokens, _, traj_pad_mask, _), _, grid_name) = data\n        i, ((xyt, kb_tokens, _, _), _) = data\n\n        pred = greedy_word_generator.generate_word_only(xyt, kb_tokens)\n        pred = pred.removeprefix(\"<sos>\")\n#         preds[i] = [pred]\n        preds[i] = pred\n\n    return preds","metadata":{"execution":{"iopub.status.busy":"2024-02-28T14:37:52.439810Z","iopub.execute_input":"2024-02-28T14:37:52.440454Z","iopub.status.idle":"2024-02-28T14:37:52.471379Z","shell.execute_reply.started":"2024-02-28T14:37:52.440420Z","shell.execute_reply":"2024-02-28T14:37:52.470577Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"###################### протестируем predict_greedy_raw ######################\n\nMODEL_TO_TEST_GREEDY_GEN__PATH = \"/kaggle/input/m1-bigger-v2-0-13413-extra-l2-0-ls0-switch-1-pt/\" \\\n    \"m1_bigger_v2__2023_11_12__02_27_14__0.13413_extra_l2_0_ls0_switch_1.pt\"\n\n\ndef get_targets(dataset: NeuroSwipeDatasetv3) -> tp.List[str]:\n    targets = []\n    for (_, _, _, word_pad_mask), target_tokens in dataset:\n        target_len = int(torch.sum(~word_pad_mask)) - 1\n        target = word_char_tokenizer.decode(target_tokens[:target_len])\n        targets.append(target)\n    return targets\n\n\ndef get_accuracy(preds, targets) -> float:\n    return sum(pred == target for pred, target \n               in zip(preds, targets)) / len(targets)\n\n\ndef get_greedy_generator_accuracy(val_dataset, model, \n                                  word_char_tokenizer, device) -> float:\n    val_targets = get_targets(val_dataset)\n    greedy_generator = GreedyGenerator(model, word_char_tokenizer, device)\n    greedy_preds = predict_greedy_raw(val_dataset, greedy_generator)\n    return get_accuracy(greedy_preds, val_targets)\n    \n\ndef test_greedy_generator(val_dataset, model_getter, word_char_tokenizer, device) -> float:\n    \n    model = model_getter(device, MODEL_TO_TEST_GREEDY_GEN__PATH)\n\n    return get_greedy_generator_accuracy(val_dataset, model, word_char_tokenizer, device)\n\n\n\ntest_greedy_generator(val_dataset, get_m1_bigger_model, word_char_tokenizer, device)","metadata":{"execution":{"iopub.status.busy":"2024-02-28T15:03:36.241263Z","iopub.execute_input":"2024-02-28T15:03:36.241881Z","iopub.status.idle":"2024-02-28T15:03:51.464175Z","shell.execute_reply.started":"2024-02-28T15:03:36.241848Z","shell.execute_reply":"2024-02-28T15:03:51.463279Z"},"trusted":true},"execution_count":30,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/584 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5adc0416ca1140358f276d2bbde0aa65"}},"metadata":{}},{"execution_count":30,"output_type":"execute_result","data":{"text/plain":"0.8561643835616438"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def train_eval_loop(model, train_dataset, val_dataset, criterion,\n                    lr=1e-4, epoch_n=10, batch_size=32,\n                    collate_fn = None,\n                    device=None, early_stopping_patience=10, l2_reg_alpha=0,\n                    max_batches_per_epoch_train=10000,\n                    max_batches_per_epoch_val=1000,\n                    optimizer_ctor=None,\n                    lr_scheduler_ctor=None,\n                    shuffle_train=True,\n                    label_smoothing = 0.0,\n                    dataloader_workers_n=0,\n                    criterion_ignore_index = -100,\n                    model_name_postfix = \"\",\n                    model_save_root = \".\"\n                    ):\n    \"\"\"\n    Цикл для обучения модели. После каждой эпохи качество модели оценивается по отложенной выборке.\n    :param model: torch.nn.Module - обучаемая модель\n    :param train_dataset: torch.utils.data.Dataset - данные для обучения\n    :param val_dataset: torch.utils.data.Dataset - данные для оценки качества\n    :param criterion: функция потерь для настройки модели\n    :param lr: скорость обучения\n    :param epoch_n: максимальное количество эпох\n    :param batch_size: количество примеров, обрабатываемых моделью за одну итерацию\n    :param device: cuda/cpu - устройство, на котором выполнять вычисления\n    :param early_stopping_patience: наибольшее количество эпох, в течение которых допускается\n        отсутствие улучшения модели, чтобы обучение продолжалось.\n    :param l2_reg_alpha: коэффициент L2-регуляризации\n    :param max_batches_per_epoch_train: максимальное количество итераций на одну эпоху обучения\n    :param max_batches_per_epoch_val: максимальное количество итераций на одну эпоху валидации\n    :return: кортеж из двух элементов:\n        - среднее значение функции потерь на валидации на лучшей эпохе\n        - лучшая модель\n    \"\"\"\n    if device is None:\n        device =  torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n\n    model.to(device)\n\n    if optimizer_ctor is None:\n        optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=l2_reg_alpha)\n    else:\n        optimizer = optimizer_ctor(model.parameters(), lr=lr)\n\n    if lr_scheduler_ctor is not None:\n        lr_scheduler = lr_scheduler_ctor(optimizer)\n    else:\n        lr_scheduler = None\n\n    train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=shuffle_train,\n                                        num_workers=dataloader_workers_n, collate_fn=collate_fn)\n    val_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False,\n                                      num_workers=dataloader_workers_n, collate_fn=collate_fn)\n\n    best_val_loss = float('inf')\n    best_epoch_i = 0\n\n    best_model_path = \"m1_bigger_v2.pt\"\n    best_model = copy.deepcopy(model)\n\n    if os.path.exists(best_model_path):\n        best_model.load_state_dict(torch.load(best_model_path))\n        print(f\"Загружено состояние модели {best_model_path}\")\n\n    for epoch_i in tqdm(range(epoch_n), position = 0):\n        try:\n            model.train()\n            mean_train_loss = 0\n            train_batches_n = 0\n            for batch_i, (batch_x, batch_y) in tqdm(enumerate(train_dataloader), total = min(max_batches_per_epoch_train, len(train_dataset) // batch_size), position=1, leave = False):\n                if batch_i > max_batches_per_epoch_train:\n                    break\n                    \n\n                batch_x, batch_y = [move_all_to_device(el, device) for el in (batch_x, batch_y)]\n\n                pred = model(*batch_x)\n                loss = criterion(pred, batch_y, ignore_index = criterion_ignore_index, label_smoothing=label_smoothing)\n\n                model.zero_grad()\n                loss.backward()\n\n                optimizer.step()\n\n                mean_train_loss += float(loss)\n                train_batches_n += 1\n\n            mean_train_loss /= train_batches_n\n            \n            print('Среднее значение функции потерь на обучении', mean_train_loss)\n\n\n\n            model.eval()\n            mean_val_loss = 0\n            val_batches_n = 0\n\n            with torch.no_grad():\n                for batch_i, (batch_x, batch_y) in enumerate(val_dataloader):\n                    if batch_i > max_batches_per_epoch_val:\n                        break\n\n                    batch_x, batch_y = [move_all_to_device(el, device) for el in (batch_x, batch_y)]\n\n                    pred = model(*batch_x)\n                    loss = criterion(pred, batch_y, \n                                     ignore_index = criterion_ignore_index, \n                                     label_smoothing=label_smoothing)\n\n                    mean_val_loss += float(loss)\n                    val_batches_n += 1\n\n            mean_val_loss /= val_batches_n\n            print('Среднее значение функции потерь на валидации', mean_val_loss)\n\n            if mean_val_loss < best_val_loss:\n                best_epoch_i = epoch_i\n                best_val_loss = mean_val_loss\n                best_model = copy.deepcopy(model)\n                torch.save(model.state_dict(), os.path.join(model_save_root, best_model_path))\n                \n                cur_time = \"{:%Y_%m_%d__%H_%M_%S}\".format(datetime.now())\n                \n               \n                greedy_accuracy = get_greedy_generator_accuracy(val_dataset, model, word_char_tokenizer, device)\n                \n                torch.save(model.state_dict(), os.path.join(model_save_root, f\"m1_bigger_v2__{cur_time}__{mean_val_loss:.5f}__greed_acc_{greedy_accuracy:.5f}__{model_name_postfix}.pt\"))\n                print(f\"Greedy accuracy = {greedy_accuracy}\")\n                print('Новая лучшая модель!')\n            elif epoch_i - best_epoch_i > early_stopping_patience:\n                print('Модель не улучшилась за последние {} эпох, прекращаем обучение'.format(\n                    early_stopping_patience))\n                break\n\n            if lr_scheduler is not None:\n                lr_scheduler.step(mean_val_loss)\n\n            print()\n        except KeyboardInterrupt:\n            print('Досрочно остановлено пользователем')\n            break\n        except Exception as ex:\n            print('Ошибка при обучении: {}\\n{}'.format(ex, traceback.format_exc()))\n            break\n\n    return best_val_loss, best_model\n","metadata":{"execution":{"iopub.status.busy":"2024-02-28T15:06:08.601553Z","iopub.execute_input":"2024-02-28T15:06:08.601920Z","iopub.status.idle":"2024-02-28T15:06:08.659727Z","shell.execute_reply.started":"2024-02-28T15:06:08.601889Z","shell.execute_reply":"2024-02-28T15:06:08.658714Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"l2_reg_alpha =  0 #5e-5\nlabel_smoothing=  0 #0.045\n\nbest_val_loss, best_model = train_eval_loop(\n    transformer, train_dataset, val_dataset, cross_entropy_with_reshape,\n    lr=1e-4, epoch_n=10000, batch_size=BATCH_SIZE, collate_fn = collate_fn,\n    device=device, early_stopping_patience=10, l2_reg_alpha=l2_reg_alpha,\n    max_batches_per_epoch_train=2000,\n    max_batches_per_epoch_val=1000,\n    optimizer_ctor=None,\n    lr_scheduler_ctor=lr_scheduler,\n    shuffle_train=True,\n    dataloader_workers_n=0,\n    criterion_ignore_index = word_char_tokenizer.char_to_idx['<pad>'],\n    model_name_postfix = f'{GRID_NAME}_l2_{l2_reg_alpha}_ls{label_smoothing}_switch_2',\n    model_save_root = \"../..\",\n    label_smoothing=label_smoothing\n)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}