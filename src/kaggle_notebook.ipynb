{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":6948085,"sourceType":"datasetVersion","datasetId":3990388}],"dockerImageVersionId":30580,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"%load_ext autoreload\n%autoreload 2","metadata":{"execution":{"iopub.status.busy":"2023-11-12T19:40:56.610098Z","iopub.status.idle":"2023-11-12T19:40:56.610433Z","shell.execute_reply.started":"2023-11-12T19:40:56.610269Z","shell.execute_reply":"2023-11-12T19:40:56.610285Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%cd /kaggle/working/yandex_cup_2023_ml_neuroswipe/src","metadata":{"execution":{"iopub.status.busy":"2023-11-12T19:40:56.611727Z","iopub.status.idle":"2023-11-12T19:40:56.612233Z","shell.execute_reply.started":"2023-11-12T19:40:56.611974Z","shell.execute_reply":"2023-11-12T19:40:56.611996Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport json\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset, DataLoader, IterableDataset\nfrom tqdm import tqdm\nimport numpy as np\n\nfrom model import SwipeCurveTransformer, get_m1_bigger_model\nfrom tokenizers import CharLevelTokenizerv2, KeyboardTokenizerv1\nfrom dataset import NeuroSwipeDatasetv2\nfrom word_generators import GreedyGenerator\nfrom utils import prepare_batch","metadata":{"execution":{"iopub.status.busy":"2023-11-12T19:40:56.613726Z","iopub.status.idle":"2023-11-12T19:40:56.614179Z","shell.execute_reply.started":"2023-11-12T19:40:56.613953Z","shell.execute_reply":"2023-11-12T19:40:56.613974Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"IN_KAGGLE = False\nRANDOM_SEED = 12\n\nif IN_KAGGLE:\n    DATA_ROOT = \"/kaggle/input/neuroswipe-defualt-only-v1\"\n    MODELS_DIR = \"\"\nelse:\n    DATA_ROOT = \"../data/data_separated_grid\"\n    MODELS_DIR = \"../data/trained_models/m1\"","metadata":{"execution":{"iopub.status.busy":"2023-11-12T19:40:56.616109Z","iopub.status.idle":"2023-11-12T19:40:56.616448Z","shell.execute_reply.started":"2023-11-12T19:40:56.616281Z","shell.execute_reply":"2023-11-12T19:40:56.616298Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def init_random_seed(value=42):\n    # random.seed(value)\n    np.random.seed(value)\n    torch.manual_seed(value)\n    torch.cuda.manual_seed(value)\n    # torch.backends.cudnn.deterministic = True","metadata":{"execution":{"iopub.status.busy":"2023-11-12T19:40:56.617957Z","iopub.status.idle":"2023-11-12T19:40:56.618267Z","shell.execute_reply.started":"2023-11-12T19:40:56.618113Z","shell.execute_reply":"2023-11-12T19:40:56.618127Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"init_random_seed(RANDOM_SEED)","metadata":{"execution":{"iopub.status.busy":"2023-11-12T19:40:56.619533Z","iopub.status.idle":"2023-11-12T19:40:56.619894Z","shell.execute_reply.started":"2023-11-12T19:40:56.619702Z","shell.execute_reply":"2023-11-12T19:40:56.619718Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_grid(grid_name: str, grids_path: str) -> dict:\n    with open(grids_path, \"r\", encoding=\"utf-8\") as f:\n        return json.load(f)[grid_name]","metadata":{"execution":{"iopub.status.busy":"2023-11-12T19:40:56.621169Z","iopub.status.idle":"2023-11-12T19:40:56.621660Z","shell.execute_reply.started":"2023-11-12T19:40:56.621459Z","shell.execute_reply":"2023-11-12T19:40:56.621479Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"MAX_TRAJ_LEN = 299\n\ngrid_name = \"extra\"\n\ngrid_name_to_grid_path = os.path.join(DATA_ROOT, \"gridname_to_grid.json\")\ngrid_name_to_grid = {grid_name: get_grid(grid_name, grid_name_to_grid_path)}\n\n\nkb_tokenizer = KeyboardTokenizerv1()\nword_char_tokenizer = CharLevelTokenizerv2(os.path.join(DATA_ROOT, \"voc.txt\"))\nkeyboard_selection_set = set(kb_tokenizer.i2t)\n\ntrain_path = os.path.join(DATA_ROOT,\n                          \"train__extra_only_no_errors__2023_11_01__19_49_14.jsonl\")\n\n# In case the jupyter notebook is running in kaggle\n# with variables  persistence, I don't want it\n# to waste around 20 minutes creating train_dataset.\n\ntrain_dataset = NeuroSwipeDatasetv2(\n        data_path = train_path,\n        gridname_to_grid = grid_name_to_grid,\n        kb_tokenizer = kb_tokenizer,\n        max_traj_len = MAX_TRAJ_LEN,\n        word_tokenizer = word_char_tokenizer,\n        include_time = False,\n        include_velocities = True,\n        include_accelerations = True,\n        has_target=True,\n        has_one_grid_only=True,\n        include_grid_name=False,\n        keyboard_selection_set=keyboard_selection_set,\n        total = 349_172\n    )\n\nval_path = os.path.join(DATA_ROOT, \"valid__in_train_format__extra_only.jsonl\")\n\n\nval_dataset = NeuroSwipeDatasetv2(\n    data_path = val_path,\n    gridname_to_grid = grid_name_to_grid,\n    kb_tokenizer = kb_tokenizer,\n    max_traj_len = MAX_TRAJ_LEN,\n    word_tokenizer = word_char_tokenizer,\n    include_time = False,\n    include_velocities = True,\n    include_accelerations = True,\n    has_target=True,\n    has_one_grid_only=True,\n    include_grid_name=False,\n    keyboard_selection_set=keyboard_selection_set,\n    total = 584\n)","metadata":{"execution":{"iopub.status.busy":"2023-11-12T20:22:02.603107Z","iopub.execute_input":"2023-11-12T20:22:02.603942Z","iopub.status.idle":"2023-11-12T20:23:24.537050Z","shell.execute_reply.started":"2023-11-12T20:22:02.603908Z","shell.execute_reply":"2023-11-12T20:23:24.536047Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')","metadata":{"execution":{"iopub.status.busy":"2023-11-12T20:23:35.536799Z","iopub.execute_input":"2023-11-12T20:23:35.537669Z","iopub.status.idle":"2023-11-12T20:23:35.569801Z","shell.execute_reply.started":"2023-11-12T20:23:35.537632Z","shell.execute_reply":"2023-11-12T20:23:35.568848Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"transformer = get_m1_bigger_model(device)","metadata":{"execution":{"iopub.status.busy":"2023-11-12T20:23:39.256652Z","iopub.execute_input":"2023-11-12T20:23:39.257628Z","iopub.status.idle":"2023-11-12T20:23:39.315396Z","shell.execute_reply.started":"2023-11-12T20:23:39.257580Z","shell.execute_reply":"2023-11-12T20:23:39.314272Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def cross_entropy_with_reshape(pred, target, ignore_index=-100, label_smoothing=0.0):\n    \"\"\"\n    pred - BatchSize x TargetLen x VocabSize\n    target - BatchSize x TargetLen\n    \"\"\"\n    pred_flat = pred.view(-1, pred.shape[-1])  # BatchSize*TargetLen x VocabSize\n    target_flat = target.reshape(-1)  # BatchSize*TargetLen\n    return F.cross_entropy(pred_flat,\n                           target_flat,\n                           ignore_index=ignore_index,\n                           label_smoothing=label_smoothing)","metadata":{"execution":{"iopub.status.busy":"2023-11-12T20:23:40.416580Z","iopub.execute_input":"2023-11-12T20:23:40.416981Z","iopub.status.idle":"2023-11-12T20:23:40.450010Z","shell.execute_reply.started":"2023-11-12T20:23:40.416950Z","shell.execute_reply":"2023-11-12T20:23:40.448896Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def lr_scheduler(optimizer):\n    return torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer,\n                                                      patience=20,\n                                                      factor=0.5,\n                                                      verbose=True)","metadata":{"execution":{"iopub.status.busy":"2023-11-12T20:23:41.312377Z","iopub.execute_input":"2023-11-12T20:23:41.312705Z","iopub.status.idle":"2023-11-12T20:23:41.344141Z","shell.execute_reply.started":"2023-11-12T20:23:41.312680Z","shell.execute_reply":"2023-11-12T20:23:41.343207Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import traceback\nfrom datetime import datetime\nimport copy\n\nfrom typing import Callable\n\n\ndef train_eval_loop(model, train_dataset, val_dataset, criterion,\n                    lr=1e-4, epoch_n=10, batch_size=32,\n                    device=None, early_stopping_patience=10, l2_reg_alpha=0,\n                    max_batches_per_epoch_train=10000,\n                    max_batches_per_epoch_val=1000,\n                    data_loader_ctor=DataLoader,\n                    optimizer_ctor=None,\n                    lr_scheduler_ctor=None,\n                    shuffle_train=True,\n                    label_smoothing = 0.0,\n                    dataloader_workers_n=0,\n                    criterion_ignore_index = -100,\n                    model_name_postfix = \"\",\n                    model_save_root = \".\",\n                    prepare_batch: Callable = lambda x, y: (x, y)):\n    \"\"\"\n    Цикл для обучения модели. После каждой эпохи качество модели оценивается по отложенной выборке.\n    :param model: torch.nn.Module - обучаемая модель\n    :param train_dataset: torch.utils.data.Dataset - данные для обучения\n    :param val_dataset: torch.utils.data.Dataset - данные для оценки качества\n    :param criterion: функция потерь для настройки модели\n    :param lr: скорость обучения\n    :param epoch_n: максимальное количество эпох\n    :param batch_size: количество примеров, обрабатываемых моделью за одну итерацию\n    :param device: cuda/cpu - устройство, на котором выполнять вычисления\n    :param early_stopping_patience: наибольшее количество эпох, в течение которых допускается\n        отсутствие улучшения модели, чтобы обучение продолжалось.\n    :param l2_reg_alpha: коэффициент L2-регуляризации\n    :param max_batches_per_epoch_train: максимальное количество итераций на одну эпоху обучения\n    :param max_batches_per_epoch_val: максимальное количество итераций на одну эпоху валидации\n    :param data_loader_ctor: функция для создания объекта, преобразующего датасет в батчи\n        (по умолчанию torch.utils.data.DataLoader)\n    :return: кортеж из двух элементов:\n        - среднее значение функции потерь на валидации на лучшей эпохе\n        - лучшая модель\n    \"\"\"\n    if device is None:\n        device =  torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n\n    model.to(device)\n\n    if optimizer_ctor is None:\n        optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=l2_reg_alpha)\n    else:\n        optimizer = optimizer_ctor(model.parameters(), lr=lr)\n\n    if lr_scheduler_ctor is not None:\n        lr_scheduler = lr_scheduler_ctor(optimizer)\n    else:\n        lr_scheduler = None\n\n    train_dataloader = data_loader_ctor(train_dataset, batch_size=batch_size, shuffle=shuffle_train,\n                                        num_workers=dataloader_workers_n)\n    val_dataloader = data_loader_ctor(val_dataset, batch_size=batch_size, shuffle=False,\n                                      num_workers=dataloader_workers_n)\n\n    best_val_loss = float('inf')\n    best_epoch_i = 0\n\n    best_model_path = \"m1_bigger_v2.pt\"\n    best_model = copy.deepcopy(model)\n\n    if os.path.exists(best_model_path):\n        best_model.load_state_dict(torch.load(best_model_path))\n        print(f\"Загружено состояние модели {best_model_path}\")\n\n    for epoch_i in tqdm(range(epoch_n), position = 0):\n        try:\n            model.train()\n            mean_train_loss = 0\n            train_batches_n = 0\n            for batch_i, (batch_x, batch_y) in tqdm(enumerate(train_dataloader), total = min(max_batches_per_epoch_train, len(train_dataset) // batch_size), position=1, leave = False):\n                if batch_i > max_batches_per_epoch_train:\n                    break\n\n                batch_x, batch_y = prepare_batch(batch_x, batch_y, device)\n\n                pred = model(*batch_x)\n                loss = criterion(pred, batch_y, ignore_index = criterion_ignore_index, label_smoothing=label_smoothing)\n\n                model.zero_grad()\n                loss.backward()\n\n                optimizer.step()\n\n                mean_train_loss += float(loss)\n                train_batches_n += 1\n\n            mean_train_loss /= train_batches_n\n            \n            print('Среднее значение функции потерь на обучении', mean_train_loss)\n\n\n\n            model.eval()\n            mean_val_loss = 0\n            val_batches_n = 0\n\n            with torch.no_grad():\n                for batch_i, (batch_x, batch_y) in enumerate(val_dataloader):\n                    if batch_i > max_batches_per_epoch_val:\n                        break\n\n                    batch_x, batch_y = prepare_batch(batch_x, batch_y, device)\n\n                    pred = model(*batch_x)\n                    loss = criterion(pred, batch_y, ignore_index = criterion_ignore_index, label_smoothing=label_smoothing)\n\n                    mean_val_loss += float(loss)\n                    val_batches_n += 1\n\n            mean_val_loss /= val_batches_n\n            print('Среднее значение функции потерь на валидации', mean_val_loss)\n\n            if mean_val_loss < best_val_loss:\n                best_epoch_i = epoch_i\n                best_val_loss = mean_val_loss\n                best_model = copy.deepcopy(model)\n                torch.save(model.state_dict(), os.path.join(model_save_root, best_model_path))\n                cur_time = \"{:%Y_%m_%d__%H_%M_%S}\".format(datetime.now())\n                \n                grid_name_to_greedy_generator = {grid_name: GreedyGenerator(model, word_char_tokenizer, device)}\n                greedy_predictions = predict_greedy_raw(val_dataset, grid_name_to_greedy_generator)\n                greedy_accuracy = sum(greedy_prediction == val_target for greedy_prediction, val_target in zip(greedy_predictions, val_targets)) / len(val_targets)\n                \n                torch.save(model.state_dict(), os.path.join(model_save_root, f\"m1_bigger_v2__{cur_time}__{mean_val_loss:.5f}__greed_acc_{greedy_accuracy:.5f}__{model_name_postfix}.pt\"))\n                print(f\"Greedy accuracy = {greedy_accuracy}\")\n                print('Новая лучшая модель!')\n            elif epoch_i - best_epoch_i > early_stopping_patience:\n                print('Модель не улучшилась за последние {} эпох, прекращаем обучение'.format(\n                    early_stopping_patience))\n                break\n\n            if lr_scheduler is not None:\n                lr_scheduler.step(mean_val_loss)\n\n            print()\n        except KeyboardInterrupt:\n            print('Досрочно остановлено пользователем')\n            break\n        except Exception as ex:\n            print('Ошибка при обучении: {}\\n{}'.format(ex, traceback.format_exc()))\n            break\n\n    return best_val_loss, best_model\n","metadata":{"execution":{"iopub.status.busy":"2023-11-12T20:23:44.044741Z","iopub.execute_input":"2023-11-12T20:23:44.045113Z","iopub.status.idle":"2023-11-12T20:23:44.096892Z","shell.execute_reply.started":"2023-11-12T20:23:44.045087Z","shell.execute_reply":"2023-11-12T20:23:44.095892Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tqdm.notebook import tqdm\n","metadata":{"execution":{"iopub.status.busy":"2023-11-12T20:23:46.032644Z","iopub.execute_input":"2023-11-12T20:23:46.033483Z","iopub.status.idle":"2023-11-12T20:23:46.064500Z","shell.execute_reply.started":"2023-11-12T20:23:46.033449Z","shell.execute_reply":"2023-11-12T20:23:46.063561Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def truncate_padding(seq, mask):\n    max_curve_len = int(torch.max(torch.sum(~mask, dim = 1)))\n    seq = seq[:, :max_curve_len]\n    mask = mask[:, :max_curve_len]\n    return seq, mask\n\ndef prepare_batch_with_pad_truncation(x, y, device):\n    (xyt, kb_tokens, dec_in_char_seq, traj_pad_mask, word_pad_mask), dec_out_char_seq = x, y\n\n    xyt, traj_pad_mask = truncate_padding(xyt, traj_pad_mask)\n    kb_tokens, traj_pad_mask = truncate_padding(kb_tokens, traj_pad_mask)\n#     dec_in_char_seq, word_pad_mask = truncate_padding(kb_tokens, traj_pad_mask)\n#     dec_out_char_seq, word_pad_mask = truncate_padding(kb_tokens, traj_pad_mask)\n\n    # print(max_curve_len)\n\n    xyt = xyt.transpose_(0, 1).to(device)  # (curves_seq_len, batch_size, n_coord_feats)\n    kb_tokens = kb_tokens.transpose_(0, 1).to(device) # (curves_seq_len, batch_size)\n    dec_in_char_seq = dec_in_char_seq.transpose_(0, 1).to(device)  # (chars_seq_len - 1, batch_size)\n    dec_out_char_seq = dec_out_char_seq.transpose_(0, 1).to(device)  # (chars_seq_len - 1, batch_size)\n\n    traj_pad_mask = traj_pad_mask.to(device)  # (batch_size, max_curve_len)\n    # traj_pad_mask = torch.zeros_like(kb_tokens, dtype = torch.bool).transpose_(0, 1).to(device)\n    word_pad_mask = word_pad_mask.to(device)  # (batch_size, chars_seq_len - 1)\n\n    return (xyt, kb_tokens, dec_in_char_seq, traj_pad_mask, word_pad_mask), dec_out_char_seq\n\nprepare_batch = prepare_batch_with_pad_truncation","metadata":{"execution":{"iopub.status.busy":"2023-11-12T20:23:46.921706Z","iopub.execute_input":"2023-11-12T20:23:46.922446Z","iopub.status.idle":"2023-11-12T20:23:46.958458Z","shell.execute_reply.started":"2023-11-12T20:23:46.922415Z","shell.execute_reply":"2023-11-12T20:23:46.957522Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from typing import List\n\ndef predict_greedy_raw(dataset,\n                       grid_name_to_greedy_generator,\n                      ) -> List[List[str]]:\n    \"\"\"\n    Creates predictions using greedy generation.\n    \n    Arguments:\n    ----------\n    dataset: NeuroSwipeDatasetv2\n    grid_name_to_greedy_generator: dict\n        Dict mapping grid names to GreedyGenerator objects.\n    \"\"\"\n    preds = [None] * len(dataset)\n\n    for data in tqdm(enumerate(dataset), total=len(dataset)):\n#         i, ((xyt, kb_tokens, _, traj_pad_mask, _), _, grid_name) = data\n        i, ((xyt, kb_tokens, _, traj_pad_mask, _), _) = data\n\n        pred = grid_name_to_greedy_generator[grid_name](xyt, kb_tokens, traj_pad_mask)\n        pred = pred.removeprefix(\"<sos>\")\n#         preds[i] = [pred]\n        preds[i] = pred\n\n    return preds","metadata":{"execution":{"iopub.status.busy":"2023-11-12T20:23:48.873666Z","iopub.execute_input":"2023-11-12T20:23:48.874050Z","iopub.status.idle":"2023-11-12T20:23:48.907564Z","shell.execute_reply.started":"2023-11-12T20:23:48.874021Z","shell.execute_reply":"2023-11-12T20:23:48.906531Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from typing import List\ndef get_targets(dataset: NeuroSwipeDatasetv2) -> List[str]:\n    targets = []\n    for (_, _, _, _, word_pad_mask), target_tokens in dataset:\n        target_len = int(torch.sum(~word_pad_mask)) - 1\n        target = word_char_tokenizer.decode(target_tokens[:target_len])\n        targets.append(target)\n    return targets\n","metadata":{"execution":{"iopub.status.busy":"2023-11-12T20:24:01.538439Z","iopub.execute_input":"2023-11-12T20:24:01.538805Z","iopub.status.idle":"2023-11-12T20:24:01.572588Z","shell.execute_reply.started":"2023-11-12T20:24:01.538776Z","shell.execute_reply":"2023-11-12T20:24:01.571318Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"val_targets = get_targets(val_dataset)","metadata":{"execution":{"iopub.status.busy":"2023-11-12T20:24:02.044542Z","iopub.execute_input":"2023-11-12T20:24:02.044918Z","iopub.status.idle":"2023-11-12T20:24:02.375529Z","shell.execute_reply.started":"2023-11-12T20:24:02.044887Z","shell.execute_reply":"2023-11-12T20:24:02.374693Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"transformer.load_state_dict(\n    torch.load(\"/kaggle/working/m1_bigger_v2__2023_11_12__15_09_14__0.13099__greed_acc_0.85939__default_l2_0_ls0_switch_2.pt\",\n              map_location = device))","metadata":{"execution":{"iopub.status.busy":"2023-11-12T20:24:32.674507Z","iopub.execute_input":"2023-11-12T20:24:32.674900Z","iopub.status.idle":"2023-11-12T20:24:32.741021Z","shell.execute_reply.started":"2023-11-12T20:24:32.674866Z","shell.execute_reply":"2023-11-12T20:24:32.739779Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"grid_name_to_greedy_generator = {grid_name: GreedyGenerator(transformer, word_char_tokenizer, device)}","metadata":{"execution":{"iopub.status.busy":"2023-11-12T20:24:33.070549Z","iopub.execute_input":"2023-11-12T20:24:33.070945Z","iopub.status.idle":"2023-11-12T20:24:33.104039Z","shell.execute_reply.started":"2023-11-12T20:24:33.070916Z","shell.execute_reply":"2023-11-12T20:24:33.103129Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"greedy_predictions = predict_greedy_raw(val_dataset, grid_name_to_greedy_generator)","metadata":{"execution":{"iopub.status.busy":"2023-11-12T20:24:33.415864Z","iopub.execute_input":"2023-11-12T20:24:33.416253Z","iopub.status.idle":"2023-11-12T20:24:54.729029Z","shell.execute_reply.started":"2023-11-12T20:24:33.416224Z","shell.execute_reply":"2023-11-12T20:24:54.727875Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sum(greedy_prediction == val_target for greedy_prediction, val_target in zip(greedy_predictions, val_targets)) / len(val_targets)","metadata":{"execution":{"iopub.status.busy":"2023-11-12T20:24:54.730735Z","iopub.execute_input":"2023-11-12T20:24:54.731087Z","iopub.status.idle":"2023-11-12T20:24:54.764898Z","shell.execute_reply.started":"2023-11-12T20:24:54.731059Z","shell.execute_reply":"2023-11-12T20:24:54.763881Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"l2_reg_alpha =  0 #5e-5\nlabel_smoothing=  0 #0.045\n\nbest_val_loss, best_model = train_eval_loop(\n    transformer, train_dataset, val_dataset, cross_entropy_with_reshape,\n    lr=1e-4, epoch_n=10000, batch_size=320,\n    device=device, early_stopping_patience=10, l2_reg_alpha=l2_reg_alpha,\n    max_batches_per_epoch_train=2000,\n    max_batches_per_epoch_val=1000,\n    data_loader_ctor=DataLoader,\n    optimizer_ctor=None,\n    lr_scheduler_ctor=lr_scheduler,\n    shuffle_train=True,\n    dataloader_workers_n=0,\n    criterion_ignore_index = word_char_tokenizer.char_to_idx['<pad>'],\n    model_name_postfix = f'{grid_name}_l2_{l2_reg_alpha}_ls{label_smoothing}_switch_2',\n    prepare_batch=prepare_batch,\n    model_save_root = \"../..\",\n    label_smoothing=label_smoothing\n)","metadata":{"execution":{"iopub.status.busy":"2023-11-12T20:25:51.944090Z","iopub.execute_input":"2023-11-12T20:25:51.944469Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# First epoch: \n\n# Среднее значение функции потерь на обучении 1.2045975528854778\n# Среднее значение функции потерь на валидации 0.5010274122158687","metadata":{"execution":{"iopub.status.busy":"2023-11-12T19:40:56.651049Z","iopub.status.idle":"2023-11-12T19:40:56.651365Z","shell.execute_reply.started":"2023-11-12T19:40:56.651204Z","shell.execute_reply":"2023-11-12T19:40:56.651218Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"```\nСреднее значение функции потерь на обучении 1.2045975528854778\nСреднее значение функции потерь на валидации 0.5010274122158687\nНовая лучшая модель!\n\n2001/? [11:46<00:00, 2.94it/s]\nСреднее значение функции потерь на обучении 0.9051285277063521\nСреднее значение функции потерь на валидации 0.4248993237813314\nНовая лучшая модель!\n\n2001/? [11:43<00:00, 2.76it/s]\nСреднее значение функции потерь на обучении 0.8538736782331338\nСреднее значение функции потерь на валидации 0.3928388337294261\nНовая лучшая модель!\n\n2001/? [11:43<00:00, 2.56it/s]\nСреднее значение функции потерь на обучении 0.8256472818914621\nСреднее значение функции потерь на валидации 0.3676854441563288\nНовая лучшая модель!\n\n2001/? [11:40<00:00, 2.64it/s]\nСреднее значение функции потерь на обучении 0.8055656312823832\nСреднее значение функции потерь на валидации 0.35403793156147\nНовая лучшая модель!\n\n2001/? [11:42<00:00, 2.82it/s]\nСреднее значение функции потерь на обучении 0.791520650925367\nСреднее значение функции потерь на валидации 0.34193819264570874\nНовая лучшая модель!\n\n2001/? [11:41<00:00, 3.06it/s]\nСреднее значение функции потерь на обучении 0.7799409364593559\nСреднее значение функции потерь на валидации 0.3324617197116216\nНовая лучшая модель!\n\n2001/? [11:44<00:00, 2.47it/s]\nСреднее значение функции потерь на обучении 0.7715481882807852\nСреднее значение функции потерь на валидации 0.3211148182551066\nНовая лучшая модель!\n\n2001/? [11:41<00:00, 3.06it/s]\nСреднее значение функции потерь на обучении 0.7643214609550274\nСреднее значение функции потерь на валидации 0.31518318951129914\nНовая лучшая модель!\n\n2001/? [11:41<00:00, 2.85it/s]\nСреднее значение функции потерь на обучении 0.7581036963324616\nСреднее значение функции потерь на валидации 0.3094484398762385\nНовая лучшая модель!\n\n2001/? [11:46<00:00, 2.62it/s]\nСреднее значение функции потерь на обучении 0.7524177488358482\nСреднее значение функции потерь на валидации 0.3030394206444422\nНовая лучшая модель!\n\n2001/? [11:45<00:00, 2.86it/s]\nСреднее значение функции потерь на обучении 0.7466873974576108\nСреднее значение функции потерь на валидации 0.2996497412522634\nНовая лучшая модель!\n\n2001/? [11:45<00:00, 2.80it/s]\nСреднее значение функции потерь на обучении 0.7439289238975979\nСреднее значение функции потерь на валидации 0.29270503520965574\nНовая лучшая модель!\n\n2001/? [11:44<00:00, 2.80it/s]\nСреднее значение функции потерь на обучении 0.739722256002755\nСреднее значение функции потерь на валидации 0.2876604378223419\nНовая лучшая модель!\n\n2001/? [11:43<00:00, 2.66it/s]\nСреднее значение функции потерь на обучении 0.7350960545751942\nСреднее значение функции потерь на валидации 0.28610232720772427\nНовая лучшая модель!\n\n2001/? [11:42<00:00, 2.75it/s]\nСреднее значение функции потерь на обучении 0.7321513988327111\nСреднее значение функции потерь на валидации 0.28779847621917726\n\n2001/? [11:44<00:00, 2.98it/s]\nСреднее значение функции потерь на обучении 0.7278626844145428\nСреднее значение функции потерь на валидации 0.2804383928577105\nНовая лучшая модель!\n\n2001/? [11:44<00:00, 2.64it/s]\nСреднее значение функции потерь на обучении 0.7260185109860059\nСреднее значение функции потерь на валидации 0.2751611083745956\nНовая лучшая модель!\n\n2001/? [11:43<00:00, 2.92it/s]\nСреднее значение функции потерь на обучении 0.7236041619681168\nСреднее значение функции потерь на валидации 0.27163358430067697\nНовая лучшая модель!\n\n2001/? [11:47<00:00, 2.97it/s]\nСреднее значение функции потерь на обучении 0.7213456676281553\nСреднее значение функции потерь на валидации 0.2692498445510864\nНовая лучшая модель!\n\n2001/? [11:52<00:00, 2.88it/s]\nСреднее значение функции потерь на обучении 0.7186731718171543\nСреднее значение функции потерь на валидации 0.2708129515250524\n\n2001/? [11:48<00:00, 3.01it/s]\nСреднее значение функции потерь на обучении 0.716283163626393\nСреднее значение функции потерь на валидации 0.268450199564298\nНовая лучшая модель!\n\n2001/? [11:44<00:00, 3.02it/s]\nСреднее значение функции потерь на обучении 0.7147186489059948\nСреднее значение функции потерь на валидации 0.2660525545477867\nНовая лучшая модель!\n\n2001/? [11:42<00:00, 2.87it/s]\nСреднее значение функции потерь на обучении 0.7126921191923264\nСреднее значение функции потерь на валидации 0.263121996819973\nНовая лучшая модель!\n\n2001/? [11:42<00:00, 3.00it/s]\nСреднее значение функции потерь на обучении 0.7097944344418576\nСреднее значение функции потерь на валидации 0.2610153297583262\nНовая лучшая модель!\n```","metadata":{}},{"cell_type":"markdown","source":"Around 32 epoches alpha = 0. Then alpha = 1e-4","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}