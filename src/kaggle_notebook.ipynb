{"cells":[{"cell_type":"code","execution_count":14,"metadata":{"execution":{"iopub.execute_input":"2023-12-28T23:19:43.373586Z","iopub.status.busy":"2023-12-28T23:19:43.372693Z","iopub.status.idle":"2023-12-28T23:19:43.406294Z","shell.execute_reply":"2023-12-28T23:19:43.405097Z","shell.execute_reply.started":"2023-12-28T23:19:43.373552Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["The autoreload extension is already loaded. To reload it, use:\n","  %reload_ext autoreload\n"]}],"source":["%load_ext autoreload\n","%autoreload 2"]},{"cell_type":"code","execution_count":15,"metadata":{"execution":{"iopub.execute_input":"2023-12-28T23:20:00.050973Z","iopub.status.busy":"2023-12-28T23:20:00.050603Z","iopub.status.idle":"2023-12-28T23:20:02.969759Z","shell.execute_reply":"2023-12-28T23:20:02.968758Z","shell.execute_reply.started":"2023-12-28T23:20:00.050945Z"},"trusted":true},"outputs":[],"source":["# !git clone https://github.com/proshian/yandex-cup-2023-ml-neuroswipe.git\n","# %cd yandex-cup-2023-ml-neuroswipe\n","# ! git checkout remake_after_finals "]},{"cell_type":"code","execution_count":16,"metadata":{"execution":{"iopub.execute_input":"2023-12-28T23:20:11.334677Z","iopub.status.busy":"2023-12-28T23:20:11.333900Z","iopub.status.idle":"2023-12-28T23:20:59.222596Z","shell.execute_reply":"2023-12-28T23:20:59.221480Z","shell.execute_reply.started":"2023-12-28T23:20:11.334642Z"},"trusted":true},"outputs":[],"source":["# !pip install dvc --quiet\n","# !pip install dvc_gdrive --quiet"]},{"cell_type":"code","execution_count":19,"metadata":{"execution":{"iopub.execute_input":"2023-12-28T23:21:56.386145Z","iopub.status.busy":"2023-12-28T23:21:56.385847Z","iopub.status.idle":"2023-12-28T23:21:56.424359Z","shell.execute_reply":"2023-12-28T23:21:56.423480Z","shell.execute_reply.started":"2023-12-28T23:21:56.386116Z"},"trusted":true},"outputs":[],"source":["# %cd /kaggle/working/yandex-cup-2023-ml-neuroswipe/src"]},{"cell_type":"code","execution_count":20,"metadata":{"execution":{"iopub.execute_input":"2023-12-28T23:22:02.891136Z","iopub.status.busy":"2023-12-28T23:22:02.890270Z","iopub.status.idle":"2023-12-28T23:22:02.922511Z","shell.execute_reply":"2023-12-28T23:22:02.921698Z","shell.execute_reply.started":"2023-12-28T23:22:02.891098Z"},"trusted":true},"outputs":[],"source":["import os\n","import json\n","\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torch.utils.data import Dataset, DataLoader, IterableDataset\n","from tqdm.notebook import tqdm\n","import numpy as np\n","\n","from model import SwipeCurveTransformer, get_m1_bigger_model\n","from tokenizers import CharLevelTokenizerv2, KeyboardTokenizerv1\n","from tokenizers import ALL_CYRILLIC_LETTERS_ALPHABET_ORD\n","from dataset import NeuroSwipeDatasetv3\n","from word_generators import GreedyGenerator\n","from utils import prepare_batch\n"]},{"cell_type":"code","execution_count":45,"metadata":{"execution":{"iopub.execute_input":"2023-12-28T23:22:03.084125Z","iopub.status.busy":"2023-12-28T23:22:03.083736Z","iopub.status.idle":"2023-12-28T23:22:04.352861Z","shell.execute_reply":"2023-12-28T23:22:04.351619Z","shell.execute_reply.started":"2023-12-28T23:22:03.084096Z"},"trusted":true},"outputs":[],"source":["BATCH_SIZE = 32\n","IN_KAGGLE = False\n","RANDOM_SEED = 12\n","DATA_ROOT = \"../data/data_separated_grid\"\n","MODELS_DIR = \"../data/trained_models/m1\"\n","TRAIN_DATA_PATH = os.path.join(DATA_ROOT, \"train__extra_only_no_errors__2023_11_01__19_49_14.jsonl\")\n","VAL_DATA_PATH = os.path.join(DATA_ROOT, \"valid__in_train_format__extra_only.jsonl\")\n","\n","# keyboard_selection_set is a set of labels of keys that will be\n","# considered when finding the nearest keyboard label.  In this\n","# case only cyrillic letters are considered. This means that\n","# all action keys like \"shift\", \"backspace\", \"enter\", etc. are excluded.\n","DS_KWARGS = dict(\n","    include_time = False,\n","    include_velocities = True,\n","    include_accelerations = True,\n","    has_target=True,\n","    has_one_grid_only=True,\n","    include_grid_name=False,\n","    keyboard_selection_set=set(ALL_CYRILLIC_LETTERS_ALPHABET_ORD)\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":25,"metadata":{},"outputs":[],"source":["# if IN_KAGGLE:\n","#     DATA_ROOT = \"/kaggle/input/neuroswipe-defualt-only-v1\"\n","#     MODELS_DIR = \"\"\n","# else:\n","#     DATA_ROOT = \"../data/data_separated_grid\"\n","#     MODELS_DIR = \"../data/trained_models/m1\""]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":27,"metadata":{"execution":{"iopub.execute_input":"2023-12-28T23:22:04.355242Z","iopub.status.busy":"2023-12-28T23:22:04.354940Z","iopub.status.idle":"2023-12-28T23:22:06.649243Z","shell.execute_reply":"2023-12-28T23:22:06.648143Z","shell.execute_reply.started":"2023-12-28T23:22:04.355216Z"},"trusted":true},"outputs":[],"source":["def init_random_seed(value=42):\n","    # random.seed(value)\n","    np.random.seed(value)\n","    torch.manual_seed(value)\n","    torch.cuda.manual_seed(value)\n","    # torch.backends.cudnn.deterministic = True"]},{"cell_type":"code","execution_count":28,"metadata":{"execution":{"iopub.execute_input":"2023-12-28T23:22:06.839109Z","iopub.status.busy":"2023-12-28T23:22:06.838329Z","iopub.status.idle":"2023-12-28T23:22:06.874891Z","shell.execute_reply":"2023-12-28T23:22:06.873660Z","shell.execute_reply.started":"2023-12-28T23:22:06.839050Z"},"trusted":true},"outputs":[],"source":["def get_grid(grid_name: str, grids_path: str) -> dict:\n","    with open(grids_path, \"r\", encoding=\"utf-8\") as f:\n","        return json.load(f)[grid_name]"]},{"cell_type":"code","execution_count":71,"metadata":{},"outputs":[],"source":["def get_datasets(grid_name: str, grid_name_to_grid_path: str,\n","                 train_data_path: str, val_data_path: str,\n","                 ds_kwargs: dict, kb_tokenizer: KeyboardTokenizerv1,\n","                 word_char_tokenizer: CharLevelTokenizerv2\n","                 ) -> tuple[NeuroSwipeDatasetv3, NeuroSwipeDatasetv3]:\n","    \n","    gridname_to_grid  = {grid_name: get_grid(grid_name, grid_name_to_grid_path)}\n","\n","    train_ds = NeuroSwipeDatasetv3(\n","        data_path=train_data_path,\n","        gridname_to_grid = gridname_to_grid,\n","        kb_tokenizer=kb_tokenizer,\n","        word_tokenizer =word_char_tokenizer,\n","        total = 349_172,\n","        **ds_kwargs\n","    )\n","\n","    val_ds = NeuroSwipeDatasetv3(\n","        data_path=val_data_path,\n","        gridname_to_grid =gridname_to_grid,\n","        kb_tokenizer=kb_tokenizer,\n","        word_tokenizer =word_char_tokenizer,\n","        total = 10_000,\n","        **ds_kwargs\n","    )\n","\n","    return train_ds, val_ds"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":72,"metadata":{},"outputs":[],"source":["init_random_seed(RANDOM_SEED)"]},{"cell_type":"code","execution_count":73,"metadata":{"execution":{"iopub.execute_input":"2023-12-28T23:22:06.876879Z","iopub.status.busy":"2023-12-28T23:22:06.876445Z","iopub.status.idle":"2023-12-28T23:23:29.126181Z","shell.execute_reply":"2023-12-28T23:23:29.125326Z","shell.execute_reply.started":"2023-12-28T23:22:06.876839Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|██████████| 349172/349172 [01:16<00:00, 4569.90it/s]\n","  6%|▌         | 584/10000 [00:00<00:01, 5560.65it/s]\n"]}],"source":["# Pickling the dataset would be great to not waste\n","# around 20 minutes creating train_dataset.\n","\n","kb_tokenizer = KeyboardTokenizerv1()\n","voc_path=os.path.join(DATA_ROOT, \"voc.txt\")\n","word_char_tokenizer = CharLevelTokenizerv2(voc_path)\n","\n","train_dataset, val_dataset = get_datasets(\n","    grid_name=\"extra\",\n","    grid_name_to_grid_path=os.path.join(DATA_ROOT, \"gridname_to_grid.json\"),\n","    train_data_path=TRAIN_DATA_PATH,\n","    val_data_path=VAL_DATA_PATH,\n","    ds_kwargs=DS_KWARGS,\n","    kb_tokenizer=kb_tokenizer,\n","    word_char_tokenizer=word_char_tokenizer,\n",")"]},{"cell_type":"code","execution_count":39,"metadata":{"execution":{"iopub.execute_input":"2023-12-28T23:23:29.127441Z","iopub.status.busy":"2023-12-28T23:23:29.127189Z","iopub.status.idle":"2023-12-28T23:23:29.179012Z","shell.execute_reply":"2023-12-28T23:23:29.178267Z","shell.execute_reply.started":"2023-12-28T23:23:29.127419Z"},"trusted":true},"outputs":[],"source":["device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"]},{"cell_type":"code","execution_count":40,"metadata":{"execution":{"iopub.execute_input":"2023-12-28T23:23:29.180249Z","iopub.status.busy":"2023-12-28T23:23:29.180006Z","iopub.status.idle":"2023-12-28T23:23:32.439542Z","shell.execute_reply":"2023-12-28T23:23:32.438675Z","shell.execute_reply.started":"2023-12-28T23:23:29.180228Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["c:\\Users\\proshian\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\transformer.py:282: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n","  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n"]}],"source":["transformer = get_m1_bigger_model(device)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":[]},{"cell_type":"code","execution_count":41,"metadata":{"execution":{"iopub.execute_input":"2023-12-28T23:23:38.650956Z","iopub.status.busy":"2023-12-28T23:23:38.650325Z","iopub.status.idle":"2023-12-28T23:23:38.683288Z","shell.execute_reply":"2023-12-28T23:23:38.682306Z","shell.execute_reply.started":"2023-12-28T23:23:38.650923Z"},"trusted":true},"outputs":[],"source":["def cross_entropy_with_reshape(pred, target, ignore_index=-100, label_smoothing=0.0):\n","    \"\"\"\n","    pred - BatchSize x TargetLen x VocabSize\n","    target - BatchSize x TargetLen\n","    \"\"\"\n","    pred_flat = pred.view(-1, pred.shape[-1])  # BatchSize*TargetLen x VocabSize\n","    target_flat = target.reshape(-1)  # BatchSize*TargetLen\n","    return F.cross_entropy(pred_flat,\n","                           target_flat,\n","                           ignore_index=ignore_index,\n","                           label_smoothing=label_smoothing)"]},{"cell_type":"code","execution_count":42,"metadata":{"execution":{"iopub.execute_input":"2023-12-28T23:23:39.110428Z","iopub.status.busy":"2023-12-28T23:23:39.109645Z","iopub.status.idle":"2023-12-28T23:23:39.141174Z","shell.execute_reply":"2023-12-28T23:23:39.140292Z","shell.execute_reply.started":"2023-12-28T23:23:39.110395Z"},"trusted":true},"outputs":[],"source":["def lr_scheduler(optimizer):\n","    return torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer,\n","                                                      patience=20,\n","                                                      factor=0.5,\n","                                                      verbose=True)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":43,"metadata":{"execution":{"iopub.execute_input":"2023-12-29T00:05:52.914828Z","iopub.status.busy":"2023-12-29T00:05:52.914068Z","iopub.status.idle":"2023-12-29T00:05:52.949519Z","shell.execute_reply":"2023-12-29T00:05:52.948535Z","shell.execute_reply.started":"2023-12-29T00:05:52.914793Z"},"trusted":true},"outputs":[],"source":["from torch.nn.utils.rnn import pad_sequence\n","\n","\n","def collate_fn(batch: list):\n","    \"\"\"\n","    batch - list of tuples:\n","    ((traj_feats, kb_tokens, dec_in_char_seq, word_pad_mask), dec_out_char_seq)\n","    \"\"\"\n","    x, dec_out_char_seq = zip(*batch)\n","    (traj_feats, kb_tokens, dec_in_char_seq, word_pad_mask) = zip(*x)\n","\n","    traj_lens = torch.tensor([len(x) for x in traj_feats])\n","\n","    # traj_feats[i].shape = (curve_len, n_coord_feats)\n","    traj_feats = pad_sequence(traj_feats, batch_first=False)  # (curves_len, batch_size, n_coord_feats)\n","    # kb_tokens[i].shape = (curve_len,) \n","    kb_tokens = pad_sequence(kb_tokens, batch_first=False)  # (curves_len, batch_size)\n","    \n","    dec_in_char_seq = torch.stack(dec_in_char_seq).transpose_(0, 1)  # (chars_seq_len - 1, batch_size)\n","    dec_out_char_seq = torch.stack(dec_out_char_seq).transpose_(0, 1)  # (chars_seq_len - 1, batch_size)\n","    word_pad_mask = torch.stack(word_pad_mask)\n","\n","    \n","    \n","\n","    max_curve_len = traj_feats.shape[0]\n","    \n","    # ! Проверить. Мб переделать с помощью slicing'а\n","    traj_pad_mask = torch.arange(max_curve_len).expand(len(traj_lens), max_curve_len) >= traj_lens.unsqueeze(1)  # (batch_size, max_curve_len)    \n","\n","    return (traj_feats, kb_tokens, dec_in_char_seq, traj_pad_mask, word_pad_mask), dec_out_char_seq"]},{"cell_type":"code","execution_count":60,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":84,"metadata":{},"outputs":[],"source":["# Протестируем корректность collate_fn (вызывается неявно в DataLoader)\n","\n","batch_size = 4\n","\n","\n","PAD_CHAR_TOKEN = word_char_tokenizer.char_to_idx[\"<pad>\"]\n","\n","\n","train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=False,\n","                                        num_workers=0, collate_fn=collate_fn)\n","\n","\n","dataset_els = [train_dataset[i] for i in range(batch_size)]\n","unprocessed_batch_x = [el[0] for el in dataset_els]\n","unprocessed_batch_y = [el[1] for el in dataset_els]\n","\n","max_out_seq_len = max([len(y) for y in unprocessed_batch_y])\n","\n","batch_x, batch_y = next(iter(train_dataloader))\n","\n","\n","############### Проверка корректности batch_y ###################\n","assert batch_y.shape == (max_out_seq_len, batch_size)\n","\n","\n","for i in range(batch_size):\n","    assert (batch_y[:len(unprocessed_batch_y[i]), i] == unprocessed_batch_y[i]).all()\n","    assert (batch_y[len(unprocessed_batch_y[i]):, i] == PAD_CHAR_TOKEN).all()\n","\n","print(\"batch_y is correct\")\n","\n","\n","############### Проверка корректности batch_x ###################"]},{"cell_type":"code","execution_count":78,"metadata":{},"outputs":[{"data":{"text/plain":["torch.Size([35, 4])"]},"execution_count":78,"metadata":{},"output_type":"execute_result"}],"source":["batch_y.shape "]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"data":{"text/plain":["tensor([[ 6, 11, 11, 14],\n","        [12, 20, 19, 20],\n","        [ 6, 16, 15, 33],\n","        [33,  9, 33, 35],\n","        [35, 12, 35, 35],\n","        [35,  1, 35, 35],\n","        [35, 33, 35, 35],\n","        [35, 35, 35, 35],\n","        [35, 35, 35, 35],\n","        [35, 35, 35, 35],\n","        [35, 35, 35, 35],\n","        [35, 35, 35, 35],\n","        [35, 35, 35, 35],\n","        [35, 35, 35, 35],\n","        [35, 35, 35, 35],\n","        [35, 35, 35, 35],\n","        [35, 35, 35, 35],\n","        [35, 35, 35, 35],\n","        [35, 35, 35, 35],\n","        [35, 35, 35, 35],\n","        [35, 35, 35, 35],\n","        [35, 35, 35, 35],\n","        [35, 35, 35, 35],\n","        [35, 35, 35, 35],\n","        [35, 35, 35, 35],\n","        [35, 35, 35, 35],\n","        [35, 35, 35, 35],\n","        [35, 35, 35, 35],\n","        [35, 35, 35, 35],\n","        [35, 35, 35, 35],\n","        [35, 35, 35, 35],\n","        [35, 35, 35, 35],\n","        [35, 35, 35, 35],\n","        [35, 35, 35, 35],\n","        [35, 35, 35, 35]])"]},"execution_count":63,"metadata":{},"output_type":"execute_result"}],"source":["batch_y.shape"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# batch_x, batch_y = prepare_batch(batch_x, batch_y, device)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":113,"metadata":{"execution":{"iopub.execute_input":"2023-12-29T00:06:02.654660Z","iopub.status.busy":"2023-12-29T00:06:02.654273Z","iopub.status.idle":"2023-12-29T00:06:02.704457Z","shell.execute_reply":"2023-12-29T00:06:02.703582Z","shell.execute_reply.started":"2023-12-29T00:06:02.654631Z"},"trusted":true},"outputs":[],"source":["import traceback\n","from datetime import datetime\n","import copy\n","\n","from typing import Callable\n","\n","\n","def train_eval_loop(model, train_dataset, val_dataset, criterion,\n","                    lr=1e-4, epoch_n=10, batch_size=BATCH_SIZE,\n","                    collate_fn = None,\n","                    device=None, early_stopping_patience=10, l2_reg_alpha=0,\n","                    max_batches_per_epoch_train=10000,\n","                    max_batches_per_epoch_val=1000,\n","                    optimizer_ctor=None,\n","                    lr_scheduler_ctor=None,\n","                    shuffle_train=True,\n","                    label_smoothing = 0.0,\n","                    dataloader_workers_n=0,\n","                    criterion_ignore_index = -100,\n","                    model_name_postfix = \"\",\n","                    model_save_root = \".\",\n","                    prepare_batch: Callable = lambda x, y: (x, y)):\n","    \"\"\"\n","    Цикл для обучения модели. После каждой эпохи качество модели оценивается по отложенной выборке.\n","    :param model: torch.nn.Module - обучаемая модель\n","    :param train_dataset: torch.utils.data.Dataset - данные для обучения\n","    :param val_dataset: torch.utils.data.Dataset - данные для оценки качества\n","    :param criterion: функция потерь для настройки модели\n","    :param lr: скорость обучения\n","    :param epoch_n: максимальное количество эпох\n","    :param batch_size: количество примеров, обрабатываемых моделью за одну итерацию\n","    :param device: cuda/cpu - устройство, на котором выполнять вычисления\n","    :param early_stopping_patience: наибольшее количество эпох, в течение которых допускается\n","        отсутствие улучшения модели, чтобы обучение продолжалось.\n","    :param l2_reg_alpha: коэффициент L2-регуляризации\n","    :param max_batches_per_epoch_train: максимальное количество итераций на одну эпоху обучения\n","    :param max_batches_per_epoch_val: максимальное количество итераций на одну эпоху валидации\n","    :return: кортеж из двух элементов:\n","        - среднее значение функции потерь на валидации на лучшей эпохе\n","        - лучшая модель\n","    \"\"\"\n","    if device is None:\n","        device =  torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","    model.to(device)\n","\n","    if optimizer_ctor is None:\n","        optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=l2_reg_alpha)\n","    else:\n","        optimizer = optimizer_ctor(model.parameters(), lr=lr)\n","\n","    if lr_scheduler_ctor is not None:\n","        lr_scheduler = lr_scheduler_ctor(optimizer)\n","    else:\n","        lr_scheduler = None\n","\n","    train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=shuffle_train,\n","                                        num_workers=dataloader_workers_n, collate_fn=collate_fn)\n","    val_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False,\n","                                      num_workers=dataloader_workers_n, collate_fn=collate_fn)\n","\n","    best_val_loss = float('inf')\n","    best_epoch_i = 0\n","\n","    best_model_path = \"m1_bigger_v2.pt\"\n","    best_model = copy.deepcopy(model)\n","\n","    if os.path.exists(best_model_path):\n","        best_model.load_state_dict(torch.load(best_model_path))\n","        print(f\"Загружено состояние модели {best_model_path}\")\n","\n","    for epoch_i in tqdm(range(epoch_n), position = 0):\n","        try:\n","            model.train()\n","            mean_train_loss = 0\n","            train_batches_n = 0\n","            for batch_i, (batch_x, batch_y) in tqdm(enumerate(train_dataloader), total = min(max_batches_per_epoch_train, len(train_dataset) // batch_size), position=1, leave = False):\n","                if batch_i > max_batches_per_epoch_train:\n","                    break\n","                    \n","\n","                batch_x, batch_y = prepare_batch(batch_x, batch_y, device)\n","\n","                pred = model(*batch_x)\n","                loss = criterion(pred, batch_y, ignore_index = criterion_ignore_index, label_smoothing=label_smoothing)\n","\n","                model.zero_grad()\n","                loss.backward()\n","\n","                optimizer.step()\n","\n","                mean_train_loss += float(loss)\n","                train_batches_n += 1\n","\n","            mean_train_loss /= train_batches_n\n","            \n","            print('Среднее значение функции потерь на обучении', mean_train_loss)\n","\n","\n","\n","            model.eval()\n","            mean_val_loss = 0\n","            val_batches_n = 0\n","\n","            with torch.no_grad():\n","                for batch_i, (batch_x, batch_y) in enumerate(val_dataloader):\n","                    if batch_i > max_batches_per_epoch_val:\n","                        break\n","\n","                    batch_x, batch_y = prepare_batch(batch_x, batch_y, device)\n","\n","                    pred = model(*batch_x)\n","                    loss = criterion(pred, batch_y, ignore_index = criterion_ignore_index, label_smoothing=label_smoothing)\n","\n","                    mean_val_loss += float(loss)\n","                    val_batches_n += 1\n","\n","            mean_val_loss /= val_batches_n\n","            print('Среднее значение функции потерь на валидации', mean_val_loss)\n","\n","            if mean_val_loss < best_val_loss:\n","                best_epoch_i = epoch_i\n","                best_val_loss = mean_val_loss\n","                best_model = copy.deepcopy(model)\n","                torch.save(model.state_dict(), os.path.join(model_save_root, best_model_path))\n","                cur_time = \"{:%Y_%m_%d__%H_%M_%S}\".format(datetime.now())\n","                \n","                grid_name_to_greedy_generator = {grid_name: GreedyGenerator(model, word_char_tokenizer, device)}\n","                greedy_predictions = predict_greedy_raw(val_dataset, grid_name_to_greedy_generator)\n","                greedy_accuracy = sum(greedy_prediction == val_target for greedy_prediction, val_target in zip(greedy_predictions, val_targets)) / len(val_targets)\n","                \n","                torch.save(model.state_dict(), os.path.join(model_save_root, f\"m1_bigger_v2__{cur_time}__{mean_val_loss:.5f}__greed_acc_{greedy_accuracy:.5f}__{model_name_postfix}.pt\"))\n","                print(f\"Greedy accuracy = {greedy_accuracy}\")\n","                print('Новая лучшая модель!')\n","            elif epoch_i - best_epoch_i > early_stopping_patience:\n","                print('Модель не улучшилась за последние {} эпох, прекращаем обучение'.format(\n","                    early_stopping_patience))\n","                break\n","\n","            if lr_scheduler is not None:\n","                lr_scheduler.step(mean_val_loss)\n","\n","            print()\n","        except KeyboardInterrupt:\n","            print('Досрочно остановлено пользователем')\n","            break\n","        except Exception as ex:\n","            print('Ошибка при обучении: {}\\n{}'.format(ex, traceback.format_exc()))\n","            break\n","\n","    return best_val_loss, best_model\n"]},{"cell_type":"code","execution_count":68,"metadata":{"execution":{"iopub.execute_input":"2023-12-28T23:32:38.299290Z","iopub.status.busy":"2023-12-28T23:32:38.298308Z","iopub.status.idle":"2023-12-28T23:32:38.331198Z","shell.execute_reply":"2023-12-28T23:32:38.329848Z","shell.execute_reply.started":"2023-12-28T23:32:38.299252Z"},"trusted":true},"outputs":[],"source":[]},{"cell_type":"code","execution_count":110,"metadata":{"execution":{"iopub.execute_input":"2023-12-29T00:04:40.078001Z","iopub.status.busy":"2023-12-29T00:04:40.077622Z","iopub.status.idle":"2023-12-29T00:04:40.111074Z","shell.execute_reply":"2023-12-29T00:04:40.110194Z","shell.execute_reply.started":"2023-12-29T00:04:40.077971Z"},"trusted":true},"outputs":[],"source":["def truncate_padding(seq, mask):\n","    max_curve_len = int(torch.max(torch.sum(~mask, dim = 1)))\n","    seq = seq[:, :max_curve_len]\n","    mask = mask[:, :max_curve_len]\n","    return seq, mask\n","\n","def prepare_batch(x, y, device):\n","    (xyt, kb_tokens, dec_in_char_seq, traj_pad_mask, word_pad_mask), dec_out_char_seq = x, y\n","\n"," \n","\n","    xyt = xyt.to(device)  # (curves_seq_len, batch_size, n_coord_feats)\n","    kb_tokens = kb_tokens.to(device) # (curves_seq_len, batch_size)\n","    dec_in_char_seq = dec_in_char_seq.to(device)  # (chars_seq_len - 1, batch_size)\n","    dec_out_char_seq = dec_out_char_seq.to(device)  # (chars_seq_len - 1, batch_size)\n","\n","    traj_pad_mask = traj_pad_mask.to(device)  # (batch_size, max_curve_len)\n","    # traj_pad_mask = torch.zeros_like(kb_tokens, dtype = torch.bool).transpose_(0, 1).to(device)\n","    word_pad_mask = word_pad_mask.to(device)  # (batch_size, chars_seq_len - 1)\n","\n","    return (xyt, kb_tokens, dec_in_char_seq, traj_pad_mask, word_pad_mask), dec_out_char_seq\n","\n","# prepare_batch = prepare_batch_with_pad_truncation"]},{"cell_type":"code","execution_count":52,"metadata":{"execution":{"iopub.execute_input":"2023-12-28T23:27:03.548666Z","iopub.status.busy":"2023-12-28T23:27:03.548329Z","iopub.status.idle":"2023-12-28T23:27:03.582554Z","shell.execute_reply":"2023-12-28T23:27:03.581521Z","shell.execute_reply.started":"2023-12-28T23:27:03.548642Z"},"trusted":true},"outputs":[],"source":["from typing import List\n","\n","def predict_greedy_raw(dataset,\n","                       grid_name_to_greedy_generator,\n","                      ) -> List[List[str]]:\n","    \"\"\"\n","    Creates predictions using greedy generation.\n","    \n","    Arguments:\n","    ----------\n","    dataset: NeuroSwipeDatasetv2\n","    grid_name_to_greedy_generator: dict\n","        Dict mapping grid names to GreedyGenerator objects.\n","    \"\"\"\n","    preds = [None] * len(dataset)\n","\n","    for data in tqdm(enumerate(dataset), total=len(dataset)):\n","#         i, ((xyt, kb_tokens, _, traj_pad_mask, _), _, grid_name) = data\n","        i, ((xyt, kb_tokens, _, _), _) = data\n","\n","        pred = grid_name_to_greedy_generator[grid_name].generate_word_only(xyt, kb_tokens)\n","        pred = pred.removeprefix(\"<sos>\")\n","#         preds[i] = [pred]\n","        preds[i] = pred\n","\n","    return preds"]},{"cell_type":"code","execution_count":53,"metadata":{"execution":{"iopub.execute_input":"2023-12-28T23:27:05.416909Z","iopub.status.busy":"2023-12-28T23:27:05.416095Z","iopub.status.idle":"2023-12-28T23:27:05.451961Z","shell.execute_reply":"2023-12-28T23:27:05.450951Z","shell.execute_reply.started":"2023-12-28T23:27:05.416870Z"},"trusted":true},"outputs":[],"source":["from typing import List\n","def get_targets(dataset: NeuroSwipeDatasetv3) -> List[str]:\n","    targets = []\n","    for (_, _, _, word_pad_mask), target_tokens in dataset:\n","        target_len = int(torch.sum(~word_pad_mask)) - 1\n","        target = word_char_tokenizer.decode(target_tokens[:target_len])\n","        targets.append(target)\n","    return targets\n"]},{"cell_type":"code","execution_count":54,"metadata":{"execution":{"iopub.execute_input":"2023-12-28T23:27:06.518522Z","iopub.status.busy":"2023-12-28T23:27:06.517847Z","iopub.status.idle":"2023-12-28T23:27:06.793448Z","shell.execute_reply":"2023-12-28T23:27:06.792623Z","shell.execute_reply.started":"2023-12-28T23:27:06.518488Z"},"trusted":true},"outputs":[],"source":["val_targets = get_targets(val_dataset)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":55,"metadata":{"execution":{"iopub.execute_input":"2023-12-28T23:27:14.876882Z","iopub.status.busy":"2023-12-28T23:27:14.876139Z","iopub.status.idle":"2023-12-28T23:27:14.941659Z","shell.execute_reply":"2023-12-28T23:27:14.940802Z","shell.execute_reply.started":"2023-12-28T23:27:14.876850Z"},"trusted":true},"outputs":[{"data":{"text/plain":["<All keys matched successfully>"]},"execution_count":55,"metadata":{},"output_type":"execute_result"}],"source":["transformer.load_state_dict(\n","    torch.load(\"/kaggle/input/m1-bigger-v2-0-13413-extra-l2-0-ls0-switch-1-pt/m1_bigger_v2__2023_11_12__02_27_14__0.13413_extra_l2_0_ls0_switch_1.pt\",\n","              map_location = device))"]},{"cell_type":"code","execution_count":48,"metadata":{"execution":{"iopub.execute_input":"2023-12-28T23:23:50.954542Z","iopub.status.busy":"2023-12-28T23:23:50.954186Z","iopub.status.idle":"2023-12-28T23:23:50.987498Z","shell.execute_reply":"2023-12-28T23:23:50.986617Z","shell.execute_reply.started":"2023-12-28T23:23:50.954512Z"},"trusted":true},"outputs":[],"source":["grid_name_to_greedy_generator = {grid_name: GreedyGenerator(transformer, word_char_tokenizer, device)}"]},{"cell_type":"code","execution_count":49,"metadata":{"execution":{"iopub.execute_input":"2023-12-28T23:23:51.810518Z","iopub.status.busy":"2023-12-28T23:23:51.810180Z","iopub.status.idle":"2023-12-28T23:24:09.159210Z","shell.execute_reply":"2023-12-28T23:24:09.158218Z","shell.execute_reply.started":"2023-12-28T23:23:51.810494Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"5a932b9feb774e429e3e2f85db8c4e22","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/584 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"}],"source":["greedy_predictions = predict_greedy_raw(val_dataset, grid_name_to_greedy_generator)"]},{"cell_type":"code","execution_count":50,"metadata":{"execution":{"iopub.execute_input":"2023-12-28T23:24:09.161466Z","iopub.status.busy":"2023-12-28T23:24:09.161096Z","iopub.status.idle":"2023-12-28T23:24:09.196670Z","shell.execute_reply":"2023-12-28T23:24:09.195565Z","shell.execute_reply.started":"2023-12-28T23:24:09.161431Z"},"trusted":true},"outputs":[{"data":{"text/plain":["0.8561643835616438"]},"execution_count":50,"metadata":{},"output_type":"execute_result"}],"source":["sum(greedy_prediction == val_target for greedy_prediction, val_target in zip(greedy_predictions, val_targets)) / len(val_targets)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":97,"metadata":{"execution":{"iopub.execute_input":"2023-12-28T23:50:16.080487Z","iopub.status.busy":"2023-12-28T23:50:16.079726Z","iopub.status.idle":"2023-12-28T23:50:16.113622Z","shell.execute_reply":"2023-12-28T23:50:16.112474Z","shell.execute_reply.started":"2023-12-28T23:50:16.080453Z"},"trusted":true},"outputs":[{"data":{"text/plain":["torch.Size([165, 165])"]},"execution_count":97,"metadata":{},"output_type":"execute_result"}],"source":["transformer._get_mask(165).shape"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":109,"metadata":{"execution":{"iopub.execute_input":"2023-12-29T00:04:25.852590Z","iopub.status.busy":"2023-12-29T00:04:25.852226Z","iopub.status.idle":"2023-12-29T00:04:25.884731Z","shell.execute_reply":"2023-12-29T00:04:25.883822Z","shell.execute_reply.started":"2023-12-29T00:04:25.852561Z"},"trusted":true},"outputs":[{"data":{"text/plain":["<function __main__.prepare_batch_with_pad_truncation(x, y, device)>"]},"execution_count":109,"metadata":{},"output_type":"execute_result"}],"source":["prepare_batch"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-12-29T00:06:04.676899Z","iopub.status.busy":"2023-12-29T00:06:04.676241Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"279a45d44a7d45d9809d78598acf9241","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/10000 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"d4ddadc1e1d44958842f40bf27b0904d","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1091 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"}],"source":["l2_reg_alpha =  0 #5e-5\n","label_smoothing=  0 #0.045\n","\n","best_val_loss, best_model = train_eval_loop(\n","    transformer, train_dataset, val_dataset, cross_entropy_with_reshape,\n","    lr=1e-4, epoch_n=10000, batch_size=320, collate_fn = collate_fn,\n","    device=device, early_stopping_patience=10, l2_reg_alpha=l2_reg_alpha,\n","    max_batches_per_epoch_train=2000,\n","    max_batches_per_epoch_val=1000,\n","    optimizer_ctor=None,\n","    lr_scheduler_ctor=lr_scheduler,\n","    shuffle_train=True,\n","    dataloader_workers_n=0,\n","    criterion_ignore_index = word_char_tokenizer.char_to_idx['<pad>'],\n","    model_name_postfix = f'{grid_name}_l2_{l2_reg_alpha}_ls{label_smoothing}_switch_2',\n","    prepare_batch=prepare_batch,\n","    model_save_root = \"../..\",\n","    label_smoothing=label_smoothing\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2023-11-12T19:40:56.651049Z","iopub.status.idle":"2023-11-12T19:40:56.651365Z","shell.execute_reply":"2023-11-12T19:40:56.651218Z","shell.execute_reply.started":"2023-11-12T19:40:56.651204Z"},"trusted":true},"outputs":[],"source":["# First epoch: \n","\n","# Среднее значение функции потерь на обучении 1.2045975528854778\n","# Среднее значение функции потерь на валидации 0.5010274122158687"]},{"cell_type":"markdown","metadata":{},"source":["```\n","Среднее значение функции потерь на обучении 1.2045975528854778\n","Среднее значение функции потерь на валидации 0.5010274122158687\n","Новая лучшая модель!\n","\n","2001/? [11:46<00:00, 2.94it/s]\n","Среднее значение функции потерь на обучении 0.9051285277063521\n","Среднее значение функции потерь на валидации 0.4248993237813314\n","Новая лучшая модель!\n","\n","2001/? [11:43<00:00, 2.76it/s]\n","Среднее значение функции потерь на обучении 0.8538736782331338\n","Среднее значение функции потерь на валидации 0.3928388337294261\n","Новая лучшая модель!\n","\n","2001/? [11:43<00:00, 2.56it/s]\n","Среднее значение функции потерь на обучении 0.8256472818914621\n","Среднее значение функции потерь на валидации 0.3676854441563288\n","Новая лучшая модель!\n","\n","2001/? [11:40<00:00, 2.64it/s]\n","Среднее значение функции потерь на обучении 0.8055656312823832\n","Среднее значение функции потерь на валидации 0.35403793156147\n","Новая лучшая модель!\n","\n","2001/? [11:42<00:00, 2.82it/s]\n","Среднее значение функции потерь на обучении 0.791520650925367\n","Среднее значение функции потерь на валидации 0.34193819264570874\n","Новая лучшая модель!\n","\n","2001/? [11:41<00:00, 3.06it/s]\n","Среднее значение функции потерь на обучении 0.7799409364593559\n","Среднее значение функции потерь на валидации 0.3324617197116216\n","Новая лучшая модель!\n","\n","2001/? [11:44<00:00, 2.47it/s]\n","Среднее значение функции потерь на обучении 0.7715481882807852\n","Среднее значение функции потерь на валидации 0.3211148182551066\n","Новая лучшая модель!\n","\n","2001/? [11:41<00:00, 3.06it/s]\n","Среднее значение функции потерь на обучении 0.7643214609550274\n","Среднее значение функции потерь на валидации 0.31518318951129914\n","Новая лучшая модель!\n","\n","2001/? [11:41<00:00, 2.85it/s]\n","Среднее значение функции потерь на обучении 0.7581036963324616\n","Среднее значение функции потерь на валидации 0.3094484398762385\n","Новая лучшая модель!\n","\n","2001/? [11:46<00:00, 2.62it/s]\n","Среднее значение функции потерь на обучении 0.7524177488358482\n","Среднее значение функции потерь на валидации 0.3030394206444422\n","Новая лучшая модель!\n","\n","2001/? [11:45<00:00, 2.86it/s]\n","Среднее значение функции потерь на обучении 0.7466873974576108\n","Среднее значение функции потерь на валидации 0.2996497412522634\n","Новая лучшая модель!\n","\n","2001/? [11:45<00:00, 2.80it/s]\n","Среднее значение функции потерь на обучении 0.7439289238975979\n","Среднее значение функции потерь на валидации 0.29270503520965574\n","Новая лучшая модель!\n","\n","2001/? [11:44<00:00, 2.80it/s]\n","Среднее значение функции потерь на обучении 0.739722256002755\n","Среднее значение функции потерь на валидации 0.2876604378223419\n","Новая лучшая модель!\n","\n","2001/? [11:43<00:00, 2.66it/s]\n","Среднее значение функции потерь на обучении 0.7350960545751942\n","Среднее значение функции потерь на валидации 0.28610232720772427\n","Новая лучшая модель!\n","\n","2001/? [11:42<00:00, 2.75it/s]\n","Среднее значение функции потерь на обучении 0.7321513988327111\n","Среднее значение функции потерь на валидации 0.28779847621917726\n","\n","2001/? [11:44<00:00, 2.98it/s]\n","Среднее значение функции потерь на обучении 0.7278626844145428\n","Среднее значение функции потерь на валидации 0.2804383928577105\n","Новая лучшая модель!\n","\n","2001/? [11:44<00:00, 2.64it/s]\n","Среднее значение функции потерь на обучении 0.7260185109860059\n","Среднее значение функции потерь на валидации 0.2751611083745956\n","Новая лучшая модель!\n","\n","2001/? [11:43<00:00, 2.92it/s]\n","Среднее значение функции потерь на обучении 0.7236041619681168\n","Среднее значение функции потерь на валидации 0.27163358430067697\n","Новая лучшая модель!\n","\n","2001/? [11:47<00:00, 2.97it/s]\n","Среднее значение функции потерь на обучении 0.7213456676281553\n","Среднее значение функции потерь на валидации 0.2692498445510864\n","Новая лучшая модель!\n","\n","2001/? [11:52<00:00, 2.88it/s]\n","Среднее значение функции потерь на обучении 0.7186731718171543\n","Среднее значение функции потерь на валидации 0.2708129515250524\n","\n","2001/? [11:48<00:00, 3.01it/s]\n","Среднее значение функции потерь на обучении 0.716283163626393\n","Среднее значение функции потерь на валидации 0.268450199564298\n","Новая лучшая модель!\n","\n","2001/? [11:44<00:00, 3.02it/s]\n","Среднее значение функции потерь на обучении 0.7147186489059948\n","Среднее значение функции потерь на валидации 0.2660525545477867\n","Новая лучшая модель!\n","\n","2001/? [11:42<00:00, 2.87it/s]\n","Среднее значение функции потерь на обучении 0.7126921191923264\n","Среднее значение функции потерь на валидации 0.263121996819973\n","Новая лучшая модель!\n","\n","2001/? [11:42<00:00, 3.00it/s]\n","Среднее значение функции потерь на обучении 0.7097944344418576\n","Среднее значение функции потерь на валидации 0.2610153297583262\n","Новая лучшая модель!\n","```"]},{"cell_type":"markdown","metadata":{},"source":["Around 32 epoches alpha = 0. Then alpha = 1e-4"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"datasetId":3990388,"sourceId":6948085,"sourceType":"datasetVersion"},{"datasetId":4234577,"sourceId":7299591,"sourceType":"datasetVersion"}],"dockerImageVersionId":30627,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.5"}},"nbformat":4,"nbformat_minor":4}
