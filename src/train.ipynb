{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2024-03-04T12:09:01.695874Z","iopub.status.busy":"2024-03-04T12:09:01.695061Z","iopub.status.idle":"2024-03-04T12:09:01.723626Z","shell.execute_reply":"2024-03-04T12:09:01.722743Z","shell.execute_reply.started":"2024-03-04T12:09:01.695843Z"},"trusted":true},"outputs":[],"source":["%load_ext autoreload\n","%autoreload 2"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# !git clone https://github.com/proshian/yandex-cup-2023-ml-neuroswipe.git\n","# %cd yandex-cup-2023-ml-neuroswipe\n","# ! git checkout datasetv4"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# !pip install dvc --quiet\n","# !pip install dvc_gdrive --quiet"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-04T12:09:01.756629Z","iopub.status.busy":"2024-03-04T12:09:01.756306Z","iopub.status.idle":"2024-03-04T12:09:04.394984Z","shell.execute_reply":"2024-03-04T12:09:04.393760Z","shell.execute_reply.started":"2024-03-04T12:09:01.756603Z"},"trusted":true},"outputs":[],"source":["# %cd /kaggle/working/yandex-cup-2023-ml-neuroswipe\n","# ! git pull\n","# ! git checkout datasetv4"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-04T12:09:04.398168Z","iopub.status.busy":"2024-03-04T12:09:04.397780Z","iopub.status.idle":"2024-03-04T12:09:04.420903Z","shell.execute_reply":"2024-03-04T12:09:04.420059Z","shell.execute_reply.started":"2024-03-04T12:09:04.398132Z"},"trusted":true},"outputs":[],"source":["%cd /kaggle/working/yandex-cup-2023-ml-neuroswipe/src"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2024-03-04T12:09:04.423468Z","iopub.status.busy":"2024-03-04T12:09:04.423129Z","iopub.status.idle":"2024-03-04T12:09:04.440822Z","shell.execute_reply":"2024-03-04T12:09:04.439938Z","shell.execute_reply.started":"2024-03-04T12:09:04.423434Z"},"trusted":true},"outputs":[],"source":["############# Script arguments emulation #############\n","\n","GRID_NAME = \"default\"\n","BATCH_SIZE = 320\n","IN_KAGGLE = False\n","RANDOM_SEED = 12\n","\n","DATA_ROOT = \"../data/data_separated_grid\"\n","MODELS_DIR = \"../data/trained_models/m1\""]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2024-03-04T13:35:05.806961Z","iopub.status.busy":"2024-03-04T13:35:05.806571Z","iopub.status.idle":"2024-03-04T13:35:05.883404Z","shell.execute_reply":"2024-03-04T13:35:05.882451Z","shell.execute_reply.started":"2024-03-04T13:35:05.806932Z"},"trusted":true},"outputs":[],"source":["import os\n","import json\n","import typing as tp\n","import traceback\n","from datetime import datetime\n","import copy\n","\n","import torch\n","# import torch.nn as nn\n","import torch.nn.functional as F\n","from torch.utils.data import DataLoader\n","from tqdm import tqdm\n","import numpy as np\n","from torch.utils.tensorboard import SummaryWriter\n","\n","\n","from model import SwipeCurveTransformer, get_m1_bigger_model\n","from tokenizers import CharLevelTokenizerv2, KeyboardTokenizerv1\n","from tokenizers import ALL_CYRILLIC_LETTERS_ALPHABET_ORD\n","from dataset import CurveDataset, CollateFn\n","from word_generators import GreedyGenerator\n","from nearest_key_lookup import NearestKeyLookup, ExtendedNearestKeyLookup\n","from transforms import TransformerInputOutputGetter"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2024-03-04T12:09:20.666004Z","iopub.status.busy":"2024-03-04T12:09:20.665471Z","iopub.status.idle":"2024-03-04T12:09:20.736699Z","shell.execute_reply":"2024-03-04T12:09:20.735602Z","shell.execute_reply.started":"2024-03-04T12:09:20.665977Z"},"trusted":true},"outputs":[],"source":["################ Other constants ####################\n","GRID_NAME_TO_DS_PATHS = {\n","    \"extra\": {\n","        \"train\": os.path.join(DATA_ROOT, \"train__extra_only_no_errors__2023_11_01__19_49_14.jsonl\"),\n","        \"val\": os.path.join(DATA_ROOT, \"valid__in_train_format__extra_only.jsonl\")\n","    },\n","    \"default\": {\n","        \"train\": os.path.join(DATA_ROOT, \"train__default_only_no_errors__2023_10_31__03_26_16.jsonl\"),\n","        \"val\": os.path.join(DATA_ROOT, \"valid__in_train_format__default_only.jsonl\")\n","    }\n","}"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2024-03-04T11:21:41.168567Z","iopub.status.busy":"2024-03-04T11:21:41.168159Z","iopub.status.idle":"2024-03-04T11:21:41.239918Z","shell.execute_reply":"2024-03-04T11:21:41.238437Z","shell.execute_reply.started":"2024-03-04T11:21:41.168538Z"},"trusted":true},"outputs":[],"source":["# if IN_KAGGLE:\n","#     DATA_ROOT = \"/kaggle/input/neuroswipe-defualt-only-v1\"\n","#     MODELS_DIR = \"\""]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2024-03-04T12:09:20.738202Z","iopub.status.busy":"2024-03-04T12:09:20.737901Z","iopub.status.idle":"2024-03-04T12:09:20.811010Z","shell.execute_reply":"2024-03-04T12:09:20.809965Z","shell.execute_reply.started":"2024-03-04T12:09:20.738178Z"},"trusted":true},"outputs":[],"source":["def init_random_seed(value):\n","    # random.seed(value)\n","    np.random.seed(value)\n","    torch.manual_seed(value)\n","    torch.cuda.manual_seed(value)\n","    # torch.backends.cudnn.deterministic = True"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2024-03-04T12:09:20.812885Z","iopub.status.busy":"2024-03-04T12:09:20.812363Z","iopub.status.idle":"2024-03-04T12:09:20.880890Z","shell.execute_reply":"2024-03-04T12:09:20.879978Z","shell.execute_reply.started":"2024-03-04T12:09:20.812851Z"},"trusted":true},"outputs":[],"source":["def get_grid(grid_name: str, grids_path: str) -> dict:\n","    with open(grids_path, \"r\", encoding=\"utf-8\") as f:\n","        return json.load(f)[grid_name]"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2024-03-04T13:38:50.939065Z","iopub.status.busy":"2024-03-04T13:38:50.938695Z","iopub.status.idle":"2024-03-04T13:38:51.017225Z","shell.execute_reply":"2024-03-04T13:38:51.016225Z","shell.execute_reply.started":"2024-03-04T13:38:50.939035Z"},"trusted":true},"outputs":[],"source":["from typing import List, Dict, Tuple, Optional, Set\n","\n","def get_gridname_to_out_of_bounds_coords_dict(\n","        data_paths: List[str], gridname_to_wh: dict,\n","        total: Optional[int] = None\n","        ) -> Dict[str, Set[Tuple[int, int]]]:\n","    \"\"\"\n","    Returns a dictionary with grid names as keys and lists of out of bounds coordinates as values.\n","    \"\"\"\n","    gname_to_out_of_bounds = {gname: set() for gname in gridname_to_wh.keys()}\n","\n","    for data_path in data_paths:\n","        with open(data_path, \"r\", encoding=\"utf-8\") as json_file:\n","            for line in tqdm(json_file, total=total):\n","                json_data = json.loads(line)\n","                curve = json_data['curve']\n","                grid_name = curve['grid_name']\n","                w, h = gridname_to_wh[grid_name]\n","                X, Y = curve['x'], curve['y']\n","                out_of_bounds = set((x, y) for x, y in zip(X, Y) \n","                                    if x < 0 or x >= w or y < 0 or y >= h)\n","                gname_to_out_of_bounds[grid_name].update(out_of_bounds)\n","    return gname_to_out_of_bounds"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2024-03-04T13:38:55.005609Z","iopub.status.busy":"2024-03-04T13:38:55.004658Z","iopub.status.idle":"2024-03-04T13:38:55.085895Z","shell.execute_reply":"2024-03-04T13:38:55.084877Z","shell.execute_reply.started":"2024-03-04T13:38:55.005573Z"},"trusted":true},"outputs":[],"source":["def get_datasets(grid_name: str, grid_name_to_grid_path: str,\n","                 train_data_path: str, val_data_path: str,\n","                 nearest_key_candidates: tp.Set[str],\n","                 kb_tokenizer: KeyboardTokenizerv1,\n","                 word_char_tokenizer: CharLevelTokenizerv2\n","                 ) -> tuple[CurveDataset, CurveDataset]:\n","    \n","    gridname_to_grid  = {grid_name: get_grid(grid_name, grid_name_to_grid_path)}\n","\n","    gname_to_wh = {\n","        gname: (grid['width'], grid['height']) \n","        for gname, grid in gridname_to_grid.items()\n","    }\n","    \n","    print(\"Accumulating out-of-bounds coordinates...\")\n","    gname_to_out_of_bounds = get_gridname_to_out_of_bounds_coords_dict(\n","        [train_data_path, val_data_path], gname_to_wh, total=6_000_000\n","    )\n","    \n","    print(\"Creating ExtendedNearestKeyLookups...\")\n","    gridname_to_nkl = {\n","        gname: ExtendedNearestKeyLookup(grid, nearest_key_candidates, gname_to_out_of_bounds[gname])\n","        for gname, grid in gridname_to_grid.items()\n","    }\n","    \n","    \n","    transformer_in_out_getter = TransformerInputOutputGetter(\n","        grid_name_to_nk_lookup=gridname_to_nkl,\n","        grid_name_to_wh=gname_to_wh,\n","        kb_tokenizer=kb_tokenizer,\n","        word_tokenizer=word_char_tokenizer,\n","        include_time=False,\n","        include_velocities=True,\n","        include_accelerations=True\n","    )\n","    \n","    print(\"Creating datasets...\")\n","    train_ds = CurveDataset(\n","        data_path=train_data_path,\n","        transform = transformer_in_out_getter,\n","        total = 5_237_584,  # 349_172 for extra\n","    )\n","\n","    val_ds = CurveDataset(\n","        data_path=val_data_path,\n","        transform = transformer_in_out_getter,\n","        total = 9_416,\n","    )\n","    \n","    return train_ds, val_ds"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2024-03-04T13:38:56.638956Z","iopub.status.busy":"2024-03-04T13:38:56.638245Z","iopub.status.idle":"2024-03-04T13:38:56.710410Z","shell.execute_reply":"2024-03-04T13:38:56.709480Z","shell.execute_reply.started":"2024-03-04T13:38:56.638924Z"},"trusted":true},"outputs":[],"source":["init_random_seed(RANDOM_SEED)"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2024-03-04T13:46:01.085839Z","iopub.status.busy":"2024-03-04T13:46:01.085452Z","iopub.status.idle":"2024-03-04T13:53:43.537616Z","shell.execute_reply":"2024-03-04T13:53:43.536731Z","shell.execute_reply.started":"2024-03-04T13:46:01.085813Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Accumulating out-of-bounds coordinates...\n"]},{"name":"stderr","output_type":"stream","text":[" 87%|████████▋ | 5237584/6000000 [04:18<00:37, 20274.45it/s]\n","  0%|          | 9416/6000000 [00:00<04:45, 20953.72it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Creating ExtendedNearestKeyLookups...\n","Creating datasets...\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 5237584/5237584 [05:14<00:00, 16649.41it/s]\n","100%|██████████| 9416/9416 [00:00<00:00, 17750.98it/s]\n"]}],"source":["# Pickling the dataset would be great to not waste\n","# around 20 minutes creating train_dataset.\n","\n","kb_tokenizer = KeyboardTokenizerv1()\n","voc_path=os.path.join(DATA_ROOT, \"voc.txt\")\n","word_char_tokenizer = CharLevelTokenizerv2(voc_path)\n","\n","train_dataset, val_dataset = get_datasets(\n","    grid_name=GRID_NAME,\n","    grid_name_to_grid_path=os.path.join(DATA_ROOT, \"gridname_to_grid.json\"),\n","    train_data_path = GRID_NAME_TO_DS_PATHS[GRID_NAME]['train'],\n","    val_data_path = GRID_NAME_TO_DS_PATHS[GRID_NAME]['val'],\n","    nearest_key_candidates = ALL_CYRILLIC_LETTERS_ALPHABET_ORD,\n","    kb_tokenizer=kb_tokenizer,\n","    word_char_tokenizer=word_char_tokenizer,\n",")"]},{"cell_type":"code","execution_count":20,"metadata":{},"outputs":[{"data":{"text/plain":["'г'"]},"execution_count":20,"metadata":{},"output_type":"execute_result"}],"source":["train_dataset.transform.get_encoder_feats.grid_name_to_nk_lookup['default'].extended_coord_to_kb_label[624, -24]"]},{"cell_type":"code","execution_count":49,"metadata":{},"outputs":[],"source":["n_iters = 100000"]},{"cell_type":"code","execution_count":50,"metadata":{},"outputs":[],"source":["for i in range(n_iters):\n","    train_dataset.transform.get_encoder_feats.grid_name_to_nk_lookup['default'](624, -24)"]},{"cell_type":"code","execution_count":51,"metadata":{},"outputs":[],"source":["for i in range(n_iters):\n","    train_dataset.transform.get_encoder_feats.grid_name_to_nk_lookup['default'](1, 1)"]},{"cell_type":"code","execution_count":52,"metadata":{},"outputs":[],"source":["for i in range(n_iters):\n","    train_dataset.transform.get_encoder_feats.grid_name_to_nk_lookup['default'](-1111, -1111)"]},{"cell_type":"code","execution_count":57,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["  0%|          | 16512/5237584 [01:27<7:42:23, 188.19it/s] \n"]},{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[1;32mIn[57], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(train_dataset))):\n\u001b[1;32m----> 2\u001b[0m     \u001b[43mtrain_dataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\n","File \u001b[1;32mc:\\Users\\proshian\\Documents\\yandex-cup-2023-ml-neuroswipe\\src\\dataset.py:93\u001b[0m, in \u001b[0;36mCurveDataset.__getitem__\u001b[1;34m(self, idx)\u001b[0m\n\u001b[0;32m     91\u001b[0m sample \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata_list[idx]  \u001b[38;5;66;03m# X, Y, T, grid_name, tgt_word\u001b[39;00m\n\u001b[0;32m     92\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform:\n\u001b[1;32m---> 93\u001b[0m     sample \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43msample\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     94\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m sample\n","File \u001b[1;32mc:\\Users\\proshian\\Documents\\yandex-cup-2023-ml-neuroswipe\\src\\transforms.py:141\u001b[0m, in \u001b[0;36mTransformerInputOutputGetter.__call__\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m    138\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, data: DatasetEl\n\u001b[0;32m    139\u001b[0m              ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[Tuple[Tensor, Tensor, Tensor], Tensor]:\n\u001b[0;32m    140\u001b[0m     X, Y, T, grid_name, tgt_word \u001b[38;5;241m=\u001b[39m data\n\u001b[1;32m--> 141\u001b[0m     traj_feats, kb_tokens \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_encoder_feats\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mT\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrid_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    142\u001b[0m     decoder_in, decoder_out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_decoder_in_out(tgt_word)\n\u001b[0;32m    143\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (traj_feats, kb_tokens, decoder_in), decoder_out\n","File \u001b[1;32mc:\\Users\\proshian\\Documents\\yandex-cup-2023-ml-neuroswipe\\src\\transforms.py:103\u001b[0m, in \u001b[0;36mEncoderFeaturesGetter.__call__\u001b[1;34m(self, X, Y, T, grid_name)\u001b[0m\n\u001b[0;32m    101\u001b[0m X, Y, T \u001b[38;5;241m=\u001b[39m (torch\u001b[38;5;241m.\u001b[39mtensor(arr) \u001b[38;5;28;01mfor\u001b[39;00m arr \u001b[38;5;129;01min\u001b[39;00m (X, Y, T))\n\u001b[0;32m    102\u001b[0m traj_feats \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_traj_feats(X, Y, T, grid_name)\n\u001b[1;32m--> 103\u001b[0m kb_tokens \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_kb_tokens\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrid_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    104\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m traj_feats, kb_tokens\n","File \u001b[1;32mc:\\Users\\proshian\\Documents\\yandex-cup-2023-ml-neuroswipe\\src\\transforms.py:67\u001b[0m, in \u001b[0;36mEncoderFeaturesGetter._get_kb_tokens\u001b[1;34m(self, X, Y, grid_name)\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_get_kb_tokens\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, Y, grid_name) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m     66\u001b[0m     nearest_key_lookup \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgrid_name_to_nk_lookup[grid_name]\n\u001b[1;32m---> 67\u001b[0m     kb_labels \u001b[38;5;241m=\u001b[39m \u001b[43m[\u001b[49m\u001b[43mnearest_key_lookup\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mzip\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m     68\u001b[0m     kb_tokens \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkb_tokenizer\u001b[38;5;241m.\u001b[39mget_token(label) \u001b[38;5;28;01mfor\u001b[39;00m label \u001b[38;5;129;01min\u001b[39;00m kb_labels]\n\u001b[0;32m     69\u001b[0m     kb_tokens \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(kb_tokens, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mint64)\n","File \u001b[1;32mc:\\Users\\proshian\\Documents\\yandex-cup-2023-ml-neuroswipe\\src\\transforms.py:67\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_get_kb_tokens\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, Y, grid_name) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m     66\u001b[0m     nearest_key_lookup \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgrid_name_to_nk_lookup[grid_name]\n\u001b[1;32m---> 67\u001b[0m     kb_labels \u001b[38;5;241m=\u001b[39m [\u001b[43mnearest_key_lookup\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m x, y \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(X, Y)]\n\u001b[0;32m     68\u001b[0m     kb_tokens \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkb_tokenizer\u001b[38;5;241m.\u001b[39mget_token(label) \u001b[38;5;28;01mfor\u001b[39;00m label \u001b[38;5;129;01min\u001b[39;00m kb_labels]\n\u001b[0;32m     69\u001b[0m     kb_tokens \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(kb_tokens, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mint64)\n","\u001b[1;31mKeyboardInterrupt\u001b[0m: "]}],"source":["for i in tqdm(range(len(train_dataset))):\n","    train_dataset[i]"]},{"cell_type":"code","execution_count":59,"metadata":{},"outputs":[],"source":["from dataset import NeuroSwipeDatasetv3"]},{"cell_type":"code","execution_count":61,"metadata":{},"outputs":[],"source":["def get_datasets_old(grid_name: str, grid_name_to_grid_path: str,\n","                 train_data_path: str, val_data_path: str,\n","                 ds_kwargs: dict, kb_tokenizer: KeyboardTokenizerv1,\n","                 word_char_tokenizer: CharLevelTokenizerv2\n","                 ) -> tuple[NeuroSwipeDatasetv3, NeuroSwipeDatasetv3]:\n","    \n","    gridname_to_grid  = {grid_name: get_grid(grid_name, grid_name_to_grid_path)}\n","\n","    train_ds = NeuroSwipeDatasetv3(\n","        data_path=train_data_path,\n","        gridname_to_grid = gridname_to_grid,\n","        kb_tokenizer=kb_tokenizer,\n","        word_tokenizer =word_char_tokenizer,\n","        total = 5_237_584,  # 349_172 for extra\n","        **ds_kwargs\n","    )\n","\n","    val_ds = NeuroSwipeDatasetv3(\n","        data_path=val_data_path,\n","        gridname_to_grid =gridname_to_grid,\n","        kb_tokenizer=kb_tokenizer,\n","        word_tokenizer =word_char_tokenizer,\n","        total = 9_416,\n","        **ds_kwargs\n","    )\n","\n","    return train_ds, val_ds"]},{"cell_type":"code","execution_count":63,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|██████████| 5237584/5237584 [13:35<00:00, 6425.51it/s] \n","100%|██████████| 9416/9416 [00:02<00:00, 4328.65it/s]\n"]}],"source":["DS_KWARGS = dict(\n","    include_time = False,\n","    include_velocities = True,\n","    include_accelerations = True,\n","    has_target=True,\n","    has_one_grid_only=True,\n","    include_grid_name=False,\n","    keyboard_selection_set=set(ALL_CYRILLIC_LETTERS_ALPHABET_ORD)\n",")\n","\n","\n","train_dataset, val_dataset = get_datasets_old(\n","    grid_name=GRID_NAME,\n","    grid_name_to_grid_path=os.path.join(DATA_ROOT, \"gridname_to_grid.json\"),\n","    train_data_path = GRID_NAME_TO_DS_PATHS[GRID_NAME]['train'],\n","    val_data_path = GRID_NAME_TO_DS_PATHS[GRID_NAME]['val'],\n","    ds_kwargs=DS_KWARGS,\n","    kb_tokenizer=kb_tokenizer,\n","    word_char_tokenizer=word_char_tokenizer,\n",")"]},{"cell_type":"code","execution_count":65,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["  0%|          | 1984/5237584 [00:02<2:05:15, 696.63it/s] \n"]},{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[1;32mIn[65], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(train_dataset))):\n\u001b[1;32m----> 2\u001b[0m     \u001b[43mtrain_dataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\n","File \u001b[1;32mc:\\Users\\proshian\\Documents\\yandex-cup-2023-ml-neuroswipe\\src\\dataset.py:416\u001b[0m, in \u001b[0;36mNeuroSwipeDatasetv3.__getitem__\u001b[1;34m(self, idx)\u001b[0m\n\u001b[0;32m    414\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minclude_velocities:\n\u001b[0;32m    415\u001b[0m     dx_dt \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_dx_dt(X, T)\n\u001b[1;32m--> 416\u001b[0m     dy_dt \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_dx_dt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mY\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mT\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    417\u001b[0m     xyt \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat(\n\u001b[0;32m    418\u001b[0m         [\n\u001b[0;32m    419\u001b[0m             xyt,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    423\u001b[0m         axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    424\u001b[0m     )\n\u001b[0;32m    426\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minclude_accelerations:\n","File \u001b[1;32mc:\\Users\\proshian\\Documents\\yandex-cup-2023-ml-neuroswipe\\src\\dataset.py:339\u001b[0m, in \u001b[0;36mNeuroSwipeDatasetv3._get_dx_dt\u001b[1;34m(self, X, T)\u001b[0m\n\u001b[0;32m    337\u001b[0m dx_dt \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mzeros_like(X)\n\u001b[0;32m    338\u001b[0m \u001b[38;5;66;03m# dx_dt[1:-1] = (X[2:] - X[:-2]) / (T[2:] - T[:-2])\u001b[39;00m\n\u001b[1;32m--> 339\u001b[0m dx_dt[\u001b[38;5;241m1\u001b[39m:\u001b[38;5;28mlen\u001b[39m(X)\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m=\u001b[39m (X[\u001b[38;5;241m2\u001b[39m:\u001b[38;5;28mlen\u001b[39m(X)] \u001b[38;5;241m-\u001b[39m X[:\u001b[38;5;28mlen\u001b[39m(X)\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m]) \u001b[38;5;241m/\u001b[39m (T[\u001b[38;5;241m2\u001b[39m:\u001b[38;5;28mlen\u001b[39m(X)] \u001b[38;5;241m-\u001b[39m T[:\u001b[38;5;28mlen\u001b[39m(X)\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m])\n\u001b[0;32m    341\u001b[0m \u001b[38;5;66;03m# Example:\u001b[39;00m\n\u001b[0;32m    342\u001b[0m \u001b[38;5;66;03m# x0 x1 x2 x3\u001b[39;00m\n\u001b[0;32m    343\u001b[0m \u001b[38;5;66;03m# t0 t1 t2 t3\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    351\u001b[0m \u001b[38;5;66;03m#     print(dx_dt)\u001b[39;00m\n\u001b[0;32m    352\u001b[0m \u001b[38;5;66;03m#     raise ValueError(\"dx_dt contains NaNs\")\u001b[39;00m\n\u001b[0;32m    354\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m dx_dt\n","File \u001b[1;32mc:\\Users\\proshian\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\_tensor.py:964\u001b[0m, in \u001b[0;36mTensor.__len__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    961\u001b[0m \u001b[38;5;21m__neg__\u001b[39m \u001b[38;5;241m=\u001b[39m _C\u001b[38;5;241m.\u001b[39m_TensorBase\u001b[38;5;241m.\u001b[39mneg\n\u001b[0;32m    962\u001b[0m \u001b[38;5;21m__abs__\u001b[39m \u001b[38;5;241m=\u001b[39m _C\u001b[38;5;241m.\u001b[39m_TensorBase\u001b[38;5;241m.\u001b[39mabs\n\u001b[1;32m--> 964\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__len__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    965\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    966\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(Tensor\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__len__\u001b[39m, (\u001b[38;5;28mself\u001b[39m,), \u001b[38;5;28mself\u001b[39m)\n","\u001b[1;31mKeyboardInterrupt\u001b[0m: "]}],"source":["for i in tqdm(range(len(train_dataset))):\n","    train_dataset[i]"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[],"source":["import json\n","from typing import Optional, List, Tuple, Dict, Set, Callable\n","import array\n","\n","import numpy as np\n","import torch\n","from torch.utils.data import Dataset\n","from tqdm import tqdm\n","from torch.nn.utils.rnn import pad_sequence\n","\n","from tokenizers import CharLevelTokenizerv2, KeyboardTokenizerv1\n","\n","class CurveDatasetv2(Dataset):\n","    \"\"\"\n","    Dataset class for NeuroSwipe jsonl dataset\n","    \n","    curve_dataset_obj[i] is a tuple (X, Y, T, grid_name, tgt_word)\n","    If there is no 'word' property in .json file, `tgt_word` is None.\n","\n","    Extracting features (for example nearest keyboard  key label) \n","    is be done via transforms.  Transfroms are be applied in __getitem__\n","    but if they may be split into two args in the future: \n","    init_transforms and get_item_transforms.\n","    \"\"\"\n","\n","    def __init__(self,\n","                 data_path: str,\n","                 transform: Optional[Callable] = None,\n","                 total: Optional[int] = None):\n","        \"\"\"\n","        Arguments:\n","        ----------\n","        data_path: str\n","            Path to the NeuroSwipe dataset in JSON format.\n","            A custom version of the dataset is used: \"grid\" property\n","            is replaced with \"grid_name\". The grid itself is stored in\n","            a separate gridname_to_grid dictionary.\n","            Dataset is a list of JSON lines. Each line is a dictionary\n","            with the following properties:\n","            - word (str): word that was typed. \n","                Is abscent in test and val datasets.\n","            - curve (dict): dictionary that contains the following properties:\n","                - x (List[int]): x coordinates of the swipe trajectory.\n","                - y (List[int]): y coordinates of the swipe trajectory.\n","                - t (List[int]): time (in ms) from the beginning of the swipe.\n","                - grid_name (str): name of the keyboard grid.\n","        transform: Optional[Callable]\n","            A function that takes raw data (X, Y, T, grid_name, tgt_word)\n","            and returns a tuple (model_input, target).\n","        total: Optional[int]\n","            Number of dataset elements. Is used only for progress bar.\n","        \"\"\"\n","        self.data_list = self._get_data(data_path, total = total)\n","        self.transform = transform\n","\n","    def _get_data(self,\n","                  data_path: str,\n","                  total: Optional[int] = None):\n","        data_list = []\n","        with open(data_path, \"r\", encoding=\"utf-8\") as json_file:\n","            for line in tqdm(json_file, total = total):\n","                data_list.append(\n","                    self.transform(\n","                        self._get_data_from_json_line(line)\n","                    )\n","                )\n","        return data_list\n","\n","    def _get_data_from_json_line(self,\n","                                 line\n","                                 ) -> Tuple[list, list, list, str]:\n","        \"\"\"\n","        Parses a JSON line and returns a dictionary with data.\n","        \"\"\"\n","        data = json.loads(line)\n","\n","        X = array.array('h', data['curve']['x'])\n","        Y = array.array('h', data['curve']['y'])\n","        T = array.array('h', data['curve']['t'])\n","\n","        grid_name = data['curve']['grid_name']   \n","\n","        tgt_word = data['word'] if 'word' in data else None\n","\n","        return X, Y, T, grid_name, tgt_word\n","\n","    def __len__(self):\n","        return len(self.data_list)\n","    \n","    def __getitem__(self, idx):\n","        return self.data_list[idx] "]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[],"source":["def get_datasetsv2(grid_name: str, grid_name_to_grid_path: str,\n","                 train_data_path: str, val_data_path: str,\n","                 nearest_key_candidates: tp.Set[str],\n","                 kb_tokenizer: KeyboardTokenizerv1,\n","                 word_char_tokenizer: CharLevelTokenizerv2\n","                 ) -> tuple[CurveDataset, CurveDataset]:\n","    \n","    gridname_to_grid  = {grid_name: get_grid(grid_name, grid_name_to_grid_path)}\n","\n","    gname_to_wh = {\n","        gname: (grid['width'], grid['height']) \n","        for gname, grid in gridname_to_grid.items()\n","    }\n","    \n","    print(\"Accumulating out-of-bounds coordinates...\")\n","    gname_to_out_of_bounds = get_gridname_to_out_of_bounds_coords_dict(\n","        [train_data_path, val_data_path], gname_to_wh, total=6_000_000\n","    )\n","    \n","    print(\"Creating ExtendedNearestKeyLookups...\")\n","    gridname_to_nkl = {\n","        gname: ExtendedNearestKeyLookup(grid, nearest_key_candidates, gname_to_out_of_bounds[gname])\n","        for gname, grid in gridname_to_grid.items()\n","    }\n","    \n","    \n","    transformer_in_out_getter = TransformerInputOutputGetter(\n","        grid_name_to_nk_lookup=gridname_to_nkl,\n","        grid_name_to_wh=gname_to_wh,\n","        kb_tokenizer=kb_tokenizer,\n","        word_tokenizer=word_char_tokenizer,\n","        include_time=False,\n","        include_velocities=True,\n","        include_accelerations=True\n","    )\n","    \n","    print(\"Creating datasets...\")\n","    train_ds = CurveDatasetv2(\n","        data_path=train_data_path,\n","        transform = transformer_in_out_getter,\n","        total = 5_237_584,  # 349_172 for extra\n","    )\n","\n","    val_ds = CurveDatasetv2(\n","        data_path=val_data_path,\n","        transform = transformer_in_out_getter,\n","        total = 9_416,\n","    )\n","    \n","    return train_ds, val_ds"]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Accumulating out-of-bounds coordinates...\n"]},{"name":"stderr","output_type":"stream","text":[" 87%|████████▋ | 5237584/6000000 [04:40<00:40, 18701.45it/s]\n","  0%|          | 9416/6000000 [00:00<06:25, 15539.80it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Creating ExtendedNearestKeyLookups...\n","Creating datasets...\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 5237584/5237584 [04:44<00:00, 18403.42it/s]\n","100%|██████████| 9416/9416 [00:00<00:00, 22207.71it/s]\n"]}],"source":["# Pickling the dataset would be great to not waste\n","# around 20 minutes creating train_dataset.\n","\n","kb_tokenizer = KeyboardTokenizerv1()\n","voc_path=os.path.join(DATA_ROOT, \"voc.txt\")\n","word_char_tokenizer = CharLevelTokenizerv2(voc_path)\n","\n","train_dataset, val_dataset = get_datasets(\n","    grid_name=GRID_NAME,\n","    grid_name_to_grid_path=os.path.join(DATA_ROOT, \"gridname_to_grid.json\"),\n","    train_data_path = GRID_NAME_TO_DS_PATHS[GRID_NAME]['train'],\n","    val_data_path = GRID_NAME_TO_DS_PATHS[GRID_NAME]['val'],\n","    nearest_key_candidates = ALL_CYRILLIC_LETTERS_ALPHABET_ORD,\n","    kb_tokenizer=kb_tokenizer,\n","    word_char_tokenizer=word_char_tokenizer,\n",")"]},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["  1%|          | 38451/5237584 [02:31<5:40:36, 254.40it/s] \n"]},{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[1;32mIn[13], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(train_dataset))):\n\u001b[1;32m----> 2\u001b[0m     \u001b[43mtrain_dataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\n","File \u001b[1;32mc:\\Users\\proshian\\Documents\\yandex-cup-2023-ml-neuroswipe\\src\\dataset.py:93\u001b[0m, in \u001b[0;36mCurveDataset.__getitem__\u001b[1;34m(self, idx)\u001b[0m\n\u001b[0;32m     91\u001b[0m sample \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata_list[idx]  \u001b[38;5;66;03m# X, Y, T, grid_name, tgt_word\u001b[39;00m\n\u001b[0;32m     92\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform:\n\u001b[1;32m---> 93\u001b[0m     sample \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43msample\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     94\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m sample\n","File \u001b[1;32mc:\\Users\\proshian\\Documents\\yandex-cup-2023-ml-neuroswipe\\src\\transforms.py:141\u001b[0m, in \u001b[0;36mTransformerInputOutputGetter.__call__\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m    138\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, data: DatasetEl\n\u001b[0;32m    139\u001b[0m              ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[Tuple[Tensor, Tensor, Tensor], Tensor]:\n\u001b[0;32m    140\u001b[0m     X, Y, T, grid_name, tgt_word \u001b[38;5;241m=\u001b[39m data\n\u001b[1;32m--> 141\u001b[0m     traj_feats, kb_tokens \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_encoder_feats\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mT\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrid_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    142\u001b[0m     decoder_in, decoder_out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_decoder_in_out(tgt_word)\n\u001b[0;32m    143\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (traj_feats, kb_tokens, decoder_in), decoder_out\n","File \u001b[1;32mc:\\Users\\proshian\\Documents\\yandex-cup-2023-ml-neuroswipe\\src\\transforms.py:102\u001b[0m, in \u001b[0;36mEncoderFeaturesGetter.__call__\u001b[1;34m(self, X, Y, T, grid_name)\u001b[0m\n\u001b[0;32m     99\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, X: Iterable, Y: Iterable,\n\u001b[0;32m    100\u001b[0m              T: Iterable, grid_name: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[Tensor, Tensor]:\n\u001b[0;32m    101\u001b[0m     X, Y, T \u001b[38;5;241m=\u001b[39m (torch\u001b[38;5;241m.\u001b[39mtensor(arr) \u001b[38;5;28;01mfor\u001b[39;00m arr \u001b[38;5;129;01min\u001b[39;00m (X, Y, T))\n\u001b[1;32m--> 102\u001b[0m     traj_feats \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_traj_feats\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mT\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrid_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    103\u001b[0m     kb_tokens \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_kb_tokens(X, Y, grid_name)\n\u001b[0;32m    104\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m traj_feats, kb_tokens\n","File \u001b[1;32mc:\\Users\\proshian\\Documents\\yandex-cup-2023-ml-neuroswipe\\src\\transforms.py:80\u001b[0m, in \u001b[0;36mEncoderFeaturesGetter._get_traj_feats\u001b[1;34m(self, X, Y, T, grid_name)\u001b[0m\n\u001b[0;32m     78\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minclude_velocities:\n\u001b[0;32m     79\u001b[0m     dx_dt \u001b[38;5;241m=\u001b[39m get_dx_dt(X, T)\n\u001b[1;32m---> 80\u001b[0m     dy_dt \u001b[38;5;241m=\u001b[39m \u001b[43mget_dx_dt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mY\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mT\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     81\u001b[0m     traj_feats\u001b[38;5;241m.\u001b[39mextend([dx_dt, dy_dt])\n\u001b[0;32m     83\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minclude_accelerations:\n","File \u001b[1;32mc:\\Users\\proshian\\Documents\\yandex-cup-2023-ml-neuroswipe\\src\\transforms.py:28\u001b[0m, in \u001b[0;36mget_dx_dt\u001b[1;34m(X, T)\u001b[0m\n\u001b[0;32m     26\u001b[0m dx_dt \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mzeros_like(X)\n\u001b[0;32m     27\u001b[0m \u001b[38;5;66;03m# dx_dt[1:-1] = (X[2:] - X[:-2]) / (T[2:] - T[:-2])\u001b[39;00m\n\u001b[1;32m---> 28\u001b[0m dx_dt[\u001b[38;5;241m1\u001b[39m:\u001b[38;5;28mlen\u001b[39m(X)\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m=\u001b[39m (X[\u001b[38;5;241m2\u001b[39m:\u001b[38;5;28mlen\u001b[39m(X)] \u001b[38;5;241m-\u001b[39m X[:\u001b[38;5;28mlen\u001b[39m(X)\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m]) \u001b[38;5;241m/\u001b[39m (T[\u001b[38;5;241m2\u001b[39m:\u001b[38;5;28mlen\u001b[39m(X)] \u001b[38;5;241m-\u001b[39m T[:\u001b[38;5;28mlen\u001b[39m(X)\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m])\n\u001b[0;32m     30\u001b[0m \u001b[38;5;66;03m# Example:\u001b[39;00m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;66;03m# x0 x1 x2 x3\u001b[39;00m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;66;03m# t0 t1 t2 t3\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[38;5;66;03m#     print(dx_dt)\u001b[39;00m\n\u001b[0;32m     40\u001b[0m \u001b[38;5;66;03m#     raise ValueError(\"dx_dt contains NaNs\")\u001b[39;00m\n\u001b[0;32m     42\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m dx_dt\n","File \u001b[1;32mc:\\Users\\proshian\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\_tensor.py:964\u001b[0m, in \u001b[0;36mTensor.__len__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    961\u001b[0m \u001b[38;5;21m__neg__\u001b[39m \u001b[38;5;241m=\u001b[39m _C\u001b[38;5;241m.\u001b[39m_TensorBase\u001b[38;5;241m.\u001b[39mneg\n\u001b[0;32m    962\u001b[0m \u001b[38;5;21m__abs__\u001b[39m \u001b[38;5;241m=\u001b[39m _C\u001b[38;5;241m.\u001b[39m_TensorBase\u001b[38;5;241m.\u001b[39mabs\n\u001b[1;32m--> 964\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__len__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    965\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    966\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(Tensor\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__len__\u001b[39m, (\u001b[38;5;28mself\u001b[39m,), \u001b[38;5;28mself\u001b[39m)\n","\u001b[1;31mKeyboardInterrupt\u001b[0m: "]}],"source":["for i in tqdm(range(len(train_dataset))):\n","    train_dataset[i]"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-04T13:54:23.371341Z","iopub.status.busy":"2024-03-04T13:54:23.370609Z","iopub.status.idle":"2024-03-04T13:54:23.443298Z","shell.execute_reply":"2024-03-04T13:54:23.442322Z","shell.execute_reply.started":"2024-03-04T13:54:23.371311Z"},"trusted":true},"outputs":[],"source":["device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-04T13:54:24.157059Z","iopub.status.busy":"2024-03-04T13:54:24.156697Z","iopub.status.idle":"2024-03-04T13:54:24.255813Z","shell.execute_reply":"2024-03-04T13:54:24.254786Z","shell.execute_reply.started":"2024-03-04T13:54:24.157031Z"},"trusted":true},"outputs":[],"source":["transformer = get_m1_bigger_model(device)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-04T13:54:25.813704Z","iopub.status.busy":"2024-03-04T13:54:25.813320Z","iopub.status.idle":"2024-03-04T13:54:25.886333Z","shell.execute_reply":"2024-03-04T13:54:25.885275Z","shell.execute_reply.started":"2024-03-04T13:54:25.813678Z"},"trusted":true},"outputs":[],"source":["def cross_entropy_with_reshape(pred, target, ignore_index=-100, label_smoothing=0.0):\n","    \"\"\"\n","    pred - BatchSize x TargetLen x VocabSize\n","    target - BatchSize x TargetLen\n","    \"\"\"\n","    pred_flat = pred.view(-1, pred.shape[-1])  # BatchSize*TargetLen x VocabSize\n","    target_flat = target.reshape(-1)  # BatchSize*TargetLen\n","    return F.cross_entropy(pred_flat,\n","                           target_flat,\n","                           ignore_index=ignore_index,\n","                           label_smoothing=label_smoothing)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-04T13:54:26.164529Z","iopub.status.busy":"2024-03-04T13:54:26.164190Z","iopub.status.idle":"2024-03-04T13:54:26.235473Z","shell.execute_reply":"2024-03-04T13:54:26.234442Z","shell.execute_reply.started":"2024-03-04T13:54:26.164503Z"},"trusted":true},"outputs":[],"source":["def lr_scheduler(optimizer):\n","    return torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer,\n","                                                      patience=20,\n","                                                      factor=0.5,\n","                                                      verbose=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-04T13:54:26.467902Z","iopub.status.busy":"2024-03-04T13:54:26.467355Z","iopub.status.idle":"2024-03-04T13:54:26.539070Z","shell.execute_reply":"2024-03-04T13:54:26.538195Z","shell.execute_reply.started":"2024-03-04T13:54:26.467875Z"},"trusted":true},"outputs":[],"source":["def move_all_to_device(x, device):\n","    if torch.is_tensor(x):\n","        return x.to(device)\n","    elif not isinstance(x, (list, tuple)):\n","        raise ValueError(f'Unexpected data type {type(x)}')\n","    new_x = []\n","    for el in x:\n","        if not torch.is_tensor(el):\n","            raise ValueError(f'Unexpected data type {type(el)}')\n","        new_x.append(el.to(device))\n","    return new_x"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-04T13:54:27.261710Z","iopub.status.busy":"2024-03-04T13:54:27.261018Z","iopub.status.idle":"2024-03-04T13:54:27.333970Z","shell.execute_reply":"2024-03-04T13:54:27.332793Z","shell.execute_reply.started":"2024-03-04T13:54:27.261678Z"},"trusted":true},"outputs":[],"source":["collate_fn = CollateFn(\n","    word_pad_idx = word_char_tokenizer.char_to_idx['<pad>'], batch_first = False)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-04T13:54:27.836872Z","iopub.status.busy":"2024-03-04T13:54:27.836505Z","iopub.status.idle":"2024-03-04T13:54:29.617141Z","shell.execute_reply":"2024-03-04T13:54:29.616109Z","shell.execute_reply.started":"2024-03-04T13:54:27.836845Z"},"trusted":true},"outputs":[],"source":["# Протестируем корректность collate_fn (вызывается неявно в DataLoader)\n","\n","batch_size = 6\n","\n","\n","PAD_CHAR_TOKEN = word_char_tokenizer.char_to_idx[\"<pad>\"]\n","\n","\n","train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=False,\n","                              num_workers=0, collate_fn=collate_fn)\n","\n","\n","dataset_els = [train_dataset[i] for i in range(batch_size)]\n","unproc_batch_x, unproc_batch_y = zip(*dataset_els)\n","\n","batch_x, batch_y = next(iter(train_dataloader))\n","\n","\n","############### Проверка корректности batch_y ###################\n","max_out_seq_len = max([len(y) for y in unproc_batch_y])\n","\n","assert batch_y.shape == (max_out_seq_len, batch_size)\n","\n","\n","for i in range(batch_size):\n","    assert (batch_y[:len(unproc_batch_y[i]), i] == unproc_batch_y[i]).all()\n","    assert (batch_y[len(unproc_batch_y[i]):, i] == PAD_CHAR_TOKEN).all()\n","\n","print(\"batch_y is correct\")\n","\n","\n","\n","############### Проверка корректности batch_x ###################\n","unproc_batch_traj_feats, unproc_batch_kb_tokens, unproc_batch_dec_in_char_seq = zip(*unproc_batch_x)\n","\n","(traj_feats, kb_tokens, dec_in_char_seq, traj_pad_mask, word_pad_mask) = batch_x\n","\n","\n","# каждая сущность, полученная выше из unpoc_batch_x - это tuple длины batch_size.\n","# Например, unproc_batch_traj_feats[i] = train_dataset[i][0][0]\n","\n","N_TRAJ_FEATS = 6\n","max_curve_len = max([el.shape[0] for el in unproc_batch_traj_feats]) \n","\n","assert max_curve_len == max([el.shape[0] for el in unproc_batch_kb_tokens])\n","\n","assert traj_feats.shape == (max_curve_len, batch_size, N_TRAJ_FEATS)\n","assert kb_tokens.shape == (max_curve_len, batch_size)\n","assert dec_in_char_seq.shape == (max_out_seq_len, batch_size)\n","assert traj_pad_mask.shape == (batch_size, max_curve_len)\n","assert word_pad_mask.shape == (batch_size, max_out_seq_len)\n","\n","\n","for i in range(batch_size):\n","    assert (traj_feats[:len(unproc_batch_traj_feats[i]), i] == unproc_batch_traj_feats[i]).all()\n","    assert (kb_tokens[:len(unproc_batch_kb_tokens[i]), i] == unproc_batch_kb_tokens[i]).all()\n","\n","    assert (dec_in_char_seq[:len(unproc_batch_dec_in_char_seq[i]), i] == unproc_batch_dec_in_char_seq[i]).all()\n","    assert (dec_in_char_seq[len(unproc_batch_dec_in_char_seq[i]):, i] == PAD_CHAR_TOKEN).all()\n","\n","    assert (traj_pad_mask[i, :len(unproc_batch_traj_feats[i])] == False).all()\n","    assert (traj_pad_mask[i, len(unproc_batch_traj_feats[i]):] == True).all()\n","    \n","    assert (word_pad_mask[i, :len(unproc_batch_dec_in_char_seq[i])] == False).all()\n","    assert (word_pad_mask[i, len(unproc_batch_dec_in_char_seq[i]):] == True).all()\n","\n","print(\"batch_x is correct\")"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-04T13:54:29.619256Z","iopub.status.busy":"2024-03-04T13:54:29.618953Z","iopub.status.idle":"2024-03-04T13:54:29.699195Z","shell.execute_reply":"2024-03-04T13:54:29.698138Z","shell.execute_reply.started":"2024-03-04T13:54:29.619232Z"},"trusted":true},"outputs":[],"source":["from typing import List\n","\n","# def predict_greedy_raw(dataset,\n","#                        greedy_word_generator: GreedyGenerator,\n","#                       ) -> List[List[str]]:\n","#     \"\"\"\n","#     Creates predictions using greedy generation.\n","\n","#     Supposed to be used with a dataset of a single grid\n","    \n","#     Arguments:\n","#     ----------\n","#     dataset: NeuroSwipeDatasetv2\n","#     grid_name_to_greedy_generator: dict\n","#         Dict mapping grid names to GreedyGenerator objects.\n","#     \"\"\"\n","#     preds = [None] * len(dataset)\n","\n","#     for data in tqdm(enumerate(dataset), total=len(dataset)):\n","# #         i, ((xyt, kb_tokens, _, traj_pad_mask, _), _, grid_name) = data\n","#         i, ((xyt, kb_tokens, _, _), _) = data\n","\n","#         pred = greedy_word_generator.generate_word_only(xyt, kb_tokens)\n","#         pred = pred.removeprefix(\"<sos>\")\n","# #         preds[i] = [pred]\n","#         preds[i] = pred\n","\n","#     return preds\n","\n","\n","\n","\n","def predict_greedy_raw(dataset,\n","                       greedy_word_generator: GreedyGenerator,\n","                      ) -> List[List[str]]:\n","    \"\"\"\n","    Creates predictions using greedy generation.\n","\n","    Supposed to be used with a dataset of a single grid\n","    \n","    Arguments:\n","    ----------\n","    dataset: NeuroSwipeDatasetv2\n","    grid_name_to_greedy_generator: dict\n","        Dict mapping grid names to GreedyGenerator objects.\n","    \"\"\"\n","    preds = [None] * len(dataset)\n","\n","    for data in tqdm(enumerate(dataset), total=len(dataset)):\n","#         i, ((xyt, kb_tokens, _, traj_pad_mask, _), _, grid_name) = data\n","        i, ((xyt, kb_tokens, _), _) = data\n","\n","        pred = greedy_word_generator.generate_word_only(xyt, kb_tokens)\n","        pred = pred.removeprefix(\"<sos>\")\n","#         preds[i] = [pred]\n","        preds[i] = pred\n","\n","    return preds\n","\n","\n","\n","\n","# def get_targets(dataset: NeuroSwipeDatasetv3) -> tp.List[str]:\n","#     targets = []\n","#     for (_, _, _, word_pad_mask), target_tokens in dataset:\n","#         target_len = int(torch.sum(~word_pad_mask)) - 1\n","#         target = word_char_tokenizer.decode(target_tokens[:target_len])\n","#         targets.append(target)\n","#     return targets\n","\n","def get_targets(dataset: CurveDataset) -> tp.List[str]:\n","    targets = []\n","    for (_, _, _), target_tokens in dataset:\n","        target_len = int(torch.sum(~word_pad_mask)) - 1\n","        target = word_char_tokenizer.decode(target_tokens[:target_len])\n","        targets.append(target)\n","    return targets\n","\n","\n","def get_accuracy(preds, targets) -> float:\n","    return sum(pred == target for pred, target \n","               in zip(preds, targets)) / len(targets)\n","\n","\n","def get_greedy_generator_accuracy(val_dataset, model, \n","                                  word_char_tokenizer, device) -> float:\n","    val_targets = get_targets(val_dataset)\n","    greedy_generator = GreedyGenerator(model, word_char_tokenizer, device)\n","    greedy_preds = predict_greedy_raw(val_dataset, greedy_generator)\n","    return get_accuracy(greedy_preds, val_targets)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-04T13:54:29.701321Z","iopub.status.busy":"2024-03-04T13:54:29.700426Z","iopub.status.idle":"2024-03-04T13:56:11.381156Z","shell.execute_reply":"2024-03-04T13:56:11.379183Z","shell.execute_reply.started":"2024-03-04T13:54:29.701295Z"},"trusted":true},"outputs":[],"source":["###################### протестируем predict_greedy_raw ######################\n","\n","\n","MODEL_TO_TEST_GREEDY_GEN__PATH = None\n","\n","# MODEL_TO_TEST_GREEDY_GEN__PATH = \"/kaggle/input/m1-bigger-v2-0-13413-extra-l2-0-ls0-switch-1-pt/\" \\\n","#     \"m1_bigger_v2__2023_11_12__02_27_14__0.13413_extra_l2_0_ls0_switch_1.pt\"\n","    \n","\n","def test_greedy_generator(val_dataset, model_getter, model_weights, word_char_tokenizer, device) -> float:\n","    \n","    model = model_getter(device, model_weights)\n","\n","    return get_greedy_generator_accuracy(val_dataset, model, word_char_tokenizer, device)\n","\n","\n","\n","test_greedy_generator(val_dataset, get_m1_bigger_model, MODEL_TO_TEST_GREEDY_GEN__PATH, word_char_tokenizer, device)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-04T13:56:19.594395Z","iopub.status.busy":"2024-03-04T13:56:19.594001Z","iopub.status.idle":"2024-03-04T13:56:19.687539Z","shell.execute_reply":"2024-03-04T13:56:19.686557Z","shell.execute_reply.started":"2024-03-04T13:56:19.594367Z"},"trusted":true},"outputs":[],"source":["def train_eval_loop(model, train_dataset, val_dataset, criterion,\n","                    tb, epoch_start, lr=1e-4, epoch_n=10, batch_size=32,\n","                    collate_fn = None,\n","                    device=None, early_stopping_patience=20, l2_reg_alpha=0,\n","                    max_batches_per_epoch_train=10000,\n","                    max_batches_per_epoch_val=1000,\n","                    optimizer_ctor=None,\n","                    lr_scheduler_ctor=None,\n","                    shuffle_train=True,\n","                    label_smoothing = 0.0,\n","                    dataloader_workers_n=0,\n","                    criterion_ignore_index = -100,\n","                    model_name_postfix = \"\",\n","                    model_save_root = \".\",\n","                    ):\n","    \"\"\"\n","    Цикл для обучения модели. После каждой эпохи качество модели оценивается по отложенной выборке.\n","    :param model: torch.nn.Module - обучаемая модель\n","    :param train_dataset: torch.utils.data.Dataset - данные для обучения\n","    :param val_dataset: torch.utils.data.Dataset - данные для оценки качества\n","    :param criterion: функция потерь для настройки модели\n","    :param lr: скорость обучения\n","    :param epoch_n: максимальное количество эпох\n","    :param batch_size: количество примеров, обрабатываемых моделью за одну итерацию\n","    :param device: cuda/cpu - устройство, на котором выполнять вычисления\n","    :param early_stopping_patience: наибольшее количество эпох, в течение которых допускается\n","        отсутствие улучшения модели, чтобы обучение продолжалось.\n","    :param l2_reg_alpha: коэффициент L2-регуляризации\n","    :param max_batches_per_epoch_train: максимальное количество итераций на одну эпоху обучения\n","    :param max_batches_per_epoch_val: максимальное количество итераций на одну эпоху валидации\n","    :return: кортеж из двух элементов:\n","        - среднее значение функции потерь на валидации на лучшей эпохе\n","        - лучшая модель\n","    \"\"\"\n","    if device is None:\n","        device =  torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","    model.to(device)\n","\n","    if optimizer_ctor is None:\n","        optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=l2_reg_alpha)\n","    else:\n","        optimizer = optimizer_ctor(model.parameters(), lr=lr)\n","\n","    if lr_scheduler_ctor is not None:\n","        lr_scheduler = lr_scheduler_ctor(optimizer)\n","    else:\n","        lr_scheduler = None\n","\n","    train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=shuffle_train,\n","                                        num_workers=dataloader_workers_n, collate_fn=collate_fn)\n","    val_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False,\n","                                      num_workers=dataloader_workers_n, collate_fn=collate_fn)\n","\n","    best_val_loss = float('inf')\n","    best_epoch_i = 0\n","\n","    best_model_path = \"m1_bigger_v2.pt\"\n","    \n","    n_train_examples_in_epoch = (batch_size * max_batches_per_epoch_train \n","                                 if max_batches_per_epoch_train < len(train_dataset) // batch_size\n","                                 else len(train_dataset))\n","\n","    if os.path.exists(best_model_path):\n","        best_model.load_state_dict(torch.load(best_model_path))\n","        print(f\"Загружено состояние модели {best_model_path}\")\n","\n","    for epoch_i in tqdm(range(epoch_start, epoch_start + epoch_n), position = 0):\n","        try:\n","            model.train()\n","            mean_train_loss = 0\n","            train_batches_n = 0\n","            for batch_i, (batch_x, batch_y) in tqdm(enumerate(train_dataloader), total = min(max_batches_per_epoch_train, len(train_dataset) // batch_size), position=1, leave = False):\n","                if batch_i > max_batches_per_epoch_train:\n","                    break\n","                    \n","\n","                batch_x, batch_y = [move_all_to_device(el, device) for el in (batch_x, batch_y)]\n","\n","                pred = model(*batch_x)\n","                loss = criterion(pred, batch_y, ignore_index = criterion_ignore_index, \n","                                 label_smoothing=label_smoothing)\n","\n","                model.zero_grad()\n","                loss.backward()\n","\n","                optimizer.step()\n","\n","                mean_train_loss += float(loss)\n","                train_batches_n += 1\n","\n","            mean_train_loss /= train_batches_n\n","            \n","            print('Среднее значение функции потерь на обучении', mean_train_loss)\n","\n","            tb.add_scalar('mean_loss/train', mean_train_loss, epoch_i * n_train_examples_in_epoch)\n","\n","\n","\n","            model.eval()\n","            mean_val_loss = 0\n","            val_batches_n = 0\n","\n","            with torch.no_grad():\n","                for batch_i, (batch_x, batch_y) in enumerate(val_dataloader):\n","                    if batch_i > max_batches_per_epoch_val:\n","                        break\n","\n","                    batch_x, batch_y = [move_all_to_device(el, device) for el in (batch_x, batch_y)]\n","\n","                    pred = model(*batch_x)\n","                    loss = criterion(pred, batch_y, \n","                                     ignore_index = criterion_ignore_index, \n","                                     label_smoothing=label_smoothing)\n","\n","                    mean_val_loss += float(loss)\n","                    val_batches_n += 1\n","\n","            mean_val_loss /= val_batches_n\n","            print('Среднее значение функции потерь на валидации', mean_val_loss)\n","            tb.add_scalar('mean_loss/val', mean_val_loss, epoch_i * n_train_examples_in_epoch)\n","\n","            if mean_val_loss < best_val_loss:\n","                best_epoch_i = epoch_i\n","                best_val_loss = mean_val_loss\n","                best_model = copy.deepcopy(model)\n","                torch.save(model.state_dict(), os.path.join(model_save_root, best_model_path))\n","                \n","                cur_time = \"{:%Y_%m_%d__%H_%M_%S}\".format(datetime.now())\n","                \n","               \n","                greedy_accuracy = get_greedy_generator_accuracy(val_dataset, model, word_char_tokenizer, device)\n","                tb.add_scalar('greedy_accuracy/val', greedy_accuracy, epoch_i * n_train_examples_in_epoch)\n","                \n","                torch.save(model.state_dict(), os.path.join(model_save_root, f\"m1_bigger_v2__{cur_time}__{mean_val_loss:.5f}__greed_acc_{greedy_accuracy:.5f}__{model_name_postfix}__epoch_i_{epoch_i}.pt\"))\n","                print(f\"Greedy accuracy = {greedy_accuracy}\")\n","                print('Новая лучшая модель!')\n","            elif epoch_i - best_epoch_i > early_stopping_patience:\n","                print('Модель не улучшилась за последние {} эпох, прекращаем обучение'.format(\n","                    early_stopping_patience))\n","                break\n","\n","            if lr_scheduler is not None:\n","                lr_scheduler.step(mean_val_loss)\n","\n","            print()\n","        except KeyboardInterrupt:\n","            print('Досрочно остановлено пользователем')\n","            break\n","        except Exception as ex:\n","            print('Ошибка при обучении: {}\\n{}'.format(ex, traceback.format_exc()))\n","            break"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-04T13:56:24.059429Z","iopub.status.busy":"2024-03-04T13:56:24.059052Z","iopub.status.idle":"2024-03-04T13:56:24.133280Z","shell.execute_reply":"2024-03-04T13:56:24.132283Z","shell.execute_reply.started":"2024-03-04T13:56:24.059400Z"},"trusted":true},"outputs":[],"source":["EXPERIMENT_NAME = f\"m1_bigger_model__{GRID_NAME}__from_random_weights__batch__{BATCH_SIZE}/SEED_{RANDOM_SEED}__run1\"\n","TENSORBOARD_LOG_PATH = f\"/kaggle/working/tensorboard_log/{EXPERIMENT_NAME}\"\n","\n","tb = SummaryWriter(TENSORBOARD_LOG_PATH)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-04T13:56:25.056182Z","iopub.status.busy":"2024-03-04T13:56:25.055839Z"},"trusted":true},"outputs":[],"source":["l2_reg_alpha =  0 #5e-5\n","label_smoothing=  0 #0.045\n","epoch_start = 0\n","\n","best_val_loss, best_model = train_eval_loop(\n","    transformer, train_dataset, val_dataset, cross_entropy_with_reshape, tb, epoch_start,\n","    lr=1e-4, epoch_n=10000, batch_size=BATCH_SIZE, collate_fn = collate_fn,\n","    device=device, early_stopping_patience=20, l2_reg_alpha=l2_reg_alpha,\n","    max_batches_per_epoch_train=2000,\n","    max_batches_per_epoch_val=1000,\n","    optimizer_ctor=None,\n","    lr_scheduler_ctor=lr_scheduler,\n","    shuffle_train=True,\n","    dataloader_workers_n=0,\n","    criterion_ignore_index = word_char_tokenizer.char_to_idx['<pad>'],\n","    model_name_postfix = f'{GRID_NAME}_l2_{l2_reg_alpha}_ls{label_smoothing}',\n","    model_save_root = \"../..\",\n","    label_smoothing=label_smoothing,\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Эпоха должна длиться 16 минут"]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30665,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.5"}},"nbformat":4,"nbformat_minor":4}
