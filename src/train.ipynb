{"cells":[{"cell_type":"raw","metadata":{"execution":{"iopub.execute_input":"2024-05-02T17:33:44.510671Z","iopub.status.busy":"2024-05-02T17:33:44.510266Z","iopub.status.idle":"2024-05-02T17:33:44.515204Z","shell.execute_reply":"2024-05-02T17:33:44.513998Z","shell.execute_reply.started":"2024-05-02T17:33:44.510640Z"}},"source":["# !git clone https://github.com/proshian/yandex-cup-2023-ml-neuroswipe.git\n","# %cd yandex-cup-2023-ml-neuroswipe"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-02T18:09:55.129636Z","iopub.status.busy":"2024-05-02T18:09:55.129280Z","iopub.status.idle":"2024-05-02T18:10:20.845429Z","shell.execute_reply":"2024-05-02T18:10:20.844380Z","shell.execute_reply.started":"2024-05-02T18:09:55.129610Z"},"trusted":true},"outputs":[],"source":["!pip install lightning --quiet\n","!pip install torchmetrics --quiet"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-02T18:10:20.848706Z","iopub.status.busy":"2024-05-02T18:10:20.847835Z","iopub.status.idle":"2024-05-02T18:10:20.869240Z","shell.execute_reply":"2024-05-02T18:10:20.868362Z","shell.execute_reply.started":"2024-05-02T18:10:20.848670Z"},"trusted":true},"outputs":[],"source":["%load_ext autoreload\n","%autoreload 2"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-02T18:13:10.631350Z","iopub.status.busy":"2024-05-02T18:13:10.630237Z","iopub.status.idle":"2024-05-02T18:13:13.001177Z","shell.execute_reply":"2024-05-02T18:13:12.999976Z","shell.execute_reply.started":"2024-05-02T18:13:10.631313Z"},"trusted":true},"outputs":[],"source":["%cd /kaggle/working/yandex-cup-2023-ml-neuroswipe\n","! git pull\n","!git checkout transformer-conformer-lightning\n","\n","%cd /kaggle/working/yandex-cup-2023-ml-neuroswipe/src"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-02T18:13:15.157002Z","iopub.status.busy":"2024-05-02T18:13:15.156319Z","iopub.status.idle":"2024-05-02T18:13:15.161171Z","shell.execute_reply":"2024-05-02T18:13:15.160227Z","shell.execute_reply.started":"2024-05-02T18:13:15.156965Z"},"trusted":true},"outputs":[],"source":["# !rm -r /kaggle/working/yandex-cup-2023-ml-neuroswipe/src/lightning_logs\n","# !rm -r /kaggle/working/yandex-cup-2023-ml-neuroswipe/src/checkpoints\n","# !rm -r /kaggle/working/yandex-cup-2023-ml-neuroswipe/src/checkpoint_epoch_end"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-02T18:13:15.990820Z","iopub.status.busy":"2024-05-02T18:13:15.990113Z","iopub.status.idle":"2024-05-02T18:13:15.994795Z","shell.execute_reply":"2024-05-02T18:13:15.993784Z","shell.execute_reply.started":"2024-05-02T18:13:15.990790Z"},"trusted":true},"outputs":[],"source":["# !zip -r /kaggle/working/src.zip /kaggle/working/yandex-cup-2023-ml-neuroswipe/src"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-02T18:13:16.287367Z","iopub.status.busy":"2024-05-02T18:13:16.286682Z","iopub.status.idle":"2024-05-02T18:13:16.291051Z","shell.execute_reply":"2024-05-02T18:13:16.290135Z","shell.execute_reply.started":"2024-05-02T18:13:16.287334Z"},"trusted":true},"outputs":[],"source":["# !rm /kaggle/working/src.zip "]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-02T18:29:00.755843Z","iopub.status.busy":"2024-05-02T18:29:00.754968Z","iopub.status.idle":"2024-05-02T18:29:00.761854Z","shell.execute_reply":"2024-05-02T18:29:00.760735Z","shell.execute_reply.started":"2024-05-02T18:29:00.755810Z"},"trusted":true},"outputs":[],"source":["############# Script arguments emulation #############\n","\n","GRID_NAME = \"default\"\n","TRAIN_BATCH_SIZE = 256\n","VAL_BATCH_SIZE = 512\n","IN_KAGGLE = False\n","RANDOM_SEED = 12\n","NOISE_RANGE = 0  # set to 0 to avoid augmentation\n","LOG_DIR = \"lightning_logs/\"\n","MODEL_NAME = \"transformer_m1_bigger\"\n","TRANSFORM_NAME = \"traj_feats_and_nearest_key\"\n","\n","USE_AUGMENTATIONS_STR = f\"uniform_int_noise_{NOISE_RANGE}__\" if NOISE_RANGE else \"\"\n","EXPERIMENT_NAME = f\"{MODEL_NAME}__{GRID_NAME}__{USE_AUGMENTATIONS_STR}from_random_weights__batch__{TRAIN_BATCH_SIZE}/SEED_{RANDOM_SEED}\"\n","\n","DATA_ROOT = \"../data/data_separated_grid\"\n","MODELS_DIR = \"../data/trained_models/m1\""]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-02T18:13:17.180124Z","iopub.status.busy":"2024-05-02T18:13:17.179478Z","iopub.status.idle":"2024-05-02T18:13:17.199280Z","shell.execute_reply":"2024-05-02T18:13:17.198561Z","shell.execute_reply.started":"2024-05-02T18:13:17.180093Z"},"trusted":true},"outputs":[],"source":["import os\n","import json\n","import typing as tp\n","\n","\n","import torch\n","# import torch.nn as nn\n","import torch.nn.functional as F\n","from torch.utils.data import DataLoader\n","from tqdm.notebook import tqdm\n","import numpy as np\n","from torch.utils.tensorboard import SummaryWriter\n","\n","\n","# from model import SwipeCurveTransformer, get_m1_bigger_model\n","from ns_tokenizers import CharLevelTokenizerv2, KeyboardTokenizerv1\n","from ns_tokenizers import ALL_CYRILLIC_LETTERS_ALPHABET_ORD\n","from dataset import CurveDataset, CollateFn\n","from word_generators import GreedyGenerator  # NearestKeyLookup\n","from nearest_key_lookup import ExtendedNearestKeyLookup\n","from transforms import FullTransform"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-02T18:13:17.439348Z","iopub.status.busy":"2024-05-02T18:13:17.438750Z","iopub.status.idle":"2024-05-02T18:13:17.444676Z","shell.execute_reply":"2024-05-02T18:13:17.443733Z","shell.execute_reply.started":"2024-05-02T18:13:17.439316Z"},"trusted":true},"outputs":[],"source":["################ Other constants ####################    \n","GRID_NAME_TO_DS_PATHS = {\n","    \"extra\": {\n","        \"train\": os.path.join(DATA_ROOT, \"train__extra_only_no_errors__2023_11_01__19_49_14.jsonl\"),\n","        \"val\": os.path.join(DATA_ROOT, \"valid__in_train_format__extra_only.jsonl\")\n","    },\n","    \"default\": {\n","        \"train\": os.path.join(DATA_ROOT, \"train__default_only_no_errors__2023_10_31__03_26_16.jsonl\"),\n","        \"val\": os.path.join(DATA_ROOT, \"valid__in_train_format__default_only.jsonl\")\n","    }\n","}\n","\n","\n","DS_PATHS =  GRID_NAME_TO_DS_PATHS[GRID_NAME]"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-02T18:13:23.993490Z","iopub.status.busy":"2024-05-02T18:13:23.992600Z","iopub.status.idle":"2024-05-02T18:13:23.997118Z","shell.execute_reply":"2024-05-02T18:13:23.996238Z","shell.execute_reply.started":"2024-05-02T18:13:23.993455Z"},"trusted":true},"outputs":[],"source":["# if IN_KAGGLE:\n","#     DATA_ROOT = \"/kaggle/input/neuroswipe-defualt-only-v1\"\n","#     MODELS_DIR = \"\""]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-02T18:13:24.545698Z","iopub.status.busy":"2024-05-02T18:13:24.545335Z","iopub.status.idle":"2024-05-02T18:13:24.550608Z","shell.execute_reply":"2024-05-02T18:13:24.549535Z","shell.execute_reply.started":"2024-05-02T18:13:24.545669Z"},"trusted":true},"outputs":[],"source":["def init_random_seed(value):\n","    # random.seed(value)\n","    np.random.seed(value)\n","    torch.manual_seed(value)\n","    torch.cuda.manual_seed(value)\n","    # torch.backends.cudnn.deterministic = True"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-02T18:13:24.801751Z","iopub.status.busy":"2024-05-02T18:13:24.800840Z","iopub.status.idle":"2024-05-02T18:13:24.806777Z","shell.execute_reply":"2024-05-02T18:13:24.805697Z","shell.execute_reply.started":"2024-05-02T18:13:24.801719Z"},"trusted":true},"outputs":[],"source":["def get_grid(grid_name: str, grids_path: str) -> dict:\n","    with open(grids_path, \"r\", encoding=\"utf-8\") as f:\n","        return json.load(f)[grid_name]"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-02T18:13:25.073331Z","iopub.status.busy":"2024-05-02T18:13:25.072610Z","iopub.status.idle":"2024-05-02T18:13:25.082270Z","shell.execute_reply":"2024-05-02T18:13:25.081365Z","shell.execute_reply.started":"2024-05-02T18:13:25.073299Z"},"trusted":true},"outputs":[],"source":["from typing import List, Dict, Tuple, Optional, Set\n","\n","def get_gridname_to_out_of_bounds_coords_dict(\n","        data_paths: List[str], gridname_to_wh: dict,\n","        totals: tp.Iterable[Optional[int]] = None\n","        ) -> Dict[str, Set[Tuple[int, int]]]:\n","    \"\"\"\n","    Returns a dictionary with grid names as keys and lists of out of bounds coordinates as values.\n","    \"\"\"\n","    totals = totals or [None] * len(data_paths)\n","    \n","    gname_to_out_of_bounds = {gname: set() for gname in gridname_to_wh.keys()}\n","\n","    for data_path, total in zip(data_paths, totals):\n","        with open(data_path, \"r\", encoding=\"utf-8\") as json_file:\n","            for line in tqdm(json_file, total=total):\n","                json_data = json.loads(line)\n","                curve = json_data['curve']\n","                grid_name = curve['grid_name']\n","                w, h = gridname_to_wh[grid_name]\n","                X, Y = curve['x'], curve['y']\n","                out_of_bounds = set((x, y) for x, y in zip(X, Y) \n","                                    if x < 0 or x >= w or y < 0 or y >= h)\n","                gname_to_out_of_bounds[grid_name].update(out_of_bounds)\n","    return gname_to_out_of_bounds"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-02T18:13:25.467358Z","iopub.status.busy":"2024-05-02T18:13:25.466660Z","iopub.status.idle":"2024-05-02T18:13:25.478831Z","shell.execute_reply":"2024-05-02T18:13:25.477889Z","shell.execute_reply.started":"2024-05-02T18:13:25.467325Z"},"trusted":true},"outputs":[],"source":["from typing import Dict, Set, Tuple\n","\n","\n","def update_out_of_bounds_with_noise(\n","    noise_min, noise_max,\n","    gname_to_out_of_bounds, gridname_to_wh: dict,\n","    )-> Dict[str, Set[Tuple[int, int]]]:\n","    \n","    assert noise_min <= 0\n","    assert noise_max >= 0\n","    \n","    additional_out_of_bounds = {gname: set() for gname in gridname_to_wh.keys()}\n","    \n","    for gname in gname_to_out_of_bounds.keys():\n","        w, h = gridname_to_wh[gname]\n","        \n","        for x, y in gname_to_out_of_bounds[gname]:\n","            for i in range(noise_min, noise_max+1):\n","                for j in range(noise_min, noise_max+1):\n","                    if x+i < 0 or x+i >= w or y+j < 0 or y+j >=h: \n","                        additional_out_of_bounds[gname].add((x+i, y+j))\n","        \n","        for x in range(noise_min, w+noise_max+1):\n","            for y in range(noise_min, 0):\n","                additional_out_of_bounds[gname].add((x, y))\n","        \n","        for x in range(noise_min, w+noise_max+1):\n","            for y in range(h+1, h+noise_max+1):\n","                additional_out_of_bounds[gname].add((x, y))\n","        \n","        for x in range(w, w+noise_max+1):\n","            for y in range(0, h+1):\n","                additional_out_of_bounds[gname].add((x, y))\n","        \n","        for x in range(noise_min, 0):\n","            for y in range(0, h+1):\n","                additional_out_of_bounds[gname].add((x, y))\n","                \n","        gname_to_out_of_bounds[gname].update(additional_out_of_bounds[gname])\n","        \n","    return gname_to_out_of_bounds\n","        "]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-02T18:13:26.593553Z","iopub.status.busy":"2024-05-02T18:13:26.592682Z","iopub.status.idle":"2024-05-02T18:13:26.601320Z","shell.execute_reply":"2024-05-02T18:13:26.600305Z","shell.execute_reply.started":"2024-05-02T18:13:26.593519Z"},"trusted":true},"outputs":[],"source":["import numpy as np\n","\n","class RandIntToTrajTransform:\n","    def __init__(self, min_ = -3, max_ = 3) -> None:\n","        self.min = min_\n","        self.max = max_\n","        \n","    def __call__(self, data):\n","        X, Y, T, grid_name, tgt_word = data\n","        X = np.array(X, dtype = int) + np.random.randint(self.min, self.max, (len(X),))\n","        Y = np.array(Y, dtype = int) + np.random.randint(self.min, self.max, (len(Y),))\n","        return X, Y, T, grid_name, tgt_word\n","    \n","class SequentialTransform:\n","    def __init__(self, transforms) -> None:\n","        self.transforms = transforms\n","    \n","    def __call__(self, data):\n","        for transform in self.transforms:\n","            data = transform(data)\n","        return data"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-02T18:13:28.585046Z","iopub.status.busy":"2024-05-02T18:13:28.584691Z","iopub.status.idle":"2024-05-02T18:13:28.607345Z","shell.execute_reply":"2024-05-02T18:13:28.606581Z","shell.execute_reply.started":"2024-05-02T18:13:28.585011Z"},"trusted":true},"outputs":[],"source":["from typing import Callable, Tuple, Optional\n","from predict import get_grid\n","\n","def get_transforms(gridname_to_grid_path: str,\n","                   grid_name: str,\n","                   transform_name: str,\n","                   char_tokenizer: KeyboardTokenizerv1,\n","                   uniform_noise_range: bool,\n","                   totals: Tuple[Optional[int], Optional[int]] = (None, None)\n","                   ) -> Tuple[Callable, Callable]:\n","    \"\"\"Returns train and validation transforms.\"\"\"\n","    \n","    grid = get_grid(grid_name, gridname_to_grid_path)\n","    w, h = grid['width'], grid['height']\n","    \n","    if transform_name == \"traj_feats_and_nearest_key\":\n","\n","        gname_to_wh = {grid_name: (w, h)}\n","                \n","        print(\"Accumulating out-of-bounds coordinates...\")\n","        gname_to_out_of_bounds = get_gridname_to_out_of_bounds_coords_dict(\n","            DS_PATHS.values(), \n","            gridname_to_wh = gname_to_wh,\n","            totals=totals\n","        )\n","\n","        print(\"augmenting gname_to_out_of_bounds\")\n","        gname_to_out_of_bounds = update_out_of_bounds_with_noise(\n","            noise_min = -NOISE_RANGE, noise_max=NOISE_RANGE+1,\n","            gname_to_out_of_bounds = gname_to_out_of_bounds, gridname_to_wh = gname_to_wh,\n","        )\n","\n","\n","        print(\"Creating ExtendedNearestKeyLookups...\")\n","        gridname_to_nkl = {\n","            grid_name: ExtendedNearestKeyLookup(\n","                grid, ALL_CYRILLIC_LETTERS_ALPHABET_ORD,\n","                gname_to_out_of_bounds[grid_name]\n","            )\n","        }\n","\n","\n","        kb_tokenizer = KeyboardTokenizerv1()\n","\n","\n","        full_transform = FullTransform(\n","            grid_name_to_nk_lookup=gridname_to_nkl,\n","            grid_name_to_wh=gname_to_wh,\n","            kb_tokenizer=kb_tokenizer,\n","            word_tokenizer=char_tokenizer,\n","            include_time=False,\n","            include_velocities=True,\n","            include_accelerations=True,\n","            kb_tokens_dtype=torch.int32,\n","            word_tokens_dtype=torch.int64\n","        )\n","\n","        train_transform = None\n","        if uniform_noise_range != 0:\n","            augmentation_transform = RandIntToTrajTransform(-uniform_noise_range, uniform_noise_range + 1)\n","            train_transform = SequentialTransform([augmentation_transform, full_transform])\n","        else:\n","            train_transform = full_transform\n","            \n","        val_transform = full_transform\n","\n","\n","    elif transform_name == \"traj_feats_and_distances\":\n","        raise NotImplementedError(f\"transform '{transform_name}' is not implemented yet.\")\n","\n","    else:\n","        raise ValueError(f\"Unknown transform name: '{transform_name}'\")\n","\n","    return train_transform, val_transform\n","                "]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-02T18:13:29.434997Z","iopub.status.busy":"2024-05-02T18:13:29.434181Z","iopub.status.idle":"2024-05-02T18:17:26.736895Z","shell.execute_reply":"2024-05-02T18:17:26.735949Z","shell.execute_reply.started":"2024-05-02T18:13:29.434967Z"},"trusted":true},"outputs":[],"source":["gridname_to_grid_path = os.path.join(DATA_ROOT, \"gridname_to_grid.json\")\n","voc_path=os.path.join(DATA_ROOT, \"voc.txt\")\n","char_tokenizer = CharLevelTokenizerv2(voc_path)\n","kb_tokenizer = KeyboardTokenizerv1()\n","\n","\n","train_transform, val_transform = get_transforms(\n","    gridname_to_grid_path=gridname_to_grid_path,\n","    grid_name=GRID_NAME,\n","    transform_name=TRANSFORM_NAME,\n","    char_tokenizer=char_tokenizer,\n","    uniform_noise_range=NOISE_RANGE,\n","    totals=(6_000_000, None)\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-02T18:17:26.739124Z","iopub.status.busy":"2024-05-02T18:17:26.738741Z","iopub.status.idle":"2024-05-02T18:21:12.331345Z","shell.execute_reply":"2024-05-02T18:21:12.330372Z","shell.execute_reply.started":"2024-05-02T18:17:26.739091Z"},"trusted":true},"outputs":[],"source":["train_dataset = CurveDataset(\n","    data_path=DS_PATHS['train'],\n","    store_gnames=False,\n","    init_transform=None,\n","    get_item_transform=train_transform,\n","    total=5_237_584 # 349172\n",")\n","\n","val_dataset = CurveDataset(\n","    data_path=DS_PATHS['val'],\n","    store_gnames=False,\n","    init_transform=None,\n","    get_item_transform=val_transform,\n","    total=10_000 # 349172\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-02T18:29:07.516878Z","iopub.status.busy":"2024-05-02T18:29:07.515980Z","iopub.status.idle":"2024-05-02T18:29:07.521017Z","shell.execute_reply":"2024-05-02T18:29:07.519980Z","shell.execute_reply.started":"2024-05-02T18:29:07.516848Z"},"trusted":true},"outputs":[],"source":["init_random_seed(RANDOM_SEED)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-02T18:29:07.994319Z","iopub.status.busy":"2024-05-02T18:29:07.993457Z","iopub.status.idle":"2024-05-02T18:29:07.998758Z","shell.execute_reply":"2024-05-02T18:29:07.997736Z","shell.execute_reply.started":"2024-05-02T18:29:07.994286Z"},"trusted":true},"outputs":[],"source":["device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-02T18:29:08.053191Z","iopub.status.busy":"2024-05-02T18:29:08.052894Z","iopub.status.idle":"2024-05-02T18:29:08.058646Z","shell.execute_reply":"2024-05-02T18:29:08.057630Z","shell.execute_reply.started":"2024-05-02T18:29:08.053168Z"},"trusted":true},"outputs":[],"source":["def cross_entropy_with_reshape(pred, target, ignore_index=-100, label_smoothing=0.0):\n","    \"\"\"\n","    pred - BatchSize x TargetLen x VocabSize\n","    target - BatchSize x TargetLen\n","    \"\"\"\n","    pred_flat = pred.view(-1, pred.shape[-1])  # BatchSize*TargetLen x VocabSize\n","    target_flat = target.reshape(-1)  # BatchSize*TargetLen\n","    return F.cross_entropy(pred_flat,\n","                           target_flat,\n","                           ignore_index=ignore_index,\n","                           label_smoothing=label_smoothing)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-02T18:29:08.091629Z","iopub.status.busy":"2024-05-02T18:29:08.091111Z","iopub.status.idle":"2024-05-02T18:29:08.095705Z","shell.execute_reply":"2024-05-02T18:29:08.094807Z","shell.execute_reply.started":"2024-05-02T18:29:08.091604Z"},"trusted":true},"outputs":[],"source":["def lr_scheduler(optimizer):\n","    return torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer,\n","                                                      patience=20,\n","                                                      factor=0.5,\n","                                                      verbose=True)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-02T18:29:08.140774Z","iopub.status.busy":"2024-05-02T18:29:08.140475Z","iopub.status.idle":"2024-05-02T18:29:08.145008Z","shell.execute_reply":"2024-05-02T18:29:08.144030Z","shell.execute_reply.started":"2024-05-02T18:29:08.140748Z"},"trusted":true},"outputs":[],"source":["collate_fn = CollateFn(\n","    word_pad_idx = char_tokenizer.char_to_idx['<pad>'], batch_first = False)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-02T18:29:08.206661Z","iopub.status.busy":"2024-05-02T18:29:08.206366Z","iopub.status.idle":"2024-05-02T18:29:08.212557Z","shell.execute_reply":"2024-05-02T18:29:08.211648Z","shell.execute_reply.started":"2024-05-02T18:29:08.206635Z"},"trusted":true},"outputs":[],"source":["import multiprocessing\n","\n","multiprocessing.cpu_count()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-02T18:29:08.262818Z","iopub.status.busy":"2024-05-02T18:29:08.262535Z","iopub.status.idle":"2024-05-02T18:29:08.270801Z","shell.execute_reply":"2024-05-02T18:29:08.269960Z","shell.execute_reply.started":"2024-05-02T18:29:08.262794Z"},"trusted":true},"outputs":[],"source":["def get_word_level_accuracy(y_true_batch: torch.Tensor, \n","                            pred_batch: torch.Tensor, \n","                            pad_token: int, \n","                            mask: torch.Tensor) -> float:\n","    # By default y_true.shape = pred.shape = (chars_seq_len, batch_size)\n","    # So we have to transpose here or before calling\n","\n","    y_true_batch = y_true_batch.masked_fill(mask, pad_token)\n","    pred_batch = pred_batch.masked_fill(mask, pad_token)\n","    equality_results = torch.all(torch.eq(y_true_batch, pred_batch), dim = 1)\n","        \n","    return float(equality_results.sum() / len(equality_results))\n","\n","\n","decode_batch = lambda seq_batch, tokenizer: [tokenizer.decode(seq) for seq in seq_batch]\n","\n","\n","def get_word_level_metric(metric_fn,\n","                          y_true_batch: torch.Tensor, \n","                          pred_batch: torch.Tensor, \n","                          tokenizer,\n","                          mask: torch.Tensor) -> float:\n","    \n","    y_true_batch.masked_fill_(mask, tokenizer.char_to_idx['<pad>'])\n","    pred_batch.masked_fill_(mask, tokenizer.char_to_idx['<pad>'])\n","        \n","    y_true_batch = decode_batch(y_true_batch, char_tokenizer)\n","    pred_batch = decode_batch(pred_batch, char_tokenizer)\n","    \n","    return metric_fn(y_true_batch, pred_batch)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-02T18:29:08.295451Z","iopub.status.busy":"2024-05-02T18:29:08.295191Z","iopub.status.idle":"2024-05-02T18:29:08.304916Z","shell.execute_reply":"2024-05-02T18:29:08.304086Z","shell.execute_reply.started":"2024-05-02T18:29:08.295428Z"},"trusted":true},"outputs":[],"source":["######  testing get_word_level_accuracy, get_word_level_metric\n","from sklearn.metrics import f1_score, accuracy_score\n","import torch\n","\n","batch_size = 10\n","seq_len = 5\n","y_true__rand = torch.randint(0, 32, (batch_size, seq_len))\n","pred__rand = torch.randint(0, 32, (batch_size, seq_len))\n","pred__rand[:3] = y_true__rand[:3]\n","\n","mask = torch.zeros((batch_size, seq_len), dtype = torch.bool)\n","mask[:, :-3] = True\n","\n","print(\n","    get_word_level_accuracy(\n","        y_true__rand, pred__rand, pad_token = -1, mask = mask)\n",")\n","\n","print(\n","    get_word_level_metric(accuracy_score, y_true__rand, pred__rand,\n","                      char_tokenizer, mask = mask)\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-02T18:29:08.386322Z","iopub.status.busy":"2024-05-02T18:29:08.385560Z","iopub.status.idle":"2024-05-02T18:29:08.413521Z","shell.execute_reply":"2024-05-02T18:29:08.412781Z","shell.execute_reply.started":"2024-05-02T18:29:08.386293Z"},"trusted":true},"outputs":[],"source":["from lightning import LightningModule\n","from lightning import Trainer\n","from lightning.pytorch.callbacks.early_stopping import EarlyStopping\n","from lightning.pytorch.callbacks import ModelCheckpoint\n","from lightning.pytorch import loggers as pl_loggers\n","import torchmetrics\n","\n","\n","from model import MODEL_GETTERS_DICT\n","\n","# ! Make sure:\n","# * Add metrics\n","\n","#! Maybe store:\n","# * batch_size\n","# * early_stopping_patience\n","\n","#! Maybe:\n","# * Checpointing by condition: if model improved on val_loss and val_loss < max_val_loss_to_save\n","\n","\n","class LitNeuroswipeModel(LightningModule):\n","    def __init__(self, model_name: str, criterion, \n","                 num_classes: int,\n","                 train_batch_size: int = None,\n","                 criterion_ignore_index: int = -100, optim_kwargs = None, \n","                 optimizer_ctor=None, lr_scheduler_ctor=None, label_smoothing=0.0,\n","                 ) -> None:\n","        super().__init__()\n","\n","        self.optim_kwargs = optim_kwargs or dict(lr=1e-4, weight_decay=0)\n","        \n","        self.model_name = model_name\n","        self.train_batch_size = train_batch_size\n","        self.label_smoothing = label_smoothing\n","        self.criterion_ignore_index = criterion_ignore_index\n","\n","        self.optimizer_ctor = optimizer_ctor\n","        self.lr_scheduler_ctor = lr_scheduler_ctor\n","\n","        self.model = MODEL_GETTERS_DICT[model_name]()\n","        self.criterion = criterion\n","        \n","        self.train_token_acc = torchmetrics.classification.Accuracy(\n","            task=\"multiclass\", num_classes=num_classes, ignore_index=criterion_ignore_index)\n","        self.val_token_acc = torchmetrics.classification.Accuracy(\n","            task=\"multiclass\", num_classes=num_classes, ignore_index=criterion_ignore_index)\n","        self.train_token_f1 = torchmetrics.classification.F1Score(\n","            task=\"multiclass\", num_classes=num_classes, ignore_index=criterion_ignore_index)\n","        self.val_token_f1 = torchmetrics.classification.F1Score(\n","            task=\"multiclass\", num_classes=num_classes, ignore_index=criterion_ignore_index)\n","\n","    def forward(self, x, kb_tokens, y, x_pad_mask, y_pad_mask):\n","        x_encoded = self.model.encode(x, kb_tokens, x_pad_mask)\n","        return self.model.decode(x_encoded, y, x_pad_mask, y_pad_mask)\n","    \n","    def configure_optimizers(self):\n","        optimizer = self.optimizer_ctor(self.parameters(), **self.optim_kwargs)\n","        \n","        optimizers_configuration = {'optimizer': optimizer}\n","\n","        if self.lr_scheduler_ctor:\n","            lr_scheduler = self.lr_scheduler_ctor(optimizer)\n","            optimizers_configuration['lr_scheduler'] = lr_scheduler\n","            optimizers_configuration['monitor'] = 'val_loss'\n","\n","        return optimizers_configuration\n","\n","\n","    def training_step(self, batch, batch_idx):\n","        batch_x, batch_y = batch\n","        \n","        batch_size = batch_y.shape[-1]\n","\n","        # batch_x, batch_y = move_all_to_device(batch_x, batch_y, self.device)\n","\n","        # * batch_x is a Tuple of (curve_traj_feats, curve_kb_tokens,\n","        #   decoder_in, curve_pad_mask, dec_seq_pad_mask).\n","        # * batch_y is decoder_out.\n","        \n","        # preds.shape = (chars_seq_len, batch_size, n_classes)\n","        \n","        curve_traj_feats, curve_kb_tokens, ecoder_in, curve_pad_mask, dec_seq_pad_mask = batch_x\n","\n","        pred = self.forward(*batch_x)\n","\n","        loss = self.criterion(pred, batch_y, ignore_index=self.criterion_ignore_index,\n","                              label_smoothing=self.label_smoothing)\n","        \n","        \n","        argmax_pred = torch.argmax(pred, dim=2)\n","        wl_acccuracy = get_word_level_accuracy(\n","            argmax_pred.T, batch_y.T, pad_token = self.criterion_ignore_index, mask = dec_seq_pad_mask)\n","        \n","        \n","        flat_y = batch_y.reshape(-1)\n","        n_classes = pred.shape[-1]\n","        flat_preds = pred.reshape(-1, n_classes)\n","        \n","        self.train_token_acc(flat_preds, flat_y)\n","        self.log('train_token_level_accuracy', self.train_token_acc, on_step=True, on_epoch=False)\n","        \n","        self.train_token_f1(flat_preds, flat_y)\n","        self.log('train_token_level_f1', self.train_token_f1, on_step=True, on_epoch=False)\n","        \n","        \n","        self.log(\"train_word_level_accuracy\", wl_acccuracy, on_step=True, on_epoch=True, \n","                 prog_bar=True, logger=True, batch_size = batch_size)\n","        \n","        self.log(\"train_loss\", loss, on_step=True, on_epoch=True, \n","                 prog_bar=True, logger=True, batch_size = batch_size)\n","\n","        return loss\n","\n","    def validation_step(self, batch, batch_idx):\n","        batch_x, batch_y = batch\n","        batch_size = batch_y.shape[-1]\n","        # batch_x, batch_y = move_all_to_device(batch_x, batch_y, self.device)\n","        curve_traj_feats, curve_kb_tokens, ecoder_in, curve_pad_mask, dec_seq_pad_mask = batch_x\n","        pred = self.forward(*batch_x)\n","        loss = self.criterion(pred, batch_y, ignore_index=self.criterion_ignore_index,\n","                              label_smoothing=self.label_smoothing)\n","        argmax_pred = torch.argmax(pred, dim=2)\n","        wl_acccuracy = get_word_level_accuracy(\n","            argmax_pred.T, batch_y.T, pad_token = self.criterion_ignore_index, mask = dec_seq_pad_mask)\n","        \n","        \n","        flat_y = batch_y.reshape(-1)\n","        n_classes = pred.shape[-1]\n","        flat_preds = pred.reshape(-1, n_classes)\n","        \n","        \n","        self.val_token_acc(flat_preds, flat_y)\n","        self.log('val_token_level_accuracy', self.train_token_acc, on_step=False, on_epoch=True)\n","        \n","        self.val_token_f1(flat_preds, flat_y)\n","        self.log('val_token_level_f1', self.train_token_f1, on_step=False, on_epoch=True)\n","        \n","        \n","        \n","        self.log(\"val_word_level_accuracy\", wl_acccuracy, on_step=False, on_epoch=True, \n","                 prog_bar=True, logger=True, batch_size = batch_size)\n","        self.log(\"val_loss\", loss, on_step=False, on_epoch=True, prog_bar=True, \n","                 logger=True, batch_size = batch_size)\n","        return loss\n","\n","\n","tb_logger = pl_loggers.TensorBoardLogger(save_dir=LOG_DIR, name=EXPERIMENT_NAME)\n","\n","early_stopping_cb = EarlyStopping(\n","    monitor='val_loss', mode = 'min', patience=25)\n","\n","model_checkpoint_cb = ModelCheckpoint(\n","    monitor='val_loss', mode = 'min', save_top_k=10, \n","    dirpath='checkpoints/', filename=f'{MODEL_NAME}-{GRID_NAME}--' + '{epoch}-{val_loss:.2f}-{val_word_level_accuracy:.2f}')\n","\n","# It's more reliable to continue training from epoch-end-checkpoints\n","model_checkpoint_on_train_epoch_end = ModelCheckpoint(\n","    save_on_train_epoch_end = True, dirpath='checkpoint_epoch_end/', \n","    save_top_k=-1,\n","    filename=f'{MODEL_NAME}-{GRID_NAME}--' + '{epoch}-{val_loss:.2f}-{val_word_level_accuracy:.2f}')"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-02T18:29:08.419366Z","iopub.status.busy":"2024-05-02T18:29:08.419033Z","iopub.status.idle":"2024-05-02T18:29:08.427524Z","shell.execute_reply":"2024-05-02T18:29:08.426687Z","shell.execute_reply.started":"2024-05-02T18:29:08.419336Z"},"trusted":true},"outputs":[],"source":["# ls yandex-cup-2023-ml-neuroswipe/src/checkpoints"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-02T18:29:08.451323Z","iopub.status.busy":"2024-05-02T18:29:08.451070Z","iopub.status.idle":"2024-05-02T18:29:08.456463Z","shell.execute_reply":"2024-05-02T18:29:08.455529Z","shell.execute_reply.started":"2024-05-02T18:29:08.451300Z"},"trusted":true},"outputs":[],"source":["dataloader_workers_n = 4\n","\n","\n","train_loader = DataLoader(\n","    train_dataset, batch_size=TRAIN_BATCH_SIZE, shuffle=True,\n","    num_workers=dataloader_workers_n, persistent_workers = True, \n","    collate_fn=collate_fn)\n","\n","val_loader = DataLoader(val_dataset, batch_size=VAL_BATCH_SIZE, shuffle=False,\n","                        num_workers=dataloader_workers_n, persistent_workers = True, \n","                        collate_fn=collate_fn)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-02T18:29:08.506732Z","iopub.status.busy":"2024-05-02T18:29:08.506440Z","iopub.status.idle":"2024-05-02T18:29:08.511574Z","shell.execute_reply":"2024-05-02T18:29:08.510618Z","shell.execute_reply.started":"2024-05-02T18:29:08.506708Z"},"trusted":true},"outputs":[],"source":["from lightning.pytorch.callbacks import Callback\n","\n","class EmptyCudaCacheCallback(Callback):\n","    def on_train_epoch_end(self, trainer, pl_module):\n","        torch.cuda.empty_cache()\n","        \n","epmty_cuda_cache_cb = EmptyCudaCacheCallback()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-02T18:30:11.784885Z","iopub.status.busy":"2024-05-02T18:30:11.784197Z"},"trusted":true},"outputs":[],"source":["label_smoothing = 0.045\n","\n","\n","pl_model = LitNeuroswipeModel(\n","    model_name = MODEL_NAME, criterion = cross_entropy_with_reshape, \n","    num_classes = 35,  # = len(char_tokenizer.idx_to_char) - len(['<pad>', '<unk>']) = 37 - 2\n","    train_batch_size = TRAIN_BATCH_SIZE,\n","    criterion_ignore_index = char_tokenizer.char_to_idx['<pad>'], \n","    optim_kwargs = dict(lr=1e-4, weight_decay=0.0001), \n","    optimizer_ctor=torch.optim.Adam, lr_scheduler_ctor=lr_scheduler, label_smoothing=0.045,\n",")\n","\n","trainer = Trainer(\n","#     limit_train_batches = 400,  # for validating code before actual training\n","    log_every_n_steps = 100,\n","    num_sanity_val_steps=1,\n","    accelerator = 'gpu',\n","#     max_epochs=35,\n","    callbacks=[\n","        early_stopping_cb, model_checkpoint_cb, \n","        model_checkpoint_on_train_epoch_end, epmty_cuda_cache_cb,\n","    ],\n","    logger=tb_logger,\n","    val_check_interval=3000,\n",")\n","\n","trainer.fit(pl_model, train_loader, val_loader,\n","#             ckpt_path = \n","           )"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30699,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"}},"nbformat":4,"nbformat_minor":4}
