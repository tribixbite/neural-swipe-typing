{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"%load_ext autoreload\n%autoreload 2","metadata":{"execution":{"iopub.status.busy":"2023-11-08T23:58:01.344956Z","iopub.execute_input":"2023-11-08T23:58:01.345299Z","iopub.status.idle":"2023-11-08T23:58:01.371832Z","shell.execute_reply.started":"2023-11-08T23:58:01.345269Z","shell.execute_reply":"2023-11-08T23:58:01.370960Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"%cd /kaggle/working/yandex_cup_2023_ml_neuroswipe/src","metadata":{"execution":{"iopub.status.busy":"2023-11-08T23:58:49.075828Z","iopub.execute_input":"2023-11-08T23:58:49.076231Z","iopub.status.idle":"2023-11-08T23:58:49.097522Z","shell.execute_reply.started":"2023-11-08T23:58:49.076194Z","shell.execute_reply":"2023-11-08T23:58:49.096593Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"/kaggle/working/yandex_cup_2023_ml_neuroswipe/src\n","output_type":"stream"}]},{"cell_type":"code","source":"import os\nimport json\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset, DataLoader, IterableDataset\nfrom tqdm import tqdm\nimport numpy as np\n\nfrom model import SwipeCurveTransformer, get_m1_model\nfrom tokenizers import CharLevelTokenizerv2, KeyboardTokenizerv1\nfrom dataset import NeuroSwipeDatasetv2\nfrom word_generators import GreedyGenerator","metadata":{"execution":{"iopub.status.busy":"2023-11-08T23:58:49.791131Z","iopub.execute_input":"2023-11-08T23:58:49.791505Z","iopub.status.idle":"2023-11-08T23:58:52.913358Z","shell.execute_reply.started":"2023-11-08T23:58:49.791472Z","shell.execute_reply":"2023-11-08T23:58:52.912590Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"IN_KAGGLE = True\nRANDOM_SEED = 31\n\nif IN_KAGGLE:\n    DATA_ROOT = \"/kaggle/input/neuroswipe-defualt-only-v1\"\n    MODELS_DIR = \"\"\nelse:\n    DATA_ROOT = \"../data/data_separated_grid\"\n    MODELS_DIR = \"../data/trained_models/m1\"","metadata":{"execution":{"iopub.status.busy":"2023-11-08T23:58:52.915215Z","iopub.execute_input":"2023-11-08T23:58:52.915600Z","iopub.status.idle":"2023-11-08T23:58:52.944459Z","shell.execute_reply.started":"2023-11-08T23:58:52.915573Z","shell.execute_reply":"2023-11-08T23:58:52.943644Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"def init_random_seed(value=42):\n    # random.seed(value)\n    np.random.seed(value)\n    torch.manual_seed(value)\n    torch.cuda.manual_seed(value)\n    # torch.backends.cudnn.deterministic = True","metadata":{"execution":{"iopub.status.busy":"2023-11-08T23:58:52.945448Z","iopub.execute_input":"2023-11-08T23:58:52.945713Z","iopub.status.idle":"2023-11-08T23:58:52.975655Z","shell.execute_reply.started":"2023-11-08T23:58:52.945689Z","shell.execute_reply":"2023-11-08T23:58:52.974658Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"init_random_seed(RANDOM_SEED)","metadata":{"execution":{"iopub.status.busy":"2023-11-08T23:58:52.977521Z","iopub.execute_input":"2023-11-08T23:58:52.977771Z","iopub.status.idle":"2023-11-08T23:58:53.010276Z","shell.execute_reply.started":"2023-11-08T23:58:52.977748Z","shell.execute_reply":"2023-11-08T23:58:53.009419Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"def get_grid(grid_name: str, grids_path: str) -> dict:\n    with open(grids_path, \"r\", encoding=\"utf-8\") as f:\n        return json.load(f)[grid_name]","metadata":{"execution":{"iopub.status.busy":"2023-11-08T23:58:53.011438Z","iopub.execute_input":"2023-11-08T23:58:53.011719Z","iopub.status.idle":"2023-11-08T23:58:53.039940Z","shell.execute_reply.started":"2023-11-08T23:58:53.011695Z","shell.execute_reply":"2023-11-08T23:58:53.039145Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"MAX_TRAJ_LEN = 299\n\ngrid_name = \"default\"\n\ngrid_name_to_grid_path = os.path.join(DATA_ROOT, \"gridname_to_grid.json\")\ngrid_name_to_grid = {grid_name: get_grid(grid_name, grid_name_to_grid_path)}\n\n\nkb_tokenizer = KeyboardTokenizerv1()\nword_char_tokenizer = CharLevelTokenizerv2(os.path.join(DATA_ROOT, \"voc.txt\"))\nkeyboard_selection_set = set(kb_tokenizer.i2t)\n\ntrain_path = os.path.join(DATA_ROOT,\n#                           \"valid__in_train_format__default_only.jsonl\")\n                          \"train__default_only_no_errors__2023_10_31__03_26_16.jsonl\")\n\n# In case the jupyter notebook is running in kaggle\n# with variables  persistence, I don't want it\n# to waste around 20 minutes creating train_dataset.\ntry:\n    train_dataset\nexcept NameError:\n    train_dataset = NeuroSwipeDatasetv2(\n        data_path = train_path,\n        gridname_to_grid = grid_name_to_grid,\n        kb_tokenizer = kb_tokenizer,\n        max_traj_len = MAX_TRAJ_LEN,\n        word_tokenizer = word_char_tokenizer,\n        include_time = False,\n        include_velocities = True,\n        include_accelerations = True,\n        has_target=True,\n        has_one_grid_only=True,\n        include_grid_name=False,\n        keyboard_selection_set=keyboard_selection_set,\n        total = 5_237_584\n    )\n\nval_path = os.path.join(DATA_ROOT, \"valid__in_train_format__default_only.jsonl\")\n\n\nval_dataset = NeuroSwipeDatasetv2(\n    data_path = val_path,\n    gridname_to_grid = grid_name_to_grid,\n    kb_tokenizer = kb_tokenizer,\n    max_traj_len = MAX_TRAJ_LEN,\n    word_tokenizer = word_char_tokenizer,\n    include_time = False,\n    include_velocities = True,\n    include_accelerations = True,\n    has_target=True,\n    has_one_grid_only=True,\n    include_grid_name=False,\n    keyboard_selection_set=keyboard_selection_set,\n    total = 9_416\n)","metadata":{"execution":{"iopub.status.busy":"2023-11-08T23:59:18.887617Z","iopub.execute_input":"2023-11-08T23:59:18.888502Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stderr","text":" 66%|██████▋   | 3479349/5237584 [08:11<03:59, 7337.84it/s]","output_type":"stream"}]},{"cell_type":"code","source":"device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"transformer = get_m1_model(device)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from utils import prepare_batch","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def cross_entropy_with_reshape(pred, target, ignore_index=-100):\n    \"\"\"\n    pred - BatchSize x TargetLen x VocabSize\n    target - BatchSize x TargetLen\n    \"\"\"\n    pred_flat = pred.view(-1, pred.shape[-1])  # BatchSize*TargetLen x VocabSize\n    target_flat = target.reshape(-1)  # BatchSize*TargetLen\n    return F.cross_entropy(pred_flat, target_flat, ignore_index=ignore_index)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def lr_scheduler(optimizer):\n    return torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer,\n                                                      patience=20,\n                                                      factor=0.5,\n                                                      verbose=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import traceback\nfrom datetime import datetime\nimport copy\n\nfrom typing import Callable\n\n\ndef train_eval_loop(model, train_dataset, val_dataset, criterion,\n                    lr=1e-4, epoch_n=10, batch_size=32,\n                    device=None, early_stopping_patience=10, l2_reg_alpha=0,\n                    max_batches_per_epoch_train=10000,\n                    max_batches_per_epoch_val=1000,\n                    data_loader_ctor=DataLoader,\n                    optimizer_ctor=None,\n                    lr_scheduler_ctor=None,\n                    shuffle_train=True,\n                    dataloader_workers_n=0,\n                    criterion_ignore_index = -100,\n                    model_name_postfix = \"\",\n                    model_save_root = \".\",\n                    prepare_batch: Callable = lambda x, y: (x, y)):\n    \"\"\"\n    Цикл для обучения модели. После каждой эпохи качество модели оценивается по отложенной выборке.\n    :param model: torch.nn.Module - обучаемая модель\n    :param train_dataset: torch.utils.data.Dataset - данные для обучения\n    :param val_dataset: torch.utils.data.Dataset - данные для оценки качества\n    :param criterion: функция потерь для настройки модели\n    :param lr: скорость обучения\n    :param epoch_n: максимальное количество эпох\n    :param batch_size: количество примеров, обрабатываемых моделью за одну итерацию\n    :param device: cuda/cpu - устройство, на котором выполнять вычисления\n    :param early_stopping_patience: наибольшее количество эпох, в течение которых допускается\n        отсутствие улучшения модели, чтобы обучение продолжалось.\n    :param l2_reg_alpha: коэффициент L2-регуляризации\n    :param max_batches_per_epoch_train: максимальное количество итераций на одну эпоху обучения\n    :param max_batches_per_epoch_val: максимальное количество итераций на одну эпоху валидации\n    :param data_loader_ctor: функция для создания объекта, преобразующего датасет в батчи\n        (по умолчанию torch.utils.data.DataLoader)\n    :return: кортеж из двух элементов:\n        - среднее значение функции потерь на валидации на лучшей эпохе\n        - лучшая модель\n    \"\"\"\n    if device is None:\n        device =  torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n\n    model.to(device)\n\n    if optimizer_ctor is None:\n        optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=l2_reg_alpha)\n    else:\n        optimizer = optimizer_ctor(model.parameters(), lr=lr)\n\n    if lr_scheduler_ctor is not None:\n        lr_scheduler = lr_scheduler_ctor(optimizer)\n    else:\n        lr_scheduler = None\n\n    train_dataloader = data_loader_ctor(train_dataset, batch_size=batch_size, shuffle=shuffle_train,\n                                        num_workers=dataloader_workers_n)\n    val_dataloader = data_loader_ctor(val_dataset, batch_size=batch_size, shuffle=False,\n                                      num_workers=dataloader_workers_n)\n\n    best_val_loss = float('inf')\n    best_epoch_i = 0\n\n    best_model_path = \"best_model.pt\"\n    best_model = copy.deepcopy(model)\n\n    if os.path.exists(best_model_path):\n        best_model.load_state_dict(torch.load(best_model_path))\n        print(f\"Загружено состояние модели {best_model_path}\")\n\n    for epoch_i in tqdm(range(epoch_n), position = 0):\n        try:\n            model.train()\n            mean_train_loss = 0\n            train_batches_n = 0\n            for batch_i, (batch_x, batch_y) in tqdm(enumerate(train_dataloader), total = min(max_batches_per_epoch_train, len(train_dataset) // batch_size), position=1, leave = False):\n                if batch_i > max_batches_per_epoch_train:\n                    break\n\n                batch_x, batch_y = prepare_batch(batch_x, batch_y, device)\n\n                pred = model(*batch_x)\n                loss = criterion(pred, batch_y, ignore_index = criterion_ignore_index)\n\n                model.zero_grad()\n                loss.backward()\n\n                optimizer.step()\n\n                mean_train_loss += float(loss)\n                train_batches_n += 1\n\n            mean_train_loss /= train_batches_n\n            \n            print('Среднее значение функции потерь на обучении', mean_train_loss)\n\n\n\n            model.eval()\n            mean_val_loss = 0\n            val_batches_n = 0\n\n            with torch.no_grad():\n                for batch_i, (batch_x, batch_y) in enumerate(val_dataloader):\n                    if batch_i > max_batches_per_epoch_val:\n                        break\n\n                    batch_x, batch_y = prepare_batch(batch_x, batch_y, device)\n\n                    pred = model(*batch_x)\n                    loss = criterion(pred, batch_y)\n\n                    mean_val_loss += float(loss)\n                    val_batches_n += 1\n\n            mean_val_loss /= val_batches_n\n            print('Среднее значение функции потерь на валидации', mean_val_loss)\n\n            if mean_val_loss < best_val_loss:\n                best_epoch_i = epoch_i\n                best_val_loss = mean_val_loss\n                best_model = copy.deepcopy(model)\n                torch.save(model.state_dict(), os.path.join(model_save_root, best_model_path))\n                cur_time = \"{:%Y_%m_%d__%H_%M_%S}\".format(datetime.now())\n                torch.save(model.state_dict(), os.path.join(model_save_root, f\"best_model__{cur_time}__{mean_val_loss:.5f}_{model_name_postfix}.pt\"))\n                print('Новая лучшая модель!')\n            elif epoch_i - best_epoch_i > early_stopping_patience:\n                print('Модель не улучшилась за последние {} эпох, прекращаем обучение'.format(\n                    early_stopping_patience))\n                break\n\n            if lr_scheduler is not None:\n                lr_scheduler.step(mean_val_loss)\n\n            print()\n        except KeyboardInterrupt:\n            print('Досрочно остановлено пользователем')\n            break\n        except Exception as ex:\n            print('Ошибка при обучении: {}\\n{}'.format(ex, traceback.format_exc()))\n            break\n\n    return best_val_loss, best_model\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tqdm.notebook import tqdm\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"transformer.load_state_dict(\n    torch.load(\"/kaggle/input/m1-05-11-23/best_model__2023_11_04__16_51_28__0.02548_default_switch_2.pt\",\n              map_location = device))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"best_val_loss, best_model = train_eval_loop(\n    transformer, train_dataset, val_dataset, cross_entropy_with_reshape,\n    lr=1e-4, epoch_n=10000, batch_size=320,\n    device=device, early_stopping_patience=10, l2_reg_alpha=0,\n    max_batches_per_epoch_train=10,\n    max_batches_per_epoch_val=1000,\n    data_loader_ctor=DataLoader,\n    optimizer_ctor=None,\n    lr_scheduler_ctor=lr_scheduler,\n    shuffle_train=True,\n    dataloader_workers_n=0,\n    criterion_ignore_index = word_char_tokenizer.char_to_idx['<pad>'],\n    model_name_postfix = f'{grid_name}_switch_2_try_2',\n    prepare_batch=prepare_batch,\n    model_save_root = \"..\"\n)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}