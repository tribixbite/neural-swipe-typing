{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader, IterableDataset\n",
    "\n",
    "# from model import SwipeCurveEncoderTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Optional\n",
    "\n",
    "class CharLevelTokenizerv1:\n",
    "    def __init__(self, vocab_path):\n",
    "        self.char_to_idx = {}\n",
    "        self.idx_to_char = {}\n",
    "        self.max_word_len = None  # is set in _build_vocab\n",
    "        self._build_vocab(vocab_path)\n",
    "\n",
    "    def _build_vocab(self, vocab_path):\n",
    "        self.max_word_len = 0\n",
    "        unique_chars = set({\"<pad>\": 0, \"<sos>\": 1, \"<eos>\": 2, \"<unk>\": 3})\n",
    "        with open(vocab_path, \"r\", encoding=\"utf-8\") as f:\n",
    "            vocab = f.read().split(\"\\n\")\n",
    "            for word in vocab:\n",
    "                self.max_word_len = max(self.max_word_len, len(word) + 2)\n",
    "                for char in word:\n",
    "                    unique_chars.add(char)\n",
    "        self.char_to_idx = {char: idx for idx, char in enumerate(unique_chars)}\n",
    "        self.idx_to_char = {idx: char for idx, char in enumerate(unique_chars)}\n",
    "\n",
    "    def _tokenize_word(self, word):\n",
    "        \"\"\"\n",
    "        Tokenizes a word into a list of integers.\n",
    "        \"\"\"\n",
    "        tokenized_word = []\n",
    "        tokenized_word.append(self.char_to_idx[\"<sos>\"])\n",
    "        for char in word:\n",
    "            tokenized_word.append(self.char_to_idx[char])\n",
    "        tokenized_word.append(self.char_to_idx[\"<eos>\"])\n",
    "        return tokenized_word\n",
    "    \n",
    "    def _pad_word(self, word):\n",
    "        \"\"\"\n",
    "        Pads a word to the max_word_len.\n",
    "        \"\"\"\n",
    "        return word + [self.char_to_idx[\"<pad>\"]] * (self.max_word_len - len(word))\n",
    "    \n",
    "    def tokenize(self, word):\n",
    "        \"\"\"\n",
    "        Tokenizes a word and pads it to the max_word_len.\n",
    "        \"\"\"\n",
    "        token_seq = torch.tensor(self._pad_word(self._tokenize_word(word)))\n",
    "        mask = torch.zeros(self.max_word_len, dtype=torch.bool)\n",
    "        mask[:len(word)+2] = True\n",
    "        return token_seq, mask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Я вижу два решения:\n",
    "\n",
    "Для простоты я бы сделал 2 класса датасета\n",
    "Если нужно кодировать лишь последовательность букв, он и хранит последовательности букв сразу и не хранит коордианты\n",
    "\n",
    "В обоих случаях декодер оперирует эмбеддингами букв текста\n",
    "\n",
    "### 1. На вход энкодера x, y, t, dx/dt, dy/st, x'', y'', keybard_key_embedding\n",
    "**Что делать, если ближайшая клавиша неалфавитная (пунктуация, клавиши-действия)?**\n",
    "Добавлю для всех неалфавитных клавиш один специальный токен\n",
    "\n",
    "**Где происходит инициализация токенизатора?**\n",
    "я бы вынес токенезатор вне датасета и передавал бы его в конструктор датасета.\n",
    "\n",
    "\n",
    "для каждой раскладки свои instance'ы датасета и модели.\n",
    "\n",
    "\n",
    "\n",
    "### 2. На вход энкодера последовательность клавиш клавиатуры\n",
    "Если ближайшая клавиша неалфавитная **пропускать**\n",
    "\n",
    "**Где происходит инициализация токенизатора?**\n",
    "\n",
    "\n",
    "один instance датасета и одна модель для всех раскладок.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Реализовывать ли для каждого варианта отдельный токенизатор:\n",
    "\n",
    "У нас может быть различное количество токенов: в некотоорых раскладках отсутствует символ \"ъ\", например\n",
    "\n",
    "Когда датасет содержит лишь одну раскладку, токенизатор должен учесть символы из одной раскладки. Когда датасет содержит несколько раскладок, токенизатор должен учесть символы из всех раскладок.\n",
    "\n",
    "Кажется, что варьируется только наличие 'ъ' и 'ё'. Во-первых, не ясно нужны ли эти символы. Есть желание заменять 'ё' на 'е', а 'ъ' на 'ь'. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KeyboardTokenizerv1:\n",
    "    \n",
    "    i2t = ['а', 'б', 'в', 'г', 'д', 'е', 'ë', 'ж', 'з', 'и', 'й',\n",
    "           'к', 'л', 'м', 'н', 'о', 'п', 'р', 'с', 'т', 'у', 'ф',\n",
    "           'х', 'ц', 'ч', 'ш', 'щ', 'ъ', 'ы', 'ь', 'э', 'ю', 'я',\n",
    "           '-', '<unk>', '<pad>']\n",
    "    \n",
    "    t2i = {t: i for i, t in enumerate(i2t)}\n",
    "\n",
    "    def get_token(self, char):\n",
    "        return self.t2i.get(char, self.t2i['<unk>'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from typing import Optional, List, Tuple, Dict\n",
    "import array\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "class NeuroSwipeDatasetv1(Dataset):\n",
    "    \"\"\"\n",
    "    Dataset class for NeuroSwipe dataset.\n",
    "    The dataset file weights over 3 GB and contains over 6 million swipe gestures.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 data_path: str,\n",
    "                 kb_keys: List[dict],  # keybard_keys\n",
    "                 kb_tokenizer,\n",
    "                 max_traj_len: int,\n",
    "                 word_tokenizer,  # should contain max word len\n",
    "                 include_velocities: bool = True,\n",
    "                 include_accelerations: bool = True,\n",
    "                 total: Optional[int] = None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            data_path (string): Path to the NeuroSwipe dataset in JSON format.\n",
    "                A custom version of the dataset is used:\n",
    "                \"grid\" property is replaced with \"grid_name\" property.\n",
    "        \"\"\"\n",
    "        if include_accelerations and not include_velocities:\n",
    "\n",
    "            raise ValueError(\"Accelerations are supposed \\\n",
    "                             to be an addition to velocities. Add velocities.\")\n",
    "\n",
    "        self.max_traj_len = max_traj_len\n",
    "        self.include_velocities = include_velocities\n",
    "        self.include_accelerations = include_accelerations\n",
    "\n",
    "        self.word_tokenizer = word_tokenizer\n",
    "\n",
    "        self.data_list = []\n",
    "        self._set_data(data_path, kb_keys, kb_tokenizer, self.data_list, total = total)\n",
    "    \n",
    "\n",
    "    def _get_key_center(self, hitbox: Dict[str, int]) -> Tuple[int, int]:\n",
    "        x = hitbox['x'] + hitbox['w'] / 2\n",
    "        y = hitbox['y'] + hitbox['h'] / 2\n",
    "        return x, y\n",
    "\n",
    "    def _coord_to_kb_label(self, x: int, y:int, keys: List[dict]) -> str:\n",
    "        nearest_kb_label = None\n",
    "        min_dist = float(\"inf\")\n",
    "        for key in keys:\n",
    "            key_x, key_y = self._get_key_center(key['hitbox'])\n",
    "            dist = (x - key_x)**2 + (y - key_y)**2\n",
    "            if dist < min_dist:\n",
    "                min_dist = dist\n",
    "                if 'label' in key:\n",
    "                    nearest_kb_label = key['label']\n",
    "                elif 'action' in key:\n",
    "                    nearest_kb_label = key['action']  # tokenizer will covert it to <unk>\n",
    "                else:\n",
    "                    raise ValueError(\"Key has no label or action\")\n",
    "\n",
    "        return nearest_kb_label\n",
    "            \n",
    "\n",
    "    def _set_data(self,\n",
    "                  data_path: str,\n",
    "                  kb_keys: str,\n",
    "                  kb_tokenizer,\n",
    "                  data_list: list,\n",
    "                  total: Optional[int] = None):\n",
    "        with open(data_path, \"r\", encoding=\"utf-8\") as json_file:\n",
    "            for line in tqdm(json_file, total = total):\n",
    "                data_list.append(self._get_data_from_json_line(line, kb_keys, kb_tokenizer))\n",
    "\n",
    "\n",
    "    def _get_dx_dt(self,\n",
    "                   X: torch.tensor,\n",
    "                   T: torch.tensor,\n",
    "                   len: int) -> List[float]:\n",
    "        \"\"\"\n",
    "        Calculates dx/dt for a list of x coordinates and a list of t coordinates.\n",
    "\n",
    "        Arguments:\n",
    "        ----------\n",
    "        X : torch.tensor\n",
    "            x (position) coordinates.\n",
    "        T : torch.tensor\n",
    "            T[i] = time from the beginning of the swipe corresponding to X[i].\n",
    "        len : int\n",
    "            Length of the swipe trajectory. Indexes greater than len are ignored.\n",
    "\n",
    "        \"\"\"\n",
    "        dx_dt = torch.zeros_like(X)\n",
    "        # dx_dt[1:-1] = (X[2:] - X[:-2]) / (T[2:] - T[:-2])\n",
    "        dx_dt[1:len-1] = (X[2:len] - X[:len-2]) / (T[2:len] - T[:len-2])\n",
    "\n",
    "        # Example:\n",
    "        # x0 x1 x2 x3\n",
    "        # t0 t1 t2 t3\n",
    "        # dx_dt[0] = 0\n",
    "        # dx_dt[1] = (x2 - x0) / (t2 - t0)\n",
    "        # dx_dt[2] = (x3 - x1) / (t3 - t1)\n",
    "        # dx_dt[3] = 0\n",
    "\n",
    "\n",
    "        # if True in torch.isnan(dx_dt):\n",
    "        #     print(dx_dt)\n",
    "        #     raise ValueError(\"dx_dt contains NaNs\")\n",
    "\n",
    "        return dx_dt\n",
    "\n",
    "    def _get_data_from_json_line(self, line, kb_keys, kb_tokenizer) -> Tuple[list, list, list, str]:\n",
    "        \"\"\"\n",
    "        Parses a JSON line and returns a dictionary with data.\n",
    "        \"\"\"\n",
    "        data = json.loads(line)\n",
    "        word: str = data['word']\n",
    "\n",
    "        X = array.array('h', data['curve']['x'])\n",
    "        Y = array.array('h', data['curve']['y'])\n",
    "        T = array.array('h', data['curve']['t'])        \n",
    "\n",
    "        kb_labels = [self._coord_to_kb_label(x, y, kb_keys) for x,y in zip(X, Y)]\n",
    "        kb_tokens = [kb_tokenizer.get_token(label) for label in kb_labels]\n",
    "        kb_tokens += [kb_tokenizer.get_token('<pad>')] * (self.max_traj_len - len(kb_labels))\n",
    "        kb_tokens = array.array('h', kb_tokens)\n",
    "\n",
    "        return X, Y, T, word, kb_tokens\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_list)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        X_list, Y_list, T_list, word, kb_tokens = self.data_list[idx]\n",
    "\n",
    "        X = torch.zeros(self.max_traj_len, dtype=torch.float32)\n",
    "        Y = torch.zeros(self.max_traj_len, dtype=torch.float32)\n",
    "        T = torch.zeros(self.max_traj_len, dtype=torch.float32)\n",
    "        \n",
    "        X[:len(X_list)] = torch.tensor(X_list, dtype=torch.float32)\n",
    "        Y[:len(Y_list)] = torch.tensor(Y_list, dtype=torch.float32)\n",
    "        T[:len(T_list)] = torch.tensor(T_list, dtype=torch.float32)\n",
    "\n",
    "        xyt = torch.cat(\n",
    "            [\n",
    "                X.reshape(-1, 1),\n",
    "                Y.reshape(-1, 1),\n",
    "                T.reshape(-1, 1)\n",
    "            ],\n",
    "            axis = 1\n",
    "        )\n",
    "\n",
    "        traj_len = len(X_list)\n",
    "\n",
    "        if self.include_velocities:\n",
    "            dx_dt = self._get_dx_dt(X, T, traj_len)\n",
    "            dy_dt = self._get_dx_dt(Y, T, traj_len)\n",
    "            xyt = torch.cat(\n",
    "                [\n",
    "                    xyt,\n",
    "                    dx_dt.reshape(-1, 1),\n",
    "                    dy_dt.reshape(-1, 1)\n",
    "                ],\n",
    "                axis = 1\n",
    "            )\n",
    "\n",
    "        if self.include_accelerations:\n",
    "            d2x_dt2 = self._get_dx_dt(dx_dt, T, traj_len)\n",
    "            d2y_dt2 = self._get_dx_dt(dy_dt, T, traj_len)\n",
    "            xyt = torch.cat(\n",
    "                [\n",
    "                    xyt,\n",
    "                    d2x_dt2.reshape(-1, 1),\n",
    "                    d2y_dt2.reshape(-1, 1)\n",
    "                ],\n",
    "                axis = 1\n",
    "            )\n",
    "\n",
    "        traj_pad_mask = torch.zeros(self.max_traj_len, dtype=torch.bool)\n",
    "        traj_pad_mask[:len(X_list)] = True\n",
    "\n",
    "        char_seq, word_mask = self.word_tokenizer.tokenize(word)\n",
    "\n",
    "        kb_tokens = torch.tensor(kb_tokens, dtype=torch.int64)\n",
    "    \n",
    "        return xyt, kb_tokens, traj_pad_mask, char_seq, word_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_kb_keys(grid_name: str, grids_path: str) -> dict:\n",
    "    with open(grids_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        grids = json.load(f)\n",
    "        grid = grids[grid_name]\n",
    "        return grid['keys']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:03<00:00, 280.27it/s]\n"
     ]
    }
   ],
   "source": [
    "sample_data = r\"..\\data\\data_separated_grid\\sample_deleteme__default_only.jsonl\"\n",
    "grid_path =  r\"..\\data\\data_separated_grid\\gridname_to_grid.json\"\n",
    "grid_name = \"default\"\n",
    "\n",
    "kb_keys = get_kb_keys(grid_name, grid_path)\n",
    "kb_tokenizer = KeyboardTokenizerv1()\n",
    "word_tokenizer = CharLevelTokenizerv1(\"../data/data_separated_grid/voc.txt\")\n",
    "\n",
    "\n",
    "dataset = NeuroSwipeDatasetv1(\n",
    "    data_path = sample_data,\n",
    "    kb_keys = kb_keys,\n",
    "    kb_tokenizer = kb_tokenizer,\n",
    "    max_traj_len = 299,\n",
    "    word_tokenizer = word_tokenizer,\n",
    "    include_velocities = True,\n",
    "    include_accelerations = True,\n",
    "    total = 1000\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([299, 7]) torch.Size([299]) torch.Size([299]) torch.Size([36]) torch.Size([36])\n"
     ]
    }
   ],
   "source": [
    "i = 40\n",
    "xyt, kb_tokens, traj_pad_mask, char_seq, word_mask = dataset[i]\n",
    "print(xyt.shape, kb_tokens.shape, traj_pad_mask.shape, char_seq.shape, word_mask.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class SwipeCurveTransformerEncoderv1(nn.Module):\n",
    "    \"\"\"\n",
    "    Transformer-based Curve encoder takes in a sequence of vectors and creates a representation\n",
    "    of a swipe gesture on a samrtphone keyboard.\n",
    "    Each vector contains information about finger trajectory at a time step.\n",
    "    It contains:\n",
    "    * x coordinate\n",
    "    * y coordinate\n",
    "    * Optionally: t\n",
    "    * Optionally: dx/dt\n",
    "    * Optionally: dy/dt\n",
    "    * Optionally: keyboard key that has x and y coordinates within its boundaries\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, input_size, d_model,\n",
    "                 dim_feedforward, num_layers, num_heads_first, num_heads_other,\n",
    "                 dropout = 0.1):\n",
    "        \"\"\"\n",
    "        Arguments:\n",
    "        ----------\n",
    "        input_size: int\n",
    "            Size of input vectors.\n",
    "        d_model: int\n",
    "            Size of the embeddings (output vectors).\n",
    "            Should be equal to char embedding size of the decoder.\n",
    "        dim_feedforward: int\n",
    "        num_layers: int\n",
    "            Number of encoder layers including the first layer.\n",
    "\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        # self.pos_encoder = PositionalEncoding(input_size, dropout)\n",
    "        self.first_encoder_layer = nn.TransformerEncoderLayer(\n",
    "            input_size, num_heads_first, dim_feedforward, dropout)\n",
    "        self.liner = nn.Linear(input_size, d_model)  # to convert embedding to d_model size\n",
    "        num_layer_after_first = num_layers - 1\n",
    "        if num_layer_after_first > 0:\n",
    "            encoder_layer = nn.TransformerEncoderLayer(d_model, num_heads_other, dim_feedforward, dropout)\n",
    "            self.transformer_encoder = nn.TransformerEncoder(encoder_layer, num_layers)\n",
    "        else:\n",
    "            self.transformer_encoder = None\n",
    "    \n",
    "\n",
    "    def forward(self, x, pad_mask: torch.tensor):\n",
    "        # x = self.pos_encoder(x)\n",
    "        x = self.first_encoder_layer(x, src_key_padding_mask=pad_mask)\n",
    "        x = self.liner(x)\n",
    "        if self.transformer_encoder:\n",
    "            x = self.transformer_encoder(x, src_key_padding_mask=pad_mask)\n",
    "        return x\n",
    "\n",
    "\n",
    "\n",
    "class SwipeCurveTransformerDecoderv1(nn.Module):\n",
    "    \"\"\"\n",
    "    Decodes a swipe gesture representation into a sequence of characters.\n",
    "\n",
    "    Uses decoder transformer with masked attention to prevent the model from cheating.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, char_emb_size, nhead, num_decoder_layers,\n",
    "                 dim_feedforward, dropout, activation = F.relu):\n",
    "        super().__init__()\n",
    "\n",
    "        self.decoder_layer = nn.TransformerDecoderLayer(char_emb_size, nhead, dim_feedforward, dropout, activation)\n",
    "        self.transformer_decoder = nn.TransformerDecoder(self.decoder_layer, num_decoder_layers)\n",
    "        self.out = nn.Linear(char_emb_size, char_emb_size)\n",
    "        self.softmax = nn.LogSoftmax(dim=2)\n",
    "    \n",
    "    def forward(self, x, memory, tgt_mask, memory_key_padding_mask, tgt_key_padding_mask):\n",
    "        x = self.transformer_decoder(x,\n",
    "                                     memory,\n",
    "                                     tgt_mask=tgt_mask,\n",
    "                                     memory_key_padding_mask=memory_key_padding_mask,\n",
    "                                     tgt_key_padding_mask=tgt_key_padding_mask)\n",
    "        x = self.out(x)\n",
    "        # x = self.softmax(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model: int, max_len, dropout: float = 0.0):\n",
    "        super().__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "        position = torch.arange(max_len).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2) * (-math.log(10000.0) / d_model))\n",
    "        pe = torch.zeros(max_len, 1, d_model)\n",
    "        pe[:, 0, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 0, 1::2] = torch.cos(position * div_term)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Arguments:\n",
    "            x: Tensor, shape ``[seq_len, batch_size, embedding_dim]``\n",
    "        \"\"\"\n",
    "        x = x + self.pe[:x.size(0)]\n",
    "        return self.dropout(x)\n",
    "\n",
    "\n",
    "class SwipeCurveTransformer(nn.Module):\n",
    "    \"\"\"\n",
    "    SwipeCurveTransformer is a sequence-to-sequence model that encodes a sequence of vectors\n",
    "    representing a swipe gesture into a sequence of characters.\n",
    "    \"\"\"\n",
    "\n",
    "    def _get_mask(self, max_seq_len: int):\n",
    "        \"\"\"\n",
    "        Returns a mask for the decoder transformer.\n",
    "        \"\"\"\n",
    "        mask = torch.triu(torch.ones(max_seq_len, max_seq_len), diagonal=1)\n",
    "        mask = mask.masked_fill(mask == 1, float('-inf'))\n",
    "        return mask\n",
    "\n",
    "    def __init__(self,\n",
    "                 input_size,\n",
    "                 char_emb_size,\n",
    "                 char_vocab_size,\n",
    "                 num_encoder_layers,\n",
    "                 num_decoder_layers,\n",
    "                 dim_feedforward,\n",
    "                 num_heads,\n",
    "                 dropout,\n",
    "                 max_out_seq_len,\n",
    "                 activation = F.relu):\n",
    "        super().__init__()\n",
    "\n",
    "        curv_emb_size = char_emb_size\n",
    "        \n",
    "        self.char_embedding = nn.Embedding(char_vocab_size, char_emb_size)\n",
    "\n",
    "        self.encoder = SwipeCurveTransformerEncoderv1(\n",
    "            input_size, curv_emb_size, dim_feedforward, num_encoder_layers, num_heads, dropout)\n",
    "        self.pos_encoder = PositionalEncoding(char_emb_size, max_out_seq_len)\n",
    "        self.decoder = SwipeCurveTransformerDecoderv1(\n",
    "            char_emb_size, num_heads, num_decoder_layers, dim_feedforward, dropout, activation)\n",
    "        self.out = nn.Linear(char_emb_size, char_emb_size)\n",
    "        self.softmax = nn.LogSoftmax(dim=2)\n",
    "\n",
    "        self.mask = self._get_mask(max_out_seq_len)\n",
    "\n",
    "    def forward(self, x, y, x_pad_mask, y_pad_mask):\n",
    "        x = self.encoder(x, x_pad_mask)\n",
    "        y = self.char_embedding(y)\n",
    "        y = self.pos_encoder(y)\n",
    "        y = self.decoder(y, x, self.mask, x_pad_mask, y_pad_mask)\n",
    "        y = self.out(y)\n",
    "        y = self.softmax(y)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_mask(max_seq_len: int):\n",
    "#     \"\"\"\n",
    "#     Returns a mask for the decoder transformer.\n",
    "#     \"\"\"\n",
    "#     mask = torch.triu(torch.ones(max_seq_len, max_seq_len), diagonal=1)\n",
    "#     mask = mask.masked_fill(mask == 1, float('-inf'))\n",
    "#     return mask\n",
    "\n",
    "# mask = get_mask(5)\n",
    "# print(mask)\n",
    "\n",
    "# >>>\n",
    "# tensor([[0., -inf, -inf, -inf, -inf],\n",
    "#         [0., 0., -inf, -inf, -inf],\n",
    "#         [0., 0., 0., -inf, -inf],\n",
    "#         [0., 0., 0., 0., -inf],\n",
    "#         [0., 0., 0., 0., 0.]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[nan, nan, nan,  ..., nan, nan, nan],\n",
       "         [nan, nan, nan,  ..., nan, nan, nan],\n",
       "         [nan, nan, nan,  ..., nan, nan, nan],\n",
       "         ...,\n",
       "         [nan, nan, nan,  ..., nan, nan, nan],\n",
       "         [nan, nan, nan,  ..., nan, nan, nan],\n",
       "         [nan, nan, nan,  ..., nan, nan, nan]],\n",
       "\n",
       "        [[nan, nan, nan,  ..., nan, nan, nan],\n",
       "         [nan, nan, nan,  ..., nan, nan, nan],\n",
       "         [nan, nan, nan,  ..., nan, nan, nan],\n",
       "         ...,\n",
       "         [nan, nan, nan,  ..., nan, nan, nan],\n",
       "         [nan, nan, nan,  ..., nan, nan, nan],\n",
       "         [nan, nan, nan,  ..., nan, nan, nan]],\n",
       "\n",
       "        [[nan, nan, nan,  ..., nan, nan, nan],\n",
       "         [nan, nan, nan,  ..., nan, nan, nan],\n",
       "         [nan, nan, nan,  ..., nan, nan, nan],\n",
       "         ...,\n",
       "         [nan, nan, nan,  ..., nan, nan, nan],\n",
       "         [nan, nan, nan,  ..., nan, nan, nan],\n",
       "         [nan, nan, nan,  ..., nan, nan, nan]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[nan, nan, nan,  ..., nan, nan, nan],\n",
       "         [nan, nan, nan,  ..., nan, nan, nan],\n",
       "         [nan, nan, nan,  ..., nan, nan, nan],\n",
       "         ...,\n",
       "         [nan, nan, nan,  ..., nan, nan, nan],\n",
       "         [nan, nan, nan,  ..., nan, nan, nan],\n",
       "         [nan, nan, nan,  ..., nan, nan, nan]],\n",
       "\n",
       "        [[nan, nan, nan,  ..., nan, nan, nan],\n",
       "         [nan, nan, nan,  ..., nan, nan, nan],\n",
       "         [nan, nan, nan,  ..., nan, nan, nan],\n",
       "         ...,\n",
       "         [nan, nan, nan,  ..., nan, nan, nan],\n",
       "         [nan, nan, nan,  ..., nan, nan, nan],\n",
       "         [nan, nan, nan,  ..., nan, nan, nan]],\n",
       "\n",
       "        [[nan, nan, nan,  ..., nan, nan, nan],\n",
       "         [nan, nan, nan,  ..., nan, nan, nan],\n",
       "         [nan, nan, nan,  ..., nan, nan, nan],\n",
       "         ...,\n",
       "         [nan, nan, nan,  ..., nan, nan, nan],\n",
       "         [nan, nan, nan,  ..., nan, nan, nan],\n",
       "         [nan, nan, nan,  ..., nan, nan, nan]]], grad_fn=<TransposeBackward1>)"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq_len = 32\n",
    "batch_size = 10\n",
    "in_features = 40\n",
    "\n",
    "\n",
    "\n",
    "encoder = SwipeCurveTransformerEncoderv1(\n",
    "    input_size=in_features,\n",
    "    d_model=128,\n",
    "    dim_feedforward=128,\n",
    "    num_layers=1,\n",
    "    num_heads_first=2,\n",
    "    num_heads_other=4,\n",
    "    dropout=0.1)\n",
    "\n",
    "\n",
    "\n",
    "pad_mask = torch.zeros(batch_size, seq_len, dtype=torch.bool)\n",
    "pad_mask[:10, :] = True\n",
    "\n",
    "# print(pad_mask)\n",
    "\n",
    "encoded = encoder(torch.rand(seq_len, batch_size, in_features), pad_mask)\n",
    "\n",
    "encoded.transpose_(0,1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "SwipeCurveTransformerDecoderv1.forward() missing 2 required positional arguments: 'memory_key_padding_mask' and 'tgt_key_padding_mask'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\proshian\\Documents\\yandex_cup_2023_ml_neuroswipe\\src\\playground.ipynb Cell 16\u001b[0m line \u001b[0;36m1\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/proshian/Documents/yandex_cup_2023_ml_neuroswipe/src/playground.ipynb#X25sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m mask\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/proshian/Documents/yandex_cup_2023_ml_neuroswipe/src/playground.ipynb#X25sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m target_mask \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mtriu(torch\u001b[39m.\u001b[39mones(seq_len, seq_len), diagonal\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/proshian/Documents/yandex_cup_2023_ml_neuroswipe/src/playground.ipynb#X25sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m decoder(torch\u001b[39m.\u001b[39;49mrand(batch_size, seq_len, char_emb_size), torch\u001b[39m.\u001b[39;49mrand(batch_size, seq_len, char_emb_size), tgt_mask\u001b[39m=\u001b[39;49mtorch\u001b[39m.\u001b[39;49mrand(seq_len, seq_len)\u001b[39m.\u001b[39;49mmasked_fill(torch\u001b[39m.\u001b[39;49mrand(seq_len, seq_len) \u001b[39m>\u001b[39;49m \u001b[39m0.5\u001b[39;49m, \u001b[39mfloat\u001b[39;49m(\u001b[39m'\u001b[39;49m\u001b[39m-inf\u001b[39;49m\u001b[39m'\u001b[39;49m)))\u001b[39m.\u001b[39mshape\n",
      "File \u001b[1;32mc:\\Users\\proshian\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "\u001b[1;31mTypeError\u001b[0m: SwipeCurveTransformerDecoderv1.forward() missing 2 required positional arguments: 'memory_key_padding_mask' and 'tgt_key_padding_mask'"
     ]
    }
   ],
   "source": [
    "decoder = SwipeCurveTransformerDecoderv1(char_emb_size=128, nhead=1, num_decoder_layers=1, dim_feedforward=128, dropout=0.1)\n",
    "\n",
    "seq_len = 32\n",
    "batch_size = 10\n",
    "char_emb_size = 128\n",
    "\n",
    "def get_mask(max_seq_len: int):\n",
    "    \"\"\"\n",
    "    Returns a mask for the decoder transformer.\n",
    "    \"\"\"\n",
    "    mask = torch.triu(torch.ones(max_seq_len, max_seq_len), diagonal=1)\n",
    "    mask = mask.masked_fill(mask == 1, float('-inf'))\n",
    "    return mask\n",
    "\n",
    "target_mask = torch.triu(torch.ones(seq_len, seq_len), diagonal=1)\n",
    "\n",
    "decoder(\n",
    "    torch.rand(batch_size, seq_len, char_emb_size),\n",
    "    torch.rand(batch_size, seq_len, char_emb_size),\n",
    "    tgt_mask=torch.rand(seq_len, seq_len).masked_fill(torch.rand(seq_len, seq_len) > 0.5, float('-inf'))).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder = SwipeCurveTransformerDecoderv1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_char_tokenizer = CharLevelTokenizerv1(\"../data/data_separated_grid/voc.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 6, 32, 11, 34, 10, 10,  9, 31, 29, 26,  5, 33, 14, 14, 14, 14, 14, 14,\n",
       "         14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14]),\n",
       " tensor([ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "          True,  True, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False]))"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_char_tokenizer.tokenize(\"троллейбус\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['э', '-', 'г', 'к', 'ф', 'с', '<sos>', 'ь', 'ш', 'е', 'л', 'р', 'ы', '<unk>', '<pad>', 'з', 'ж', 'ц', 'н', 'а', 'щ', 'ю', 'в', 'п', 'и', 'х', 'у', 'ъ', 'ч', 'б', 'м', 'й', 'т', '<eos>', 'о', 'д', 'я'])\n"
     ]
    }
   ],
   "source": [
    "print(word_char_tokenizer.char_to_idx.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(word_char_tokenizer.tokenize('информационно-телекоммуникационной')[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(word_char_tokenizer.tokenize('информационно')[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer = SwipeCurveTransformer(\n",
    "    input_size=7,\n",
    "    char_emb_size=128,\n",
    "    char_vocab_size=len(word_char_tokenizer.char_to_idx),\n",
    "    num_encoder_layers=1,\n",
    "    num_decoder_layers=2,\n",
    "    dim_feedforward=128,\n",
    "    num_heads=1,\n",
    "    dropout=0.1,\n",
    "    max_out_seq_len=36)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\proshian\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "loader = DataLoader(dataset, batch_size=10, shuffle=True)\n",
    "\n",
    "for xyt, kb_tokens, traj_pad_mask, char_seq, word_pad_mask in loader:\n",
    "    # (batch_size, seq_len, n_point_feats) to (seq_len, batch_size, n_point_feats)\n",
    "    xyt = torch.transpose(xyt, 0, 1)\n",
    "    char_seq = torch.transpose(char_seq, 0, 1)\n",
    "\n",
    "    # print(xyt.shape)\n",
    "    # print(traj_pad_mask.shape)\n",
    "    # print(char_seq.shape)\n",
    "    # print(word_pad_mask.shape)\n",
    "    # print()\n",
    "\n",
    "    char_seq_pred = transformer(xyt, char_seq, traj_pad_mask, word_pad_mask)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[nan, nan, nan,  ..., nan, nan, nan],\n",
       "         [nan, nan, nan,  ..., nan, nan, nan],\n",
       "         [nan, nan, nan,  ..., nan, nan, nan],\n",
       "         ...,\n",
       "         [nan, nan, nan,  ..., nan, nan, nan],\n",
       "         [nan, nan, nan,  ..., nan, nan, nan],\n",
       "         [nan, nan, nan,  ..., nan, nan, nan]],\n",
       "\n",
       "        [[nan, nan, nan,  ..., nan, nan, nan],\n",
       "         [nan, nan, nan,  ..., nan, nan, nan],\n",
       "         [nan, nan, nan,  ..., nan, nan, nan],\n",
       "         ...,\n",
       "         [nan, nan, nan,  ..., nan, nan, nan],\n",
       "         [nan, nan, nan,  ..., nan, nan, nan],\n",
       "         [nan, nan, nan,  ..., nan, nan, nan]],\n",
       "\n",
       "        [[nan, nan, nan,  ..., nan, nan, nan],\n",
       "         [nan, nan, nan,  ..., nan, nan, nan],\n",
       "         [nan, nan, nan,  ..., nan, nan, nan],\n",
       "         ...,\n",
       "         [nan, nan, nan,  ..., nan, nan, nan],\n",
       "         [nan, nan, nan,  ..., nan, nan, nan],\n",
       "         [nan, nan, nan,  ..., nan, nan, nan]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[nan, nan, nan,  ..., nan, nan, nan],\n",
       "         [nan, nan, nan,  ..., nan, nan, nan],\n",
       "         [nan, nan, nan,  ..., nan, nan, nan],\n",
       "         ...,\n",
       "         [nan, nan, nan,  ..., nan, nan, nan],\n",
       "         [nan, nan, nan,  ..., nan, nan, nan],\n",
       "         [nan, nan, nan,  ..., nan, nan, nan]],\n",
       "\n",
       "        [[nan, nan, nan,  ..., nan, nan, nan],\n",
       "         [nan, nan, nan,  ..., nan, nan, nan],\n",
       "         [nan, nan, nan,  ..., nan, nan, nan],\n",
       "         ...,\n",
       "         [nan, nan, nan,  ..., nan, nan, nan],\n",
       "         [nan, nan, nan,  ..., nan, nan, nan],\n",
       "         [nan, nan, nan,  ..., nan, nan, nan]],\n",
       "\n",
       "        [[nan, nan, nan,  ..., nan, nan, nan],\n",
       "         [nan, nan, nan,  ..., nan, nan, nan],\n",
       "         [nan, nan, nan,  ..., nan, nan, nan],\n",
       "         ...,\n",
       "         [nan, nan, nan,  ..., nan, nan, nan],\n",
       "         [nan, nan, nan,  ..., nan, nan, nan],\n",
       "         [nan, nan, nan,  ..., nan, nan, nan]]], grad_fn=<LogSoftmaxBackward0>)"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "char_seq_pred.transpose(0,1)[0].shape\n",
    "char_seq_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\proshian\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 10, 128])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_heads = 2\n",
    "num_decoder_layers = 1\n",
    "dim_feedforward = 128\n",
    "dropout = 0.1\n",
    "activation = F.relu\n",
    "max_out_seq_len = 32\n",
    "\n",
    "char_emb_size = 128\n",
    "seq_len = 32\n",
    "batch_size = 10\n",
    "\n",
    "decoder = SwipeCurveTransformerDecoderv1(\n",
    "    char_emb_size, num_heads, num_decoder_layers, dim_feedforward, dropout, activation)\n",
    "\n",
    "tgt_mask = torch.triu(torch.ones(max_out_seq_len, max_out_seq_len), diagonal=1)\n",
    "tgt_mask = tgt_mask.masked_fill(tgt_mask == 1, float('-inf'))\n",
    "\n",
    "memory_pad_mask = torch.zeros(max_out_seq_len, dtype=torch.bool)\n",
    "memory_pad_mask[:10] = True\n",
    "memory_pad_mask = memory_pad_mask.unsqueeze(0).repeat(batch_size, 1)\n",
    "\n",
    "tgt_pad_mask = torch.zeros(max_out_seq_len, dtype=torch.bool)\n",
    "tgt_pad_mask[:10] = True\n",
    "tgt_pad_mask = tgt_pad_mask.unsqueeze(0).repeat(batch_size, 1)\n",
    "\n",
    "decoder(\n",
    "    torch.rand(seq_len, batch_size, char_emb_size),\n",
    "    torch.rand(seq_len, batch_size, char_emb_size),\n",
    "    tgt_mask=tgt_mask,\n",
    "    memory_key_padding_mask=memory_pad_mask,\n",
    "    tgt_key_padding_mask=tgt_pad_mask\n",
    ").shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
