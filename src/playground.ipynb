{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader, IterableDataset\n",
    "\n",
    "# from model import SwipeCurveEncoderTransformer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class SwipeCurveEncoderTransformer_old(nn.Module):\n",
    "#     \"\"\"\n",
    "#     Transformer-based Curve encoder takes in a sequence of vectors and creates a representation\n",
    "#     of a swipe gesture on a samrtphone keyboard.\n",
    "#     Each vector contains information about finger trajectory at a time step.\n",
    "#     It contains:\n",
    "#     * x coordinate\n",
    "#     * y coordinate\n",
    "#     * Optionally: t\n",
    "#     * Optionally: dx/dt\n",
    "#     * Optionally: dy/dt\n",
    "#     * Optionally: keyboard key that has x and y coordinates within its boundaries\n",
    "#     \"\"\"\n",
    "\n",
    "#     def __init__(self, input_size, hidden_size, num_layers, num_heads, dropout):\n",
    "#         super().__init__()\n",
    "#         self.input_size = input_size\n",
    "#         self.hidden_size = hidden_size\n",
    "#         self.num_layers = num_layers\n",
    "#         self.num_heads = num_heads\n",
    "#         self.dropout = dropout\n",
    "\n",
    "#         # self.pos_encoder = PositionalEncoding(input_size, dropout)\n",
    "#         self.encoder_layer = nn.TransformerEncoderLayer(input_size, num_heads, hidden_size, dropout)\n",
    "#         self.transformer_encoder = nn.TransformerEncoder(self.encoder_layer, num_layers)\n",
    "    \n",
    "#     def forward(self, x):\n",
    "#         # x = self.pos_encoder(x)\n",
    "#         x = self.transformer_encoder(x)\n",
    "#         return x\n",
    "\n",
    "\n",
    "\n",
    "# class SwipeCurveDecoderTransformerv1(nn.Module):\n",
    "#     \"\"\"\n",
    "#     Decodes a swipe gesture representation into a sequence of characters.\n",
    "\n",
    "#     Uses decoder transformer with masked attention to prevent the model from cheating.\n",
    "#     \"\"\"\n",
    "\n",
    "#     def __init__(self, d_model, nhead, num_encoder_layers, num_decoder_layers, dim_feedforward, dropout, activation):\n",
    "#         super().__init__()\n",
    "#         self.d_model = d_model\n",
    "#         self.nhead = nhead\n",
    "#         self.num_encoder_layers = num_encoder_layers\n",
    "#         self.num_decoder_layers = num_decoder_layers\n",
    "#         self.dim_feedforward = dim_feedforward\n",
    "#         self.dropout = dropout\n",
    "#         self.activation = activation\n",
    "\n",
    "#         self.decoder_layer = nn.TransformerDecoderLayer(d_model, nhead, dim_feedforward, dropout, activation)\n",
    "#         self.transformer_decoder = nn.TransformerDecoder(self.decoder_layer, num_decoder_layers)\n",
    "\n",
    "#     def forward(self, x, memory):\n",
    "#         x = self.transformer_decoder(x, memory)\n",
    "#         return x\n",
    "\n",
    "\n",
    "# class SwipeCurveTransformer(nn.Module):\n",
    "#     \"\"\"\n",
    "#     SwipeCurveTransformer is a sequence-to-sequence model that encodes a sequence of vectors\n",
    "#     representing a swipe gesture into a sequence of characters.\n",
    "#     \"\"\"\n",
    "\n",
    "#     def __init__(self, input_size, hidden_size, num_layers, num_heads, dropout):\n",
    "#         super().__init__()\n",
    "#         self.input_size = input_size\n",
    "#         self.hidden_size = hidden_size\n",
    "#         self.num_layers = num_layers\n",
    "#         self.num_heads = num_heads\n",
    "#         self.dropout = dropout\n",
    "\n",
    "#         self.encoder = SwipeCurveEncoderTransformerv1(input_size, hidden_size, num_layers, num_heads, dropout)\n",
    "#         self.decoder = SwipeCurveDecoderTransformerv1(input_size, num_heads, num_layers, num_layers, hidden_size, dropout, 'relu')\n",
    "#         self.out = nn.Linear(input_size, input_size)\n",
    "#         self.softmax = nn.LogSoftmax(dim=2)\n",
    "\n",
    "#     def forward(self, x, y):\n",
    "#         x = self.encoder(x)\n",
    "#         x = self.decoder(y, x)\n",
    "#         x = self.out(x)\n",
    "#         x = self.softmax(x)\n",
    "#         return x\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class SwipeCurveEncoderTransformerLSTM(nn.Module):\n",
    "#     \"\"\"\n",
    "#     Transformer-based Curve encoder takes in a sequence of vectors and creates a representation\n",
    "#     of a swipe gesture on a samrtphone keyboard.\n",
    "#     Each vector contains information about finger trajectory at a time step.\n",
    "#     It contains:\n",
    "#     * x coordinate\n",
    "#     * y coordinate\n",
    "#     * Optionally: t\n",
    "#     * Optionally: dx/dt\n",
    "#     * Optionally: dy/dt\n",
    "#     * Optionally: keyboard key that has x and y coordinates within its boundaries\n",
    "#     \"\"\"\n",
    "\n",
    "#     def __init__(self, input_size, hidden_size, num_layers, num_heads, dropout):\n",
    "#         super().__init__()\n",
    "#         self.input_size = input_size\n",
    "#         self.hidden_size = hidden_size\n",
    "#         self.num_layers = num_layers\n",
    "#         self.num_heads = num_heads\n",
    "#         self.dropout = dropout\n",
    "\n",
    "#         # self.pos_encoder = PositionalEncoding(input_size, dropout)\n",
    "#         self.encoder_layer = nn.TransformerEncoderLayer(input_size, num_heads, hidden_size, dropout)\n",
    "#         self.transformer_encoder = nn.TransformerEncoder(self.encoder_layer, num_layers)\n",
    "#         self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True, bidirectional=True)\n",
    "    \n",
    "#     def forward(self, x):\n",
    "#         # x = self.pos_encoder(x)\n",
    "#         x = self.transformer_encoder(x)\n",
    "#         x, _ = self.lstm(x)\n",
    "#         return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from torch.utils.data import IterableDataset\n",
    "\n",
    "\n",
    "class NeuroSwipeIterableDatasetv1(IterableDataset):\n",
    "    \"\"\"\n",
    "    Dataset class for NeuroSwipe dataset.\n",
    "    The dataset file weights over 3 GB and contains over 6 million swipe gestures.\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, data_path):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            data_path (string): Path to the NeuroSwipe dataset in JSON format.\n",
    "                A custom version of the dataset is used:\n",
    "                \"grid\" property is replaced with \"grid_name\" property.\n",
    "        \"\"\"\n",
    "        self.json_file = open(data_path, \"r\", encoding=\"utf-8\")\n",
    "\n",
    "    def __del__(self):\n",
    "        self.json_file.close()\n",
    "\n",
    "    def _get_data_from_json_line(self, line):\n",
    "        \"\"\"\n",
    "        Parses a JSON line and returns a dictionary with data.\n",
    "        \"\"\"\n",
    "        data = json.loads(line)\n",
    "        word: str = data['word']\n",
    "\n",
    "        X_list = data['curve']['x']\n",
    "        Y_list = data['curve']['y']\n",
    "        T_list = data['curve']['t']\n",
    "\n",
    "        X = torch.tensor(X_list, dtype=torch.float32)\n",
    "        Y = torch.tensor(Y_list, dtype=torch.float32)\n",
    "        T = torch.tensor(T_list, dtype=torch.float32)\n",
    "\n",
    "        return X, Y, T, word\n",
    "    \n",
    "    def __iter__(self):\n",
    "        for line in self.json_file:\n",
    "            yield self._get_data_from_json_line(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Optional\n",
    "\n",
    "class CharLevelTokenizerv1:\n",
    "    def __init__(self, vocab_path):\n",
    "        self.char_to_idx = {}\n",
    "        self.idx_to_char = {}\n",
    "        self.max_word_len = None  # is set in _build_vocab\n",
    "        self._build_vocab(vocab_path)\n",
    "\n",
    "    def _build_vocab(self, vocab_path):\n",
    "        self.max_word_len = 0\n",
    "        unique_chars = set({\"<pad>\": 0, \"<sos>\": 1, \"<eos>\": 2, \"<unk>\": 3})\n",
    "        with open(vocab_path, \"r\", encoding=\"utf-8\") as f:\n",
    "            vocab = f.read().split(\"\\n\")\n",
    "            for word in vocab:\n",
    "                self.max_word_len = max(self.max_word_len, len(word) + 2)\n",
    "                for char in word:\n",
    "                    unique_chars.add(char)\n",
    "        self.char_to_idx = {char: idx for idx, char in enumerate(unique_chars)}\n",
    "        self.idx_to_char = {idx: char for idx, char in enumerate(unique_chars)}\n",
    "\n",
    "    def _tokenize_word(self, word):\n",
    "        \"\"\"\n",
    "        Tokenizes a word into a list of integers.\n",
    "        \"\"\"\n",
    "        tokenized_word = []\n",
    "        tokenized_word.append(self.char_to_idx[\"<sos>\"])\n",
    "        for char in word:\n",
    "            tokenized_word.append(self.char_to_idx[char])\n",
    "        tokenized_word.append(self.char_to_idx[\"<eos>\"])\n",
    "        return tokenized_word\n",
    "    \n",
    "    def _pad_word(self, word):\n",
    "        \"\"\"\n",
    "        Pads a word to the max_word_len.\n",
    "        \"\"\"\n",
    "        return word + [self.char_to_idx[\"<pad>\"]] * (self.max_word_len - len(word))\n",
    "    \n",
    "    def tokenize(self, word):\n",
    "        \"\"\"\n",
    "        Tokenizes a word and pads it to the max_word_len.\n",
    "        \"\"\"\n",
    "        token_seq = torch.tensor(self._pad_word(self._tokenize_word(word)))\n",
    "        mask = torch.zeros(self.max_word_len, dtype=torch.bool)\n",
    "        mask[:len(word)+2] = True\n",
    "        return token_seq, mask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from typing import Optional, List, Tuple\n",
    "import array\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "class NeuroSwipeDatasetv1(Dataset):\n",
    "    \"\"\"\n",
    "    Dataset class for NeuroSwipe dataset.\n",
    "    The dataset file weights over 3 GB and contains over 6 million swipe gestures.\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 data_path,\n",
    "                 max_traj_len: int,\n",
    "                 word_tokenizer,  # should contain max word len\n",
    "                 add_velcities: bool = True,\n",
    "                 add_accelerations: bool = True,\n",
    "                 total: Optional[int] = None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            data_path (string): Path to the NeuroSwipe dataset in JSON format.\n",
    "                A custom version of the dataset is used:\n",
    "                \"grid\" property is replaced with \"grid_name\" property.\n",
    "        \"\"\"\n",
    "        if add_accelerations and not add_velcities:\n",
    "\n",
    "            raise ValueError(\"Accelerations are supposed \\\n",
    "                             to be an addition to velocities. Add velocities.\")\n",
    "\n",
    "        self.max_traj_len = max_traj_len\n",
    "        self.add_velcities = add_velcities\n",
    "        self.add_accelerations = add_accelerations\n",
    "\n",
    "        self.word_tokenizer = word_tokenizer\n",
    "\n",
    "        self.data_list = []\n",
    "        self._set_data(data_path, self.data_list, total = total)\n",
    "    \n",
    "    def _set_data(self, data_path: str, data_list: list, total: Optional[int] = None):\n",
    "        with open(data_path, \"r\", encoding=\"utf-8\") as json_file:\n",
    "            for line in tqdm(json_file, total = total):\n",
    "                data_list.append(self._get_data_from_json_line(line))\n",
    "\n",
    "    def _get_dx_dt(self, X: torch.tensor, T: torch.tensor) -> List[float]:\n",
    "        \"\"\"\n",
    "        Calculates dx/dt for a list of x coordinates and a list of t coordinates.\n",
    "        \"\"\"\n",
    "        dx_dt = torch.zeros_like(X)\n",
    "        dx_dt[1:-1] = (X[2:] - X[:-2]) / (T[2:] - T[:-2])\n",
    "\n",
    "        # x0 x1 x2 x3\n",
    "        # t0 t1 t2 t3\n",
    "        # dx_dt[0] = 0\n",
    "        # dx_dt[1] = (x2 - x0) / (t2 - t0)\n",
    "        # dx_dt[2] = (x3 - x1) / (t3 - t1)\n",
    "        # dx_dt[3] = 0\n",
    "\n",
    "        return dx_dt\n",
    "\n",
    "    def _get_data_from_json_line(self, line) -> Tuple[list, list, list, str]:\n",
    "        \"\"\"\n",
    "        Parses a JSON line and returns a dictionary with data.\n",
    "        \"\"\"\n",
    "        data = json.loads(line)\n",
    "        word: str = data['word']\n",
    "        try:\n",
    "            X = array.array('h', data['curve']['x'])\n",
    "            Y = array.array('h', data['curve']['y'])\n",
    "            T = array.array('h', data['curve']['t'])\n",
    "        except:\n",
    "            print(data['curve']['x'])\n",
    "            print(data['curve']['y'])\n",
    "            print(data['curve']['t'])\n",
    "\n",
    "        return X, Y, T, word\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_list)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        X_list, Y_list, T_list, word =  self.data_list[idx]\n",
    "\n",
    "        X = torch.zeros(self.max_traj_len, dtype=torch.float32)\n",
    "        Y = torch.zeros(self.max_traj_len, dtype=torch.float32)\n",
    "        T = torch.zeros(self.max_traj_len, dtype=torch.float32)\n",
    "        \n",
    "        X[:len(X_list)] = torch.tensor(X_list, dtype=torch.float32)\n",
    "        Y[:len(Y_list)] = torch.tensor(Y_list, dtype=torch.float32)\n",
    "        T[:len(T_list)] = torch.tensor(T_list, dtype=torch.float32)\n",
    "\n",
    "        xyt = torch.cat(\n",
    "            [\n",
    "                X.reshape(-1, 1),\n",
    "                Y.reshape(-1, 1),\n",
    "                T.reshape(-1, 1)\n",
    "            ],\n",
    "            axis = 1\n",
    "        )\n",
    "\n",
    "        if self.add_velcities:\n",
    "            dx_dt = self._get_dx_dt(X, T)\n",
    "            dy_dt = self._get_dx_dt(Y, T)\n",
    "            xyt = torch.cat(\n",
    "                [\n",
    "                    xyt,\n",
    "                    dx_dt.reshape(-1, 1),\n",
    "                    dy_dt.reshape(-1, 1)\n",
    "                ],\n",
    "                axis = 1\n",
    "            )\n",
    "\n",
    "        if self.add_accelerations:\n",
    "            d2x_dt2 = self._get_dx_dt(dx_dt, T)\n",
    "            d2y_dt2 = self._get_dx_dt(dy_dt, T)\n",
    "            xyt = torch.cat(\n",
    "                [\n",
    "                    xyt,\n",
    "                    d2x_dt2.reshape(-1, 1),\n",
    "                    d2y_dt2.reshape(-1, 1)\n",
    "                ],\n",
    "                axis = 1\n",
    "            )\n",
    "\n",
    "        traj_pad_mask = torch.zeros(self.max_traj_len, dtype=torch.bool)\n",
    "        traj_pad_mask[:len(X_list)] = True\n",
    "\n",
    "        char_seq, word_mask = self.word_tokenizer.tokenize(word)\n",
    "    \n",
    "        return xyt, traj_pad_mask, char_seq, word_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset_path = \"../data/data_separated_grid/train.jsonl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 1216087/6000000 [01:17<05:04, 15717.60it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\proshian\\Documents\\yandex_cup_2023_ml_neuroswipe\\src\\playground.ipynb Cell 7\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/proshian/Documents/yandex_cup_2023_ml_neuroswipe/src/playground.ipynb#W6sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m dataset \u001b[39m=\u001b[39m NeuroSwipeDatasetv1(data_path\u001b[39m=\u001b[39;49mtrain_dataset_path, total \u001b[39m=\u001b[39;49m \u001b[39m6_000_000\u001b[39;49m)\n",
      "\u001b[1;32mc:\\Users\\proshian\\Documents\\yandex_cup_2023_ml_neuroswipe\\src\\playground.ipynb Cell 7\u001b[0m line \u001b[0;36m2\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/proshian/Documents/yandex_cup_2023_ml_neuroswipe/src/playground.ipynb#W6sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/proshian/Documents/yandex_cup_2023_ml_neuroswipe/src/playground.ipynb#W6sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m \u001b[39mArgs:\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/proshian/Documents/yandex_cup_2023_ml_neuroswipe/src/playground.ipynb#W6sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m \u001b[39m    data_path (string): Path to the NeuroSwipe dataset in JSON format.\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/proshian/Documents/yandex_cup_2023_ml_neuroswipe/src/playground.ipynb#W6sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m \u001b[39m        A custom version of the dataset is used:\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/proshian/Documents/yandex_cup_2023_ml_neuroswipe/src/playground.ipynb#W6sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m \u001b[39m        \"grid\" property is replaced with \"grid_name\" property.\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/proshian/Documents/yandex_cup_2023_ml_neuroswipe/src/playground.ipynb#W6sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/proshian/Documents/yandex_cup_2023_ml_neuroswipe/src/playground.ipynb#W6sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata_list \u001b[39m=\u001b[39m []\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/proshian/Documents/yandex_cup_2023_ml_neuroswipe/src/playground.ipynb#W6sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_set_data(data_path, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdata_list, total \u001b[39m=\u001b[39;49m total)\n",
      "\u001b[1;32mc:\\Users\\proshian\\Documents\\yandex_cup_2023_ml_neuroswipe\\src\\playground.ipynb Cell 7\u001b[0m line \u001b[0;36m2\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/proshian/Documents/yandex_cup_2023_ml_neuroswipe/src/playground.ipynb#W6sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_set_data\u001b[39m(\u001b[39mself\u001b[39m, data_path: \u001b[39mstr\u001b[39m, data_list: \u001b[39mlist\u001b[39m, total: Optional[\u001b[39mint\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m):\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/proshian/Documents/yandex_cup_2023_ml_neuroswipe/src/playground.ipynb#W6sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39m(data_path, \u001b[39m\"\u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\u001b[39m, encoding\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mutf-8\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mas\u001b[39;00m json_file:\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/proshian/Documents/yandex_cup_2023_ml_neuroswipe/src/playground.ipynb#W6sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m         \u001b[39mfor\u001b[39;00m line \u001b[39min\u001b[39;00m tqdm(json_file, total \u001b[39m=\u001b[39m total):\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/proshian/Documents/yandex_cup_2023_ml_neuroswipe/src/playground.ipynb#W6sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m             data_list\u001b[39m.\u001b[39mappend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_data_from_json_line(line))\n",
      "File \u001b[1;32mc:\\Users\\proshian\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tqdm\\std.py:1178\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1175\u001b[0m time \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_time\n\u001b[0;32m   1177\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 1178\u001b[0m     \u001b[39mfor\u001b[39;00m obj \u001b[39min\u001b[39;00m iterable:\n\u001b[0;32m   1179\u001b[0m         \u001b[39myield\u001b[39;00m obj\n\u001b[0;32m   1180\u001b[0m         \u001b[39m# Update and possibly print the progressbar.\u001b[39;00m\n\u001b[0;32m   1181\u001b[0m         \u001b[39m# Note: does not call self.update(1) for speed optimisation.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\proshian\\AppData\\Local\\Programs\\Python\\Python310\\lib\\codecs.py:319\u001b[0m, in \u001b[0;36mBufferedIncrementalDecoder.decode\u001b[1;34m(self, input, final)\u001b[0m\n\u001b[0;32m    314\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_buffer_decode\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m, errors, final):\n\u001b[0;32m    315\u001b[0m     \u001b[39m# Overwrite this method in subclasses: It must decode input\u001b[39;00m\n\u001b[0;32m    316\u001b[0m     \u001b[39m# and return an (output, length consumed) tuple\u001b[39;00m\n\u001b[0;32m    317\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mNotImplementedError\u001b[39;00m\n\u001b[1;32m--> 319\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdecode\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m, final\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m):\n\u001b[0;32m    320\u001b[0m     \u001b[39m# decode input (taking the buffer into account)\u001b[39;00m\n\u001b[0;32m    321\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbuffer \u001b[39m+\u001b[39m \u001b[39minput\u001b[39m\n\u001b[0;32m    322\u001b[0m     (result, consumed) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_buffer_decode(data, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39merrors, final)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "dataset = NeuroSwipeDatasetv1(data_path=train_dataset_path, total = 6_000_000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# организовать padding encoder'a и decoder'a\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class SwipeCurveTransformerEncoderv1(nn.Module):\n",
    "    \"\"\"\n",
    "    Transformer-based Curve encoder takes in a sequence of vectors and creates a representation\n",
    "    of a swipe gesture on a samrtphone keyboard.\n",
    "    Each vector contains information about finger trajectory at a time step.\n",
    "    It contains:\n",
    "    * x coordinate\n",
    "    * y coordinate\n",
    "    * Optionally: t\n",
    "    * Optionally: dx/dt\n",
    "    * Optionally: dy/dt\n",
    "    * Optionally: keyboard key that has x and y coordinates within its boundaries\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, input_size, d_model,\n",
    "                 dim_feedforward, num_layers, num_heads,\n",
    "                 dropout = 0.1):\n",
    "        \"\"\"\n",
    "        Arguments:\n",
    "        ----------\n",
    "        input_size: int\n",
    "            Size of input vectors.\n",
    "        d_model: int\n",
    "            Size of the embeddings (output vectors).\n",
    "            Should be equal to char embedding size of the decoder.\n",
    "        dim_feedforward: int\n",
    "        num_layers: int\n",
    "            Number of encoder layers including the first layer.\n",
    "\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        # self.pos_encoder = PositionalEncoding(input_size, dropout)\n",
    "        self.first_encoder_layer = nn.TransformerEncoderLayer(input_size, num_heads, dim_feedforward, dropout)\n",
    "        self.liner = nn.Linear(input_size, d_model)  # to convert embedding to d_model size\n",
    "        num_layer_after_first = num_layers - 1\n",
    "        if num_layer_after_first > 0:\n",
    "            encoder_layer = nn.TransformerEncoderLayer(d_model, num_heads, dim_feedforward, dropout)\n",
    "            self.transformer_encoder = nn.TransformerEncoder(encoder_layer, num_layers)\n",
    "        else:\n",
    "            self.transformer_encoder = None\n",
    "    \n",
    "\n",
    "    def forward(self, x, pad_mask: torch.tensor):\n",
    "        # x = self.pos_encoder(x)\n",
    "        x = self.first_encoder_layer(x, src_key_padding_mask=pad_mask)\n",
    "        x = self.liner(x)\n",
    "        if self.transformer_encoder:\n",
    "            x = self.transformer_encoder(x, src_key_padding_mask=pad_mask)\n",
    "        return x\n",
    "\n",
    "\n",
    "\n",
    "class SwipeCurveTransformerDecoderv1(nn.Module):\n",
    "    \"\"\"\n",
    "    Decodes a swipe gesture representation into a sequence of characters.\n",
    "\n",
    "    Uses decoder transformer with masked attention to prevent the model from cheating.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, char_emb_size, nhead, num_decoder_layers,\n",
    "                 dim_feedforward, dropout, activation = F.relu):\n",
    "        super().__init__()\n",
    "\n",
    "        self.decoder_layer = nn.TransformerDecoderLayer(char_emb_size, nhead, dim_feedforward, dropout, activation)\n",
    "        self.transformer_decoder = nn.TransformerDecoder(self.decoder_layer, num_decoder_layers)\n",
    "        self.out = nn.Linear(char_emb_size, char_emb_size)\n",
    "        self.softmax = nn.LogSoftmax(dim=2)\n",
    "    \n",
    "    def forward(self, x, memory, tgt_mask, memory_key_padding_mask, tgt_key_padding_mask):\n",
    "        x = self.transformer_decoder(x,\n",
    "                                     memory,\n",
    "                                     tgt_mask=tgt_mask,\n",
    "                                     memory_key_padding_mask=memory_key_padding_mask,\n",
    "                                     tgt_key_padding_mask=tgt_key_padding_mask)\n",
    "        x = self.out(x)\n",
    "        # x = self.softmax(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model: int, max_len, dropout: float = 0.0):\n",
    "        super().__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "        position = torch.arange(max_len).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2) * (-math.log(10000.0) / d_model))\n",
    "        pe = torch.zeros(max_len, 1, d_model)\n",
    "        pe[:, 0, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 0, 1::2] = torch.cos(position * div_term)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Arguments:\n",
    "            x: Tensor, shape ``[seq_len, batch_size, embedding_dim]``\n",
    "        \"\"\"\n",
    "        x = x + self.pe[:x.size(0)]\n",
    "        return self.dropout(x)\n",
    "\n",
    "\n",
    "class SwipeCurveTransformer(nn.Module):\n",
    "    \"\"\"\n",
    "    SwipeCurveTransformer is a sequence-to-sequence model that encodes a sequence of vectors\n",
    "    representing a swipe gesture into a sequence of characters.\n",
    "    \"\"\"\n",
    "\n",
    "    def _get_mask(self, max_seq_len: int):\n",
    "        \"\"\"\n",
    "        Returns a mask for the decoder transformer.\n",
    "        \"\"\"\n",
    "        mask = torch.triu(torch.ones(max_seq_len, max_seq_len), diagonal=1)\n",
    "        mask = mask.masked_fill(mask == 1, float('-inf'))\n",
    "        return mask\n",
    "\n",
    "    def __init__(self,\n",
    "                 input_size,\n",
    "                 char_emb_size,\n",
    "                 char_vocab_size,\n",
    "                 num_encoder_layers,\n",
    "                 num_decoder_layers,\n",
    "                 dim_feedforward,\n",
    "                 num_heads,\n",
    "                 dropout,\n",
    "                 max_out_seq_len,\n",
    "                 activation = F.relu):\n",
    "        super().__init__()\n",
    "\n",
    "        curv_emb_size = char_emb_size\n",
    "        \n",
    "        self.char_embedding = nn.Embedding(char_vocab_size, char_emb_size)\n",
    "\n",
    "        self.encoder = SwipeCurveTransformerEncoderv1(\n",
    "            input_size, curv_emb_size, dim_feedforward, num_encoder_layers, num_heads, dropout)\n",
    "        self.pos_encoder = PositionalEncoding(char_emb_size, max_out_seq_len)\n",
    "        self.decoder = SwipeCurveTransformerDecoderv1(\n",
    "            char_emb_size, num_heads, num_decoder_layers, dim_feedforward, dropout, activation)\n",
    "        self.out = nn.Linear(char_emb_size, char_emb_size)\n",
    "        self.softmax = nn.LogSoftmax(dim=2)\n",
    "\n",
    "        self.mask = self._get_mask(max_out_seq_len)\n",
    "\n",
    "    def forward(self, x, y, x_pad_mask, y_pad_mask):\n",
    "        x = self.encoder(x, x_pad_mask)\n",
    "        y = self.char_embedding(y)\n",
    "        y = self.pos_encoder(y)\n",
    "        y = self.decoder(y, x, self.mask, x_pad_mask, y_pad_mask)\n",
    "        y = self.out(y)\n",
    "        y = self.softmax(y)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_mask(max_seq_len: int):\n",
    "#     \"\"\"\n",
    "#     Returns a mask for the decoder transformer.\n",
    "#     \"\"\"\n",
    "#     mask = torch.triu(torch.ones(max_seq_len, max_seq_len), diagonal=1)\n",
    "#     mask = mask.masked_fill(mask == 1, float('-inf'))\n",
    "#     return mask\n",
    "\n",
    "# mask = get_mask(5)\n",
    "# print(mask)\n",
    "\n",
    "# >>>\n",
    "# tensor([[0., -inf, -inf, -inf, -inf],\n",
    "#         [0., 0., -inf, -inf, -inf],\n",
    "#         [0., 0., 0., -inf, -inf],\n",
    "#         [0., 0., 0., 0., -inf],\n",
    "#         [0., 0., 0., 0., 0.]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "         True, True, True, True, True, True, True, True],\n",
      "        [True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "         True, True, True, True, True, True, True, True],\n",
      "        [True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "         True, True, True, True, True, True, True, True],\n",
      "        [True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "         True, True, True, True, True, True, True, True],\n",
      "        [True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "         True, True, True, True, True, True, True, True],\n",
      "        [True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "         True, True, True, True, True, True, True, True],\n",
      "        [True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "         True, True, True, True, True, True, True, True],\n",
      "        [True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "         True, True, True, True, True, True, True, True],\n",
      "        [True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "         True, True, True, True, True, True, True, True],\n",
      "        [True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "         True, True, True, True, True, True, True, True]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 10, 128])"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder = SwipeCurveTransformerEncoderv1(input_size=40, d_model=128, dim_feedforward=128, num_layers=2, num_heads=4, dropout=0.1)\n",
    "\n",
    "seq_len = 32\n",
    "batch_size = 10\n",
    "in_features = 40\n",
    "\n",
    "pad_mask = torch.zeros(batch_size, seq_len, dtype=torch.bool)\n",
    "pad_mask[:10, :] = True\n",
    "\n",
    "print(pad_mask)\n",
    "\n",
    "encoder(torch.rand(seq_len, batch_size, in_features), pad_mask).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "SwipeCurveTransformerDecoderv1.forward() missing 2 required positional arguments: 'memory_key_padding_mask' and 'tgt_key_padding_mask'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\proshian\\Documents\\yandex_cup_2023_ml_neuroswipe\\src\\playground.ipynb Cell 16\u001b[0m line \u001b[0;36m1\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/proshian/Documents/yandex_cup_2023_ml_neuroswipe/src/playground.ipynb#X25sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m mask\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/proshian/Documents/yandex_cup_2023_ml_neuroswipe/src/playground.ipynb#X25sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m target_mask \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mtriu(torch\u001b[39m.\u001b[39mones(seq_len, seq_len), diagonal\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/proshian/Documents/yandex_cup_2023_ml_neuroswipe/src/playground.ipynb#X25sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m decoder(torch\u001b[39m.\u001b[39;49mrand(batch_size, seq_len, char_emb_size), torch\u001b[39m.\u001b[39;49mrand(batch_size, seq_len, char_emb_size), tgt_mask\u001b[39m=\u001b[39;49mtorch\u001b[39m.\u001b[39;49mrand(seq_len, seq_len)\u001b[39m.\u001b[39;49mmasked_fill(torch\u001b[39m.\u001b[39;49mrand(seq_len, seq_len) \u001b[39m>\u001b[39;49m \u001b[39m0.5\u001b[39;49m, \u001b[39mfloat\u001b[39;49m(\u001b[39m'\u001b[39;49m\u001b[39m-inf\u001b[39;49m\u001b[39m'\u001b[39;49m)))\u001b[39m.\u001b[39mshape\n",
      "File \u001b[1;32mc:\\Users\\proshian\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "\u001b[1;31mTypeError\u001b[0m: SwipeCurveTransformerDecoderv1.forward() missing 2 required positional arguments: 'memory_key_padding_mask' and 'tgt_key_padding_mask'"
     ]
    }
   ],
   "source": [
    "decoder = SwipeCurveTransformerDecoderv1(char_emb_size=128, nhead=1, num_decoder_layers=1, dim_feedforward=128, dropout=0.1)\n",
    "\n",
    "seq_len = 32\n",
    "batch_size = 10\n",
    "char_emb_size = 128\n",
    "\n",
    "def get_mask(max_seq_len: int):\n",
    "    \"\"\"\n",
    "    Returns a mask for the decoder transformer.\n",
    "    \"\"\"\n",
    "    mask = torch.triu(torch.ones(max_seq_len, max_seq_len), diagonal=1)\n",
    "    mask = mask.masked_fill(mask == 1, float('-inf'))\n",
    "    return mask\n",
    "\n",
    "target_mask = torch.triu(torch.ones(seq_len, seq_len), diagonal=1)\n",
    "\n",
    "decoder(\n",
    "    torch.rand(batch_size, seq_len, char_emb_size),\n",
    "    torch.rand(batch_size, seq_len, char_emb_size),\n",
    "    tgt_mask=torch.rand(seq_len, seq_len).masked_fill(torch.rand(seq_len, seq_len) > 0.5, float('-inf'))).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder = SwipeCurveTransformerDecoderv1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = CharLevelTokenizerv1(\"../data/data_separated_grid/voc.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 6, 32, 11, 34, 10, 10,  9, 31, 29, 26,  5, 33, 14, 14, 14, 14, 14, 14,\n",
       "         14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14]),\n",
       " tensor([ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "          True,  True, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False]))"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.tokenize(\"троллейбус\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['э', '-', 'г', 'к', 'ф', 'с', '<sos>', 'ь', 'ш', 'е', 'л', 'р', 'ы', '<unk>', '<pad>', 'з', 'ж', 'ц', 'н', 'а', 'щ', 'ю', 'в', 'п', 'и', 'х', 'у', 'ъ', 'ч', 'б', 'м', 'й', 'т', '<eos>', 'о', 'д', 'я'])\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.char_to_idx.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokenizer.tokenize('информационно-телекоммуникационной')[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokenizer.tokenize('информационно')[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1000it [00:00, 12990.21it/s]\n"
     ]
    }
   ],
   "source": [
    "sample_data = r\"..\\data\\data_separated_grid\\sample_deleteme.jsonl\"\n",
    "\n",
    "dataset = NeuroSwipeDatasetv1(data_path=sample_data, max_traj_len=299, word_tokenizer=tokenizer, add_velcities=True, add_accelerations=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer = SwipeCurveTransformer(\n",
    "    input_size=5,\n",
    "    char_emb_size=128,\n",
    "    char_vocab_size=len(tokenizer.char_to_idx),\n",
    "    num_encoder_layers=1,\n",
    "    num_decoder_layers=2,\n",
    "    dim_feedforward=128,\n",
    "    num_heads=1,\n",
    "    dropout=0.1,\n",
    "    max_out_seq_len=36)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([299, 2, 5])\n",
      "torch.Size([2, 299])\n",
      "torch.Size([36, 2])\n",
      "torch.Size([2, 36])\n",
      "\n",
      "torch.Size([299, 2, 5])\n",
      "torch.Size([2, 299])\n",
      "torch.Size([36, 2])\n",
      "torch.Size([2, 36])\n",
      "\n",
      "torch.Size([299, 2, 5])\n",
      "torch.Size([2, 299])\n",
      "torch.Size([36, 2])\n",
      "torch.Size([2, 36])\n",
      "\n",
      "torch.Size([299, 2, 5])\n",
      "torch.Size([2, 299])\n",
      "torch.Size([36, 2])\n",
      "torch.Size([2, 36])\n",
      "\n",
      "torch.Size([299, 2, 5])\n",
      "torch.Size([2, 299])\n",
      "torch.Size([36, 2])\n",
      "torch.Size([2, 36])\n",
      "\n",
      "torch.Size([299, 2, 5])\n",
      "torch.Size([2, 299])\n",
      "torch.Size([36, 2])\n",
      "torch.Size([2, 36])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\proshian\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([299, 2, 5])\n",
      "torch.Size([2, 299])\n",
      "torch.Size([36, 2])\n",
      "torch.Size([2, 36])\n",
      "\n",
      "torch.Size([299, 2, 5])\n",
      "torch.Size([2, 299])\n",
      "torch.Size([36, 2])\n",
      "torch.Size([2, 36])\n",
      "\n",
      "torch.Size([299, 2, 5])\n",
      "torch.Size([2, 299])\n",
      "torch.Size([36, 2])\n",
      "torch.Size([2, 36])\n",
      "\n",
      "torch.Size([299, 2, 5])\n",
      "torch.Size([2, 299])\n",
      "torch.Size([36, 2])\n",
      "torch.Size([2, 36])\n",
      "\n",
      "torch.Size([299, 2, 5])\n",
      "torch.Size([2, 299])\n",
      "torch.Size([36, 2])\n",
      "torch.Size([2, 36])\n",
      "\n",
      "torch.Size([299, 2, 5])\n",
      "torch.Size([2, 299])\n",
      "torch.Size([36, 2])\n",
      "torch.Size([2, 36])\n",
      "\n",
      "torch.Size([299, 2, 5])\n",
      "torch.Size([2, 299])\n",
      "torch.Size([36, 2])\n",
      "torch.Size([2, 36])\n",
      "\n",
      "torch.Size([299, 2, 5])\n",
      "torch.Size([2, 299])\n",
      "torch.Size([36, 2])\n",
      "torch.Size([2, 36])\n",
      "\n",
      "torch.Size([299, 2, 5])\n",
      "torch.Size([2, 299])\n",
      "torch.Size([36, 2])\n",
      "torch.Size([2, 36])\n",
      "\n",
      "torch.Size([299, 2, 5])\n",
      "torch.Size([2, 299])\n",
      "torch.Size([36, 2])\n",
      "torch.Size([2, 36])\n",
      "\n",
      "torch.Size([299, 2, 5])\n",
      "torch.Size([2, 299])\n",
      "torch.Size([36, 2])\n",
      "torch.Size([2, 36])\n",
      "\n",
      "torch.Size([299, 2, 5])\n",
      "torch.Size([2, 299])\n",
      "torch.Size([36, 2])\n",
      "torch.Size([2, 36])\n",
      "\n",
      "torch.Size([299, 2, 5])\n",
      "torch.Size([2, 299])\n",
      "torch.Size([36, 2])\n",
      "torch.Size([2, 36])\n",
      "\n",
      "torch.Size([299, 2, 5])\n",
      "torch.Size([2, 299])\n",
      "torch.Size([36, 2])\n",
      "torch.Size([2, 36])\n",
      "\n",
      "torch.Size([299, 2, 5])\n",
      "torch.Size([2, 299])\n",
      "torch.Size([36, 2])\n",
      "torch.Size([2, 36])\n",
      "\n",
      "torch.Size([299, 2, 5])\n",
      "torch.Size([2, 299])\n",
      "torch.Size([36, 2])\n",
      "torch.Size([2, 36])\n",
      "\n",
      "torch.Size([299, 2, 5])\n",
      "torch.Size([2, 299])\n",
      "torch.Size([36, 2])\n",
      "torch.Size([2, 36])\n",
      "\n",
      "torch.Size([299, 2, 5])\n",
      "torch.Size([2, 299])\n",
      "torch.Size([36, 2])\n",
      "torch.Size([2, 36])\n",
      "\n",
      "torch.Size([299, 2, 5])\n",
      "torch.Size([2, 299])\n",
      "torch.Size([36, 2])\n",
      "torch.Size([2, 36])\n",
      "\n",
      "torch.Size([299, 2, 5])\n",
      "torch.Size([2, 299])\n",
      "torch.Size([36, 2])\n",
      "torch.Size([2, 36])\n",
      "\n",
      "torch.Size([299, 2, 5])\n",
      "torch.Size([2, 299])\n",
      "torch.Size([36, 2])\n",
      "torch.Size([2, 36])\n",
      "\n",
      "torch.Size([299, 2, 5])\n",
      "torch.Size([2, 299])\n",
      "torch.Size([36, 2])\n",
      "torch.Size([2, 36])\n",
      "\n",
      "torch.Size([299, 2, 5])\n",
      "torch.Size([2, 299])\n",
      "torch.Size([36, 2])\n",
      "torch.Size([2, 36])\n",
      "\n",
      "torch.Size([299, 2, 5])\n",
      "torch.Size([2, 299])\n",
      "torch.Size([36, 2])\n",
      "torch.Size([2, 36])\n",
      "\n",
      "torch.Size([299, 2, 5])\n",
      "torch.Size([2, 299])\n",
      "torch.Size([36, 2])\n",
      "torch.Size([2, 36])\n",
      "\n",
      "torch.Size([299, 2, 5])\n",
      "torch.Size([2, 299])\n",
      "torch.Size([36, 2])\n",
      "torch.Size([2, 36])\n",
      "\n",
      "torch.Size([299, 2, 5])\n",
      "torch.Size([2, 299])\n",
      "torch.Size([36, 2])\n",
      "torch.Size([2, 36])\n",
      "\n",
      "torch.Size([299, 2, 5])\n",
      "torch.Size([2, 299])\n",
      "torch.Size([36, 2])\n",
      "torch.Size([2, 36])\n",
      "\n",
      "torch.Size([299, 2, 5])\n",
      "torch.Size([2, 299])\n",
      "torch.Size([36, 2])\n",
      "torch.Size([2, 36])\n",
      "\n",
      "torch.Size([299, 2, 5])\n",
      "torch.Size([2, 299])\n",
      "torch.Size([36, 2])\n",
      "torch.Size([2, 36])\n",
      "\n",
      "torch.Size([299, 2, 5])\n",
      "torch.Size([2, 299])\n",
      "torch.Size([36, 2])\n",
      "torch.Size([2, 36])\n",
      "\n",
      "torch.Size([299, 2, 5])\n",
      "torch.Size([2, 299])\n",
      "torch.Size([36, 2])\n",
      "torch.Size([2, 36])\n",
      "\n",
      "torch.Size([299, 2, 5])\n",
      "torch.Size([2, 299])\n",
      "torch.Size([36, 2])\n",
      "torch.Size([2, 36])\n",
      "\n",
      "torch.Size([299, 2, 5])\n",
      "torch.Size([2, 299])\n",
      "torch.Size([36, 2])\n",
      "torch.Size([2, 36])\n",
      "\n",
      "torch.Size([299, 2, 5])\n",
      "torch.Size([2, 299])\n",
      "torch.Size([36, 2])\n",
      "torch.Size([2, 36])\n",
      "\n",
      "torch.Size([299, 2, 5])\n",
      "torch.Size([2, 299])\n",
      "torch.Size([36, 2])\n",
      "torch.Size([2, 36])\n",
      "\n",
      "torch.Size([299, 2, 5])\n",
      "torch.Size([2, 299])\n",
      "torch.Size([36, 2])\n",
      "torch.Size([2, 36])\n",
      "\n",
      "torch.Size([299, 2, 5])\n",
      "torch.Size([2, 299])\n",
      "torch.Size([36, 2])\n",
      "torch.Size([2, 36])\n",
      "\n",
      "torch.Size([299, 2, 5])\n",
      "torch.Size([2, 299])\n",
      "torch.Size([36, 2])\n",
      "torch.Size([2, 36])\n",
      "\n",
      "torch.Size([299, 2, 5])\n",
      "torch.Size([2, 299])\n",
      "torch.Size([36, 2])\n",
      "torch.Size([2, 36])\n",
      "\n",
      "torch.Size([299, 2, 5])\n",
      "torch.Size([2, 299])\n",
      "torch.Size([36, 2])\n",
      "torch.Size([2, 36])\n",
      "\n",
      "torch.Size([299, 2, 5])\n",
      "torch.Size([2, 299])\n",
      "torch.Size([36, 2])\n",
      "torch.Size([2, 36])\n",
      "\n",
      "torch.Size([299, 2, 5])\n",
      "torch.Size([2, 299])\n",
      "torch.Size([36, 2])\n",
      "torch.Size([2, 36])\n",
      "\n",
      "torch.Size([299, 2, 5])\n",
      "torch.Size([2, 299])\n",
      "torch.Size([36, 2])\n",
      "torch.Size([2, 36])\n",
      "\n",
      "torch.Size([299, 2, 5])\n",
      "torch.Size([2, 299])\n",
      "torch.Size([36, 2])\n",
      "torch.Size([2, 36])\n",
      "\n",
      "torch.Size([299, 2, 5])\n",
      "torch.Size([2, 299])\n",
      "torch.Size([36, 2])\n",
      "torch.Size([2, 36])\n",
      "\n",
      "torch.Size([299, 2, 5])\n",
      "torch.Size([2, 299])\n",
      "torch.Size([36, 2])\n",
      "torch.Size([2, 36])\n",
      "\n",
      "torch.Size([299, 2, 5])\n",
      "torch.Size([2, 299])\n",
      "torch.Size([36, 2])\n",
      "torch.Size([2, 36])\n",
      "\n",
      "torch.Size([299, 2, 5])\n",
      "torch.Size([2, 299])\n",
      "torch.Size([36, 2])\n",
      "torch.Size([2, 36])\n",
      "\n",
      "torch.Size([299, 2, 5])\n",
      "torch.Size([2, 299])\n",
      "torch.Size([36, 2])\n",
      "torch.Size([2, 36])\n",
      "\n",
      "torch.Size([299, 2, 5])\n",
      "torch.Size([2, 299])\n",
      "torch.Size([36, 2])\n",
      "torch.Size([2, 36])\n",
      "\n",
      "torch.Size([299, 2, 5])\n",
      "torch.Size([2, 299])\n",
      "torch.Size([36, 2])\n",
      "torch.Size([2, 36])\n",
      "\n",
      "torch.Size([299, 2, 5])\n",
      "torch.Size([2, 299])\n",
      "torch.Size([36, 2])\n",
      "torch.Size([2, 36])\n",
      "\n",
      "torch.Size([299, 2, 5])\n",
      "torch.Size([2, 299])\n",
      "torch.Size([36, 2])\n",
      "torch.Size([2, 36])\n",
      "\n",
      "torch.Size([299, 2, 5])\n",
      "torch.Size([2, 299])\n",
      "torch.Size([36, 2])\n",
      "torch.Size([2, 36])\n",
      "\n",
      "torch.Size([299, 2, 5])\n",
      "torch.Size([2, 299])\n",
      "torch.Size([36, 2])\n",
      "torch.Size([2, 36])\n",
      "\n",
      "torch.Size([299, 2, 5])\n",
      "torch.Size([2, 299])\n",
      "torch.Size([36, 2])\n",
      "torch.Size([2, 36])\n",
      "\n",
      "torch.Size([299, 2, 5])\n",
      "torch.Size([2, 299])\n",
      "torch.Size([36, 2])\n",
      "torch.Size([2, 36])\n",
      "\n",
      "torch.Size([299, 2, 5])\n",
      "torch.Size([2, 299])\n",
      "torch.Size([36, 2])\n",
      "torch.Size([2, 36])\n",
      "\n",
      "torch.Size([299, 2, 5])\n",
      "torch.Size([2, 299])\n",
      "torch.Size([36, 2])\n",
      "torch.Size([2, 36])\n",
      "\n",
      "torch.Size([299, 2, 5])\n",
      "torch.Size([2, 299])\n",
      "torch.Size([36, 2])\n",
      "torch.Size([2, 36])\n",
      "\n",
      "torch.Size([299, 2, 5])\n",
      "torch.Size([2, 299])\n",
      "torch.Size([36, 2])\n",
      "torch.Size([2, 36])\n",
      "\n",
      "torch.Size([299, 2, 5])\n",
      "torch.Size([2, 299])\n",
      "torch.Size([36, 2])\n",
      "torch.Size([2, 36])\n",
      "\n",
      "torch.Size([299, 2, 5])\n",
      "torch.Size([2, 299])\n",
      "torch.Size([36, 2])\n",
      "torch.Size([2, 36])\n",
      "\n",
      "torch.Size([299, 2, 5])\n",
      "torch.Size([2, 299])\n",
      "torch.Size([36, 2])\n",
      "torch.Size([2, 36])\n",
      "\n",
      "torch.Size([299, 2, 5])\n",
      "torch.Size([2, 299])\n",
      "torch.Size([36, 2])\n",
      "torch.Size([2, 36])\n",
      "\n",
      "torch.Size([299, 2, 5])\n",
      "torch.Size([2, 299])\n",
      "torch.Size([36, 2])\n",
      "torch.Size([2, 36])\n",
      "\n",
      "torch.Size([299, 2, 5])\n",
      "torch.Size([2, 299])\n",
      "torch.Size([36, 2])\n",
      "torch.Size([2, 36])\n",
      "\n",
      "torch.Size([299, 2, 5])\n",
      "torch.Size([2, 299])\n",
      "torch.Size([36, 2])\n",
      "torch.Size([2, 36])\n",
      "\n",
      "torch.Size([299, 2, 5])\n",
      "torch.Size([2, 299])\n",
      "torch.Size([36, 2])\n",
      "torch.Size([2, 36])\n",
      "\n",
      "torch.Size([299, 2, 5])\n",
      "torch.Size([2, 299])\n",
      "torch.Size([36, 2])\n",
      "torch.Size([2, 36])\n",
      "\n",
      "torch.Size([299, 2, 5])\n",
      "torch.Size([2, 299])\n",
      "torch.Size([36, 2])\n",
      "torch.Size([2, 36])\n",
      "\n",
      "torch.Size([299, 2, 5])\n",
      "torch.Size([2, 299])\n",
      "torch.Size([36, 2])\n",
      "torch.Size([2, 36])\n",
      "\n",
      "torch.Size([299, 2, 5])\n",
      "torch.Size([2, 299])\n",
      "torch.Size([36, 2])\n",
      "torch.Size([2, 36])\n",
      "\n",
      "torch.Size([299, 2, 5])\n",
      "torch.Size([2, 299])\n",
      "torch.Size([36, 2])\n",
      "torch.Size([2, 36])\n",
      "\n",
      "torch.Size([299, 2, 5])\n",
      "torch.Size([2, 299])\n",
      "torch.Size([36, 2])\n",
      "torch.Size([2, 36])\n",
      "\n",
      "torch.Size([299, 2, 5])\n",
      "torch.Size([2, 299])\n",
      "torch.Size([36, 2])\n",
      "torch.Size([2, 36])\n",
      "\n",
      "torch.Size([299, 2, 5])\n",
      "torch.Size([2, 299])\n",
      "torch.Size([36, 2])\n",
      "torch.Size([2, 36])\n",
      "\n",
      "torch.Size([299, 2, 5])\n",
      "torch.Size([2, 299])\n",
      "torch.Size([36, 2])\n",
      "torch.Size([2, 36])\n",
      "\n",
      "torch.Size([299, 2, 5])\n",
      "torch.Size([2, 299])\n",
      "torch.Size([36, 2])\n",
      "torch.Size([2, 36])\n",
      "\n",
      "torch.Size([299, 2, 5])\n",
      "torch.Size([2, 299])\n",
      "torch.Size([36, 2])\n",
      "torch.Size([2, 36])\n",
      "\n",
      "torch.Size([299, 2, 5])\n",
      "torch.Size([2, 299])\n",
      "torch.Size([36, 2])\n",
      "torch.Size([2, 36])\n",
      "\n",
      "torch.Size([299, 2, 5])\n",
      "torch.Size([2, 299])\n",
      "torch.Size([36, 2])\n",
      "torch.Size([2, 36])\n",
      "\n",
      "torch.Size([299, 2, 5])\n",
      "torch.Size([2, 299])\n",
      "torch.Size([36, 2])\n",
      "torch.Size([2, 36])\n",
      "\n",
      "torch.Size([299, 2, 5])\n",
      "torch.Size([2, 299])\n",
      "torch.Size([36, 2])\n",
      "torch.Size([2, 36])\n",
      "\n",
      "torch.Size([299, 2, 5])\n",
      "torch.Size([2, 299])\n",
      "torch.Size([36, 2])\n",
      "torch.Size([2, 36])\n",
      "\n",
      "torch.Size([299, 2, 5])\n",
      "torch.Size([2, 299])\n",
      "torch.Size([36, 2])\n",
      "torch.Size([2, 36])\n",
      "\n",
      "torch.Size([299, 2, 5])\n",
      "torch.Size([2, 299])\n",
      "torch.Size([36, 2])\n",
      "torch.Size([2, 36])\n",
      "\n",
      "torch.Size([299, 2, 5])\n",
      "torch.Size([2, 299])\n",
      "torch.Size([36, 2])\n",
      "torch.Size([2, 36])\n",
      "\n",
      "torch.Size([299, 2, 5])\n",
      "torch.Size([2, 299])\n",
      "torch.Size([36, 2])\n",
      "torch.Size([2, 36])\n",
      "\n",
      "torch.Size([299, 2, 5])\n",
      "torch.Size([2, 299])\n",
      "torch.Size([36, 2])\n",
      "torch.Size([2, 36])\n",
      "\n",
      "torch.Size([299, 2, 5])\n",
      "torch.Size([2, 299])\n",
      "torch.Size([36, 2])\n",
      "torch.Size([2, 36])\n",
      "\n",
      "torch.Size([299, 2, 5])\n",
      "torch.Size([2, 299])\n",
      "torch.Size([36, 2])\n",
      "torch.Size([2, 36])\n",
      "\n",
      "torch.Size([299, 2, 5])\n",
      "torch.Size([2, 299])\n",
      "torch.Size([36, 2])\n",
      "torch.Size([2, 36])\n",
      "\n",
      "torch.Size([299, 2, 5])\n",
      "torch.Size([2, 299])\n",
      "torch.Size([36, 2])\n",
      "torch.Size([2, 36])\n",
      "\n",
      "torch.Size([299, 2, 5])\n",
      "torch.Size([2, 299])\n",
      "torch.Size([36, 2])\n",
      "torch.Size([2, 36])\n",
      "\n",
      "torch.Size([299, 2, 5])\n",
      "torch.Size([2, 299])\n",
      "torch.Size([36, 2])\n",
      "torch.Size([2, 36])\n",
      "\n",
      "torch.Size([299, 2, 5])\n",
      "torch.Size([2, 299])\n",
      "torch.Size([36, 2])\n",
      "torch.Size([2, 36])\n",
      "\n",
      "torch.Size([299, 2, 5])\n",
      "torch.Size([2, 299])\n",
      "torch.Size([36, 2])\n",
      "torch.Size([2, 36])\n",
      "\n",
      "torch.Size([299, 2, 5])\n",
      "torch.Size([2, 299])\n",
      "torch.Size([36, 2])\n",
      "torch.Size([2, 36])\n",
      "\n",
      "torch.Size([299, 2, 5])\n",
      "torch.Size([2, 299])\n",
      "torch.Size([36, 2])\n",
      "torch.Size([2, 36])\n",
      "\n",
      "torch.Size([299, 2, 5])\n",
      "torch.Size([2, 299])\n",
      "torch.Size([36, 2])\n",
      "torch.Size([2, 36])\n",
      "\n",
      "torch.Size([299, 2, 5])\n",
      "torch.Size([2, 299])\n",
      "torch.Size([36, 2])\n",
      "torch.Size([2, 36])\n",
      "\n",
      "torch.Size([299, 2, 5])\n",
      "torch.Size([2, 299])\n",
      "torch.Size([36, 2])\n",
      "torch.Size([2, 36])\n",
      "\n",
      "torch.Size([299, 2, 5])\n",
      "torch.Size([2, 299])\n",
      "torch.Size([36, 2])\n",
      "torch.Size([2, 36])\n",
      "\n",
      "torch.Size([299, 2, 5])\n",
      "torch.Size([2, 299])\n",
      "torch.Size([36, 2])\n",
      "torch.Size([2, 36])\n",
      "\n",
      "torch.Size([299, 2, 5])\n",
      "torch.Size([2, 299])\n",
      "torch.Size([36, 2])\n",
      "torch.Size([2, 36])\n",
      "\n",
      "torch.Size([299, 2, 5])\n",
      "torch.Size([2, 299])\n",
      "torch.Size([36, 2])\n",
      "torch.Size([2, 36])\n",
      "\n",
      "torch.Size([299, 2, 5])\n",
      "torch.Size([2, 299])\n",
      "torch.Size([36, 2])\n",
      "torch.Size([2, 36])\n",
      "\n",
      "torch.Size([299, 2, 5])\n",
      "torch.Size([2, 299])\n",
      "torch.Size([36, 2])\n",
      "torch.Size([2, 36])\n",
      "\n",
      "torch.Size([299, 2, 5])\n",
      "torch.Size([2, 299])\n",
      "torch.Size([36, 2])\n",
      "torch.Size([2, 36])\n",
      "\n",
      "torch.Size([299, 2, 5])\n",
      "torch.Size([2, 299])\n",
      "torch.Size([36, 2])\n",
      "torch.Size([2, 36])\n",
      "\n",
      "torch.Size([299, 2, 5])\n",
      "torch.Size([2, 299])\n",
      "torch.Size([36, 2])\n",
      "torch.Size([2, 36])\n",
      "\n",
      "torch.Size([299, 2, 5])\n",
      "torch.Size([2, 299])\n",
      "torch.Size([36, 2])\n",
      "torch.Size([2, 36])\n",
      "\n",
      "torch.Size([299, 2, 5])\n",
      "torch.Size([2, 299])\n",
      "torch.Size([36, 2])\n",
      "torch.Size([2, 36])\n",
      "\n",
      "torch.Size([299, 2, 5])\n",
      "torch.Size([2, 299])\n",
      "torch.Size([36, 2])\n",
      "torch.Size([2, 36])\n",
      "\n",
      "torch.Size([299, 2, 5])\n",
      "torch.Size([2, 299])\n",
      "torch.Size([36, 2])\n",
      "torch.Size([2, 36])\n",
      "\n",
      "torch.Size([299, 2, 5])\n",
      "torch.Size([2, 299])\n",
      "torch.Size([36, 2])\n",
      "torch.Size([2, 36])\n",
      "\n",
      "torch.Size([299, 2, 5])\n",
      "torch.Size([2, 299])\n",
      "torch.Size([36, 2])\n",
      "torch.Size([2, 36])\n",
      "\n",
      "torch.Size([299, 2, 5])\n",
      "torch.Size([2, 299])\n",
      "torch.Size([36, 2])\n",
      "torch.Size([2, 36])\n",
      "\n",
      "torch.Size([299, 2, 5])\n",
      "torch.Size([2, 299])\n",
      "torch.Size([36, 2])\n",
      "torch.Size([2, 36])\n",
      "\n",
      "torch.Size([299, 2, 5])\n",
      "torch.Size([2, 299])\n",
      "torch.Size([36, 2])\n",
      "torch.Size([2, 36])\n",
      "\n",
      "torch.Size([299, 2, 5])\n",
      "torch.Size([2, 299])\n",
      "torch.Size([36, 2])\n",
      "torch.Size([2, 36])\n",
      "\n",
      "torch.Size([299, 2, 5])\n",
      "torch.Size([2, 299])\n",
      "torch.Size([36, 2])\n",
      "torch.Size([2, 36])\n",
      "\n",
      "torch.Size([299, 2, 5])\n",
      "torch.Size([2, 299])\n",
      "torch.Size([36, 2])\n",
      "torch.Size([2, 36])\n",
      "\n",
      "torch.Size([299, 2, 5])\n",
      "torch.Size([2, 299])\n",
      "torch.Size([36, 2])\n",
      "torch.Size([2, 36])\n",
      "\n",
      "torch.Size([299, 2, 5])\n",
      "torch.Size([2, 299])\n",
      "torch.Size([36, 2])\n",
      "torch.Size([2, 36])\n",
      "\n",
      "torch.Size([299, 2, 5])\n",
      "torch.Size([2, 299])\n",
      "torch.Size([36, 2])\n",
      "torch.Size([2, 36])\n",
      "\n",
      "torch.Size([299, 2, 5])\n",
      "torch.Size([2, 299])\n",
      "torch.Size([36, 2])\n",
      "torch.Size([2, 36])\n",
      "\n",
      "torch.Size([299, 2, 5])\n",
      "torch.Size([2, 299])\n",
      "torch.Size([36, 2])\n",
      "torch.Size([2, 36])\n",
      "\n",
      "torch.Size([299, 2, 5])\n",
      "torch.Size([2, 299])\n",
      "torch.Size([36, 2])\n",
      "torch.Size([2, 36])\n",
      "\n",
      "torch.Size([299, 2, 5])\n",
      "torch.Size([2, 299])\n",
      "torch.Size([36, 2])\n",
      "torch.Size([2, 36])\n",
      "\n",
      "torch.Size([299, 2, 5])\n",
      "torch.Size([2, 299])\n",
      "torch.Size([36, 2])\n",
      "torch.Size([2, 36])\n",
      "\n",
      "torch.Size([299, 2, 5])\n",
      "torch.Size([2, 299])\n",
      "torch.Size([36, 2])\n",
      "torch.Size([2, 36])\n",
      "\n",
      "torch.Size([299, 2, 5])\n",
      "torch.Size([2, 299])\n",
      "torch.Size([36, 2])\n",
      "torch.Size([2, 36])\n",
      "\n",
      "torch.Size([299, 2, 5])\n",
      "torch.Size([2, 299])\n",
      "torch.Size([36, 2])\n",
      "torch.Size([2, 36])\n",
      "\n",
      "torch.Size([299, 2, 5])\n",
      "torch.Size([2, 299])\n",
      "torch.Size([36, 2])\n",
      "torch.Size([2, 36])\n",
      "\n",
      "torch.Size([299, 2, 5])\n",
      "torch.Size([2, 299])\n",
      "torch.Size([36, 2])\n",
      "torch.Size([2, 36])\n",
      "\n",
      "torch.Size([299, 2, 5])\n",
      "torch.Size([2, 299])\n",
      "torch.Size([36, 2])\n",
      "torch.Size([2, 36])\n",
      "\n",
      "torch.Size([299, 2, 5])\n",
      "torch.Size([2, 299])\n",
      "torch.Size([36, 2])\n",
      "torch.Size([2, 36])\n",
      "\n",
      "torch.Size([299, 2, 5])\n",
      "torch.Size([2, 299])\n",
      "torch.Size([36, 2])\n",
      "torch.Size([2, 36])\n",
      "\n",
      "torch.Size([299, 2, 5])\n",
      "torch.Size([2, 299])\n",
      "torch.Size([36, 2])\n",
      "torch.Size([2, 36])\n",
      "\n",
      "torch.Size([299, 2, 5])\n",
      "torch.Size([2, 299])\n",
      "torch.Size([36, 2])\n",
      "torch.Size([2, 36])\n",
      "\n",
      "torch.Size([299, 2, 5])\n",
      "torch.Size([2, 299])\n",
      "torch.Size([36, 2])\n",
      "torch.Size([2, 36])\n",
      "\n",
      "torch.Size([299, 2, 5])\n",
      "torch.Size([2, 299])\n",
      "torch.Size([36, 2])\n",
      "torch.Size([2, 36])\n",
      "\n",
      "torch.Size([299, 2, 5])\n",
      "torch.Size([2, 299])\n",
      "torch.Size([36, 2])\n",
      "torch.Size([2, 36])\n",
      "\n",
      "torch.Size([299, 2, 5])\n",
      "torch.Size([2, 299])\n",
      "torch.Size([36, 2])\n",
      "torch.Size([2, 36])\n",
      "\n",
      "torch.Size([299, 2, 5])\n",
      "torch.Size([2, 299])\n",
      "torch.Size([36, 2])\n",
      "torch.Size([2, 36])\n",
      "\n",
      "torch.Size([299, 2, 5])\n",
      "torch.Size([2, 299])\n",
      "torch.Size([36, 2])\n",
      "torch.Size([2, 36])\n",
      "\n",
      "torch.Size([299, 2, 5])\n",
      "torch.Size([2, 299])\n",
      "torch.Size([36, 2])\n",
      "torch.Size([2, 36])\n",
      "\n",
      "torch.Size([299, 2, 5])\n",
      "torch.Size([2, 299])\n",
      "torch.Size([36, 2])\n",
      "torch.Size([2, 36])\n",
      "\n",
      "torch.Size([299, 2, 5])\n",
      "torch.Size([2, 299])\n",
      "torch.Size([36, 2])\n",
      "torch.Size([2, 36])\n",
      "\n",
      "torch.Size([299, 2, 5])\n",
      "torch.Size([2, 299])\n",
      "torch.Size([36, 2])\n",
      "torch.Size([2, 36])\n",
      "\n",
      "torch.Size([299, 2, 5])\n",
      "torch.Size([2, 299])\n",
      "torch.Size([36, 2])\n",
      "torch.Size([2, 36])\n",
      "\n",
      "torch.Size([299, 2, 5])\n",
      "torch.Size([2, 299])\n",
      "torch.Size([36, 2])\n",
      "torch.Size([2, 36])\n",
      "\n",
      "torch.Size([299, 2, 5])\n",
      "torch.Size([2, 299])\n",
      "torch.Size([36, 2])\n",
      "torch.Size([2, 36])\n",
      "\n",
      "torch.Size([299, 2, 5])\n",
      "torch.Size([2, 299])\n",
      "torch.Size([36, 2])\n",
      "torch.Size([2, 36])\n",
      "\n",
      "torch.Size([299, 2, 5])\n",
      "torch.Size([2, 299])\n",
      "torch.Size([36, 2])\n",
      "torch.Size([2, 36])\n",
      "\n",
      "torch.Size([299, 2, 5])\n",
      "torch.Size([2, 299])\n",
      "torch.Size([36, 2])\n",
      "torch.Size([2, 36])\n",
      "\n",
      "torch.Size([299, 2, 5])\n",
      "torch.Size([2, 299])\n",
      "torch.Size([36, 2])\n",
      "torch.Size([2, 36])\n",
      "\n",
      "torch.Size([299, 2, 5])\n",
      "torch.Size([2, 299])\n",
      "torch.Size([36, 2])\n",
      "torch.Size([2, 36])\n",
      "\n",
      "torch.Size([299, 2, 5])\n",
      "torch.Size([2, 299])\n",
      "torch.Size([36, 2])\n",
      "torch.Size([2, 36])\n",
      "\n",
      "torch.Size([299, 2, 5])\n",
      "torch.Size([2, 299])\n",
      "torch.Size([36, 2])\n",
      "torch.Size([2, 36])\n",
      "\n",
      "torch.Size([299, 2, 5])\n",
      "torch.Size([2, 299])\n",
      "torch.Size([36, 2])\n",
      "torch.Size([2, 36])\n",
      "\n",
      "torch.Size([299, 2, 5])\n",
      "torch.Size([2, 299])\n",
      "torch.Size([36, 2])\n",
      "torch.Size([2, 36])\n",
      "\n",
      "torch.Size([299, 2, 5])\n",
      "torch.Size([2, 299])\n",
      "torch.Size([36, 2])\n",
      "torch.Size([2, 36])\n",
      "\n",
      "torch.Size([299, 2, 5])\n",
      "torch.Size([2, 299])\n",
      "torch.Size([36, 2])\n",
      "torch.Size([2, 36])\n",
      "\n",
      "torch.Size([299, 2, 5])\n",
      "torch.Size([2, 299])\n",
      "torch.Size([36, 2])\n",
      "torch.Size([2, 36])\n",
      "\n",
      "torch.Size([299, 2, 5])\n",
      "torch.Size([2, 299])\n",
      "torch.Size([36, 2])\n",
      "torch.Size([2, 36])\n",
      "\n",
      "torch.Size([299, 2, 5])\n",
      "torch.Size([2, 299])\n",
      "torch.Size([36, 2])\n",
      "torch.Size([2, 36])\n",
      "\n",
      "torch.Size([299, 2, 5])\n",
      "torch.Size([2, 299])\n",
      "torch.Size([36, 2])\n",
      "torch.Size([2, 36])\n",
      "\n",
      "torch.Size([299, 2, 5])\n",
      "torch.Size([2, 299])\n",
      "torch.Size([36, 2])\n",
      "torch.Size([2, 36])\n",
      "\n",
      "torch.Size([299, 2, 5])\n",
      "torch.Size([2, 299])\n",
      "torch.Size([36, 2])\n",
      "torch.Size([2, 36])\n",
      "\n",
      "torch.Size([299, 2, 5])\n",
      "torch.Size([2, 299])\n",
      "torch.Size([36, 2])\n",
      "torch.Size([2, 36])\n",
      "\n",
      "torch.Size([299, 2, 5])\n",
      "torch.Size([2, 299])\n",
      "torch.Size([36, 2])\n",
      "torch.Size([2, 36])\n",
      "\n",
      "torch.Size([299, 2, 5])\n",
      "torch.Size([2, 299])\n",
      "torch.Size([36, 2])\n",
      "torch.Size([2, 36])\n",
      "\n",
      "torch.Size([299, 2, 5])\n",
      "torch.Size([2, 299])\n",
      "torch.Size([36, 2])\n",
      "torch.Size([2, 36])\n",
      "\n",
      "torch.Size([299, 2, 5])\n",
      "torch.Size([2, 299])\n",
      "torch.Size([36, 2])\n",
      "torch.Size([2, 36])\n",
      "\n",
      "torch.Size([299, 2, 5])\n",
      "torch.Size([2, 299])\n",
      "torch.Size([36, 2])\n",
      "torch.Size([2, 36])\n",
      "\n",
      "torch.Size([299, 2, 5])\n",
      "torch.Size([2, 299])\n",
      "torch.Size([36, 2])\n",
      "torch.Size([2, 36])\n",
      "\n",
      "torch.Size([299, 2, 5])\n",
      "torch.Size([2, 299])\n",
      "torch.Size([36, 2])\n",
      "torch.Size([2, 36])\n",
      "\n",
      "torch.Size([299, 2, 5])\n",
      "torch.Size([2, 299])\n",
      "torch.Size([36, 2])\n",
      "torch.Size([2, 36])\n",
      "\n",
      "torch.Size([299, 2, 5])\n",
      "torch.Size([2, 299])\n",
      "torch.Size([36, 2])\n",
      "torch.Size([2, 36])\n",
      "\n",
      "torch.Size([299, 2, 5])\n",
      "torch.Size([2, 299])\n",
      "torch.Size([36, 2])\n",
      "torch.Size([2, 36])\n",
      "\n",
      "torch.Size([299, 2, 5])\n",
      "torch.Size([2, 299])\n",
      "torch.Size([36, 2])\n",
      "torch.Size([2, 36])\n",
      "\n",
      "torch.Size([299, 2, 5])\n",
      "torch.Size([2, 299])\n",
      "torch.Size([36, 2])\n",
      "torch.Size([2, 36])\n",
      "\n",
      "torch.Size([299, 2, 5])\n",
      "torch.Size([2, 299])\n",
      "torch.Size([36, 2])\n",
      "torch.Size([2, 36])\n",
      "\n",
      "torch.Size([299, 2, 5])\n",
      "torch.Size([2, 299])\n",
      "torch.Size([36, 2])\n",
      "torch.Size([2, 36])\n",
      "\n",
      "torch.Size([299, 2, 5])\n",
      "torch.Size([2, 299])\n",
      "torch.Size([36, 2])\n",
      "torch.Size([2, 36])\n",
      "\n",
      "torch.Size([299, 2, 5])\n",
      "torch.Size([2, 299])\n",
      "torch.Size([36, 2])\n",
      "torch.Size([2, 36])\n",
      "\n",
      "torch.Size([299, 2, 5])\n",
      "torch.Size([2, 299])\n",
      "torch.Size([36, 2])\n",
      "torch.Size([2, 36])\n",
      "\n",
      "torch.Size([299, 2, 5])\n",
      "torch.Size([2, 299])\n",
      "torch.Size([36, 2])\n",
      "torch.Size([2, 36])\n",
      "\n",
      "torch.Size([299, 2, 5])\n",
      "torch.Size([2, 299])\n",
      "torch.Size([36, 2])\n",
      "torch.Size([2, 36])\n",
      "\n",
      "torch.Size([299, 2, 5])\n",
      "torch.Size([2, 299])\n",
      "torch.Size([36, 2])\n",
      "torch.Size([2, 36])\n",
      "\n",
      "torch.Size([299, 2, 5])\n",
      "torch.Size([2, 299])\n",
      "torch.Size([36, 2])\n",
      "torch.Size([2, 36])\n",
      "\n",
      "torch.Size([299, 2, 5])\n",
      "torch.Size([2, 299])\n",
      "torch.Size([36, 2])\n",
      "torch.Size([2, 36])\n",
      "\n",
      "torch.Size([299, 2, 5])\n",
      "torch.Size([2, 299])\n",
      "torch.Size([36, 2])\n",
      "torch.Size([2, 36])\n",
      "\n",
      "torch.Size([299, 2, 5])\n",
      "torch.Size([2, 299])\n",
      "torch.Size([36, 2])\n",
      "torch.Size([2, 36])\n",
      "\n",
      "torch.Size([299, 2, 5])\n",
      "torch.Size([2, 299])\n",
      "torch.Size([36, 2])\n",
      "torch.Size([2, 36])\n",
      "\n",
      "torch.Size([299, 2, 5])\n",
      "torch.Size([2, 299])\n",
      "torch.Size([36, 2])\n",
      "torch.Size([2, 36])\n",
      "\n",
      "torch.Size([299, 2, 5])\n",
      "torch.Size([2, 299])\n",
      "torch.Size([36, 2])\n",
      "torch.Size([2, 36])\n",
      "\n",
      "torch.Size([299, 2, 5])\n",
      "torch.Size([2, 299])\n",
      "torch.Size([36, 2])\n",
      "torch.Size([2, 36])\n",
      "\n",
      "torch.Size([299, 2, 5])\n",
      "torch.Size([2, 299])\n",
      "torch.Size([36, 2])\n",
      "torch.Size([2, 36])\n",
      "\n",
      "torch.Size([299, 2, 5])\n",
      "torch.Size([2, 299])\n",
      "torch.Size([36, 2])\n",
      "torch.Size([2, 36])\n",
      "\n",
      "torch.Size([299, 2, 5])\n",
      "torch.Size([2, 299])\n",
      "torch.Size([36, 2])\n",
      "torch.Size([2, 36])\n",
      "\n",
      "torch.Size([299, 2, 5])\n",
      "torch.Size([2, 299])\n",
      "torch.Size([36, 2])\n",
      "torch.Size([2, 36])\n",
      "\n",
      "torch.Size([299, 2, 5])\n",
      "torch.Size([2, 299])\n",
      "torch.Size([36, 2])\n",
      "torch.Size([2, 36])\n",
      "\n",
      "torch.Size([299, 2, 5])\n",
      "torch.Size([2, 299])\n",
      "torch.Size([36, 2])\n",
      "torch.Size([2, 36])\n",
      "\n",
      "torch.Size([299, 2, 5])\n",
      "torch.Size([2, 299])\n",
      "torch.Size([36, 2])\n",
      "torch.Size([2, 36])\n",
      "\n",
      "torch.Size([299, 2, 5])\n",
      "torch.Size([2, 299])\n",
      "torch.Size([36, 2])\n",
      "torch.Size([2, 36])\n",
      "\n",
      "torch.Size([299, 2, 5])\n",
      "torch.Size([2, 299])\n",
      "torch.Size([36, 2])\n",
      "torch.Size([2, 36])\n",
      "\n",
      "torch.Size([299, 2, 5])\n",
      "torch.Size([2, 299])\n",
      "torch.Size([36, 2])\n",
      "torch.Size([2, 36])\n",
      "\n",
      "torch.Size([299, 2, 5])\n",
      "torch.Size([2, 299])\n",
      "torch.Size([36, 2])\n",
      "torch.Size([2, 36])\n",
      "\n",
      "torch.Size([299, 2, 5])\n",
      "torch.Size([2, 299])\n",
      "torch.Size([36, 2])\n",
      "torch.Size([2, 36])\n",
      "\n",
      "torch.Size([299, 2, 5])\n",
      "torch.Size([2, 299])\n",
      "torch.Size([36, 2])\n",
      "torch.Size([2, 36])\n",
      "\n",
      "torch.Size([299, 2, 5])\n",
      "torch.Size([2, 299])\n",
      "torch.Size([36, 2])\n",
      "torch.Size([2, 36])\n",
      "\n",
      "torch.Size([299, 2, 5])\n",
      "torch.Size([2, 299])\n",
      "torch.Size([36, 2])\n",
      "torch.Size([2, 36])\n",
      "\n",
      "torch.Size([299, 2, 5])\n",
      "torch.Size([2, 299])\n",
      "torch.Size([36, 2])\n",
      "torch.Size([2, 36])\n",
      "\n",
      "torch.Size([299, 2, 5])\n",
      "torch.Size([2, 299])\n",
      "torch.Size([36, 2])\n",
      "torch.Size([2, 36])\n",
      "\n",
      "torch.Size([299, 2, 5])\n",
      "torch.Size([2, 299])\n",
      "torch.Size([36, 2])\n",
      "torch.Size([2, 36])\n",
      "\n",
      "torch.Size([299, 2, 5])\n",
      "torch.Size([2, 299])\n",
      "torch.Size([36, 2])\n",
      "torch.Size([2, 36])\n",
      "\n",
      "torch.Size([299, 2, 5])\n",
      "torch.Size([2, 299])\n",
      "torch.Size([36, 2])\n",
      "torch.Size([2, 36])\n",
      "\n",
      "torch.Size([299, 2, 5])\n",
      "torch.Size([2, 299])\n",
      "torch.Size([36, 2])\n",
      "torch.Size([2, 36])\n",
      "\n",
      "torch.Size([299, 2, 5])\n",
      "torch.Size([2, 299])\n",
      "torch.Size([36, 2])\n",
      "torch.Size([2, 36])\n",
      "\n",
      "torch.Size([299, 2, 5])\n",
      "torch.Size([2, 299])\n",
      "torch.Size([36, 2])\n",
      "torch.Size([2, 36])\n",
      "\n",
      "torch.Size([299, 2, 5])\n",
      "torch.Size([2, 299])\n",
      "torch.Size([36, 2])\n",
      "torch.Size([2, 36])\n",
      "\n",
      "torch.Size([299, 2, 5])\n",
      "torch.Size([2, 299])\n",
      "torch.Size([36, 2])\n",
      "torch.Size([2, 36])\n",
      "\n",
      "torch.Size([299, 2, 5])\n",
      "torch.Size([2, 299])\n",
      "torch.Size([36, 2])\n",
      "torch.Size([2, 36])\n",
      "\n",
      "torch.Size([299, 2, 5])\n",
      "torch.Size([2, 299])\n",
      "torch.Size([36, 2])\n",
      "torch.Size([2, 36])\n",
      "\n",
      "torch.Size([299, 2, 5])\n",
      "torch.Size([2, 299])\n",
      "torch.Size([36, 2])\n",
      "torch.Size([2, 36])\n",
      "\n",
      "torch.Size([299, 2, 5])\n",
      "torch.Size([2, 299])\n",
      "torch.Size([36, 2])\n",
      "torch.Size([2, 36])\n",
      "\n",
      "torch.Size([299, 2, 5])\n",
      "torch.Size([2, 299])\n",
      "torch.Size([36, 2])\n",
      "torch.Size([2, 36])\n",
      "\n",
      "torch.Size([299, 2, 5])\n",
      "torch.Size([2, 299])\n",
      "torch.Size([36, 2])\n",
      "torch.Size([2, 36])\n",
      "\n",
      "torch.Size([299, 2, 5])\n",
      "torch.Size([2, 299])\n",
      "torch.Size([36, 2])\n",
      "torch.Size([2, 36])\n",
      "\n",
      "torch.Size([299, 2, 5])\n",
      "torch.Size([2, 299])\n",
      "torch.Size([36, 2])\n",
      "torch.Size([2, 36])\n",
      "\n",
      "torch.Size([299, 2, 5])\n",
      "torch.Size([2, 299])\n",
      "torch.Size([36, 2])\n",
      "torch.Size([2, 36])\n",
      "\n",
      "torch.Size([299, 2, 5])\n",
      "torch.Size([2, 299])\n",
      "torch.Size([36, 2])\n",
      "torch.Size([2, 36])\n",
      "\n",
      "torch.Size([299, 2, 5])\n",
      "torch.Size([2, 299])\n",
      "torch.Size([36, 2])\n",
      "torch.Size([2, 36])\n",
      "\n",
      "torch.Size([299, 2, 5])\n",
      "torch.Size([2, 299])\n",
      "torch.Size([36, 2])\n",
      "torch.Size([2, 36])\n",
      "\n",
      "torch.Size([299, 2, 5])\n",
      "torch.Size([2, 299])\n",
      "torch.Size([36, 2])\n",
      "torch.Size([2, 36])\n",
      "\n",
      "torch.Size([299, 2, 5])\n",
      "torch.Size([2, 299])\n",
      "torch.Size([36, 2])\n",
      "torch.Size([2, 36])\n",
      "\n",
      "torch.Size([299, 2, 5])\n",
      "torch.Size([2, 299])\n",
      "torch.Size([36, 2])\n",
      "torch.Size([2, 36])\n",
      "\n",
      "torch.Size([299, 2, 5])\n",
      "torch.Size([2, 299])\n",
      "torch.Size([36, 2])\n",
      "torch.Size([2, 36])\n",
      "\n",
      "torch.Size([299, 2, 5])\n",
      "torch.Size([2, 299])\n",
      "torch.Size([36, 2])\n",
      "torch.Size([2, 36])\n",
      "\n",
      "torch.Size([299, 2, 5])\n",
      "torch.Size([2, 299])\n",
      "torch.Size([36, 2])\n",
      "torch.Size([2, 36])\n",
      "\n",
      "torch.Size([299, 2, 5])\n",
      "torch.Size([2, 299])\n",
      "torch.Size([36, 2])\n",
      "torch.Size([2, 36])\n",
      "\n",
      "torch.Size([299, 2, 5])\n",
      "torch.Size([2, 299])\n",
      "torch.Size([36, 2])\n",
      "torch.Size([2, 36])\n",
      "\n",
      "torch.Size([299, 2, 5])\n",
      "torch.Size([2, 299])\n",
      "torch.Size([36, 2])\n",
      "torch.Size([2, 36])\n",
      "\n",
      "torch.Size([299, 2, 5])\n",
      "torch.Size([2, 299])\n",
      "torch.Size([36, 2])\n",
      "torch.Size([2, 36])\n",
      "\n",
      "torch.Size([299, 2, 5])\n",
      "torch.Size([2, 299])\n",
      "torch.Size([36, 2])\n",
      "torch.Size([2, 36])\n",
      "\n",
      "torch.Size([299, 2, 5])\n",
      "torch.Size([2, 299])\n",
      "torch.Size([36, 2])\n",
      "torch.Size([2, 36])\n",
      "\n",
      "torch.Size([299, 2, 5])\n",
      "torch.Size([2, 299])\n",
      "torch.Size([36, 2])\n",
      "torch.Size([2, 36])\n",
      "\n",
      "torch.Size([299, 2, 5])\n",
      "torch.Size([2, 299])\n",
      "torch.Size([36, 2])\n",
      "torch.Size([2, 36])\n",
      "\n",
      "torch.Size([299, 2, 5])\n",
      "torch.Size([2, 299])\n",
      "torch.Size([36, 2])\n",
      "torch.Size([2, 36])\n",
      "\n",
      "torch.Size([299, 2, 5])\n",
      "torch.Size([2, 299])\n",
      "torch.Size([36, 2])\n",
      "torch.Size([2, 36])\n",
      "\n",
      "torch.Size([299, 2, 5])\n",
      "torch.Size([2, 299])\n",
      "torch.Size([36, 2])\n",
      "torch.Size([2, 36])\n",
      "\n",
      "torch.Size([299, 2, 5])\n",
      "torch.Size([2, 299])\n",
      "torch.Size([36, 2])\n",
      "torch.Size([2, 36])\n",
      "\n",
      "torch.Size([299, 2, 5])\n",
      "torch.Size([2, 299])\n",
      "torch.Size([36, 2])\n",
      "torch.Size([2, 36])\n",
      "\n",
      "torch.Size([299, 2, 5])\n",
      "torch.Size([2, 299])\n",
      "torch.Size([36, 2])\n",
      "torch.Size([2, 36])\n",
      "\n",
      "torch.Size([299, 2, 5])\n",
      "torch.Size([2, 299])\n",
      "torch.Size([36, 2])\n",
      "torch.Size([2, 36])\n",
      "\n",
      "torch.Size([299, 2, 5])\n",
      "torch.Size([2, 299])\n",
      "torch.Size([36, 2])\n",
      "torch.Size([2, 36])\n",
      "\n",
      "torch.Size([299, 2, 5])\n",
      "torch.Size([2, 299])\n",
      "torch.Size([36, 2])\n",
      "torch.Size([2, 36])\n",
      "\n",
      "torch.Size([299, 2, 5])\n",
      "torch.Size([2, 299])\n",
      "torch.Size([36, 2])\n",
      "torch.Size([2, 36])\n",
      "\n",
      "torch.Size([299, 2, 5])\n",
      "torch.Size([2, 299])\n",
      "torch.Size([36, 2])\n",
      "torch.Size([2, 36])\n",
      "\n",
      "torch.Size([299, 2, 5])\n",
      "torch.Size([2, 299])\n",
      "torch.Size([36, 2])\n",
      "torch.Size([2, 36])\n",
      "\n",
      "torch.Size([299, 2, 5])\n",
      "torch.Size([2, 299])\n",
      "torch.Size([36, 2])\n",
      "torch.Size([2, 36])\n",
      "\n",
      "torch.Size([299, 2, 5])\n",
      "torch.Size([2, 299])\n",
      "torch.Size([36, 2])\n",
      "torch.Size([2, 36])\n",
      "\n",
      "torch.Size([299, 2, 5])\n",
      "torch.Size([2, 299])\n",
      "torch.Size([36, 2])\n",
      "torch.Size([2, 36])\n",
      "\n",
      "torch.Size([299, 2, 5])\n",
      "torch.Size([2, 299])\n",
      "torch.Size([36, 2])\n",
      "torch.Size([2, 36])\n",
      "\n",
      "torch.Size([299, 2, 5])\n",
      "torch.Size([2, 299])\n",
      "torch.Size([36, 2])\n",
      "torch.Size([2, 36])\n",
      "\n",
      "torch.Size([299, 2, 5])\n",
      "torch.Size([2, 299])\n",
      "torch.Size([36, 2])\n",
      "torch.Size([2, 36])\n",
      "\n",
      "torch.Size([299, 2, 5])\n",
      "torch.Size([2, 299])\n",
      "torch.Size([36, 2])\n",
      "torch.Size([2, 36])\n",
      "\n",
      "torch.Size([299, 2, 5])\n",
      "torch.Size([2, 299])\n",
      "torch.Size([36, 2])\n",
      "torch.Size([2, 36])\n",
      "\n",
      "torch.Size([299, 2, 5])\n",
      "torch.Size([2, 299])\n",
      "torch.Size([36, 2])\n",
      "torch.Size([2, 36])\n",
      "\n",
      "torch.Size([299, 2, 5])\n",
      "torch.Size([2, 299])\n",
      "torch.Size([36, 2])\n",
      "torch.Size([2, 36])\n",
      "\n",
      "torch.Size([299, 2, 5])\n",
      "torch.Size([2, 299])\n",
      "torch.Size([36, 2])\n",
      "torch.Size([2, 36])\n",
      "\n",
      "torch.Size([299, 2, 5])\n",
      "torch.Size([2, 299])\n",
      "torch.Size([36, 2])\n",
      "torch.Size([2, 36])\n",
      "\n",
      "torch.Size([299, 2, 5])\n",
      "torch.Size([2, 299])\n",
      "torch.Size([36, 2])\n",
      "torch.Size([2, 36])\n",
      "\n",
      "torch.Size([299, 2, 5])\n",
      "torch.Size([2, 299])\n",
      "torch.Size([36, 2])\n",
      "torch.Size([2, 36])\n",
      "\n",
      "torch.Size([299, 2, 5])\n",
      "torch.Size([2, 299])\n",
      "torch.Size([36, 2])\n",
      "torch.Size([2, 36])\n",
      "\n",
      "torch.Size([299, 2, 5])\n",
      "torch.Size([2, 299])\n",
      "torch.Size([36, 2])\n",
      "torch.Size([2, 36])\n",
      "\n",
      "torch.Size([299, 2, 5])\n",
      "torch.Size([2, 299])\n",
      "torch.Size([36, 2])\n",
      "torch.Size([2, 36])\n",
      "\n",
      "torch.Size([299, 2, 5])\n",
      "torch.Size([2, 299])\n",
      "torch.Size([36, 2])\n",
      "torch.Size([2, 36])\n",
      "\n",
      "torch.Size([299, 2, 5])\n",
      "torch.Size([2, 299])\n",
      "torch.Size([36, 2])\n",
      "torch.Size([2, 36])\n",
      "\n",
      "torch.Size([299, 2, 5])\n",
      "torch.Size([2, 299])\n",
      "torch.Size([36, 2])\n",
      "torch.Size([2, 36])\n",
      "\n",
      "torch.Size([299, 2, 5])\n",
      "torch.Size([2, 299])\n",
      "torch.Size([36, 2])\n",
      "torch.Size([2, 36])\n",
      "\n",
      "torch.Size([299, 2, 5])\n",
      "torch.Size([2, 299])\n",
      "torch.Size([36, 2])\n",
      "torch.Size([2, 36])\n",
      "\n",
      "torch.Size([299, 2, 5])\n",
      "torch.Size([2, 299])\n",
      "torch.Size([36, 2])\n",
      "torch.Size([2, 36])\n",
      "\n",
      "torch.Size([299, 2, 5])\n",
      "torch.Size([2, 299])\n",
      "torch.Size([36, 2])\n",
      "torch.Size([2, 36])\n",
      "\n",
      "torch.Size([299, 2, 5])\n",
      "torch.Size([2, 299])\n",
      "torch.Size([36, 2])\n",
      "torch.Size([2, 36])\n",
      "\n",
      "torch.Size([299, 2, 5])\n",
      "torch.Size([2, 299])\n",
      "torch.Size([36, 2])\n",
      "torch.Size([2, 36])\n",
      "\n",
      "torch.Size([299, 2, 5])\n",
      "torch.Size([2, 299])\n",
      "torch.Size([36, 2])\n",
      "torch.Size([2, 36])\n",
      "\n",
      "torch.Size([299, 2, 5])\n",
      "torch.Size([2, 299])\n",
      "torch.Size([36, 2])\n",
      "torch.Size([2, 36])\n",
      "\n",
      "torch.Size([299, 2, 5])\n",
      "torch.Size([2, 299])\n",
      "torch.Size([36, 2])\n",
      "torch.Size([2, 36])\n",
      "\n",
      "torch.Size([299, 2, 5])\n",
      "torch.Size([2, 299])\n",
      "torch.Size([36, 2])\n",
      "torch.Size([2, 36])\n",
      "\n",
      "torch.Size([299, 2, 5])\n",
      "torch.Size([2, 299])\n",
      "torch.Size([36, 2])\n",
      "torch.Size([2, 36])\n",
      "\n",
      "torch.Size([299, 2, 5])\n",
      "torch.Size([2, 299])\n",
      "torch.Size([36, 2])\n",
      "torch.Size([2, 36])\n",
      "\n",
      "torch.Size([299, 2, 5])\n",
      "torch.Size([2, 299])\n",
      "torch.Size([36, 2])\n",
      "torch.Size([2, 36])\n",
      "\n",
      "torch.Size([299, 2, 5])\n",
      "torch.Size([2, 299])\n",
      "torch.Size([36, 2])\n",
      "torch.Size([2, 36])\n",
      "\n",
      "torch.Size([299, 2, 5])\n",
      "torch.Size([2, 299])\n",
      "torch.Size([36, 2])\n",
      "torch.Size([2, 36])\n",
      "\n",
      "torch.Size([299, 2, 5])\n",
      "torch.Size([2, 299])\n",
      "torch.Size([36, 2])\n",
      "torch.Size([2, 36])\n",
      "\n",
      "torch.Size([299, 2, 5])\n",
      "torch.Size([2, 299])\n",
      "torch.Size([36, 2])\n",
      "torch.Size([2, 36])\n",
      "\n",
      "torch.Size([299, 2, 5])\n",
      "torch.Size([2, 299])\n",
      "torch.Size([36, 2])\n",
      "torch.Size([2, 36])\n",
      "\n",
      "torch.Size([299, 2, 5])\n",
      "torch.Size([2, 299])\n",
      "torch.Size([36, 2])\n",
      "torch.Size([2, 36])\n",
      "\n",
      "torch.Size([299, 2, 5])\n",
      "torch.Size([2, 299])\n",
      "torch.Size([36, 2])\n",
      "torch.Size([2, 36])\n",
      "\n",
      "torch.Size([299, 2, 5])\n",
      "torch.Size([2, 299])\n",
      "torch.Size([36, 2])\n",
      "torch.Size([2, 36])\n",
      "\n",
      "torch.Size([299, 2, 5])\n",
      "torch.Size([2, 299])\n",
      "torch.Size([36, 2])\n",
      "torch.Size([2, 36])\n",
      "\n",
      "torch.Size([299, 2, 5])\n",
      "torch.Size([2, 299])\n",
      "torch.Size([36, 2])\n",
      "torch.Size([2, 36])\n",
      "\n",
      "torch.Size([299, 2, 5])\n",
      "torch.Size([2, 299])\n",
      "torch.Size([36, 2])\n",
      "torch.Size([2, 36])\n",
      "\n",
      "torch.Size([299, 2, 5])\n",
      "torch.Size([2, 299])\n",
      "torch.Size([36, 2])\n",
      "torch.Size([2, 36])\n",
      "\n",
      "torch.Size([299, 2, 5])\n",
      "torch.Size([2, 299])\n",
      "torch.Size([36, 2])\n",
      "torch.Size([2, 36])\n",
      "\n",
      "torch.Size([299, 2, 5])\n",
      "torch.Size([2, 299])\n",
      "torch.Size([36, 2])\n",
      "torch.Size([2, 36])\n",
      "\n",
      "torch.Size([299, 2, 5])\n",
      "torch.Size([2, 299])\n",
      "torch.Size([36, 2])\n",
      "torch.Size([2, 36])\n",
      "\n",
      "torch.Size([299, 2, 5])\n",
      "torch.Size([2, 299])\n",
      "torch.Size([36, 2])\n",
      "torch.Size([2, 36])\n",
      "\n",
      "torch.Size([299, 2, 5])\n",
      "torch.Size([2, 299])\n",
      "torch.Size([36, 2])\n",
      "torch.Size([2, 36])\n",
      "\n",
      "torch.Size([299, 2, 5])\n",
      "torch.Size([2, 299])\n",
      "torch.Size([36, 2])\n",
      "torch.Size([2, 36])\n",
      "\n",
      "torch.Size([299, 2, 5])\n",
      "torch.Size([2, 299])\n",
      "torch.Size([36, 2])\n",
      "torch.Size([2, 36])\n",
      "\n",
      "torch.Size([299, 2, 5])\n",
      "torch.Size([2, 299])\n",
      "torch.Size([36, 2])\n",
      "torch.Size([2, 36])\n",
      "\n",
      "torch.Size([299, 2, 5])\n",
      "torch.Size([2, 299])\n",
      "torch.Size([36, 2])\n",
      "torch.Size([2, 36])\n",
      "\n",
      "torch.Size([299, 2, 5])\n",
      "torch.Size([2, 299])\n",
      "torch.Size([36, 2])\n",
      "torch.Size([2, 36])\n",
      "\n",
      "torch.Size([299, 2, 5])\n",
      "torch.Size([2, 299])\n",
      "torch.Size([36, 2])\n",
      "torch.Size([2, 36])\n",
      "\n",
      "torch.Size([299, 2, 5])\n",
      "torch.Size([2, 299])\n",
      "torch.Size([36, 2])\n",
      "torch.Size([2, 36])\n",
      "\n",
      "torch.Size([299, 2, 5])\n",
      "torch.Size([2, 299])\n",
      "torch.Size([36, 2])\n",
      "torch.Size([2, 36])\n",
      "\n",
      "torch.Size([299, 2, 5])\n",
      "torch.Size([2, 299])\n",
      "torch.Size([36, 2])\n",
      "torch.Size([2, 36])\n",
      "\n",
      "torch.Size([299, 2, 5])\n",
      "torch.Size([2, 299])\n",
      "torch.Size([36, 2])\n",
      "torch.Size([2, 36])\n",
      "\n",
      "torch.Size([299, 2, 5])\n",
      "torch.Size([2, 299])\n",
      "torch.Size([36, 2])\n",
      "torch.Size([2, 36])\n",
      "\n",
      "torch.Size([299, 2, 5])\n",
      "torch.Size([2, 299])\n",
      "torch.Size([36, 2])\n",
      "torch.Size([2, 36])\n",
      "\n",
      "torch.Size([299, 2, 5])\n",
      "torch.Size([2, 299])\n",
      "torch.Size([36, 2])\n",
      "torch.Size([2, 36])\n",
      "\n",
      "torch.Size([299, 2, 5])\n",
      "torch.Size([2, 299])\n",
      "torch.Size([36, 2])\n",
      "torch.Size([2, 36])\n",
      "\n",
      "torch.Size([299, 2, 5])\n",
      "torch.Size([2, 299])\n",
      "torch.Size([36, 2])\n",
      "torch.Size([2, 36])\n",
      "\n",
      "torch.Size([299, 2, 5])\n",
      "torch.Size([2, 299])\n",
      "torch.Size([36, 2])\n",
      "torch.Size([2, 36])\n",
      "\n",
      "torch.Size([299, 2, 5])\n",
      "torch.Size([2, 299])\n",
      "torch.Size([36, 2])\n",
      "torch.Size([2, 36])\n",
      "\n",
      "torch.Size([299, 2, 5])\n",
      "torch.Size([2, 299])\n",
      "torch.Size([36, 2])\n",
      "torch.Size([2, 36])\n",
      "\n",
      "torch.Size([299, 2, 5])\n",
      "torch.Size([2, 299])\n",
      "torch.Size([36, 2])\n",
      "torch.Size([2, 36])\n",
      "\n",
      "torch.Size([299, 2, 5])\n",
      "torch.Size([2, 299])\n",
      "torch.Size([36, 2])\n",
      "torch.Size([2, 36])\n",
      "\n",
      "torch.Size([299, 2, 5])\n",
      "torch.Size([2, 299])\n",
      "torch.Size([36, 2])\n",
      "torch.Size([2, 36])\n",
      "\n",
      "torch.Size([299, 2, 5])\n",
      "torch.Size([2, 299])\n",
      "torch.Size([36, 2])\n",
      "torch.Size([2, 36])\n",
      "\n",
      "torch.Size([299, 2, 5])\n",
      "torch.Size([2, 299])\n",
      "torch.Size([36, 2])\n",
      "torch.Size([2, 36])\n",
      "\n",
      "torch.Size([299, 2, 5])\n",
      "torch.Size([2, 299])\n",
      "torch.Size([36, 2])\n",
      "torch.Size([2, 36])\n",
      "\n",
      "torch.Size([299, 2, 5])\n",
      "torch.Size([2, 299])\n",
      "torch.Size([36, 2])\n",
      "torch.Size([2, 36])\n",
      "\n",
      "torch.Size([299, 2, 5])\n",
      "torch.Size([2, 299])\n",
      "torch.Size([36, 2])\n",
      "torch.Size([2, 36])\n",
      "\n",
      "torch.Size([299, 2, 5])\n",
      "torch.Size([2, 299])\n",
      "torch.Size([36, 2])\n",
      "torch.Size([2, 36])\n",
      "\n",
      "torch.Size([299, 2, 5])\n",
      "torch.Size([2, 299])\n",
      "torch.Size([36, 2])\n",
      "torch.Size([2, 36])\n",
      "\n",
      "torch.Size([299, 2, 5])\n",
      "torch.Size([2, 299])\n",
      "torch.Size([36, 2])\n",
      "torch.Size([2, 36])\n",
      "\n",
      "torch.Size([299, 2, 5])\n",
      "torch.Size([2, 299])\n",
      "torch.Size([36, 2])\n",
      "torch.Size([2, 36])\n",
      "\n",
      "torch.Size([299, 2, 5])\n",
      "torch.Size([2, 299])\n",
      "torch.Size([36, 2])\n",
      "torch.Size([2, 36])\n",
      "\n",
      "torch.Size([299, 2, 5])\n",
      "torch.Size([2, 299])\n",
      "torch.Size([36, 2])\n",
      "torch.Size([2, 36])\n",
      "\n",
      "torch.Size([299, 2, 5])\n",
      "torch.Size([2, 299])\n",
      "torch.Size([36, 2])\n",
      "torch.Size([2, 36])\n",
      "\n",
      "torch.Size([299, 2, 5])\n",
      "torch.Size([2, 299])\n",
      "torch.Size([36, 2])\n",
      "torch.Size([2, 36])\n",
      "\n",
      "torch.Size([299, 2, 5])\n",
      "torch.Size([2, 299])\n",
      "torch.Size([36, 2])\n",
      "torch.Size([2, 36])\n",
      "\n",
      "torch.Size([299, 2, 5])\n",
      "torch.Size([2, 299])\n",
      "torch.Size([36, 2])\n",
      "torch.Size([2, 36])\n",
      "\n",
      "torch.Size([299, 2, 5])\n",
      "torch.Size([2, 299])\n",
      "torch.Size([36, 2])\n",
      "torch.Size([2, 36])\n",
      "\n",
      "torch.Size([299, 2, 5])\n",
      "torch.Size([2, 299])\n",
      "torch.Size([36, 2])\n",
      "torch.Size([2, 36])\n",
      "\n",
      "torch.Size([299, 2, 5])\n",
      "torch.Size([2, 299])\n",
      "torch.Size([36, 2])\n",
      "torch.Size([2, 36])\n",
      "\n",
      "torch.Size([299, 2, 5])\n",
      "torch.Size([2, 299])\n",
      "torch.Size([36, 2])\n",
      "torch.Size([2, 36])\n",
      "\n",
      "torch.Size([299, 2, 5])\n",
      "torch.Size([2, 299])\n",
      "torch.Size([36, 2])\n",
      "torch.Size([2, 36])\n",
      "\n",
      "torch.Size([299, 2, 5])\n",
      "torch.Size([2, 299])\n",
      "torch.Size([36, 2])\n",
      "torch.Size([2, 36])\n",
      "\n",
      "torch.Size([299, 2, 5])\n",
      "torch.Size([2, 299])\n",
      "torch.Size([36, 2])\n",
      "torch.Size([2, 36])\n",
      "\n",
      "torch.Size([299, 2, 5])\n",
      "torch.Size([2, 299])\n",
      "torch.Size([36, 2])\n",
      "torch.Size([2, 36])\n",
      "\n",
      "torch.Size([299, 2, 5])\n",
      "torch.Size([2, 299])\n",
      "torch.Size([36, 2])\n",
      "torch.Size([2, 36])\n",
      "\n",
      "torch.Size([299, 2, 5])\n",
      "torch.Size([2, 299])\n",
      "torch.Size([36, 2])\n",
      "torch.Size([2, 36])\n",
      "\n",
      "torch.Size([299, 2, 5])\n",
      "torch.Size([2, 299])\n",
      "torch.Size([36, 2])\n",
      "torch.Size([2, 36])\n",
      "\n",
      "torch.Size([299, 2, 5])\n",
      "torch.Size([2, 299])\n",
      "torch.Size([36, 2])\n",
      "torch.Size([2, 36])\n",
      "\n",
      "torch.Size([299, 2, 5])\n",
      "torch.Size([2, 299])\n",
      "torch.Size([36, 2])\n",
      "torch.Size([2, 36])\n",
      "\n",
      "torch.Size([299, 2, 5])\n",
      "torch.Size([2, 299])\n",
      "torch.Size([36, 2])\n",
      "torch.Size([2, 36])\n",
      "\n",
      "torch.Size([299, 2, 5])\n",
      "torch.Size([2, 299])\n",
      "torch.Size([36, 2])\n",
      "torch.Size([2, 36])\n",
      "\n",
      "torch.Size([299, 2, 5])\n",
      "torch.Size([2, 299])\n",
      "torch.Size([36, 2])\n",
      "torch.Size([2, 36])\n",
      "\n",
      "torch.Size([299, 2, 5])\n",
      "torch.Size([2, 299])\n",
      "torch.Size([36, 2])\n",
      "torch.Size([2, 36])\n",
      "\n",
      "torch.Size([299, 2, 5])\n",
      "torch.Size([2, 299])\n",
      "torch.Size([36, 2])\n",
      "torch.Size([2, 36])\n",
      "\n",
      "torch.Size([299, 2, 5])\n",
      "torch.Size([2, 299])\n",
      "torch.Size([36, 2])\n",
      "torch.Size([2, 36])\n",
      "\n",
      "torch.Size([299, 2, 5])\n",
      "torch.Size([2, 299])\n",
      "torch.Size([36, 2])\n",
      "torch.Size([2, 36])\n",
      "\n",
      "torch.Size([299, 2, 5])\n",
      "torch.Size([2, 299])\n",
      "torch.Size([36, 2])\n",
      "torch.Size([2, 36])\n",
      "\n",
      "torch.Size([299, 2, 5])\n",
      "torch.Size([2, 299])\n",
      "torch.Size([36, 2])\n",
      "torch.Size([2, 36])\n",
      "\n",
      "torch.Size([299, 2, 5])\n",
      "torch.Size([2, 299])\n",
      "torch.Size([36, 2])\n",
      "torch.Size([2, 36])\n",
      "\n",
      "torch.Size([299, 2, 5])\n",
      "torch.Size([2, 299])\n",
      "torch.Size([36, 2])\n",
      "torch.Size([2, 36])\n",
      "\n",
      "torch.Size([299, 2, 5])\n",
      "torch.Size([2, 299])\n",
      "torch.Size([36, 2])\n",
      "torch.Size([2, 36])\n",
      "\n",
      "torch.Size([299, 2, 5])\n",
      "torch.Size([2, 299])\n",
      "torch.Size([36, 2])\n",
      "torch.Size([2, 36])\n",
      "\n",
      "torch.Size([299, 2, 5])\n",
      "torch.Size([2, 299])\n",
      "torch.Size([36, 2])\n",
      "torch.Size([2, 36])\n",
      "\n",
      "torch.Size([299, 2, 5])\n",
      "torch.Size([2, 299])\n",
      "torch.Size([36, 2])\n",
      "torch.Size([2, 36])\n",
      "\n",
      "torch.Size([299, 2, 5])\n",
      "torch.Size([2, 299])\n",
      "torch.Size([36, 2])\n",
      "torch.Size([2, 36])\n",
      "\n",
      "torch.Size([299, 2, 5])\n",
      "torch.Size([2, 299])\n",
      "torch.Size([36, 2])\n",
      "torch.Size([2, 36])\n",
      "\n",
      "torch.Size([299, 2, 5])\n",
      "torch.Size([2, 299])\n",
      "torch.Size([36, 2])\n",
      "torch.Size([2, 36])\n",
      "\n",
      "torch.Size([299, 2, 5])\n",
      "torch.Size([2, 299])\n",
      "torch.Size([36, 2])\n",
      "torch.Size([2, 36])\n",
      "\n",
      "torch.Size([299, 2, 5])\n",
      "torch.Size([2, 299])\n",
      "torch.Size([36, 2])\n",
      "torch.Size([2, 36])\n",
      "\n",
      "torch.Size([299, 2, 5])\n",
      "torch.Size([2, 299])\n",
      "torch.Size([36, 2])\n",
      "torch.Size([2, 36])\n",
      "\n",
      "torch.Size([299, 2, 5])\n",
      "torch.Size([2, 299])\n",
      "torch.Size([36, 2])\n",
      "torch.Size([2, 36])\n",
      "\n",
      "torch.Size([299, 2, 5])\n",
      "torch.Size([2, 299])\n",
      "torch.Size([36, 2])\n",
      "torch.Size([2, 36])\n",
      "\n",
      "torch.Size([299, 2, 5])\n",
      "torch.Size([2, 299])\n",
      "torch.Size([36, 2])\n",
      "torch.Size([2, 36])\n",
      "\n",
      "torch.Size([299, 2, 5])\n",
      "torch.Size([2, 299])\n",
      "torch.Size([36, 2])\n",
      "torch.Size([2, 36])\n",
      "\n",
      "torch.Size([299, 2, 5])\n",
      "torch.Size([2, 299])\n",
      "torch.Size([36, 2])\n",
      "torch.Size([2, 36])\n",
      "\n",
      "torch.Size([299, 2, 5])\n",
      "torch.Size([2, 299])\n",
      "torch.Size([36, 2])\n",
      "torch.Size([2, 36])\n",
      "\n",
      "torch.Size([299, 2, 5])\n",
      "torch.Size([2, 299])\n",
      "torch.Size([36, 2])\n",
      "torch.Size([2, 36])\n",
      "\n",
      "torch.Size([299, 2, 5])\n",
      "torch.Size([2, 299])\n",
      "torch.Size([36, 2])\n",
      "torch.Size([2, 36])\n",
      "\n",
      "torch.Size([299, 2, 5])\n",
      "torch.Size([2, 299])\n",
      "torch.Size([36, 2])\n",
      "torch.Size([2, 36])\n",
      "\n",
      "torch.Size([299, 2, 5])\n",
      "torch.Size([2, 299])\n",
      "torch.Size([36, 2])\n",
      "torch.Size([2, 36])\n",
      "\n",
      "torch.Size([299, 2, 5])\n",
      "torch.Size([2, 299])\n",
      "torch.Size([36, 2])\n",
      "torch.Size([2, 36])\n",
      "\n",
      "torch.Size([299, 2, 5])\n",
      "torch.Size([2, 299])\n",
      "torch.Size([36, 2])\n",
      "torch.Size([2, 36])\n",
      "\n",
      "torch.Size([299, 2, 5])\n",
      "torch.Size([2, 299])\n",
      "torch.Size([36, 2])\n",
      "torch.Size([2, 36])\n",
      "\n",
      "torch.Size([299, 2, 5])\n",
      "torch.Size([2, 299])\n",
      "torch.Size([36, 2])\n",
      "torch.Size([2, 36])\n",
      "\n",
      "torch.Size([299, 2, 5])\n",
      "torch.Size([2, 299])\n",
      "torch.Size([36, 2])\n",
      "torch.Size([2, 36])\n",
      "\n",
      "torch.Size([299, 2, 5])\n",
      "torch.Size([2, 299])\n",
      "torch.Size([36, 2])\n",
      "torch.Size([2, 36])\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\proshian\\Documents\\yandex_cup_2023_ml_neuroswipe\\src\\playground.ipynb Cell 26\u001b[0m line \u001b[0;36m1\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/proshian/Documents/yandex_cup_2023_ml_neuroswipe/src/playground.ipynb#X42sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m \u001b[39mprint\u001b[39m(word_pad_mask\u001b[39m.\u001b[39mshape)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/proshian/Documents/yandex_cup_2023_ml_neuroswipe/src/playground.ipynb#X42sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m \u001b[39mprint\u001b[39m()\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/proshian/Documents/yandex_cup_2023_ml_neuroswipe/src/playground.ipynb#X42sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m transformer(xyt, char_seq, traj_pad_mask, word_pad_mask)\u001b[39m.\u001b[39mshape\n",
      "File \u001b[1;32mc:\\Users\\proshian\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "\u001b[1;32mc:\\Users\\proshian\\Documents\\yandex_cup_2023_ml_neuroswipe\\src\\playground.ipynb Cell 26\u001b[0m line \u001b[0;36m1\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/proshian/Documents/yandex_cup_2023_ml_neuroswipe/src/playground.ipynb#X42sZmlsZQ%3D%3D?line=149'>150</a>\u001b[0m y \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mchar_embedding(y)\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/proshian/Documents/yandex_cup_2023_ml_neuroswipe/src/playground.ipynb#X42sZmlsZQ%3D%3D?line=150'>151</a>\u001b[0m y \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpos_encoder(y)\n\u001b[1;32m--> <a href='vscode-notebook-cell:/c%3A/Users/proshian/Documents/yandex_cup_2023_ml_neuroswipe/src/playground.ipynb#X42sZmlsZQ%3D%3D?line=151'>152</a>\u001b[0m y \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdecoder(y, x, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmask, x_pad_mask, y_pad_mask)\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/proshian/Documents/yandex_cup_2023_ml_neuroswipe/src/playground.ipynb#X42sZmlsZQ%3D%3D?line=152'>153</a>\u001b[0m y \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mout(y)\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/proshian/Documents/yandex_cup_2023_ml_neuroswipe/src/playground.ipynb#X42sZmlsZQ%3D%3D?line=153'>154</a>\u001b[0m y \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msoftmax(y)\n",
      "File \u001b[1;32mc:\\Users\\proshian\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "\u001b[1;32mc:\\Users\\proshian\\Documents\\yandex_cup_2023_ml_neuroswipe\\src\\playground.ipynb Cell 26\u001b[0m line \u001b[0;36m7\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/proshian/Documents/yandex_cup_2023_ml_neuroswipe/src/playground.ipynb#X42sZmlsZQ%3D%3D?line=74'>75</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x, memory, tgt_mask, memory_key_padding_mask, tgt_key_padding_mask):\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/proshian/Documents/yandex_cup_2023_ml_neuroswipe/src/playground.ipynb#X42sZmlsZQ%3D%3D?line=75'>76</a>\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtransformer_decoder(x,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/proshian/Documents/yandex_cup_2023_ml_neuroswipe/src/playground.ipynb#X42sZmlsZQ%3D%3D?line=76'>77</a>\u001b[0m                                  memory,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/proshian/Documents/yandex_cup_2023_ml_neuroswipe/src/playground.ipynb#X42sZmlsZQ%3D%3D?line=77'>78</a>\u001b[0m                                  tgt_mask\u001b[39m=\u001b[39;49mtgt_mask,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/proshian/Documents/yandex_cup_2023_ml_neuroswipe/src/playground.ipynb#X42sZmlsZQ%3D%3D?line=78'>79</a>\u001b[0m                                  memory_key_padding_mask\u001b[39m=\u001b[39;49mmemory_key_padding_mask,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/proshian/Documents/yandex_cup_2023_ml_neuroswipe/src/playground.ipynb#X42sZmlsZQ%3D%3D?line=79'>80</a>\u001b[0m                                  tgt_key_padding_mask\u001b[39m=\u001b[39;49mtgt_key_padding_mask)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/proshian/Documents/yandex_cup_2023_ml_neuroswipe/src/playground.ipynb#X42sZmlsZQ%3D%3D?line=80'>81</a>\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mout(x)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/proshian/Documents/yandex_cup_2023_ml_neuroswipe/src/playground.ipynb#X42sZmlsZQ%3D%3D?line=81'>82</a>\u001b[0m     \u001b[39m# x = self.softmax(x)\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\proshian\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\proshian\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:369\u001b[0m, in \u001b[0;36mTransformerDecoder.forward\u001b[1;34m(self, tgt, memory, tgt_mask, memory_mask, tgt_key_padding_mask, memory_key_padding_mask)\u001b[0m\n\u001b[0;32m    366\u001b[0m output \u001b[39m=\u001b[39m tgt\n\u001b[0;32m    368\u001b[0m \u001b[39mfor\u001b[39;00m mod \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlayers:\n\u001b[1;32m--> 369\u001b[0m     output \u001b[39m=\u001b[39m mod(output, memory, tgt_mask\u001b[39m=\u001b[39;49mtgt_mask,\n\u001b[0;32m    370\u001b[0m                  memory_mask\u001b[39m=\u001b[39;49mmemory_mask,\n\u001b[0;32m    371\u001b[0m                  tgt_key_padding_mask\u001b[39m=\u001b[39;49mtgt_key_padding_mask,\n\u001b[0;32m    372\u001b[0m                  memory_key_padding_mask\u001b[39m=\u001b[39;49mmemory_key_padding_mask)\n\u001b[0;32m    374\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnorm \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    375\u001b[0m     output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnorm(output)\n",
      "File \u001b[1;32mc:\\Users\\proshian\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\proshian\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:716\u001b[0m, in \u001b[0;36mTransformerDecoderLayer.forward\u001b[1;34m(self, tgt, memory, tgt_mask, memory_mask, tgt_key_padding_mask, memory_key_padding_mask, tgt_is_causal, memory_is_causal)\u001b[0m\n\u001b[0;32m    714\u001b[0m     x \u001b[39m=\u001b[39m x \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_ff_block(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnorm3(x))\n\u001b[0;32m    715\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 716\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnorm1(x \u001b[39m+\u001b[39;49m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sa_block(x, tgt_mask, tgt_key_padding_mask, tgt_is_causal))\n\u001b[0;32m    717\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnorm2(x \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_mha_block(x, memory, memory_mask, memory_key_padding_mask, memory_is_causal))\n\u001b[0;32m    718\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnorm3(x \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_ff_block(x))\n",
      "File \u001b[1;32mc:\\Users\\proshian\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1494\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1491\u001b[0m             tracing_state\u001b[39m.\u001b[39mpop_scope()\n\u001b[0;32m   1492\u001b[0m     \u001b[39mreturn\u001b[39;00m result\n\u001b[1;32m-> 1494\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_call_impl\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m   1495\u001b[0m     forward_call \u001b[39m=\u001b[39m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_slow_forward \u001b[39mif\u001b[39;00m torch\u001b[39m.\u001b[39m_C\u001b[39m.\u001b[39m_get_tracing_state() \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mforward)\n\u001b[0;32m   1496\u001b[0m     \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m     \u001b[39m# this function, and just call forward.\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "loader = DataLoader(dataset, batch_size=2, shuffle=True)\n",
    "\n",
    "for xyt, traj_pad_mask, char_seq, word_pad_mask in loader:\n",
    "    # (batch_size, seq_len, n_point_feats) to (seq_len, batch_size, n_point_feats)\n",
    "    xyt = torch.transpose(xyt, 0, 1)\n",
    "    char_seq = torch.transpose(char_seq, 0, 1)\n",
    "\n",
    "    # print(xyt.shape)\n",
    "    # print(traj_pad_mask.shape)\n",
    "    # print(char_seq.shape)\n",
    "    # print(word_pad_mask.shape)\n",
    "    # print()\n",
    "\n",
    "    transformer(xyt, char_seq, traj_pad_mask, word_pad_mask).shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\proshian\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 10, 128])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_heads = 2\n",
    "num_decoder_layers = 1\n",
    "dim_feedforward = 128\n",
    "dropout = 0.1\n",
    "activation = F.relu\n",
    "max_out_seq_len = 32\n",
    "\n",
    "char_emb_size = 128\n",
    "seq_len = 32\n",
    "batch_size = 10\n",
    "\n",
    "decoder = SwipeCurveTransformerDecoderv1(\n",
    "    char_emb_size, num_heads, num_decoder_layers, dim_feedforward, dropout, activation)\n",
    "\n",
    "tgt_mask = torch.triu(torch.ones(max_out_seq_len, max_out_seq_len), diagonal=1)\n",
    "tgt_mask = tgt_mask.masked_fill(tgt_mask == 1, float('-inf'))\n",
    "\n",
    "memory_pad_mask = torch.zeros(max_out_seq_len, dtype=torch.bool)\n",
    "memory_pad_mask[:10] = True\n",
    "memory_pad_mask = memory_pad_mask.unsqueeze(0).repeat(batch_size, 1)\n",
    "\n",
    "tgt_pad_mask = torch.zeros(max_out_seq_len, dtype=torch.bool)\n",
    "tgt_pad_mask[:10] = True\n",
    "tgt_pad_mask = tgt_pad_mask.unsqueeze(0).repeat(batch_size, 1)\n",
    "\n",
    "decoder(\n",
    "    torch.rand(seq_len, batch_size, char_emb_size),\n",
    "    torch.rand(seq_len, batch_size, char_emb_size),\n",
    "    tgt_mask=tgt_mask,\n",
    "    memory_key_padding_mask=memory_pad_mask,\n",
    "    tgt_key_padding_mask=tgt_pad_mask\n",
    ").shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
