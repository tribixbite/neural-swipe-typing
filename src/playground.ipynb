{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader, IterableDataset\n",
    "\n",
    "# from model import SwipeCurveEncoderTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Optional\n",
    "\n",
    "class CharLevelTokenizerv1:\n",
    "    def __init__(self, vocab_path):\n",
    "        self.char_to_idx = {}\n",
    "        self.idx_to_char = {}\n",
    "        self.max_word_len = None  # is set in _build_vocab\n",
    "        self._build_vocab(vocab_path)\n",
    "\n",
    "    def _build_vocab(self, vocab_path):\n",
    "        self.max_word_len = 0\n",
    "        unique_chars = set({\"<pad>\": 0, \"<sos>\": 1, \"<eos>\": 2, \"<unk>\": 3})\n",
    "        with open(vocab_path, \"r\", encoding=\"utf-8\") as f:\n",
    "            vocab = f.read().split(\"\\n\")\n",
    "            for word in vocab:\n",
    "                self.max_word_len = max(self.max_word_len, len(word) + 2)\n",
    "                for char in word:\n",
    "                    unique_chars.add(char)\n",
    "        self.char_to_idx = {char: idx for idx, char in enumerate(unique_chars)}\n",
    "        self.idx_to_char = {idx: char for idx, char in enumerate(unique_chars)}\n",
    "\n",
    "    def _tokenize_word(self, word):\n",
    "        \"\"\"\n",
    "        Tokenizes a word into a list of integers.\n",
    "        \"\"\"\n",
    "        tokenized_word = []\n",
    "        tokenized_word.append(self.char_to_idx[\"<sos>\"])\n",
    "        for char in word:\n",
    "            tokenized_word.append(self.char_to_idx[char])\n",
    "        tokenized_word.append(self.char_to_idx[\"<eos>\"])\n",
    "        return tokenized_word\n",
    "    \n",
    "    def _pad_word(self, word):\n",
    "        \"\"\"\n",
    "        Pads a word to the max_word_len.\n",
    "        \"\"\"\n",
    "        return word + [self.char_to_idx[\"<pad>\"]] * (self.max_word_len - len(word))\n",
    "    \n",
    "    def tokenize(self, word):\n",
    "        \"\"\"\n",
    "        Tokenizes a word and pads it to the max_word_len.\n",
    "        \"\"\"\n",
    "        token_seq = torch.tensor(self._pad_word(self._tokenize_word(word)))\n",
    "        mask = torch.ones(self.max_word_len, dtype=torch.bool)\n",
    "        mask[:len(word)+2] = False\n",
    "        return token_seq, mask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Я вижу два решения:\n",
    "\n",
    "Для простоты я бы сделал 2 класса датасета\n",
    "Если нужно кодировать лишь последовательность букв, он и хранит последовательности букв сразу и не хранит коордианты\n",
    "\n",
    "В обоих случаях декодер оперирует эмбеддингами букв текста\n",
    "\n",
    "### 1. На вход энкодера x, y, t, dx/dt, dy/st, x'', y'', keybard_key_embedding\n",
    "**Что делать, если ближайшая клавиша неалфавитная (пунктуация, клавиши-действия)?**\n",
    "Добавлю для всех неалфавитных клавиш один специальный токен\n",
    "\n",
    "**Где происходит инициализация токенизатора?**\n",
    "я бы вынес токенезатор вне датасета и передавал бы его в конструктор датасета.\n",
    "\n",
    "\n",
    "для каждой раскладки свои instance'ы датасета и модели.\n",
    "\n",
    "\n",
    "\n",
    "### 2. На вход энкодера последовательность клавиш клавиатуры\n",
    "Если ближайшая клавиша неалфавитная **пропускать**\n",
    "\n",
    "**Где происходит инициализация токенизатора?**\n",
    "\n",
    "\n",
    "один instance датасета и одна модель для всех раскладок.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Реализовывать ли для каждого варианта отдельный токенизатор:\n",
    "\n",
    "У нас может быть различное количество токенов: в некотоорых раскладках отсутствует символ \"ъ\", например\n",
    "\n",
    "Когда датасет содержит лишь одну раскладку, токенизатор должен учесть символы из одной раскладки. Когда датасет содержит несколько раскладок, токенизатор должен учесть символы из всех раскладок.\n",
    "\n",
    "Кажется, что варьируется только наличие 'ъ' и 'ё'. Во-первых, не ясно нужны ли эти символы. Есть желание заменять 'ё' на 'е', а 'ъ' на 'ь'. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KeyboardTokenizerv1:\n",
    "    \n",
    "    i2t = ['а', 'б', 'в', 'г', 'д', 'е', 'ë', 'ж', 'з', 'и', 'й',\n",
    "           'к', 'л', 'м', 'н', 'о', 'п', 'р', 'с', 'т', 'у', 'ф',\n",
    "           'х', 'ц', 'ч', 'ш', 'щ', 'ъ', 'ы', 'ь', 'э', 'ю', 'я',\n",
    "           '-', '<unk>', '<pad>']\n",
    "    \n",
    "    t2i = {t: i for i, t in enumerate(i2t)}\n",
    "\n",
    "    def get_token(self, char):\n",
    "        return self.t2i.get(char, self.t2i['<unk>'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from typing import Optional, List, Tuple, Dict\n",
    "import array\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "class NeuroSwipeDatasetv1(Dataset):\n",
    "    \"\"\"\n",
    "    Dataset class for NeuroSwipe dataset.\n",
    "    The dataset file weights over 3 GB and contains over 6 million swipe gestures.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 data_path: str,\n",
    "                 grid: dict,\n",
    "                 kb_tokenizer,\n",
    "                 max_traj_len: int,\n",
    "                 word_tokenizer,  # should contain max word len\n",
    "                 include_time: bool = True,\n",
    "                 include_velocities: bool = True,\n",
    "                 include_accelerations: bool = True,\n",
    "                 total: Optional[int] = None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            data_path (string): Path to the NeuroSwipe dataset in JSON format.\n",
    "                A custom version of the dataset is used:\n",
    "                \"grid\" property is replaced with \"grid_name\" property.\n",
    "        \"\"\"\n",
    "        if include_accelerations and not include_velocities:\n",
    "\n",
    "            raise ValueError(\"Accelerations are supposed \\\n",
    "                             to be an addition to velocities. Add velocities.\")\n",
    "\n",
    "        self.max_traj_len = max_traj_len\n",
    "        self.include_velocities = include_velocities\n",
    "        self.include_accelerations = include_accelerations\n",
    "        self.include_time = include_time\n",
    "\n",
    "        self.word_tokenizer = word_tokenizer\n",
    "\n",
    "        kb_keys = grid['keys']\n",
    "\n",
    "        self.kb_width = grid['width']\n",
    "        self.kb_height = grid['height']\n",
    "\n",
    "        self.data_list = []\n",
    "        self._set_data(data_path, kb_keys, kb_tokenizer, self.data_list, total = total)\n",
    "    \n",
    "\n",
    "    def _get_key_center(self, hitbox: Dict[str, int]) -> Tuple[int, int]:\n",
    "        x = hitbox['x'] + hitbox['w'] / 2\n",
    "        y = hitbox['y'] + hitbox['h'] / 2\n",
    "        return x, y\n",
    "\n",
    "    def _coord_to_kb_label(self, x: int, y:int, keys: List[dict]) -> str:\n",
    "        nearest_kb_label = None\n",
    "        min_dist = float(\"inf\")\n",
    "        for key in keys:\n",
    "            key_x, key_y = self._get_key_center(key['hitbox'])\n",
    "            dist = (x - key_x)**2 + (y - key_y)**2\n",
    "            if dist < min_dist:\n",
    "                min_dist = dist\n",
    "                if 'label' in key:\n",
    "                    nearest_kb_label = key['label']\n",
    "                elif 'action' in key:\n",
    "                    nearest_kb_label = key['action']  # tokenizer will covert it to <unk>\n",
    "                else:\n",
    "                    raise ValueError(\"Key has no label or action\")\n",
    "\n",
    "        return nearest_kb_label\n",
    "            \n",
    "\n",
    "    def _set_data(self,\n",
    "                  data_path: str,\n",
    "                  kb_keys: str,\n",
    "                  kb_tokenizer,\n",
    "                  data_list: list,\n",
    "                  total: Optional[int] = None):\n",
    "        with open(data_path, \"r\", encoding=\"utf-8\") as json_file:\n",
    "            for line in tqdm(json_file, total = total):\n",
    "                data_list.append(self._get_data_from_json_line(line, kb_keys, kb_tokenizer))\n",
    "\n",
    "\n",
    "    def _get_dx_dt(self,\n",
    "                   X: torch.tensor,\n",
    "                   T: torch.tensor,\n",
    "                   len: int) -> List[float]:\n",
    "        \"\"\"\n",
    "        Calculates dx/dt for a list of x coordinates and a list of t coordinates.\n",
    "\n",
    "        Arguments:\n",
    "        ----------\n",
    "        X : torch.tensor\n",
    "            x (position) coordinates.\n",
    "        T : torch.tensor\n",
    "            T[i] = time from the beginning of the swipe corresponding to X[i].\n",
    "        len : int\n",
    "            Length of the swipe trajectory. Indexes greater than len are ignored.\n",
    "\n",
    "        \"\"\"\n",
    "        dx_dt = torch.zeros_like(X)\n",
    "        # dx_dt[1:-1] = (X[2:] - X[:-2]) / (T[2:] - T[:-2])\n",
    "        dx_dt[1:len-1] = (X[2:len] - X[:len-2]) / (T[2:len] - T[:len-2])\n",
    "\n",
    "        # Example:\n",
    "        # x0 x1 x2 x3\n",
    "        # t0 t1 t2 t3\n",
    "        # dx_dt[0] = 0\n",
    "        # dx_dt[1] = (x2 - x0) / (t2 - t0)\n",
    "        # dx_dt[2] = (x3 - x1) / (t3 - t1)\n",
    "        # dx_dt[3] = 0\n",
    "\n",
    "\n",
    "        # if True in torch.isnan(dx_dt):\n",
    "        #     print(dx_dt)\n",
    "        #     raise ValueError(\"dx_dt contains NaNs\")\n",
    "\n",
    "        return dx_dt\n",
    "\n",
    "    def _get_data_from_json_line(self, line, kb_keys, kb_tokenizer) -> Tuple[list, list, list, str]:\n",
    "        \"\"\"\n",
    "        Parses a JSON line and returns a dictionary with data.\n",
    "        \"\"\"\n",
    "        data = json.loads(line)\n",
    "        word: str = data['word']\n",
    "\n",
    "        X = array.array('h', data['curve']['x'])\n",
    "        Y = array.array('h', data['curve']['y'])\n",
    "        T = array.array('h', data['curve']['t'])        \n",
    "\n",
    "        kb_labels = [self._coord_to_kb_label(x, y, kb_keys) for x,y in zip(X, Y)]\n",
    "        kb_tokens = [kb_tokenizer.get_token(label) for label in kb_labels]\n",
    "        kb_tokens += [kb_tokenizer.get_token('<pad>')] * (self.max_traj_len - len(kb_labels))\n",
    "        kb_tokens = array.array('h', kb_tokens)\n",
    "\n",
    "        return X, Y, T, word, kb_tokens\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_list)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        X_list, Y_list, T_list, word, kb_tokens = self.data_list[idx]\n",
    "\n",
    "        X = torch.zeros(self.max_traj_len, dtype=torch.float32)\n",
    "        Y = torch.zeros(self.max_traj_len, dtype=torch.float32)\n",
    "        T = torch.zeros(self.max_traj_len, dtype=torch.float32)\n",
    "        \n",
    "        X[:len(X_list)] = torch.tensor(X_list, dtype=torch.float32) / self.kb_width\n",
    "        Y[:len(Y_list)] = torch.tensor(Y_list, dtype=torch.float32) / self.kb_height\n",
    "        T[:len(T_list)] = torch.tensor(T_list, dtype=torch.float32)\n",
    "\n",
    "        xyt = torch.cat(\n",
    "            [\n",
    "                X.reshape(-1, 1),\n",
    "                Y.reshape(-1, 1),\n",
    "            ],\n",
    "            axis = 1\n",
    "        )\n",
    "\n",
    "        if self.include_time:\n",
    "            xyt = torch.cat(\n",
    "                [\n",
    "                    xyt,\n",
    "                    T.reshape(-1, 1)\n",
    "                ],\n",
    "                axis = 1\n",
    "            )\n",
    "\n",
    "        traj_len = len(X_list)\n",
    "\n",
    "        if self.include_velocities:\n",
    "            dx_dt = self._get_dx_dt(X, T, traj_len)\n",
    "            dy_dt = self._get_dx_dt(Y, T, traj_len)\n",
    "            xyt = torch.cat(\n",
    "                [\n",
    "                    xyt,\n",
    "                    dx_dt.reshape(-1, 1),\n",
    "                    dy_dt.reshape(-1, 1)\n",
    "                ],\n",
    "                axis = 1\n",
    "            )\n",
    "\n",
    "        if self.include_accelerations:\n",
    "            d2x_dt2 = self._get_dx_dt(dx_dt, T, traj_len)\n",
    "            d2y_dt2 = self._get_dx_dt(dy_dt, T, traj_len)\n",
    "            xyt = torch.cat(\n",
    "                [\n",
    "                    xyt,\n",
    "                    d2x_dt2.reshape(-1, 1),\n",
    "                    d2y_dt2.reshape(-1, 1)\n",
    "                ],\n",
    "                axis = 1\n",
    "            )\n",
    "\n",
    "        traj_pad_mask = torch.ones(self.max_traj_len, dtype=torch.bool)\n",
    "        traj_pad_mask[:len(X_list)] = False\n",
    "\n",
    "        char_seq, word_mask = self.word_tokenizer.tokenize(word)\n",
    "\n",
    "        kb_tokens = torch.tensor(kb_tokens, dtype=torch.int64)\n",
    "    \n",
    "        return xyt, kb_tokens, traj_pad_mask, char_seq, word_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_grid(grid_name: str, grids_path: str) -> dict:\n",
    "    with open(grids_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        return json.load(f)[grid_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:04<00:00, 243.61it/s]\n"
     ]
    }
   ],
   "source": [
    "sample_data = r\"..\\data\\data_separated_grid\\sample_deleteme__default_only.jsonl\"\n",
    "grid_path =  r\"..\\data\\data_separated_grid\\gridname_to_grid.json\"\n",
    "grid_name = \"default\"\n",
    "\n",
    "grid = get_grid(grid_name, grid_path)\n",
    "kb_tokenizer = KeyboardTokenizerv1()\n",
    "word_tokenizer = CharLevelTokenizerv1(\"../data/data_separated_grid/voc.txt\")\n",
    "\n",
    "\n",
    "dataset = NeuroSwipeDatasetv1(\n",
    "    data_path = sample_data,\n",
    "    grid = grid,\n",
    "    kb_tokenizer = kb_tokenizer,\n",
    "    max_traj_len = 299,\n",
    "    word_tokenizer = word_tokenizer,\n",
    "    include_time = False,\n",
    "    include_velocities = True,\n",
    "    include_accelerations = True,\n",
    "    total = 1000\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([299, 6]) torch.Size([299]) torch.Size([299]) torch.Size([36]) torch.Size([36])\n"
     ]
    }
   ],
   "source": [
    "i = 40\n",
    "xyt, kb_tokens, traj_pad_mask, char_seq, word_mask = dataset[i]\n",
    "print(xyt.shape, kb_tokens.shape, traj_pad_mask.shape, char_seq.shape, word_mask.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class SwipeCurveTransformerEncoderv1(nn.Module):\n",
    "    \"\"\"\n",
    "    Transformer-based Curve encoder takes in a sequence of vectors and creates a representation\n",
    "    of a swipe gesture on a samrtphone keyboard.\n",
    "    Each vector contains information about finger trajectory at a time step.\n",
    "    It contains:\n",
    "    * x coordinate\n",
    "    * y coordinate\n",
    "    * Optionally: t\n",
    "    * Optionally: dx/dt\n",
    "    * Optionally: dy/dt\n",
    "    * Optionally: keyboard key that has x and y coordinates within its boundaries\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, input_size, d_model,\n",
    "                 dim_feedforward, num_layers, num_heads_first, num_heads_other,\n",
    "                 dropout = 0.1):\n",
    "        \"\"\"\n",
    "        Arguments:\n",
    "        ----------\n",
    "        input_size: int\n",
    "            Size of input vectors.\n",
    "        d_model: int\n",
    "            Size of the embeddings (output vectors).\n",
    "            Should be equal to char embedding size of the decoder.\n",
    "        dim_feedforward: int\n",
    "        num_layers: int\n",
    "            Number of encoder layers including the first layer.\n",
    "\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        # self.pos_encoder = PositionalEncoding(input_size, dropout)\n",
    "        self.first_encoder_layer = nn.TransformerEncoderLayer(\n",
    "            input_size, num_heads_first, dim_feedforward, dropout)\n",
    "        self.liner = nn.Linear(input_size, d_model)  # to convert embedding to d_model size\n",
    "        num_layer_after_first = num_layers - 1\n",
    "        if num_layer_after_first > 0:\n",
    "            encoder_layer = nn.TransformerEncoderLayer(d_model, num_heads_other, dim_feedforward, dropout)\n",
    "            self.transformer_encoder = nn.TransformerEncoder(encoder_layer, num_layers)\n",
    "        else:\n",
    "            self.transformer_encoder = None\n",
    "    \n",
    "\n",
    "    def forward(self, x, pad_mask: torch.tensor):\n",
    "        # x = self.pos_encoder(x)\n",
    "        x = self.first_encoder_layer(x, src_key_padding_mask=pad_mask)\n",
    "        x = self.liner(x)\n",
    "        if self.transformer_encoder:\n",
    "            x = self.transformer_encoder(x, src_key_padding_mask=pad_mask)\n",
    "        return x\n",
    "\n",
    "\n",
    "\n",
    "class SwipeCurveTransformerDecoderv1(nn.Module):\n",
    "    \"\"\"\n",
    "    Decodes a swipe gesture representation into a sequence of characters.\n",
    "\n",
    "    Uses decoder transformer with masked attention to prevent the model from cheating.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, char_emb_size, n_classes, nhead, num_decoder_layers,\n",
    "                 dim_feedforward, dropout, activation = F.relu):\n",
    "        super().__init__()\n",
    "\n",
    "        self.decoder_layer = nn.TransformerDecoderLayer(\n",
    "            char_emb_size, nhead, dim_feedforward, dropout, activation)\n",
    "        self.transformer_decoder = nn.TransformerDecoder(self.decoder_layer, num_decoder_layers)\n",
    "        self.out = nn.Linear(char_emb_size, n_classes)\n",
    "        self.softmax = nn.LogSoftmax(dim=2)\n",
    "    \n",
    "    def forward(self, x, memory, tgt_mask, memory_key_padding_mask, tgt_key_padding_mask):\n",
    "        x = self.transformer_decoder(x,\n",
    "                                     memory,\n",
    "                                     tgt_mask=tgt_mask,\n",
    "                                     memory_key_padding_mask=memory_key_padding_mask,\n",
    "                                     tgt_key_padding_mask=tgt_key_padding_mask)\n",
    "        x = self.out(x)\n",
    "        # x = self.softmax(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model: int, max_len: int, dropout: float = 0.0):\n",
    "        super().__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "        position = torch.arange(max_len).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2) * (-math.log(10000.0) / d_model))\n",
    "        pe = torch.zeros(max_len, 1, d_model)\n",
    "        pe[:, 0, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 0, 1::2] = torch.cos(position * div_term)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Arguments:\n",
    "            x: Tensor, shape ``[seq_len, batch_size, embedding_dim]``\n",
    "        \"\"\"\n",
    "        x = x + self.pe[:x.size(0)]\n",
    "        return self.dropout(x)\n",
    "\n",
    "\n",
    "class SwipeCurveTransformer(nn.Module):\n",
    "    \"\"\"\n",
    "    SwipeCurveTransformer is a sequence-to-sequence model that encodes a sequence of vectors\n",
    "    representing a swipe gesture into a sequence of characters.\n",
    "    \"\"\"\n",
    "\n",
    "    def _get_mask(self, max_seq_len: int):\n",
    "        \"\"\"\n",
    "        Returns a mask for the decoder transformer.\n",
    "        \"\"\"\n",
    "        mask = torch.triu(torch.ones(max_seq_len, max_seq_len), diagonal=1)\n",
    "        mask = mask.masked_fill(mask == 1, float('-inf'))\n",
    "        return mask\n",
    "\n",
    "    def __init__(self,\n",
    "                 n_coord_feats: int,\n",
    "                 char_emb_size: int,\n",
    "                 char_vocab_size: int,\n",
    "                 key_emb_size: int,\n",
    "                 num_encoder_layers: int,\n",
    "                 num_decoder_layers: int,\n",
    "                 dim_feedforward: int,\n",
    "                 num_heads: int,\n",
    "                 dropout:float,\n",
    "                 max_out_seq_len: int,\n",
    "                 max_curves_seq_len: int,\n",
    "                 activation = F.relu):\n",
    "        super().__init__()\n",
    "\n",
    "        input_size = n_coord_feats + key_emb_size\n",
    "\n",
    "        curv_emb_size = char_emb_size\n",
    "        \n",
    "        self.char_embedding = nn.Embedding(char_vocab_size, char_emb_size)\n",
    "        self.key_embedding = nn.Embedding(char_vocab_size, key_emb_size)\n",
    "\n",
    "        self.encoder = SwipeCurveTransformerEncoderv1(\n",
    "            input_size, curv_emb_size, dim_feedforward,\n",
    "            num_encoder_layers, num_heads, dropout)\n",
    "        self.char_pos_encoder = PositionalEncoding(char_emb_size, max_out_seq_len)\n",
    "        self.key_pos_encoder = PositionalEncoding(key_emb_size, max_curves_seq_len)\n",
    "        self.decoder = SwipeCurveTransformerDecoderv1(\n",
    "            char_emb_size, char_vocab_size, num_heads,\n",
    "            num_decoder_layers, dim_feedforward, dropout, activation)\n",
    "        self.out = nn.Linear(char_emb_size, char_emb_size)\n",
    "        self.softmax = nn.LogSoftmax(dim=2)\n",
    "\n",
    "        self.mask = self._get_mask(max_out_seq_len)\n",
    "\n",
    "    def forward(self, x, kb_tokens, y, x_pad_mask, y_pad_mask):\n",
    "        kb_k_emb = self.key_embedding(kb_tokens)  # keyboard key\n",
    "        kb_k_emb = self.key_pos_encoder(kb_k_emb)\n",
    "        x = torch.cat((x, kb_k_emb), axis = -1)\n",
    "        x = self.encoder(x, x_pad_mask)\n",
    "        if True in torch.isnan(x):\n",
    "            print(\"has nan after encoder\")\n",
    "        y = self.char_embedding(y)\n",
    "        y = self.char_pos_encoder(y)\n",
    "        y = self.decoder(y, x, self.mask, x_pad_mask, y_pad_mask)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_mask(max_seq_len: int):\n",
    "#     \"\"\"\n",
    "#     Returns a mask for the decoder transformer.\n",
    "#     \"\"\"\n",
    "#     mask = torch.triu(torch.ones(max_seq_len, max_seq_len), diagonal=1)\n",
    "#     mask = mask.masked_fill(mask == 1, float('-inf'))\n",
    "#     return mask\n",
    "\n",
    "# mask = get_mask(5)\n",
    "# print(mask)\n",
    "\n",
    "# >>>\n",
    "# tensor([[0., -inf, -inf, -inf, -inf],\n",
    "#         [0., 0., -inf, -inf, -inf],\n",
    "#         [0., 0., 0., -inf, -inf],\n",
    "#         [0., 0., 0., 0., -inf],\n",
    "#         [0., 0., 0., 0., 0.]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_len = 32\n",
    "batch_size = 10\n",
    "in_features = 40\n",
    "\n",
    "\n",
    "\n",
    "encoder = SwipeCurveTransformerEncoderv1(\n",
    "    input_size=in_features,\n",
    "    d_model=128,\n",
    "    dim_feedforward=128,\n",
    "    num_layers=1,\n",
    "    num_heads_first=2,\n",
    "    num_heads_other=4,\n",
    "    dropout=0.1)\n",
    "\n",
    "\n",
    "\n",
    "pad_mask = torch.zeros(batch_size, seq_len, dtype=torch.bool)\n",
    "# as if each batch contains 22 actual sequnce elements and 10 padding elements\n",
    "pad_mask[:, 10:] = True\n",
    "\n",
    "\n",
    "encoded = encoder(torch.rand(seq_len, batch_size, in_features), pad_mask)\n",
    "torch.set_printoptions(threshold=100_000)\n",
    "\n",
    "encoded.transpose_(0,1)\n",
    "\n",
    "if True in torch.isnan(encoded):\n",
    "    print(encoded)\n",
    "    raise ValueError(\"encoded contains NaNs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([14, 10, 5])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\proshian\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "curves_seq_len = 20\n",
    "chars_seq_len = 14\n",
    "batch_size = 10\n",
    "char_emb_size = 32\n",
    "n_classes = 5\n",
    "\n",
    "decoder = SwipeCurveTransformerDecoderv1(\n",
    "    char_emb_size=char_emb_size,\n",
    "    n_classes=n_classes,\n",
    "    nhead=2,\n",
    "    num_decoder_layers=2,\n",
    "    dim_feedforward=128,\n",
    "    dropout=0.1)\n",
    "\n",
    "def get_mask(max_seq_len: int):\n",
    "    \"\"\"\n",
    "    Returns a mask for the decoder transformer.\n",
    "    \"\"\"\n",
    "    mask = torch.triu(torch.ones(max_seq_len, max_seq_len), diagonal=1)\n",
    "    mask = mask.masked_fill(mask == 1, float('-inf'))\n",
    "    return mask\n",
    "\n",
    "x = torch.rand(chars_seq_len, batch_size, char_emb_size)\n",
    "memory = torch.rand(curves_seq_len, batch_size, char_emb_size)\n",
    "tgt_mask = get_mask(chars_seq_len)\n",
    "memory_key_padding_mask = torch.zeros(batch_size, curves_seq_len, dtype=torch.bool)\n",
    "memory_key_padding_mask[:, 15:] = True\n",
    "tgt_key_padding_mask = torch.zeros(batch_size, chars_seq_len, dtype=torch.bool)\n",
    "tgt_key_padding_mask[:, 10:] = True\n",
    "\n",
    "\n",
    "decoded = decoder(\n",
    "    x,\n",
    "    memory,\n",
    "    tgt_mask=tgt_mask,\n",
    "    memory_key_padding_mask=memory_key_padding_mask,\n",
    "    tgt_key_padding_mask=tgt_key_padding_mask)\n",
    "\n",
    "if True in torch.isnan(decoded):\n",
    "    print(decoded)\n",
    "    # raise ValueError(\"decoded contains NaNs\")\n",
    "\n",
    "print(decoded.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_char_tokenizer = CharLevelTokenizerv1(\"../data/data_separated_grid/voc.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([20,  4, 30, 13, 33, 33, 29, 36, 17, 21,  0, 19,  9,  9,  9,  9,  9,  9,\n",
       "          9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9]),\n",
       " tensor([False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "          True,  True,  True,  True,  True,  True]))"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_char_tokenizer.tokenize(\"троллейбус\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['с', 'н', 'х', 'э', 'т', 'ж', 'а', 'ч', 'п', '<pad>', 'щ', 'ь', 'и', 'о', 'к', 'з', 'ш', 'б', 'ф', '<eos>', '<sos>', 'у', 'в', 'г', 'м', 'ц', '<unk>', 'ы', '-', 'е', 'р', 'я', 'ю', 'л', 'ъ', 'д', 'й'])\n"
     ]
    }
   ],
   "source": [
    "print(word_char_tokenizer.char_to_idx.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(word_char_tokenizer.tokenize('информационно-телекоммуникационной')[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(word_char_tokenizer.tokenize('информационно')[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer = SwipeCurveTransformer(\n",
    "    n_coord_feats=6,\n",
    "    char_emb_size=128,\n",
    "    char_vocab_size=len(word_char_tokenizer.char_to_idx),\n",
    "    key_emb_size=32,\n",
    "    num_encoder_layers=1,\n",
    "    num_decoder_layers=2,\n",
    "    dim_feedforward=128,\n",
    "    num_heads=1,\n",
    "    dropout=0.1,\n",
    "    max_out_seq_len=36,\n",
    "    max_curves_seq_len=299)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "loader = DataLoader(dataset, batch_size=10, shuffle=True)\n",
    "\n",
    "for xyt, kb_tokens, traj_pad_mask, char_seq, word_pad_mask in loader:\n",
    "    # (batch_size, seq_len, n_point_feats) to (seq_len, batch_size, n_point_feats)\n",
    "    xyt = torch.transpose(xyt, 0, 1)\n",
    "    char_seq.transpose_(0, 1)\n",
    "    kb_tokens.transpose_(0, 1)\n",
    "\n",
    "    # print(xyt.shape)\n",
    "    # print(traj_pad_mask.shape)\n",
    "    # print(char_seq.shape)\n",
    "    # print(word_pad_mask.shape)\n",
    "    # print()\n",
    "\n",
    "    char_seq_pred = transformer(xyt, kb_tokens, char_seq, traj_pad_mask, word_pad_mask)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "char_seq_pred.transpose(0,1)[0].shape\n",
    "\n",
    "if True in torch.isnan(char_seq_pred):\n",
    "    print(char_seq_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([36, 10, 37])\n"
     ]
    }
   ],
   "source": [
    "print(char_seq_pred.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
