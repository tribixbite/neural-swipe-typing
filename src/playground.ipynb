{"cells":[{"cell_type":"markdown","metadata":{},"source":["Я вижу два решения:\n","\n","Для простоты я бы сделал 2 класса датасета\n","Если нужно кодировать лишь последовательность букв, он и хранит последовательности букв сразу и не хранит коордианты\n","\n","В обоих случаях декодер оперирует эмбеддингами букв текста\n","\n","<h3>1. На вход энкодера x, y, t, dx/dt, dy/st, x'', y'', keybard_key_embedding</h3>\n","\n","**Что делать, если ближайшая клавиша неалфавитная (пунктуация, клавиши-действия)?**\n","\n","Добавлю для всех неалфавитных клавиш один специальный токен. Хотя, возможно,\n","лучше добавить отдельный токен для каждой клавиши. Кажется, в кавиатуре схожесть\n","клавиш определяется тем, насколько часто они встречаются рядом друг с другом.\n","Тогда может быть важно отличать enter, который близок к бкве `э`, например,\n","от `caps lock`, который близок к `ф`. Отмечу, что схожесть в данном случае - это\n","не просто физическое расстояние между клавишами (хотя отчасти и так), но скорее, похожесть\n","клавиш `a` и `b` означает, что для последовательностей вида `letter1`, `letter2` ... `letterX`, `letterN`\n","если вероятность, что `letterX` = `a` велика, то вероятность, что `letterX` = `b` тоже велика.\n","\n","\n","**Где происходит инициализация токенизатора?**\n","я бы вынес токенезатор вне датасета и передавал бы его в конструктор датасета.\n","\n","\n","для каждой раскладки свои instance'ы датасета и модели.\n","\n","\n","\n","<h3> 2. На вход энкодера последовательность клавиш клавиатуры </h3>\n","\n","Если ближайшая клавиша неалфавитная **пропускать**\n","\n","**Где происходит инициализация токенизатора?**\n","\n","\n","один instance датасета и одна модель для всех раскладок.\n"]},{"cell_type":"markdown","metadata":{},"source":[]},{"cell_type":"markdown","metadata":{},"source":["Реализовывать ли для каждого варианта отдельный токенизатор:\n","\n","У нас может быть различное количество токенов: в некотоорых раскладках отсутствует символ \"ъ\", например\n","\n","Когда датасет содержит лишь одну раскладку, токенизатор должен учесть символы из одной раскладки. Когда датасет содержит несколько раскладок, токенизатор должен учесть символы из всех раскладок.\n","\n","Кажется, что варьируется только наличие 'ъ' и 'ё'. Во-первых, не ясно нужны ли эти символы. Есть желание заменять 'ё' на 'е', а 'ъ' на 'ь'. "]},{"cell_type":"markdown","metadata":{},"source":[]},{"cell_type":"markdown","metadata":{},"source":["Кажется, нас совершенно устраивает токенизатор, содержащий все буквы русского языка, включая 'ё' и 'ъ'. Наличие пары лишних токенов незначительно увеличит размер эмбеддинг-матрицы, но не повлияет на обучение модели."]},{"cell_type":"code","execution_count":362,"metadata":{},"outputs":[],"source":["%load_ext autoreload\n","%autoreload 2"]},{"cell_type":"code","execution_count":300,"metadata":{"execution":{"iopub.execute_input":"2023-11-05T18:27:13.937806Z","iopub.status.busy":"2023-11-05T18:27:13.937440Z","iopub.status.idle":"2023-11-05T18:27:13.942931Z","shell.execute_reply":"2023-11-05T18:27:13.941911Z","shell.execute_reply.started":"2023-11-05T18:27:13.937778Z"},"trusted":true},"outputs":[],"source":["import os\n","\n","import torch\n","import torch.nn as nn\n","from torch.utils.data import Dataset, DataLoader, IterableDataset\n","\n","# from model import SwipeCurveEncoderTransformer"]},{"cell_type":"code","execution_count":306,"metadata":{"execution":{"iopub.execute_input":"2023-11-05T18:27:14.316233Z","iopub.status.busy":"2023-11-05T18:27:14.315870Z","iopub.status.idle":"2023-11-05T18:27:14.320715Z","shell.execute_reply":"2023-11-05T18:27:14.319617Z","shell.execute_reply.started":"2023-11-05T18:27:14.316203Z"},"trusted":true},"outputs":[],"source":["IN_KAGGLE = False"]},{"cell_type":"code","execution_count":307,"metadata":{"execution":{"iopub.execute_input":"2023-11-05T18:27:14.536455Z","iopub.status.busy":"2023-11-05T18:27:14.536110Z","iopub.status.idle":"2023-11-05T18:27:14.540877Z","shell.execute_reply":"2023-11-05T18:27:14.539961Z","shell.execute_reply.started":"2023-11-05T18:27:14.536429Z"},"trusted":true},"outputs":[],"source":["if IN_KAGGLE:\n","    DATA_ROOT = \"/kaggle/input/yandex-cup-playground\"\n","    MODELS_DIR = \"\"\n","else:\n","    DATA_ROOT = \"../data/data_separated_grid\"\n","    MODELS_DIR = \"../data/trained_models/m1\""]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":308,"metadata":{"execution":{"iopub.execute_input":"2023-11-05T18:27:15.597101Z","iopub.status.busy":"2023-11-05T18:27:15.596727Z","iopub.status.idle":"2023-11-05T18:27:15.610707Z","shell.execute_reply":"2023-11-05T18:27:15.609614Z","shell.execute_reply.started":"2023-11-05T18:27:15.597073Z"},"trusted":true},"outputs":[],"source":["from typing import List, Optional\n","\n","class CharLevelTokenizerv1:\n","    \"\"\"\n","    Tokenizes a word into a list of integers.\n","\n","    Toknized word is padded to the max_word_len.\n","\n","    Guarantees that <sos> and <pad> are tokens with `vocab_len - 1`\n","    and `vocab_len - 2` indices respectively.\n","    This is useful because model never generates <sos> and <pad> tokens.\n","    \"\"\"\n","    def __init__(self, vocab_path):\n","        self.char_to_idx = {}\n","        self.idx_to_char = {}\n","        self.max_word_len = None  # is set in _build_vocab\n","        self._build_vocab(vocab_path)\n","\n","    def _build_vocab(self, vocab_path):\n","        self.max_word_len = 0\n","        special_tokens = [\"<eos>\", \"<pad>\", \"<unk>\", \"<sos>\"]\n","        unique_chars = set()\n","\n","        with open(vocab_path, \"r\", encoding=\"utf-8\") as f:\n","            vocab = f.read().split(\"\\n\")\n","            for word in vocab:\n","                self.max_word_len = max(self.max_word_len, len(word) + 2)  # + <sos> and <eos>\n","                for char in word:\n","                    unique_chars.add(char)\n","                    \n","        unique_chars_list = sorted(list(unique_chars)) + special_tokens\n","        self.char_to_idx = {char: idx for idx, char in enumerate(unique_chars_list)}\n","        self.idx_to_char = {idx: char for idx, char in enumerate(unique_chars_list)}\n","\n","    def _tokenize_word(self, word):\n","        \"\"\"\n","        Tokenizes a word into a list of integers.\n","        \"\"\"\n","        tokenized_word = []\n","        tokenized_word.append(self.char_to_idx[\"<sos>\"])\n","        for char in word:\n","            default: int = self.char_to_idx['<unk>']\n","            tokenized_word.append(self.char_to_idx.get(char, default))\n","        tokenized_word.append(self.char_to_idx[\"<eos>\"])\n","        return tokenized_word\n","    \n","    \n","    def _pad(self, tokenized_word):\n","        \"\"\"\n","        Pads a word to the max_word_len.\n","        \"\"\"\n","        return tokenized_word + [self.char_to_idx[\"<pad>\"]] * (self.max_word_len - len(tokenized_word))\n","    \n","    def tokenize(self, word):\n","        \"\"\"\n","        Tokenizes a word and pads it to the max_word_len.\n","        \"\"\"\n","        token_seq = torch.tensor(self._pad(self._tokenize_word(word)))\n","        mask = torch.ones(self.max_word_len, dtype=torch.bool)\n","        mask[:len(word)+2] = False\n","        return token_seq, mask\n","    \n","    def decode(self, token_seq):\n","        \"\"\"\n","        Decodes a tokenized word into a string.\n","        \"\"\"\n","        return \"\".join([self.idx_to_char[int(idx)] for idx in token_seq])"]},{"cell_type":"code","execution_count":309,"metadata":{"execution":{"iopub.execute_input":"2023-11-05T18:27:15.647258Z","iopub.status.busy":"2023-11-05T18:27:15.646885Z","iopub.status.idle":"2023-11-05T18:27:16.679722Z","shell.execute_reply":"2023-11-05T18:27:16.678853Z","shell.execute_reply.started":"2023-11-05T18:27:15.647228Z"},"trusted":true},"outputs":[],"source":["import pickle\n","\n","word_tokenizer = CharLevelTokenizerv1(os.path.join(DATA_ROOT, \"voc.txt\"))\n","\n","if not IN_KAGGLE:\n","    word_tokenizer_save_path = os.path.join(DATA_ROOT, \"word_tokenizer.pkl\")\n","\n","    with open(word_tokenizer_save_path, 'wb') as f:\n","        pickle.dump(word_tokenizer, f, protocol=pickle.HIGHEST_PROTOCOL)\n","\n","    with open(word_tokenizer_save_path, 'rb') as f:\n","        word_tokenizer = pickle.load(f)"]},{"cell_type":"code","execution_count":310,"metadata":{"execution":{"iopub.execute_input":"2023-11-05T18:27:16.681656Z","iopub.status.busy":"2023-11-05T18:27:16.681319Z","iopub.status.idle":"2023-11-05T18:27:16.686570Z","shell.execute_reply":"2023-11-05T18:27:16.685625Z","shell.execute_reply.started":"2023-11-05T18:27:16.681629Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["{0: '-', 1: 'а', 2: 'б', 3: 'в', 4: 'г', 5: 'д', 6: 'е', 7: 'ж', 8: 'з', 9: 'и', 10: 'й', 11: 'к', 12: 'л', 13: 'м', 14: 'н', 15: 'о', 16: 'п', 17: 'р', 18: 'с', 19: 'т', 20: 'у', 21: 'ф', 22: 'х', 23: 'ц', 24: 'ч', 25: 'ш', 26: 'щ', 27: 'ъ', 28: 'ы', 29: 'ь', 30: 'э', 31: 'ю', 32: 'я', 33: '<eos>', 34: '<pad>', 35: '<unk>', 36: '<sos>'}\n"]}],"source":["print(word_tokenizer.idx_to_char)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":311,"metadata":{"execution":{"iopub.execute_input":"2023-11-05T18:27:16.688632Z","iopub.status.busy":"2023-11-05T18:27:16.688269Z","iopub.status.idle":"2023-11-05T18:27:16.696804Z","shell.execute_reply":"2023-11-05T18:27:16.696017Z","shell.execute_reply.started":"2023-11-05T18:27:16.688597Z"},"trusted":true},"outputs":[],"source":["class KeyboardTokenizerv1:\n","    \n","    i2t = ['а', 'б', 'в', 'г', 'д', 'е', 'ë', 'ж', 'з', 'и', 'й',\n","           'к', 'л', 'м', 'н', 'о', 'п', 'р', 'с', 'т', 'у', 'ф',\n","           'х', 'ц', 'ч', 'ш', 'щ', 'ъ', 'ы', 'ь', 'э', 'ю', 'я',\n","           '-', '<unk>', '<pad>']\n","    \n","    t2i = {t: i for i, t in enumerate(i2t)}\n","\n","    def get_token(self, char):\n","        return self.t2i.get(char, self.t2i['<unk>'])"]},{"cell_type":"code","execution_count":312,"metadata":{"execution":{"iopub.execute_input":"2023-11-05T18:27:16.777022Z","iopub.status.busy":"2023-11-05T18:27:16.776679Z","iopub.status.idle":"2023-11-05T18:27:16.818450Z","shell.execute_reply":"2023-11-05T18:27:16.817525Z","shell.execute_reply.started":"2023-11-05T18:27:16.776995Z"},"trusted":true},"outputs":[],"source":["import json\n","from typing import Optional, List, Tuple, Dict\n","import array\n","import numpy as np\n","\n","import torch\n","from torch.utils.data import Dataset\n","from tqdm import tqdm\n","\n","\n","class NeuroSwipeDatasetv1(Dataset):\n","    \"\"\"\n","    Dataset class for NeuroSwipe dataset.\n","    The dataset file weights over 3 GB and contains over 6 million swipe gestures.\n","    \"\"\"\n","\n","    def __init__(self,\n","                 data_path: str,\n","                 gridname_to_grid: dict,\n","                 kb_tokenizer: KeyboardTokenizerv1,\n","                 max_traj_len: int,\n","                 word_tokenizer: CharLevelTokenizerv1,  # should contain max word len\n","                 include_time: bool = False,\n","                 include_velocities: bool = True,\n","                 include_accelerations: bool = True,\n","                 include_grid_name: bool = False,\n","                 has_target = True,\n","                 has_one_grid_only = True,\n","                 total: Optional[int] = None):\n","        \"\"\"\n","        Argsuments:\n","        -----------\n","        data_path (string): Path to the NeuroSwipe dataset in JSON format.\n","            A custom version of the dataset is used:\n","            \"grid\" property is replaced with \"grid_name\" property.\n","        \"\"\"\n","        if include_accelerations and not include_velocities:\n","            raise ValueError(\"Accelerations are supposed \\\n","                             to be an addition to velocities. Add velocities.\")\n","        \n","        if has_one_grid_only and len(gridname_to_grid) != 1:\n","            raise ValueError(f\"has_one_grid_only is True \\\n","                             but len(gridname_to_grid) != 1\")\n","\n","        self.max_traj_len = max_traj_len\n","        self.include_velocities = include_velocities\n","        self.include_accelerations = include_accelerations\n","        self.include_time = include_time\n","        self.has_target = has_target\n","        self.include_grid_name = include_grid_name\n","\n","        self.word_tokenizer = word_tokenizer\n","\n","        self._grid_name_to_grid = gridname_to_grid\n","\n","        self._nearest_kb_label_dict = self._get_nearest_kb_label_dict(gridname_to_grid)\n","\n","        self.data_list = []\n","        self._set_data(data_path, gridname_to_grid, kb_tokenizer, self.data_list, total = total)\n","\n","\n","    def get_nearest_kb_label(self, x, y, grid_name, gridname_to_grid):\n","        \"\"\"\n","        Given coords on a keyboard (x, y) and its grid_name returns the nearest keyboard keys\n","\n","        By default it uses an array assosiated with grid_name\n","        that stores the nearest key label for every possible coord pair.\n","\n","        However sometimes the coords are outside of the keyboard boarders.\n","        In this case we find the nearest key in a loop.\n","        \"\"\"        \n","        grid = gridname_to_grid[grid_name]\n","        if x < 0 or x >= grid['width'] or y < 0 or y >= grid['height']:\n","            return self._get_kb_label_without_map(x, y, grid)\n","        else:\n","            return self._nearest_kb_label_dict[grid_name][x, y]\n","    \n","\n","\n","    def _get_key_center(self, hitbox: Dict[str, int]) -> Tuple[int, int]:\n","        x = hitbox['x'] + hitbox['w'] / 2\n","        y = hitbox['y'] + hitbox['h'] / 2\n","        return x, y\n","    \n","\n","    def _get_kb_label_without_map(self, x, y, grid: dict) -> str:\n","        \"\"\"\n","        Returns label of the nearest key on the keyboard without using a map.\n","         \n","        Iterates over all keys and calculates the distance to (x, y) to find the nearest one.\n","        \"\"\"\n","        nearest_kb_label = None\n","        min_dist = float(\"inf\")\n","        for key in grid['keys']:\n","            key_x, key_y = self._get_key_center(key['hitbox'])\n","            dist = (x - key_x)**2 + (y - key_y)**2\n","            if dist < min_dist:\n","                min_dist = dist\n","                if 'label' in key:\n","                    nearest_kb_label = key['label']\n","                elif 'action' in key:\n","                    nearest_kb_label = key['action']  # tokenizer will covert it to <unk>\n","                else:\n","                    raise ValueError(\"Key has no label or action\")\n","        return nearest_kb_label\n","\n","\n","    def _get_nearest_kb_label_dict(self, gridname_to_grid: dict) -> Dict[str, np.chararray]:\n","        \"\"\"\n","        Creates a dict that maps grid_name to a map (np.chararray) from coordinate to nearest key label.\n","        \"\"\"\n","        nearest_kb_label_dict = {}\n","        for grid_name, grid in gridname_to_grid.items():\n","            nearest_kb_label_dict[grid_name] = self._get_coord_to_kb_label(grid)\n","        return nearest_kb_label_dict\n","    \n","\n","    def _get_coord_to_kb_label(self, grid: dict) -> np.chararray:\n","        coord_to_kb_label = np.chararray(\n","            (grid['width'], grid['height']), unicode=True) # 1080 x 640 in our case\n","        coord_to_kb_label.fill('')\n","\n","        for key in grid['keys']:\n","            x_left = key['hitbox']['x']\n","            x_right = x_left + key['hitbox']['w']\n","            y_top = key['hitbox']['y']\n","            y_bottom = y_top + key['hitbox']['h']\n","\n","            # tokenizer will covert actions to <unk>\n","            label = key['label'] if 'label' in key else key['action']\n","\n","            if len(label) > 1:\n","                print(f\"Warning: label '{label}' is substituted with {label[0]}\")\n","\n","            coord_to_kb_label[x_left:x_right, y_top:y_bottom] = label\n","\n","\n","        for x in range(grid['width']):\n","            for y in range(grid['height']):\n","                if coord_to_kb_label[x, y] != '':\n","                    continue\n","                coord_to_kb_label[x, y] = self._get_kb_label_without_map(x, y, grid)\n","\n","        return coord_to_kb_label\n","            \n","\n","    def _set_data(self,\n","                  data_path: str,\n","                  gridname_to_grid: dict,\n","                  kb_tokenizer,\n","                  data_list: list,\n","                  total: Optional[int] = None):\n","        with open(data_path, \"r\", encoding=\"utf-8\") as json_file:\n","            for line in tqdm(json_file, total = total):\n","                data_list.append(self._get_data_from_json_line(line, gridname_to_grid, kb_tokenizer))\n","\n","\n","    def _get_dx_dt(self,\n","                   X: torch.tensor,\n","                   T: torch.tensor,\n","                   len: int) -> List[float]:\n","        \"\"\"\n","        Calculates dx/dt for a list of x coordinates and a list of t coordinates.\n","\n","        Arguments:\n","        ----------\n","        X : torch.tensor\n","            x (position) coordinates.\n","        T : torch.tensor\n","            T[i] = time from the beginning of the swipe corresponding to X[i].\n","        len : int\n","            Length of the swipe trajectory. Indexes greater than len are ignored.\n","        \"\"\"\n","        dx_dt = torch.zeros_like(X)\n","        # dx_dt[1:-1] = (X[2:] - X[:-2]) / (T[2:] - T[:-2])\n","        dx_dt[1:len-1] = (X[2:len] - X[:len-2]) / (T[2:len] - T[:len-2])\n","\n","        # Example:\n","        # x0 x1 x2 x3\n","        # t0 t1 t2 t3\n","        # dx_dt[0] = 0\n","        # dx_dt[1] = (x2 - x0) / (t2 - t0)\n","        # dx_dt[2] = (x3 - x1) / (t3 - t1)\n","        # dx_dt[3] = 0\n","\n","\n","        # if True in torch.isnan(dx_dt):\n","        #     print(dx_dt)\n","        #     raise ValueError(\"dx_dt contains NaNs\")\n","\n","        return dx_dt\n","    \n","    def _get_data_from_json_line(self,\n","                                 line,\n","                                 gridname_to_grid,\n","                                 kb_tokenizer) -> Tuple[list, list, list, str]:\n","        \"\"\"\n","        Parses a JSON line and returns a dictionary with data.\n","        \"\"\"\n","        data = json.loads(line)\n","\n","        X = array.array('h', data['curve']['x'])\n","        Y = array.array('h', data['curve']['y'])\n","        T = array.array('h', data['curve']['t'])\n","\n","        grid_name = data['curve']['grid_name']   \n","\n","        kb_labels = [self.get_nearest_kb_label(x, y, grid_name, gridname_to_grid) for x, y in zip(X, Y)]\n","        kb_tokens = [kb_tokenizer.get_token(label) for label in kb_labels]\n","        kb_tokens += [kb_tokenizer.get_token('<pad>')] * (self.max_traj_len - len(kb_labels))\n","        kb_tokens = array.array('h', kb_tokens)\n","\n","        if not self.has_target:\n","            return X, Y, T, kb_tokens, grid_name\n","        else:\n","            word: str = data['word']\n","            return X, Y, T, kb_tokens, word, grid_name\n","\n","\n","    def __len__(self):\n","        return len(self.data_list)\n","    \n","    def __getitem__(self, idx):\n","        if self.has_target:\n","            X_list, Y_list, T_list, kb_tokens, word, grid_name = self.data_list[idx]\n","        else:\n","            X_list, Y_list, T_list, kb_tokens, grid_name = self.data_list[idx]\n","\n","        X = torch.zeros(self.max_traj_len, dtype=torch.float32)\n","        Y = torch.zeros(self.max_traj_len, dtype=torch.float32)\n","        T = torch.zeros(self.max_traj_len, dtype=torch.float32)\n","\n","        grid = self._grid_name_to_grid[grid_name]\n","\n","        X[:len(X_list)] = torch.tensor(X_list, dtype=torch.float32) / grid['width']\n","        Y[:len(Y_list)] = torch.tensor(Y_list, dtype=torch.float32) / grid['height']\n","        T[:len(T_list)] = torch.tensor(T_list, dtype=torch.float32)\n","\n","        xyt = torch.cat(\n","            (\n","                X.reshape(-1, 1),\n","                Y.reshape(-1, 1),\n","            ),\n","            axis = 1\n","        )\n","\n","        if self.include_time:\n","            xyt = torch.cat(\n","                (\n","                    xyt,\n","                    T.reshape(-1, 1)\n","                ),\n","                axis = 1\n","            )\n","\n","        traj_len = len(X_list)\n","\n","        if self.include_velocities:\n","            dx_dt = self._get_dx_dt(X, T, traj_len)\n","            dy_dt = self._get_dx_dt(Y, T, traj_len)\n","            xyt = torch.cat(\n","                [\n","                    xyt,\n","                    dx_dt.reshape(-1, 1),\n","                    dy_dt.reshape(-1, 1)\n","                ],\n","                axis = 1\n","            )\n","\n","        if self.include_accelerations:\n","            d2x_dt2 = self._get_dx_dt(dx_dt, T, traj_len)\n","            d2y_dt2 = self._get_dx_dt(dy_dt, T, traj_len)\n","            xyt = torch.cat(\n","                [\n","                    xyt,\n","                    d2x_dt2.reshape(-1, 1),\n","                    d2y_dt2.reshape(-1, 1)\n","                ],\n","                axis = 1\n","            )\n","\n","        traj_pad_mask = torch.ones(self.max_traj_len, dtype=torch.bool)\n","        traj_pad_mask[:len(X_list)] = False\n","\n","\n","        kb_tokens = torch.tensor(kb_tokens, dtype=torch.int64)\n","\n","        if self.has_target:\n","            char_seq, word_mask = self.word_tokenizer.tokenize(word)\n","            word_mask = word_mask[:-1]\n","\n","            decoder_in_char_seq = char_seq[:-1]\n","            decoder_out_char_seq = char_seq[1:]\n","\n","        \n","        if not self.has_target:\n","            decoder_out_char_seq = None\n","            decoder_in_char_seq = None\n","            word_mask = None\n","        \n","        if self.include_grid_name:\n","            return (xyt, kb_tokens, decoder_in_char_seq, traj_pad_mask, word_mask), decoder_out_char_seq, grid_name\n","        \n","        return (xyt, kb_tokens, decoder_in_char_seq, traj_pad_mask, word_mask), decoder_out_char_seq"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":313,"metadata":{"execution":{"iopub.execute_input":"2023-11-05T18:27:17.147184Z","iopub.status.busy":"2023-11-05T18:27:17.146808Z","iopub.status.idle":"2023-11-05T18:27:17.152119Z","shell.execute_reply":"2023-11-05T18:27:17.151132Z","shell.execute_reply.started":"2023-11-05T18:27:17.147153Z"},"trusted":true},"outputs":[],"source":["def get_grid(grid_name: str, grids_path: str) -> dict:\n","    with open(grids_path, \"r\", encoding=\"utf-8\") as f:\n","        return json.load(f)[grid_name]"]},{"cell_type":"code","execution_count":314,"metadata":{"execution":{"iopub.execute_input":"2023-11-05T18:27:17.257375Z","iopub.status.busy":"2023-11-05T18:27:17.257066Z","iopub.status.idle":"2023-11-05T18:27:23.774705Z","shell.execute_reply":"2023-11-05T18:27:23.773778Z","shell.execute_reply.started":"2023-11-05T18:27:17.257351Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Warning: label 'shift' is substituted with s\n","Warning: label 'backspace' is substituted with b\n","Warning: label 'toNumberState' is substituted with t\n","Warning: label 'globe' is substituted with g\n","Warning: label 'space' is substituted with s\n","Warning: label 'enter' is substituted with e\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 9416/9416 [00:03<00:00, 2817.57it/s]\n"]}],"source":["sample_data = os.path.join(DATA_ROOT, \"valid__in_train_format__default_only.jsonl\")\n","grid_path =  os.path.join(DATA_ROOT, \"gridname_to_grid.json\")\n","grid_name = \"default\"\n","\n","grid = get_grid(grid_name, grid_path)\n","kb_tokenizer = KeyboardTokenizerv1()\n","word_tokenizer = CharLevelTokenizerv1(os.path.join(DATA_ROOT, \"voc.txt\"))\n","\n","\n","dataset = NeuroSwipeDatasetv1(\n","    data_path = sample_data,\n","    gridname_to_grid= {grid_name: grid},\n","    kb_tokenizer = kb_tokenizer,\n","    max_traj_len = 299,\n","    word_tokenizer = word_tokenizer,\n","    include_time = False,\n","    include_velocities = True,\n","    include_accelerations = True,\n","    total = 9_416\n",")"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2023-11-05T18:27:23.776552Z","iopub.status.busy":"2023-11-05T18:27:23.776257Z","iopub.status.idle":"2023-11-05T18:27:23.780504Z","shell.execute_reply":"2023-11-05T18:27:23.779616Z","shell.execute_reply.started":"2023-11-05T18:27:23.776527Z"},"trusted":true},"outputs":[],"source":["# full train dataset before adding nearest_kb_label:\n","# ----------------------------------\n","# 16.2GB RAM (when data stored as torch tensors)\n","# when stored as lists 17Gb is 61%\n","# when data stored as python arrays with dtype short: 4.8GB RAM\n","\n","\n","# Now:\n","# ----\n","# 9.3 Gb RAM"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":315,"metadata":{"execution":{"iopub.execute_input":"2023-11-05T18:27:23.781818Z","iopub.status.busy":"2023-11-05T18:27:23.781526Z","iopub.status.idle":"2023-11-05T18:27:23.862629Z","shell.execute_reply":"2023-11-05T18:27:23.861646Z","shell.execute_reply.started":"2023-11-05T18:27:23.781795Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["torch.Size([299, 6]) torch.Size([299]) torch.Size([35]) torch.Size([299]) torch.Size([35]) torch.Size([35])\n"]}],"source":["i = 40\n","(xyt, kb_tokens, dec_in_char_seq, traj_pad_mask, word_pad_mask), dec_out_char_seq = dataset[i]\n","print(xyt.shape, kb_tokens.shape, dec_in_char_seq.shape, traj_pad_mask.shape, word_pad_mask.shape, dec_out_char_seq.shape)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":344,"metadata":{"execution":{"iopub.execute_input":"2023-11-05T18:27:23.865834Z","iopub.status.busy":"2023-11-05T18:27:23.865474Z","iopub.status.idle":"2023-11-05T18:27:26.764433Z","shell.execute_reply":"2023-11-05T18:27:26.763417Z","shell.execute_reply.started":"2023-11-05T18:27:23.865807Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["[['й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й'\n","  'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й'\n","  'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й'\n","  'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й'\n","  'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й'\n","  'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й'\n","  'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й'\n","  'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й'\n","  'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й'\n","  'й' 'й' 'й' 'й' 'й' 'й' 'й' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф'\n","  'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф'\n","  'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф'\n","  'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф'\n","  'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф'\n","  'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф'\n","  'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф'\n","  'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф'\n","  'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 's'\n","  's' 's' 's' 's' 's' 's' 's' 's' 's' 's' 's' 's' 's' 's' 's' 's' 's' 's'\n","  's' 's' 's' 's' 's' 's' 's' 's' 's' 's' 's' 's' 's' 's' 's' 's' 's' 's'\n","  's' 's' 's' 's' 's' 's' 's' 's' 's' 's' 's' 's' 's' 's' 's' 's' 's' 's'\n","  's' 's' 's' 's' 's' 's' 's' 's' 's' 's' 's' 's' 's' 's' 's' 's' 's' 's'\n","  's' 's' 's' 's' 's' 's' 's' 's' 's' 's' 's' 's' 's' 's' 's' 's' 's' 's'\n","  's' 's' 's' 's' 's' 's' 's' 's' 's' 's' 's' 's' 's' 's' 's' 's' 's' 's'\n","  's' 's' 's' 's' 's' 's' 's' 's' 's' 's' 's' 's' 's' 's' 's' 's' 's' 's'\n","  's' 's' 's' 's' 's' 's' 's' 's' 's' 's' 's' 's' 's' 's' 's' 's' 's' 's'\n","  's' 's' 's' 's' 's' 's' 's' 's' 's' 't' 't' 't' 't' 't' 't' 't' 't' 't'\n","  't' 't' 't' 't' 't' 't' 't' 't' 't' 't' 't' 't' 't' 't' 't' 't' 't' 't'\n","  't' 't' 't' 't' 't' 't' 't' 't' 't' 't' 't' 't' 't' 't' 't' 't' 't' 't'\n","  't' 't' 't' 't' 't' 't' 't' 't' 't' 't' 't' 't' 't' 't' 't' 't' 't' 't'\n","  't' 't' 't' 't' 't' 't' 't' 't' 't' 't' 't' 't' 't' 't' 't' 't' 't' 't'\n","  't' 't' 't' 't' 't' 't' 't' 't' 't' 't' 't' 't' 't' 't' 't' 't' 't' 't'\n","  't' 't' 't' 't' 't' 't' 't' 't' 't' 't' 't' 't' 't' 't' 't' 't' 't' 't'\n","  't' 't' 't' 't' 't' 't' 't' 't' 't' 't' 't' 't' 't' 't' 't' 't' 't' 't'\n","  't' 't' 't' 't' 't' 't' 't' 't' 't' 't' 't' 't' 't' 't' 't' 't' 't' 't'\n","  't' 't' 't' 't' 't' 't' 't' 't' 't' 't' 't' 't' 't' 't' 't' 't' 't' 't'\n","  't' 't' 't' 't' 't' 't' 't' 't' 't' 't' 't' 't' 't' 't' 't' 't' 't' 't'\n","  't']\n"," ['й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й'\n","  'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й'\n","  'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й'\n","  'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й'\n","  'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й'\n","  'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й'\n","  'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й'\n","  'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й'\n","  'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й'\n","  'й' 'й' 'й' 'й' 'й' 'й' 'й' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф'\n","  'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф'\n","  'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф'\n","  'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф'\n","  'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф'\n","  'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф'\n","  'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф'\n","  'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф'\n","  'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 's'\n","  's' 's' 's' 's' 's' 's' 's' 's' 's' 's' 's' 's' 's' 's' 's' 's' 's' 's'\n","  's' 's' 's' 's' 's' 's' 's' 's' 's' 's' 's' 's' 's' 's' 's' 's' 's' 's'\n","  's' 's' 's' 's' 's' 's' 's' 's' 's' 's' 's' 's' 's' 's' 's' 's' 's' 's'\n","  's' 's' 's' 's' 's' 's' 's' 's' 's' 's' 's' 's' 's' 's' 's' 's' 's' 's'\n","  's' 's' 's' 's' 's' 's' 's' 's' 's' 's' 's' 's' 's' 's' 's' 's' 's' 's'\n","  's' 's' 's' 's' 's' 's' 's' 's' 's' 's' 's' 's' 's' 's' 's' 's' 's' 's'\n","  's' 's' 's' 's' 's' 's' 's' 's' 's' 's' 's' 's' 's' 's' 's' 's' 's' 's'\n","  's' 's' 's' 's' 's' 's' 's' 's' 's' 's' 's' 's' 's' 's' 's' 's' 's' 's'\n","  's' 's' 's' 's' 's' 's' 's' 's' 's' 't' 't' 't' 't' 't' 't' 't' 't' 't'\n","  't' 't' 't' 't' 't' 't' 't' 't' 't' 't' 't' 't' 't' 't' 't' 't' 't' 't'\n","  't' 't' 't' 't' 't' 't' 't' 't' 't' 't' 't' 't' 't' 't' 't' 't' 't' 't'\n","  't' 't' 't' 't' 't' 't' 't' 't' 't' 't' 't' 't' 't' 't' 't' 't' 't' 't'\n","  't' 't' 't' 't' 't' 't' 't' 't' 't' 't' 't' 't' 't' 't' 't' 't' 't' 't'\n","  't' 't' 't' 't' 't' 't' 't' 't' 't' 't' 't' 't' 't' 't' 't' 't' 't' 't'\n","  't' 't' 't' 't' 't' 't' 't' 't' 't' 't' 't' 't' 't' 't' 't' 't' 't' 't'\n","  't' 't' 't' 't' 't' 't' 't' 't' 't' 't' 't' 't' 't' 't' 't' 't' 't' 't'\n","  't' 't' 't' 't' 't' 't' 't' 't' 't' 't' 't' 't' 't' 't' 't' 't' 't' 't'\n","  't' 't' 't' 't' 't' 't' 't' 't' 't' 't' 't' 't' 't' 't' 't' 't' 't' 't'\n","  't' 't' 't' 't' 't' 't' 't' 't' 't' 't' 't' 't' 't' 't' 't' 't' 't' 't'\n","  't']\n"," ['й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й'\n","  'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й'\n","  'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й'\n","  'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й'\n","  'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й'\n","  'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й'\n","  'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й'\n","  'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й'\n","  'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й'\n","  'й' 'й' 'й' 'й' 'й' 'й' 'й' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф'\n","  'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф'\n","  'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф'\n","  'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф'\n","  'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф'\n","  'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф'\n","  'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф'\n","  'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф'\n","  'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 's'\n","  's' 's' 's' 's' 's' 's' 's' 's' 's' 's' 's' 's' 's' 's' 's' 's' 's' 's'\n","  's' 's' 's' 's' 's' 's' 's' 's' 's' 's' 's' 's' 's' 's' 's' 's' 's' 's'\n","  's' 's' 's' 's' 's' 's' 's' 's' 's' 's' 's' 's' 's' 's' 's' 's' 's' 's'\n","  's' 's' 's' 's' 's' 's' 's' 's' 's' 's' 's' 's' 's' 's' 's' 's' 's' 's'\n","  's' 's' 's' 's' 's' 's' 's' 's' 's' 's' 's' 's' 's' 's' 's' 's' 's' 's'\n","  's' 's' 's' 's' 's' 's' 's' 's' 's' 's' 's' 's' 's' 's' 's' 's' 's' 's'\n","  's' 's' 's' 's' 's' 's' 's' 's' 's' 's' 's' 's' 's' 's' 's' 's' 's' 's'\n","  's' 's' 's' 's' 's' 's' 's' 's' 's' 's' 's' 's' 's' 's' 's' 's' 's' 's'\n","  's' 's' 's' 's' 's' 's' 's' 's' 's' 't' 't' 't' 't' 't' 't' 't' 't' 't'\n","  't' 't' 't' 't' 't' 't' 't' 't' 't' 't' 't' 't' 't' 't' 't' 't' 't' 't'\n","  't' 't' 't' 't' 't' 't' 't' 't' 't' 't' 't' 't' 't' 't' 't' 't' 't' 't'\n","  't' 't' 't' 't' 't' 't' 't' 't' 't' 't' 't' 't' 't' 't' 't' 't' 't' 't'\n","  't' 't' 't' 't' 't' 't' 't' 't' 't' 't' 't' 't' 't' 't' 't' 't' 't' 't'\n","  't' 't' 't' 't' 't' 't' 't' 't' 't' 't' 't' 't' 't' 't' 't' 't' 't' 't'\n","  't' 't' 't' 't' 't' 't' 't' 't' 't' 't' 't' 't' 't' 't' 't' 't' 't' 't'\n","  't' 't' 't' 't' 't' 't' 't' 't' 't' 't' 't' 't' 't' 't' 't' 't' 't' 't'\n","  't' 't' 't' 't' 't' 't' 't' 't' 't' 't' 't' 't' 't' 't' 't' 't' 't' 't'\n","  't' 't' 't' 't' 't' 't' 't' 't' 't' 't' 't' 't' 't' 't' 't' 't' 't' 't'\n","  't' 't' 't' 't' 't' 't' 't' 't' 't' 't' 't' 't' 't' 't' 't' 't' 't' 't'\n","  't']\n"," ['й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й'\n","  'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й'\n","  'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й'\n","  'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й'\n","  'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й'\n","  'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й'\n","  'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й'\n","  'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й'\n","  'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й'\n","  'й' 'й' 'й' 'й' 'й' 'й' 'й' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф'\n","  'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф'\n","  'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф'\n","  'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф'\n","  'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф'\n","  'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф'\n","  'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф'\n","  'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф'\n","  'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 's'\n","  's' 's' 's' 's' 's' 's' 's' 's' 's' 's' 's' 's' 's' 's' 's' 's' 's' 's'\n","  's' 's' 's' 's' 's' 's' 's' 's' 's' 's' 's' 's' 's' 's' 's' 's' 's' 's'\n","  's' 's' 's' 's' 's' 's' 's' 's' 's' 's' 's' 's' 's' 's' 's' 's' 's' 's'\n","  's' 's' 's' 's' 's' 's' 's' 's' 's' 's' 's' 's' 's' 's' 's' 's' 's' 's'\n","  's' 's' 's' 's' 's' 's' 's' 's' 's' 's' 's' 's' 's' 's' 's' 's' 's' 's'\n","  's' 's' 's' 's' 's' 's' 's' 's' 's' 's' 's' 's' 's' 's' 's' 's' 's' 's'\n","  's' 's' 's' 's' 's' 's' 's' 's' 's' 's' 's' 's' 's' 's' 's' 's' 's' 's'\n","  's' 's' 's' 's' 's' 's' 's' 's' 's' 's' 's' 's' 's' 's' 's' 's' 's' 's'\n","  's' 's' 's' 's' 's' 's' 's' 's' 's' 't' 't' 't' 't' 't' 't' 't' 't' 't'\n","  't' 't' 't' 't' 't' 't' 't' 't' 't' 't' 't' 't' 't' 't' 't' 't' 't' 't'\n","  't' 't' 't' 't' 't' 't' 't' 't' 't' 't' 't' 't' 't' 't' 't' 't' 't' 't'\n","  't' 't' 't' 't' 't' 't' 't' 't' 't' 't' 't' 't' 't' 't' 't' 't' 't' 't'\n","  't' 't' 't' 't' 't' 't' 't' 't' 't' 't' 't' 't' 't' 't' 't' 't' 't' 't'\n","  't' 't' 't' 't' 't' 't' 't' 't' 't' 't' 't' 't' 't' 't' 't' 't' 't' 't'\n","  't' 't' 't' 't' 't' 't' 't' 't' 't' 't' 't' 't' 't' 't' 't' 't' 't' 't'\n","  't' 't' 't' 't' 't' 't' 't' 't' 't' 't' 't' 't' 't' 't' 't' 't' 't' 't'\n","  't' 't' 't' 't' 't' 't' 't' 't' 't' 't' 't' 't' 't' 't' 't' 't' 't' 't'\n","  't' 't' 't' 't' 't' 't' 't' 't' 't' 't' 't' 't' 't' 't' 't' 't' 't' 't'\n","  't' 't' 't' 't' 't' 't' 't' 't' 't' 't' 't' 't' 't' 't' 't' 't' 't' 't'\n","  't']\n"," ['й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й'\n","  'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й'\n","  'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й'\n","  'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й'\n","  'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й'\n","  'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й'\n","  'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й'\n","  'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й'\n","  'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й' 'й'\n","  'й' 'й' 'й' 'й' 'й' 'й' 'й' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф'\n","  'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф'\n","  'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф'\n","  'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф'\n","  'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф'\n","  'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф'\n","  'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф'\n","  'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф'\n","  'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 'ф' 's'\n","  's' 's' 's' 's' 's' 's' 's' 's' 's' 's' 's' 's' 's' 's' 's' 's' 's' 's'\n","  's' 's' 's' 's' 's' 's' 's' 's' 's' 's' 's' 's' 's' 's' 's' 's' 's' 's'\n","  's' 's' 's' 's' 's' 's' 's' 's' 's' 's' 's' 's' 's' 's' 's' 's' 's' 's'\n","  's' 's' 's' 's' 's' 's' 's' 's' 's' 's' 's' 's' 's' 's' 's' 's' 's' 's'\n","  's' 's' 's' 's' 's' 's' 's' 's' 's' 's' 's' 's' 's' 's' 's' 's' 's' 's'\n","  's' 's' 's' 's' 's' 's' 's' 's' 's' 's' 's' 's' 's' 's' 's' 's' 's' 's'\n","  's' 's' 's' 's' 's' 's' 's' 's' 's' 's' 's' 's' 's' 's' 's' 's' 's' 's'\n","  's' 's' 's' 's' 's' 's' 's' 's' 's' 's' 's' 's' 's' 's' 's' 's' 's' 's'\n","  's' 's' 's' 's' 's' 's' 's' 's' 's' 't' 't' 't' 't' 't' 't' 't' 't' 't'\n","  't' 't' 't' 't' 't' 't' 't' 't' 't' 't' 't' 't' 't' 't' 't' 't' 't' 't'\n","  't' 't' 't' 't' 't' 't' 't' 't' 't' 't' 't' 't' 't' 't' 't' 't' 't' 't'\n","  't' 't' 't' 't' 't' 't' 't' 't' 't' 't' 't' 't' 't' 't' 't' 't' 't' 't'\n","  't' 't' 't' 't' 't' 't' 't' 't' 't' 't' 't' 't' 't' 't' 't' 't' 't' 't'\n","  't' 't' 't' 't' 't' 't' 't' 't' 't' 't' 't' 't' 't' 't' 't' 't' 't' 't'\n","  't' 't' 't' 't' 't' 't' 't' 't' 't' 't' 't' 't' 't' 't' 't' 't' 't' 't'\n","  't' 't' 't' 't' 't' 't' 't' 't' 't' 't' 't' 't' 't' 't' 't' 't' 't' 't'\n","  't' 't' 't' 't' 't' 't' 't' 't' 't' 't' 't' 't' 't' 't' 't' 't' 't' 't'\n","  't' 't' 't' 't' 't' 't' 't' 't' 't' 't' 't' 't' 't' 't' 't' 't' 't' 't'\n","  't' 't' 't' 't' 't' 't' 't' 't' 't' 't' 't' 't' 't' 't' 't' 't' 't' 't'\n","  't']]\n"]}],"source":["with np.printoptions(threshold=1000000):\n","    print(dataset._nearest_kb_label_dict['default'][:5])"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":317,"metadata":{"execution":{"iopub.execute_input":"2023-11-05T18:27:26.766645Z","iopub.status.busy":"2023-11-05T18:27:26.766100Z","iopub.status.idle":"2023-11-05T18:27:26.809242Z","shell.execute_reply":"2023-11-05T18:27:26.807112Z","shell.execute_reply.started":"2023-11-05T18:27:26.766617Z"},"trusted":true},"outputs":[],"source":[]},{"cell_type":"code","execution_count":318,"metadata":{"execution":{"iopub.execute_input":"2023-11-05T18:27:26.811197Z","iopub.status.busy":"2023-11-05T18:27:26.810839Z","iopub.status.idle":"2023-11-05T18:27:26.826142Z","shell.execute_reply":"2023-11-05T18:27:26.825225Z","shell.execute_reply.started":"2023-11-05T18:27:26.811166Z"},"trusted":true},"outputs":[],"source":["# def get_mask(max_seq_len: int):\n","#     \"\"\"\n","#     Returns a mask for the decoder transformer.\n","#     \"\"\"\n","#     mask = torch.triu(torch.ones(max_seq_len, max_seq_len), diagonal=1)\n","#     mask = mask.masked_fill(mask == 1, float('-inf'))\n","#     return mask\n","\n","# mask = get_mask(5)\n","# print(mask)\n","\n","# >>>\n","# tensor([[0., -inf, -inf, -inf, -inf],\n","#         [0., 0., -inf, -inf, -inf],\n","#         [0., 0., 0., -inf, -inf],\n","#         [0., 0., 0., 0., -inf],\n","#         [0., 0., 0., 0., 0.]])"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":319,"metadata":{"execution":{"iopub.execute_input":"2023-11-05T18:27:26.828166Z","iopub.status.busy":"2023-11-05T18:27:26.827711Z","iopub.status.idle":"2023-11-05T18:27:26.858867Z","shell.execute_reply":"2023-11-05T18:27:26.857812Z","shell.execute_reply.started":"2023-11-05T18:27:26.828132Z"},"trusted":true},"outputs":[],"source":["device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"]},{"cell_type":"code","execution_count":371,"metadata":{},"outputs":[],"source":["from model import SwipeCurveTransformer\n"]},{"cell_type":"code","execution_count":369,"metadata":{"execution":{"iopub.execute_input":"2023-11-05T18:27:26.860524Z","iopub.status.busy":"2023-11-05T18:27:26.860173Z","iopub.status.idle":"2023-11-05T18:27:31.637621Z","shell.execute_reply":"2023-11-05T18:27:31.636762Z","shell.execute_reply.started":"2023-11-05T18:27:26.860498Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Encoder out shape correct\n","Decoder out shape correct\n"]},{"name":"stderr","output_type":"stream","text":["c:\\Users\\proshian\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.\n","  warnings.warn(\n"]}],"source":["!python model_tests.py"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":323,"metadata":{"execution":{"iopub.execute_input":"2023-11-05T18:27:31.676435Z","iopub.status.busy":"2023-11-05T18:27:31.676110Z","iopub.status.idle":"2023-11-05T18:27:32.676387Z","shell.execute_reply":"2023-11-05T18:27:32.675415Z","shell.execute_reply.started":"2023-11-05T18:27:31.676405Z"},"trusted":true},"outputs":[],"source":["word_char_tokenizer = CharLevelTokenizerv1(os.path.join(DATA_ROOT, \"voc.txt\"))"]},{"cell_type":"code","execution_count":324,"metadata":{"execution":{"iopub.execute_input":"2023-11-05T18:27:32.678864Z","iopub.status.busy":"2023-11-05T18:27:32.678018Z","iopub.status.idle":"2023-11-05T18:27:32.686506Z","shell.execute_reply":"2023-11-05T18:27:32.685613Z","shell.execute_reply.started":"2023-11-05T18:27:32.678829Z"},"trusted":true},"outputs":[{"data":{"text/plain":["(tensor([36, 19, 17, 15, 12, 12,  6, 10,  2, 20, 18, 33, 34, 34, 34, 34, 34, 34,\n","         34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34]),\n"," tensor([False, False, False, False, False, False, False, False, False, False,\n","         False, False,  True,  True,  True,  True,  True,  True,  True,  True,\n","          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n","          True,  True,  True,  True,  True,  True]))"]},"execution_count":324,"metadata":{},"output_type":"execute_result"}],"source":["word_char_tokenizer.tokenize(\"троллейбус\")"]},{"cell_type":"code","execution_count":325,"metadata":{"execution":{"iopub.execute_input":"2023-11-05T18:27:32.687978Z","iopub.status.busy":"2023-11-05T18:27:32.687678Z","iopub.status.idle":"2023-11-05T18:27:32.693749Z","shell.execute_reply":"2023-11-05T18:27:32.692901Z","shell.execute_reply.started":"2023-11-05T18:27:32.687953Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["dict_keys(['-', 'а', 'б', 'в', 'г', 'д', 'е', 'ж', 'з', 'и', 'й', 'к', 'л', 'м', 'н', 'о', 'п', 'р', 'с', 'т', 'у', 'ф', 'х', 'ц', 'ч', 'ш', 'щ', 'ъ', 'ы', 'ь', 'э', 'ю', 'я', '<eos>', '<pad>', '<unk>', '<sos>'])\n"]}],"source":["print(word_char_tokenizer.char_to_idx.keys())"]},{"cell_type":"code","execution_count":326,"metadata":{"execution":{"iopub.execute_input":"2023-11-05T18:27:32.695771Z","iopub.status.busy":"2023-11-05T18:27:32.694954Z","iopub.status.idle":"2023-11-05T18:27:32.705277Z","shell.execute_reply":"2023-11-05T18:27:32.704507Z","shell.execute_reply.started":"2023-11-05T18:27:32.695737Z"},"trusted":true},"outputs":[{"data":{"text/plain":["36"]},"execution_count":326,"metadata":{},"output_type":"execute_result"}],"source":["len(word_char_tokenizer.tokenize('информационно-телекоммуникационной')[0])"]},{"cell_type":"code","execution_count":327,"metadata":{"execution":{"iopub.execute_input":"2023-11-05T18:27:32.706671Z","iopub.status.busy":"2023-11-05T18:27:32.706400Z","iopub.status.idle":"2023-11-05T18:27:32.716485Z","shell.execute_reply":"2023-11-05T18:27:32.715609Z","shell.execute_reply.started":"2023-11-05T18:27:32.706648Z"},"trusted":true},"outputs":[{"data":{"text/plain":["36"]},"execution_count":327,"metadata":{},"output_type":"execute_result"}],"source":["len(word_char_tokenizer.tokenize('информационно')[0])"]},{"cell_type":"code","execution_count":328,"metadata":{"execution":{"iopub.execute_input":"2023-11-05T18:27:32.718307Z","iopub.status.busy":"2023-11-05T18:27:32.717623Z","iopub.status.idle":"2023-11-05T18:27:32.727526Z","shell.execute_reply":"2023-11-05T18:27:32.726570Z","shell.execute_reply.started":"2023-11-05T18:27:32.718275Z"},"trusted":true},"outputs":[{"data":{"text/plain":["'<sos>информационно-телекоммуникационной<eos>'"]},"execution_count":328,"metadata":{},"output_type":"execute_result"}],"source":["word_char_tokenizer.decode(word_char_tokenizer.tokenize('информационно-телекоммуникационной')[0])"]},{"cell_type":"code","execution_count":329,"metadata":{"execution":{"iopub.execute_input":"2023-11-05T18:27:32.728880Z","iopub.status.busy":"2023-11-05T18:27:32.728624Z","iopub.status.idle":"2023-11-05T18:27:32.738932Z","shell.execute_reply":"2023-11-05T18:27:32.738161Z","shell.execute_reply.started":"2023-11-05T18:27:32.728857Z"},"trusted":true},"outputs":[{"data":{"text/plain":["35"]},"execution_count":329,"metadata":{},"output_type":"execute_result"}],"source":["word_char_tokenizer.max_word_len - 1"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":430,"metadata":{"execution":{"iopub.execute_input":"2023-11-05T18:27:32.740171Z","iopub.status.busy":"2023-11-05T18:27:32.739893Z","iopub.status.idle":"2023-11-05T18:27:32.749165Z","shell.execute_reply":"2023-11-05T18:27:32.748343Z","shell.execute_reply.started":"2023-11-05T18:27:32.740148Z"},"trusted":true},"outputs":[],"source":["def prepare_batch_v1(x, y, device):\n","    (xyt, kb_tokens, dec_in_char_seq, traj_pad_mask, word_pad_mask), dec_out_char_seq = x, y\n","    \n","    if xyt is not None:\n","        xyt = xyt.transpose_(0, 1).to(device)  # (curves_seq_len, batch_size, n_coord_feats)\n","    if kb_tokens is not None:\n","        kb_tokens = kb_tokens.transpose_(0, 1).to(device) # (curves_seq_len, batch_size)\n","    if dec_in_char_seq is not None:\n","        dec_in_char_seq = dec_in_char_seq.transpose_(0, 1).to(device)  # (chars_seq_len - 1, batch_size)\n","    if dec_out_char_seq is not None:\n","        dec_out_char_seq = dec_out_char_seq.transpose_(0, 1).to(device)  # (chars_seq_len - 1, batch_size)\n","\n","    if traj_pad_mask is not None:\n","        traj_pad_mask = traj_pad_mask.to(device)  # (batch_size, curves_seq_len)\n","    if word_pad_mask is not None:\n","        word_pad_mask = word_pad_mask.to(device)  # (batch_size, chars_seq_len - 1)\n","\n","    return (xyt, kb_tokens, dec_in_char_seq, traj_pad_mask, word_pad_mask), dec_out_char_seq\n","\n","prepare_batch = prepare_batch_v1"]},{"cell_type":"code","execution_count":445,"metadata":{},"outputs":[],"source":["def turncate_traj_batch(xyt, kb_tokens, traj_pad_mask):\n","    max_curve_len = int(torch.max(torch.sum(~traj_pad_mask, dim = 1)))\n","    xyt = xyt[:, :max_curve_len]\n","    kb_tokens = kb_tokens[:, :max_curve_len]\n","    traj_pad_mask = traj_pad_mask[:, :max_curve_len]\n","    return xyt, kb_tokens, traj_pad_mask\n","\n","\n","\n","def prepare_batch_with_pad_truncation(x, y, device):\n","    (xyt, kb_tokens, dec_in_char_seq, traj_pad_mask, word_pad_mask), dec_out_char_seq = x, y\n","\n","    xyt, kb_tokens, traj_pad_mask = turncate_traj_batch(xyt, kb_tokens, traj_pad_mask)\n","\n","    # print(max_curve_len)\n","\n","    xyt = xyt.transpose_(0, 1).to(device)  # (curves_seq_len, batch_size, n_coord_feats)\n","    kb_tokens = kb_tokens.transpose_(0, 1).to(device) # (curves_seq_len, batch_size)\n","    dec_in_char_seq = dec_in_char_seq.transpose_(0, 1).to(device)  # (chars_seq_len - 1, batch_size)\n","    dec_out_char_seq = dec_out_char_seq.transpose_(0, 1).to(device)  # (chars_seq_len - 1, batch_size)\n","\n","    traj_pad_mask = traj_pad_mask.to(device)  # (batch_size, max_curve_len)\n","    # traj_pad_mask = torch.zeros_like(kb_tokens, dtype = torch.bool).transpose_(0, 1).to(device)\n","    word_pad_mask = word_pad_mask.to(device)  # (batch_size, chars_seq_len - 1)\n","\n","    return (xyt, kb_tokens, dec_in_char_seq, traj_pad_mask, word_pad_mask), dec_out_char_seq\n","\n","# prepare_batch = prepare_batch_with_pad_truncation"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":378,"metadata":{"execution":{"iopub.execute_input":"2023-11-05T18:27:32.750356Z","iopub.status.busy":"2023-11-05T18:27:32.750116Z","iopub.status.idle":"2023-11-05T18:27:32.815706Z","shell.execute_reply":"2023-11-05T18:27:32.814808Z","shell.execute_reply.started":"2023-11-05T18:27:32.750335Z"},"trusted":true},"outputs":[],"source":["max_out_seq_len = word_char_tokenizer.max_word_len - 1\n","\n","transformer = SwipeCurveTransformer(\n","    n_coord_feats=6,\n","    char_emb_size=128,\n","    char_vocab_size=len(word_char_tokenizer.char_to_idx),\n","    key_emb_size=54,\n","    num_encoder_layers=4,\n","    num_decoder_layers=3,\n","    dim_feedforward=128,\n","    num_heads_encoder_1=4,\n","    num_heads_encoder_2=4,\n","    num_heads_decoder=4,\n","    dropout=0.1,\n","    char_embedding_dropout=0.1,\n","    key_embedding_dropout=0.1,\n","    max_out_seq_len=max_out_seq_len,\n","    max_curves_seq_len=299,\n","    device = device)"]},{"cell_type":"code","execution_count":379,"metadata":{"execution":{"iopub.execute_input":"2023-11-05T18:27:32.818395Z","iopub.status.busy":"2023-11-05T18:27:32.818037Z","iopub.status.idle":"2023-11-05T18:27:32.824229Z","shell.execute_reply":"2023-11-05T18:27:32.823321Z","shell.execute_reply.started":"2023-11-05T18:27:32.818348Z"},"trusted":true},"outputs":[],"source":["import torch.nn.functional as F\n","\n","def cross_entropy_with_reshape(pred, target):\n","    \"\"\"\n","    pred - BatchSize x TargetLen x VocabSize\n","    target - BatchSize x TargetLen\n","    \"\"\"\n","    pred_flat = pred.view(-1, pred.shape[-1])  # BatchSize*TargetLen x VocabSize\n","    target_flat = target.reshape(-1)  # BatchSize*TargetLen\n","    return F.cross_entropy(pred_flat, target_flat, ignore_index=0)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":380,"metadata":{"execution":{"iopub.execute_input":"2023-11-05T18:27:32.825929Z","iopub.status.busy":"2023-11-05T18:27:32.825595Z","iopub.status.idle":"2023-11-05T18:27:32.871561Z","shell.execute_reply":"2023-11-05T18:27:32.870744Z","shell.execute_reply.started":"2023-11-05T18:27:32.825898Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["c:\\Users\\proshian\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.\n","  warnings.warn(\n"]}],"source":["from torch.utils.data import DataLoader\n","\n","loader = DataLoader(dataset, batch_size=10, shuffle=True)\n","\n","\n","for x, y in loader:\n","    x, y = prepare_batch(x, y, device)\n","\n","    char_seq_pred = transformer(*x)\n","\n","    cross_entropy_with_reshape(char_seq_pred, y)\n","\n","    \n","    break"]},{"cell_type":"code","execution_count":381,"metadata":{"execution":{"iopub.execute_input":"2023-11-05T18:27:32.873094Z","iopub.status.busy":"2023-11-05T18:27:32.872722Z","iopub.status.idle":"2023-11-05T18:27:32.878353Z","shell.execute_reply":"2023-11-05T18:27:32.877450Z","shell.execute_reply.started":"2023-11-05T18:27:32.873061Z"},"trusted":true},"outputs":[],"source":["char_seq_pred.transpose(0,1)[0].shape\n","\n","if True in torch.isnan(char_seq_pred):\n","    print(char_seq_pred)"]},{"cell_type":"code","execution_count":382,"metadata":{"execution":{"iopub.execute_input":"2023-11-05T18:27:32.879817Z","iopub.status.busy":"2023-11-05T18:27:32.879548Z","iopub.status.idle":"2023-11-05T18:27:32.891781Z","shell.execute_reply":"2023-11-05T18:27:32.890946Z","shell.execute_reply.started":"2023-11-05T18:27:32.879794Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["torch.Size([35, 10, 35])\n"]}],"source":["print(char_seq_pred.shape)  # max_word_len - 1, batch_size, char_vocab_size - 2 (omitting <sos> and <pad>)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":383,"metadata":{"execution":{"iopub.execute_input":"2023-11-05T18:27:32.893157Z","iopub.status.busy":"2023-11-05T18:27:32.892824Z","iopub.status.idle":"2023-11-05T18:27:32.902187Z","shell.execute_reply":"2023-11-05T18:27:32.901368Z","shell.execute_reply.started":"2023-11-05T18:27:32.893126Z"},"trusted":true},"outputs":[],"source":["def lr_scheduler(optimizer):\n","    return torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer,\n","                                                      patience=20,\n","                                                      factor=0.5,\n","                                                      verbose=True)"]},{"cell_type":"code","execution_count":384,"metadata":{"execution":{"iopub.execute_input":"2023-11-05T18:27:32.903630Z","iopub.status.busy":"2023-11-05T18:27:32.903286Z","iopub.status.idle":"2023-11-05T18:27:32.912135Z","shell.execute_reply":"2023-11-05T18:27:32.911278Z","shell.execute_reply.started":"2023-11-05T18:27:32.903605Z"},"trusted":true},"outputs":[],"source":["def init_random_seed(value=42):\n","    # random.seed(value)\n","    np.random.seed(value)\n","    torch.manual_seed(value)\n","    torch.cuda.manual_seed(value)\n","    # torch.backends.cudnn.deterministic = True"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":439,"metadata":{"execution":{"iopub.execute_input":"2023-11-05T18:27:32.913933Z","iopub.status.busy":"2023-11-05T18:27:32.913647Z","iopub.status.idle":"2023-11-05T18:27:32.931112Z","shell.execute_reply":"2023-11-05T18:27:32.930114Z","shell.execute_reply.started":"2023-11-05T18:27:32.913898Z"},"trusted":true},"outputs":[],"source":[]},{"cell_type":"code","execution_count":425,"metadata":{"execution":{"iopub.execute_input":"2023-11-05T18:27:32.932757Z","iopub.status.busy":"2023-11-05T18:27:32.932443Z","iopub.status.idle":"2023-11-05T18:27:32.945363Z","shell.execute_reply":"2023-11-05T18:27:32.944601Z","shell.execute_reply.started":"2023-11-05T18:27:32.932732Z"},"trusted":true},"outputs":[],"source":["class GreedyGenerator:\n","    def __init__(self, model, tokenizer, device):\n","        self.model = model\n","        self.tokenizer = tokenizer\n","        self.device = torch.device(device)\n","        self.model.to(self.device)\n","        self.eos_token_id = tokenizer.char_to_idx['<eos>'] \n","\n","    def __call__(self, xyt, kb_tokens, traj_pad_mask, max_steps_n=35):\n","        tokens = [self.tokenizer.char_to_idx['<sos>']]\n","\n","        # We don't have to put everything to device because it's done in prepare_batch.\n","\n","        with torch.no_grad():\n","            for _ in range(max_steps_n):\n","                dec_in_char_seq = torch.tensor(tokens).to(self.device)\n","                word_pad_mask = torch.zeros_like(dec_in_char_seq, dtype=torch.bool, device=self.device)\n","                # dummy_y is any tensor with n_dims = 2 (chars_seq_len - 1, batch_size).\n","                dummy_y = torch.tensor([[1]])\n","                x = [xyt, kb_tokens, dec_in_char_seq, traj_pad_mask, word_pad_mask]\n","                x = [el.unsqueeze(0) for el in x]\n","                model_input, dummy_y = prepare_batch(x, dummy_y, self.device)\n","                best_next_token = self.model(*model_input).transpose_(0, 1)\n","                best_next_token = best_next_token[0, -1].argmax()  # batch_i = 0, decoder_out_onehot_vector_seq_i = -1 \n","                if best_next_token == self.eos_token_id:\n","                    break\n","\n","                tokens.append(int(best_next_token))\n","        \n","        return self.tokenizer.decode(tokens)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":393,"metadata":{"execution":{"iopub.execute_input":"2023-11-05T18:27:32.946876Z","iopub.status.busy":"2023-11-05T18:27:32.946555Z","iopub.status.idle":"2023-11-05T18:27:32.958849Z","shell.execute_reply":"2023-11-05T18:27:32.957942Z","shell.execute_reply.started":"2023-11-05T18:27:32.946850Z"},"trusted":true},"outputs":[],"source":["# class GreedyGeneratorBatched:\n","#     def __init__(self, model, tokenizer, device):\n","#         self.model = model\n","#         self.tokenizer = tokenizer\n","#         self.device = torch.device(device)\n","#         self.model.to(self.device)\n","#         self.eos_token_id = tokenizer.char_to_idx['<eos>'] \n","\n","#     def __call__(self, xyt, kb_tokens, traj_pad_mask, max_steps_n=35):\n","#         curve_seq_len, batchsize, emb_size = xyt.shape\n","#         tokens = [[self.tokenizer.char_to_idx['<sos>']] for _ in range(batchsize)]\n","\n","#         xyt = xyt.to(self.device)\n","#         kb_tokens = kb_tokens.to(self.device)\n","#         traj_pad_mask = traj_pad_mask.to(self.device)\n","\n","#         with torch.no_grad():\n","\n","#             for _ in range(max_steps_n):\n","#                 dec_in_char_seq = torch.tensor(tokens).to(self.device)\n","#                 word_pad_mask = torch.zeros_like(dec_in_char_seq, dtype=torch.bool)\n","#                 # (seqlen, batchsize) but it's ok to have wrong sizes, what important is n_dims\n","#                 dummy_y = torch.zeros(1, 1, device = self.device)  \n","#                 x = (xyt, kb_tokens, dec_in_char_seq, traj_pad_mask, word_pad_mask)\n","#                 model_input, dummy_y = prepare_batch(x, dummy_y, self.device)\n","#                 best_next_tokens = self.model(*model_input).transpose_(0, 1)  # seq_len, batch_size\n","                \n","#                 best_next_token = best_next_token[0, -1].argmax()\n","#                 if best_next_token == self.eos_token_id:\n","#                     break\n","\n","#                 tokens.append(int(best_next_token))\n","        \n","#         return self.tokenizer.decode(tokens)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":394,"metadata":{"execution":{"iopub.execute_input":"2023-11-05T18:27:32.964133Z","iopub.status.busy":"2023-11-05T18:27:32.963841Z","iopub.status.idle":"2023-11-05T18:27:32.988854Z","shell.execute_reply":"2023-11-05T18:27:32.988018Z","shell.execute_reply.started":"2023-11-05T18:27:32.964107Z"},"trusted":true},"outputs":[],"source":["model = SwipeCurveTransformer(\n","    n_coord_feats=6,\n","    char_emb_size=128,\n","    char_vocab_size=len(word_char_tokenizer.char_to_idx),\n","    key_emb_size=54,\n","    num_encoder_layers=4,\n","    num_decoder_layers=3,\n","    dim_feedforward=128,\n","    num_heads_encoder_1=4,\n","    num_heads_encoder_2=4,\n","    num_heads_decoder=4,\n","    dropout=0.1,\n","    char_embedding_dropout=0.1,\n","    key_embedding_dropout=0.1,\n","    max_out_seq_len=max_out_seq_len,\n","    max_curves_seq_len=299,\n","    device = device)"]},{"cell_type":"code","execution_count":395,"metadata":{"execution":{"iopub.execute_input":"2023-11-05T18:27:32.990191Z","iopub.status.busy":"2023-11-05T18:27:32.989918Z","iopub.status.idle":"2023-11-05T18:27:33.076779Z","shell.execute_reply":"2023-11-05T18:27:33.075944Z","shell.execute_reply.started":"2023-11-05T18:27:32.990166Z"},"trusted":true},"outputs":[],"source":["model.load_state_dict(\n","    torch.load(os.path.join(MODELS_DIR,\n","                            'best_model__2023_11_04__18_31_37__0.02530_default_switch_2.pt'),\n","               map_location = device))\n","\n","model = model.eval()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":396,"metadata":{"execution":{"iopub.execute_input":"2023-11-05T18:27:33.078625Z","iopub.status.busy":"2023-11-05T18:27:33.077983Z","iopub.status.idle":"2023-11-05T18:27:34.613917Z","shell.execute_reply":"2023-11-05T18:27:34.613119Z","shell.execute_reply.started":"2023-11-05T18:27:33.078590Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["target               prediction          \n","-------------------------------\n","на                   на                  \n","все                  все                 \n","добрый               добрый              \n","девочка              девочка             \n","сказала              сказала             \n","скинь                скинь               \n","геев                 гееев               \n","тобой                тобой               \n","была                 быстра              \n","да                   да                  \n","муж                  маж                 \n","щас                  щас                 \n","она                  она                 \n","проблема             проблема            \n","билайн               билайн              \n","уже                  уже                 \n","раньше               раньше              \n","рам                  нам                 \n","щас                  щас                 \n","купил                купил               \n","ты                   ты                  \n","зовут                зовут               \n","короче               короче              \n","размыто              размыто             \n","давай                давай               \n","отдать               отдать              \n","привет               привет              \n","не                   не                  \n","да                   да                  \n","будете               будете              \n","связи                связи               \n","колывань             клывань             \n","меня                 меня                \n","напиши               напиши              \n","знаю                 знаю                \n","мамой                мамой               \n","не                   не                  \n","ты                   ты                  \n","только               только              \n","они                  они                 \n"]}],"source":["greedy_generator = GreedyGenerator(model, word_char_tokenizer, device)\n","\n","\n","print(\"{:<20} {:<20}\".format(\"target\", \"prediction\"))\n","print(\"-\"*31)\n","\n","n_examples = 40\n","for i in range(n_examples):\n","\n","    (xyt, kb_tokens, dec_in_char_seq, traj_pad_mask, word_pad_mask), target = dataset[i]\n","\n","    pred = greedy_generator(xyt, kb_tokens, traj_pad_mask)\n","\n","    # strip работвет только потому что в настоящих словах нет этих символов\n","    pred = pred.strip(\"<eos><pad>\") \n","    target = word_char_tokenizer.decode(target).strip(\"<eos><pad>\")\n","    print(\"{:<20} {:<20}\".format(target, pred))"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":397,"metadata":{"execution":{"iopub.execute_input":"2023-11-05T18:27:42.018602Z","iopub.status.busy":"2023-11-05T18:27:42.017700Z","iopub.status.idle":"2023-11-05T18:27:52.689246Z","shell.execute_reply":"2023-11-05T18:27:52.688319Z","shell.execute_reply.started":"2023-11-05T18:27:42.018570Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Warning: label 'shift' is substituted with s\n","Warning: label 'backspace' is substituted with b\n","Warning: label 'toNumberState' is substituted with t\n","Warning: label 'globe' is substituted with g\n","Warning: label 'space' is substituted with s\n","Warning: label 'enter' is substituted with e\n","Warning: label 'shift' is substituted with s\n","Warning: label 'backspace' is substituted with b\n","Warning: label 'toNumberState' is substituted with t\n","Warning: label 'globe' is substituted with g\n","Warning: label 'space' is substituted with s\n","Warning: label 'enter' is substituted with e\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 10000/10000 [00:01<00:00, 5438.07it/s]\n"]}],"source":["grid_name_to_grid_path = os.path.join(DATA_ROOT, \"gridname_to_grid.json\")\n","with open(grid_name_to_grid_path, \"r\", encoding=\"utf-8\") as f:\n","    grid_name_to_grid = json.load(f)\n","\n","test_path = os.path.join(DATA_ROOT, f\"test.jsonl\")\n","\n","kb_tokenizer = KeyboardTokenizerv1()\n","word_tokenizer = CharLevelTokenizerv1(os.path.join(DATA_ROOT, \"voc.txt\"))\n","\n","\n","test_dataset = NeuroSwipeDatasetv1(\n","    data_path = test_path,\n","    gridname_to_grid = grid_name_to_grid,\n","    kb_tokenizer = kb_tokenizer,\n","    max_traj_len = 299,\n","    word_tokenizer = word_tokenizer,\n","    include_time = False,\n","    include_velocities = True,\n","    include_accelerations = True,\n","    has_target=False,\n","    has_one_grid_only=False,\n","    include_grid_name=True,\n","    total = 10_000\n",")"]},{"cell_type":"code","execution_count":353,"metadata":{"execution":{"iopub.execute_input":"2023-11-05T18:46:22.727204Z","iopub.status.busy":"2023-11-05T18:46:22.726803Z","iopub.status.idle":"2023-11-05T18:46:33.423874Z","shell.execute_reply":"2023-11-05T18:46:33.423065Z","shell.execute_reply.started":"2023-11-05T18:46:22.727175Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Warning: label 'shift' is substituted with s\n","Warning: label 'backspace' is substituted with b\n","Warning: label 'toNumberState' is substituted with t\n","Warning: label 'globe' is substituted with g\n","Warning: label 'space' is substituted with s\n","Warning: label 'enter' is substituted with e\n","Warning: label 'shift' is substituted with s\n","Warning: label 'backspace' is substituted with b\n","Warning: label 'toNumberState' is substituted with t\n","Warning: label 'globe' is substituted with g\n","Warning: label 'space' is substituted with s\n","Warning: label 'enter' is substituted with e\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 10000/10000 [00:02<00:00, 3654.97it/s]\n"]}],"source":["grid_name_to_grid_path = os.path.join(DATA_ROOT, \"gridname_to_grid.json\")\n","with open(grid_name_to_grid_path, \"r\", encoding=\"utf-8\") as f:\n","    grid_name_to_grid = json.load(f)\n","\n","val_path = os.path.join(DATA_ROOT, f\"valid__in_train_format.jsonl\")\n","\n","kb_tokenizer = KeyboardTokenizerv1()\n","word_tokenizer = CharLevelTokenizerv1(os.path.join(DATA_ROOT, \"voc.txt\"))\n","\n","\n","val_dataset = NeuroSwipeDatasetv1(\n","    data_path = val_path,\n","    gridname_to_grid = grid_name_to_grid,\n","    kb_tokenizer = kb_tokenizer,\n","    max_traj_len = 299,\n","    word_tokenizer = word_tokenizer,\n","    include_time = False,\n","    include_velocities = True,\n","    include_accelerations = True,\n","    has_target=False,\n","    has_one_grid_only=False,\n","    include_grid_name=True,\n","    total = 10_000\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-05T18:27:56.988825Z","iopub.status.busy":"2023-11-05T18:27:56.988141Z","iopub.status.idle":"2023-11-05T18:27:56.992812Z","shell.execute_reply":"2023-11-05T18:27:56.991829Z","shell.execute_reply.started":"2023-11-05T18:27:56.988791Z"},"trusted":true},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":399,"metadata":{"execution":{"iopub.execute_input":"2023-11-05T18:27:57.610173Z","iopub.status.busy":"2023-11-05T18:27:57.609364Z","iopub.status.idle":"2023-11-05T18:27:57.616404Z","shell.execute_reply":"2023-11-05T18:27:57.615463Z","shell.execute_reply.started":"2023-11-05T18:27:57.610139Z"},"trusted":true},"outputs":[],"source":["def model_getter(weights_path):\n","    model = SwipeCurveTransformer(\n","    n_coord_feats=6,\n","    char_emb_size=128,\n","    char_vocab_size=len(word_char_tokenizer.char_to_idx),\n","    key_emb_size=54,\n","    num_encoder_layers=4,\n","    num_decoder_layers=3,\n","    dim_feedforward=128,\n","    num_heads_encoder_1=4,\n","    num_heads_encoder_2=4,\n","    num_heads_decoder=4,\n","    dropout=0.1,\n","    char_embedding_dropout=0.1,\n","    key_embedding_dropout=0.1,\n","    max_out_seq_len=max_out_seq_len,\n","    max_curves_seq_len=299,\n","    device = device)\n","\n","    model.load_state_dict(\n","        torch.load(weights_path,\n","                map_location = device))\n","    \n","    model = model.eval()\n","\n","    return model"]},{"cell_type":"code","execution_count":400,"metadata":{"execution":{"iopub.execute_input":"2023-11-05T18:56:38.953156Z","iopub.status.busy":"2023-11-05T18:56:38.952251Z","iopub.status.idle":"2023-11-05T18:56:39.204855Z","shell.execute_reply":"2023-11-05T18:56:39.203841Z","shell.execute_reply.started":"2023-11-05T18:56:38.953123Z"},"trusted":true},"outputs":[],"source":["grid_name_to_model = {\n","    \"default\": model_getter(os.path.join(MODELS_DIR,\n","                                         \"best_model__2023_11_04__18_31_37__0.02530_default_switch_2.pt\")),\n","    \"extra\": model_getter(os.path.join(MODELS_DIR,\n","                                       \"best_model__2023_11_05__07_55_13__0.02516_extra_switch_2__with_pad_cutting.pt\"))\n","}"]},{"cell_type":"code","execution_count":401,"metadata":{"execution":{"iopub.execute_input":"2023-11-05T18:56:42.481715Z","iopub.status.busy":"2023-11-05T18:56:42.481336Z","iopub.status.idle":"2023-11-05T18:56:42.490981Z","shell.execute_reply":"2023-11-05T18:56:42.490114Z","shell.execute_reply.started":"2023-11-05T18:56:42.481684Z"},"trusted":true},"outputs":[],"source":["grid_name_to_greedy_generator_v1 = {\n","    grid_name: GreedyGenerator(grid_name_to_model[grid_name], word_char_tokenizer, device)\n","    for grid_name in (\"default\", \"extra\")\n","}"]},{"cell_type":"code","execution_count":402,"metadata":{"execution":{"iopub.execute_input":"2023-11-05T18:56:44.710884Z","iopub.status.busy":"2023-11-05T18:56:44.710500Z","iopub.status.idle":"2023-11-05T18:56:44.715980Z","shell.execute_reply":"2023-11-05T18:56:44.714867Z","shell.execute_reply.started":"2023-11-05T18:56:44.710854Z"},"trusted":true},"outputs":[],"source":["# test_default_predictions = []\n","\n","# for i in tqdm(range(len(test_dataset)), position=0, leave=True):\n","\n","#     (xyt, kb_tokens, dec_in_char_seq, traj_pad_mask, word_pad_mask), target, grid_name = test_dataset[i]\n","\n","#     pred = grid_name_to_greedy_generator[grid_name](xyt, kb_tokens, traj_pad_mask)\n","\n","#     # strip работвет только потому что в настоящих словах нет этих символов\n","#     pred = pred.removeprefix(\"<sos>\") \n","#     test_default_predictions.append(pred)\n","\n","#     if i > 50:\n","#         break\n"]},{"cell_type":"code","execution_count":403,"metadata":{"execution":{"iopub.execute_input":"2023-11-05T18:56:44.887274Z","iopub.status.busy":"2023-11-05T18:56:44.886495Z","iopub.status.idle":"2023-11-05T18:56:44.895743Z","shell.execute_reply":"2023-11-05T18:56:44.894740Z","shell.execute_reply.started":"2023-11-05T18:56:44.887239Z"},"trusted":true},"outputs":[],"source":["def create_submission_greedy(dataset,\n","                             grid_name_to_greedy_generator,\n","                             baseline_preds_path, \n","                             out_path,\n","                             vocab_set):\n","    \"\"\"\n","    Creates submission file generating words greedily.\n","\n","    If prediction is not in the vocabulary \n","    \"\"\"\n","\n","    if os.path.exists(out_path):\n","        raise ValueError(f\"File {out_path} already exists\")\n","    \n","    with open(out_path, \"w\", encoding=\"utf-8\") as f:\n","        with open(baseline_preds_path, \"r\", encoding=\"utf-8\") as baseline_f:\n","            for i, (data, baseline_str) in tqdm(enumerate(zip(dataset, baseline_f)), total=len(dataset)):\n","                (xyt, kb_tokens, _, traj_pad_mask, _), _, grid_name = data\n","                pred = grid_name_to_greedy_generator[grid_name](xyt, kb_tokens, traj_pad_mask)\n","                pred = pred.removeprefix(\"<sos>\") \n","                if pred in vocab_set:\n","                    pred_list = [pred, *baseline_str.split(\",\")[:-1]]\n","                    pred_str = \",\".join(pred_list)\n","                    f.write(pred_str + \"\\n\")\n","                else:\n","                    f.write(baseline_str)"]},{"cell_type":"code","execution_count":404,"metadata":{"execution":{"iopub.execute_input":"2023-11-05T18:56:46.013718Z","iopub.status.busy":"2023-11-05T18:56:46.012933Z","iopub.status.idle":"2023-11-05T18:56:46.022241Z","shell.execute_reply":"2023-11-05T18:56:46.021184Z","shell.execute_reply.started":"2023-11-05T18:56:46.013671Z"},"trusted":true},"outputs":[],"source":["def create_pred_list_beam(dataset,\n","                          grid_name_to_beam_generator,\n","                          beamsize,\n","                          verbose):\n","    \"\"\"\n","    Creates submission file generating words greedily.\n","\n","    If prediction is not in the vocabulary \n","    \"\"\"\n","    all_pred_list = [None]*len(dataset)\n","\n","    for i, data in tqdm(enumerate(dataset), total=len(dataset)):\n","        try:\n","            (xyt, kb_tokens, _, traj_pad_mask, _), _, grid_name = data\n","            pred_list = grid_name_to_beam_generator[grid_name](\n","                xyt, kb_tokens, traj_pad_mask, max_steps_n = 35, beamsize=beamsize, verbose=verbose)\n","            pred_list = [pred for score, pred in pred_list]\n","            all_pred_list[i] = pred_list\n","            \n","        except KeyboardInterrupt:\n","            print('Досрочно остановлено пользователем')\n","            break\n","    return all_pred_list"]},{"cell_type":"code","execution_count":405,"metadata":{"execution":{"iopub.execute_input":"2023-11-05T18:56:47.638414Z","iopub.status.busy":"2023-11-05T18:56:47.638031Z","iopub.status.idle":"2023-11-05T18:56:47.644188Z","shell.execute_reply":"2023-11-05T18:56:47.643195Z","shell.execute_reply.started":"2023-11-05T18:56:47.638371Z"},"trusted":true},"outputs":[],"source":["def create_submission(preds_list, out_path):\n","    if os.path.exists(out_path):\n","        raise ValueError(f\"File {out_path} already exists\")\n","    \n","    with open(out_path, \"w\", encoding=\"utf-8\") as f:\n","        for preds in preds_list:\n","            pred_str = \",\".join(preds)\n","            f.write(preds + \"\\n\")"]},{"cell_type":"markdown","metadata":{},"source":[]},{"cell_type":"code","execution_count":406,"metadata":{"execution":{"iopub.execute_input":"2023-11-05T18:56:50.333655Z","iopub.status.busy":"2023-11-05T18:56:50.333258Z","iopub.status.idle":"2023-11-05T18:56:50.338556Z","shell.execute_reply":"2023-11-05T18:56:50.337621Z","shell.execute_reply.started":"2023-11-05T18:56:50.333624Z"},"trusted":true},"outputs":[],"source":["def get_vocab_set(vocab_path: str):\n","    with open(vocab_path, 'r', encoding = \"utf-8\") as f:\n","        return set(f.read().splitlines())"]},{"cell_type":"code","execution_count":407,"metadata":{"execution":{"iopub.execute_input":"2023-11-05T18:56:50.425764Z","iopub.status.busy":"2023-11-05T18:56:50.425128Z","iopub.status.idle":"2023-11-05T18:56:50.600248Z","shell.execute_reply":"2023-11-05T18:56:50.599438Z","shell.execute_reply.started":"2023-11-05T18:56:50.425731Z"},"trusted":true},"outputs":[],"source":["vocab_set = get_vocab_set(os.path.join(DATA_ROOT, \"voc.txt\"))"]},{"cell_type":"code","execution_count":416,"metadata":{},"outputs":[],"source":["prepare_batch = prepare_batch_v1"]},{"cell_type":"code","execution_count":432,"metadata":{"execution":{"iopub.execute_input":"2023-11-05T18:56:50.800401Z","iopub.status.busy":"2023-11-05T18:56:50.799653Z","iopub.status.idle":"2023-11-05T18:56:50.807886Z","shell.execute_reply":"2023-11-05T18:56:50.806924Z","shell.execute_reply.started":"2023-11-05T18:56:50.800355Z"},"trusted":true},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":451,"metadata":{},"outputs":[],"source":["import heapq\n","\n","\n","\n","class BeamGenerator:\n","    def __init__(self, model, tokenizer, voc_set, device):\n","        self.model = model\n","        self.tokenizer = tokenizer\n","        self.voc_set = voc_set\n","        self.device = torch.device(device)\n","        self.model.to(self.device)\n","        self.eos_token_id = tokenizer.char_to_idx['<eos>']\n","\n","    def __call__(self,\n","                 xyt, kb_tokens, traj_pad_mask,\n","                 max_steps_n=40,  # max tokens in a seq\n","                 return_hypotheses_n=4,  # n best hypothesis to return\n","                 beamsize=6,  # n best solutions we store in intermidiate comuptations\n","                 normalization_factor=0.5,\n","                 verbose=True\n","                 ):\n","        with torch.no_grad():\n","            \n","            tokens = [self.tokenizer.char_to_idx['<sos>']]\n","            initial_length = len(tokens)\n","\n","            # Partial hypothesis is a heap (stored as a list) of tuples.\n","            # Each tuple consists of a partial (unfinishedaka intermidiate)\n","            # hypothesis and it's weight.\n","            # Weight is a measure of likelihood of the hypothesis.\n","            # [(w1, hypothesis1), (w2, hypothesis2), ...] \n","            partial_hypotheses = [(0, tokens)]\n","            final_hypotheses = []\n","\n","\n","            xyt, kb_tokens, traj_pad_mask = (el.unsqueeze(0) for el in (xyt, kb_tokens, traj_pad_mask))\n","            xyt, kb_tokens, traj_pad_mask = turncate_traj_batch(xyt, kb_tokens, traj_pad_mask)\n","            xyt, kb_tokens, traj_pad_mask = (el.to(device) for el in (xyt, kb_tokens, traj_pad_mask))\n","            xyt, kb_tokens = (el.transpose(0, 1) for el in (xyt, kb_tokens))\n","\n","\n","            encoded = self.model.encode(xyt, kb_tokens, traj_pad_mask)\n","\n","            while len(partial_hypotheses) > 0:\n","                cur_partial_score, cur_partial_hypothesis = heapq.heappop(partial_hypotheses)\n","\n","\n","                dec_in_char_seq = torch.tensor(cur_partial_hypothesis).unsqueeze(0).to(device)\n","                word_pad_mask = torch.zeros_like(dec_in_char_seq, dtype=torch.bool, device=self.device)\n","                dec_in_char_seq.transpose_(0,1)\n","\n","                \n","                next_tokens_logits = self.model.decode(encoded, dec_in_char_seq, traj_pad_mask, word_pad_mask).transpose_(0, 1)[0, -1]\n","                next_tokens_logproba = F.log_softmax(next_tokens_logits)\n","                topk_continuations = next_tokens_logproba.topk(beamsize)\n","\n","                for token_score, token_idx in zip(topk_continuations.values, topk_continuations.indices):\n","                    # Convert tesors to loat and int to avoid memory leakage.\n","                    token_score = float(token_score)\n","                    token_idx = int(token_idx)\n","\n","                    # score - нормализованная разность log_softmax всех токенов.\n","                    # Разность, а не сумма, потому что heapq - мин-куча. \n","                    old_denorm_score = cur_partial_score * len(cur_partial_hypothesis)**normalization_factor\n","                    new_score = (old_denorm_score - token_score) / (len(cur_partial_hypothesis) + 1)**normalization_factor\n","\n","                    new_hypothesis = cur_partial_hypothesis + [token_idx]\n","                    new_item = (new_score, new_hypothesis)\n","\n","                    if token_idx == self.eos_token_id or len(new_hypothesis) - initial_length >= max_steps_n:\n","                        final_hypotheses.append(new_item)\n","                    else:\n","                        heapq.heappush(partial_hypotheses, new_item)\n","\n","                if len(partial_hypotheses) > beamsize:\n","                    partial_hypotheses = heapq.nsmallest(beamsize, partial_hypotheses)\n","                    heapq.heapify(partial_hypotheses)\n","\n","            final_scores, final_token_lists = zip(*final_hypotheses)\n","            final_texts = [self.tokenizer.decode(final_token_list) for final_token_list in final_token_lists]\n","            result = list(zip(final_scores, final_texts))\n","            result.sort()\n","\n","            if verbose:\n","                print(result)\n","\n","            clean_result = []\n","            for score, word in result:\n","                word = word.removeprefix(\"<sos>\").removesuffix(\"<eos>\")\n","                if word not in self.voc_set:\n","                    continue\n","                clean_result.append((score, word))\n","                if len(clean_result) == return_hypotheses_n:\n","                    break\n","            # result = result[:return_hypotheses_n]\n","\n","            if verbose:\n","                print(clean_result)\n","\n","            return clean_result"]},{"cell_type":"code","execution_count":452,"metadata":{"execution":{"iopub.execute_input":"2023-11-05T18:53:33.550825Z","iopub.status.busy":"2023-11-05T18:53:33.550444Z","iopub.status.idle":"2023-11-05T18:53:36.597050Z","shell.execute_reply":"2023-11-05T18:53:36.596203Z","shell.execute_reply.started":"2023-11-05T18:53:33.550795Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["  0%|          | 0/10000 [00:00<?, ?it/s]C:\\Users\\proshian\\AppData\\Local\\Temp\\ipykernel_400\\478798116.py:52: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n","  next_tokens_logproba = F.log_softmax(next_tokens_logits)\n","  0%|          | 7/10000 [00:10<4:06:42,  1.48s/it]"]},{"name":"stdout","output_type":"stream","text":["Досрочно остановлено пользователем\n"]},{"name":"stderr","output_type":"stream","text":["\n"]}],"source":["grid_name_to_beam_generator = {\n","    grid_name: BeamGenerator(grid_name_to_model[grid_name], word_char_tokenizer, vocab_set, device)\n","    for grid_name in (\"default\", \"extra\")\n","}\n","\n","test_preds = create_pred_list_beam(\n","    test_dataset,\n","    grid_name_to_beam_generator,\n","    beamsize = 4,\n","    verbose = False\n",")"]},{"cell_type":"code","execution_count":450,"metadata":{},"outputs":[{"data":{"text/plain":["[['на', 'неа', 'не', 'нас'],\n"," ['что', 'сто', 'чтоб', 'сито'],\n"," ['опоздания', 'опоздание', 'опоздании', 'опоздает'],\n"," ['сколько', 'скольки', 'скольких', 'сколь'],\n"," ['дремать', 'донимать'],\n"," ['не', 'нее', 'ну', 'на'],\n"," ['как', 'кака', 'какие', 'како'],\n"," ['садовод', 'садов'],\n"," ['заметил', 'заметили', 'заметила', 'заметит'],\n"," ['ваши', 'ваги', 'аги', 'вани'],\n"," ['ок', 'он', 'оке', 'ока'],\n"," [],\n"," ['ай', 'ау', 'айк', 'айкай'],\n"," ['ищем', 'ищет', 'идем', 'идет'],\n"," ['они', 'лет', 'он', 'оно'],\n"," None,\n"," None,\n"," None]"]},"execution_count":450,"metadata":{},"output_type":"execute_result"}],"source":["test_preds[:18]"]},{"cell_type":"code","execution_count":415,"metadata":{},"outputs":[{"data":{"text/plain":["[['на', 'неа', 'не', 'нас'],\n"," ['что', 'сто', 'чтоб', 'сито'],\n"," ['опоздания', 'опоздание', 'опоздании', 'опоздает'],\n"," ['сколько', 'скольки', 'скольких', 'сколь'],\n"," ['дремать', 'донимать'],\n"," ['не', 'нее', 'ну', 'на'],\n"," ['как', 'кака', 'какие', 'како'],\n"," ['садовод', 'садов'],\n"," ['заметил', 'заметили', 'заметила', 'заметит'],\n"," ['ваши', 'ваги', 'аги', 'вани'],\n"," ['ок', 'он', 'оке', 'ока'],\n"," [],\n"," ['ай', 'ау', 'айк', 'айкай']]"]},"execution_count":415,"metadata":{},"output_type":"execute_result"}],"source":["test_preds[:13]"]},{"cell_type":"code","execution_count":109,"metadata":{"execution":{"iopub.execute_input":"2023-11-05T18:56:54.867738Z","iopub.status.busy":"2023-11-05T18:56:54.867340Z","iopub.status.idle":"2023-11-05T18:58:29.860624Z","shell.execute_reply":"2023-11-05T18:58:29.859582Z","shell.execute_reply.started":"2023-11-05T18:56:54.867709Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["  0%|          | 0/10000 [00:00<?, ?it/s]/tmp/ipykernel_32/1800239837.py:45: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n","  next_tokens_logproba = F.log_softmax(next_tokens_logits)\n","  1%|          | 87/10000 [01:34<3:00:17,  1.09s/it]"]},{"name":"stdout","output_type":"stream","text":["Досрочно остановлено пользователем\n"]},{"name":"stderr","output_type":"stream","text":["\n"]}],"source":["grid_name_to_beam_generator = {\n","    grid_name: BeamGenerator(grid_name_to_model[grid_name], word_char_tokenizer, vocab_set, device)\n","    for grid_name in (\"default\", \"extra\")\n","}\n","\n","val_preds = create_pred_list_beam(\n","    val_dataset,\n","    grid_name_to_beam_generator,\n","    beamsize = 4,\n","    verbose = False\n",")"]},{"cell_type":"code","execution_count":110,"metadata":{"execution":{"iopub.execute_input":"2023-11-05T18:58:32.735791Z","iopub.status.busy":"2023-11-05T18:58:32.735008Z","iopub.status.idle":"2023-11-05T18:58:32.744824Z","shell.execute_reply":"2023-11-05T18:58:32.743791Z","shell.execute_reply.started":"2023-11-05T18:58:32.735759Z"},"trusted":true},"outputs":[{"data":{"text/plain":["[['на', 'нас', 'неа', 'нан'],\n"," ['все', 'всем', 'всех', 'всей'],\n"," ['этом', 'этому', 'этот', 'этим'],\n"," ['добрый', 'добрые', 'добрым'],\n"," ['девочка', 'девочки', 'девочку', 'девочке'],\n"," ['сказала', 'сказал', 'сказали', 'сказало'],\n"," ['скинь', 'скин'],\n"," ['геев'],\n"," ['тобой'],\n"," ['быстра', 'баса', 'быстро', 'быстр'],\n"," ['есть', 'если', 'ест', 'ес'],\n"," ['да', 'дора', 'дав', 'дал'],\n"," ['муж', 'мало', 'малом'],\n"," ['щас', 'щам', 'ща'],\n"," ['она', 'они', 'оная', 'он'],\n"," ['проблема', 'проблемы', 'проблему', 'проблем'],\n"," ['билайн'],\n"," ['уже', 'ужен', 'ужа', 'ужи'],\n"," ['раньше'],\n"," ['нам', 'рам', 'нас', 'рас'],\n"," ['щас', 'ща', 'щам'],\n"," ['купил', 'купила', 'купили', 'купило'],\n"," ['ты', 'бы', 'тв', 'та'],\n"," ['зовут', 'хрупки', 'хочу', 'хрупать'],\n"," ['короче', 'корочек', 'корочке', 'короч'],\n"," ['лучше', 'лучшее', 'лучшей', 'лучшие'],\n"," ['приедем', 'придем', 'приедет', 'приеду'],\n"," ['размыто', 'размыть', 'размывать', 'размыт'],\n"," ['давай', 'давайте'],\n"," ['ты', 'тв', 'та', 'тыс'],\n"," ['отдать', 'отжать', 'отдаю', 'отдают'],\n"," ['привет', 'привете', 'приветик', 'привета'],\n"," ['не', 'нее', 'на', 'неа'],\n"," ['да', 'дак', 'де', 'до']]"]},"execution_count":110,"metadata":{},"output_type":"execute_result"}],"source":["val_preds[:34]"]},{"cell_type":"code","execution_count":111,"metadata":{"execution":{"iopub.execute_input":"2023-11-05T18:58:35.487420Z","iopub.status.busy":"2023-11-05T18:58:35.486371Z","iopub.status.idle":"2023-11-05T18:58:35.498740Z","shell.execute_reply":"2023-11-05T18:58:35.497782Z","shell.execute_reply.started":"2023-11-05T18:58:35.487355Z"},"trusted":true},"outputs":[{"data":{"text/plain":["['на',\n"," 'все',\n"," 'этом',\n"," 'добрый',\n"," 'девочка',\n"," 'сказала',\n"," 'скинь',\n"," 'геев',\n"," 'тобой',\n"," 'была',\n"," 'есть',\n"," 'да',\n"," 'муж',\n"," 'щас',\n"," 'она',\n"," 'проблема',\n"," 'билайн',\n"," 'уже',\n"," 'раньше',\n"," 'рам',\n"," 'щас',\n"," 'купил',\n"," 'ты',\n"," 'зовут',\n"," 'короче',\n"," 'лучше',\n"," 'приедем',\n"," 'размыто',\n"," 'давай',\n"," 'ты',\n"," 'отдать',\n"," 'привет',\n"," 'не',\n"," 'да']"]},"execution_count":111,"metadata":{},"output_type":"execute_result"}],"source":["with open(os.path.join(DATA_ROOT, \"valid.ref\"), 'r', encoding = \"utf-8\") as f:\n","    val_reference = f.read().splitlines()\n","val_reference[:34]"]},{"cell_type":"code","execution_count":84,"metadata":{"execution":{"iopub.execute_input":"2023-11-05T18:51:50.548503Z","iopub.status.busy":"2023-11-05T18:51:50.547699Z","iopub.status.idle":"2023-11-05T18:51:50.556620Z","shell.execute_reply":"2023-11-05T18:51:50.555723Z","shell.execute_reply.started":"2023-11-05T18:51:50.548466Z"},"trusted":true},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{},"source":["при beamsize = 4 на Kaggle:\n","примерно 4 часа без P100 и 3 часа с P100\n","Если использовать prepare_batch_with_pad_clipping часа"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":51,"metadata":{},"outputs":[],"source":["# from concurrent.futures import ProcessPoolExecutor\n","# from functools import partial\n","\n","# def predict_example(data, grid_name_to_greedy_generator):\n","#     i, ((xyt, kb_tokens, _, traj_pad_mask, _), _, grid_name) = data\n","#     generator = grid_name_to_greedy_generator[grid_name]\n","#     pred = generator(xyt, kb_tokens, traj_pad_mask)\n","#     pred = pred.removeprefix(\"<sos>\")\n","#     return i, pred\n","\n","# def get_model_predictions(dataset,\n","#                           grid_name_to_greedy_generator,\n","#                           num_workers=2):\n","#     \"\"\"\n","#     Creates submission file generating words greedily.\n","\n","#     If prediction is not in the vocabulary \n","#     \"\"\"\n","#     predictions = [None] * len(dataset)\n","    \n","#     g2gg = grid_name_to_greedy_generator\n","    \n","#     with ProcessPoolExecutor(num_workers) as executor:\n","#         process_function = partial(predict_example, grid_name_to_greedy_generator=g2gg)\n","#         for idx, result in tqdm.tqdm(executor.map(process_function, enumerate(dataset)), total=len(dataset)):\n","#                 predictions[idx] = result\n","    \n","#     return predictions"]},{"cell_type":"code","execution_count":52,"metadata":{},"outputs":[],"source":["# class ParallelProcessor:\n","#     def __init__(self, num_workers):\n","#         self.num_workers = num_workers\n","\n","#     def process(self, data, process_function, *additional_args):\n","#         results = [None] * len(data)\n","#         with ProcessPoolExecutor(max_workers=self.num_workers) as executor: \n","#             process_function = partial(process_function, *additional_args)\n","#             for idx, result in tqdm.tqdm(executor.map(process_function, enumerate(data)), total=len(data)):\n","#                 results[idx] = result\n","\n","#         return results"]},{"cell_type":"code","execution_count":53,"metadata":{},"outputs":[],"source":["# from multiprocessing import Pool\n","\n","# def get_model_predictions(dataset, grid_name_to_greedy_generator, num_workers=4):\n","#     predictions = [None] * len(dataset)\n","#     g2gg = grid_name_to_greedy_generator\n","\n","#     with Pool(num_workers) as pool:\n","#         process_function = partial(predict_example, grid_name_to_greedy_generator=g2gg)\n","#         for idx, result in tqdm(pool.imap(process_function, enumerate(dataset)), total=len(dataset)):\n","#             predictions[idx] = result\n","\n","#     return predictions"]},{"cell_type":"code","execution_count":152,"metadata":{},"outputs":[{"ename":"NameError","evalue":"name 'get_model_predictions' is not defined","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[1;32mc:\\Users\\proshian\\Documents\\yandex_cup_2023_ml_neuroswipe\\src\\playground.ipynb Cell 93\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/proshian/Documents/yandex_cup_2023_ml_neuroswipe/src/playground.ipynb#Y154sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m model_preds \u001b[39m=\u001b[39m get_model_predictions(\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/proshian/Documents/yandex_cup_2023_ml_neuroswipe/src/playground.ipynb#Y154sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m     test_dataset,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/proshian/Documents/yandex_cup_2023_ml_neuroswipe/src/playground.ipynb#Y154sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     grid_name_to_greedy_generator_v1,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/proshian/Documents/yandex_cup_2023_ml_neuroswipe/src/playground.ipynb#Y154sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     num_workers\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/proshian/Documents/yandex_cup_2023_ml_neuroswipe/src/playground.ipynb#Y154sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m )\n","\u001b[1;31mNameError\u001b[0m: name 'get_model_predictions' is not defined"]}],"source":["# model_preds = get_model_predictions(\n","#     test_dataset,\n","#     grid_name_to_greedy_generator_v1,\n","#     num_workers=2\n","# )"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":62,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":63,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":74,"metadata":{},"outputs":[],"source":["from tqdm import tqdm"]},{"cell_type":"markdown","metadata":{},"source":["The sell below is commented out until i find out if computation results are the same as when we use regular prepare_batch"]},{"cell_type":"code","execution_count":226,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":227,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":73,"metadata":{},"outputs":[],"source":["grid_name_to_greedy_generator = {\n","    grid_name: GreedyGenerator(grid_name_to_model[grid_name], word_char_tokenizer, device)\n","    for grid_name in (\"default\", \"extra\")\n","}"]},{"cell_type":"code","execution_count":76,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["  0%|          | 4/10000 [00:03<2:40:03,  1.04it/s]\n"]},{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[1;32mc:\\Users\\proshian\\Documents\\yandex_cup_2023_ml_neuroswipe\\src\\playground.ipynb Cell 103\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/proshian/Documents/yandex_cup_2023_ml_neuroswipe/src/playground.ipynb#Y166sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m create_submission_greedy(\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/proshian/Documents/yandex_cup_2023_ml_neuroswipe/src/playground.ipynb#Y166sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m     test_dataset,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/proshian/Documents/yandex_cup_2023_ml_neuroswipe/src/playground.ipynb#Y166sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     grid_name_to_greedy_generator,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/proshian/Documents/yandex_cup_2023_ml_neuroswipe/src/playground.ipynb#Y166sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     baseline_preds_path \u001b[39m=\u001b[39;49m \u001b[39m\"\u001b[39;49m\u001b[39m../data/submissions/sample_submission.csv\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/proshian/Documents/yandex_cup_2023_ml_neuroswipe/src/playground.ipynb#Y166sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     out_path \u001b[39m=\u001b[39;49m \u001b[39m\"\u001b[39;49m\u001b[39mgreedy_submionvdrp.csv\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/proshian/Documents/yandex_cup_2023_ml_neuroswipe/src/playground.ipynb#Y166sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     vocab_set \u001b[39m=\u001b[39;49m vocab_set\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/proshian/Documents/yandex_cup_2023_ml_neuroswipe/src/playground.ipynb#Y166sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m )\n","\u001b[1;32mc:\\Users\\proshian\\Documents\\yandex_cup_2023_ml_neuroswipe\\src\\playground.ipynb Cell 103\u001b[0m line \u001b[0;36m1\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/proshian/Documents/yandex_cup_2023_ml_neuroswipe/src/playground.ipynb#Y166sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m \u001b[39mfor\u001b[39;00m i, (data, baseline_str) \u001b[39min\u001b[39;00m tqdm(\u001b[39menumerate\u001b[39m(\u001b[39mzip\u001b[39m(dataset, baseline_f)), total\u001b[39m=\u001b[39m\u001b[39mlen\u001b[39m(dataset)):\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/proshian/Documents/yandex_cup_2023_ml_neuroswipe/src/playground.ipynb#Y166sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m     (xyt, kb_tokens, _, traj_pad_mask, _), _, grid_name \u001b[39m=\u001b[39m data\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/proshian/Documents/yandex_cup_2023_ml_neuroswipe/src/playground.ipynb#Y166sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m     pred \u001b[39m=\u001b[39m grid_name_to_greedy_generator[grid_name](xyt, kb_tokens, traj_pad_mask)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/proshian/Documents/yandex_cup_2023_ml_neuroswipe/src/playground.ipynb#Y166sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m     pred \u001b[39m=\u001b[39m pred\u001b[39m.\u001b[39mremoveprefix(\u001b[39m\"\u001b[39m\u001b[39m<sos>\u001b[39m\u001b[39m\"\u001b[39m) \n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/proshian/Documents/yandex_cup_2023_ml_neuroswipe/src/playground.ipynb#Y166sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m     \u001b[39mif\u001b[39;00m pred \u001b[39min\u001b[39;00m vocab_set:\n","\u001b[1;32mc:\\Users\\proshian\\Documents\\yandex_cup_2023_ml_neuroswipe\\src\\playground.ipynb Cell 103\u001b[0m line \u001b[0;36m2\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/proshian/Documents/yandex_cup_2023_ml_neuroswipe/src/playground.ipynb#Y166sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m x \u001b[39m=\u001b[39m [el\u001b[39m.\u001b[39munsqueeze(\u001b[39m0\u001b[39m) \u001b[39mfor\u001b[39;00m el \u001b[39min\u001b[39;00m x]\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/proshian/Documents/yandex_cup_2023_ml_neuroswipe/src/playground.ipynb#Y166sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m model_input, dummy_y \u001b[39m=\u001b[39m prepare_batch(x, dummy_y, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdevice)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/proshian/Documents/yandex_cup_2023_ml_neuroswipe/src/playground.ipynb#Y166sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m best_next_token \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel\u001b[39m.\u001b[39;49mapply(\u001b[39m*\u001b[39;49mmodel_input)\u001b[39m.\u001b[39mtranspose_(\u001b[39m0\u001b[39m, \u001b[39m1\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/proshian/Documents/yandex_cup_2023_ml_neuroswipe/src/playground.ipynb#Y166sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m best_next_token \u001b[39m=\u001b[39m best_next_token[\u001b[39m0\u001b[39m, \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\u001b[39m.\u001b[39margmax()  \u001b[39m# batch_i = 0, decoder_out_onehot_vector_seq_i = -1 \u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/proshian/Documents/yandex_cup_2023_ml_neuroswipe/src/playground.ipynb#Y166sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m \u001b[39mif\u001b[39;00m best_next_token \u001b[39m==\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39meos_token_id:\n","\u001b[1;32mc:\\Users\\proshian\\Documents\\yandex_cup_2023_ml_neuroswipe\\src\\playground.ipynb Cell 103\u001b[0m line \u001b[0;36m2\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/proshian/Documents/yandex_cup_2023_ml_neuroswipe/src/playground.ipynb#Y166sZmlsZQ%3D%3D?line=211'>212</a>\u001b[0m kb_k_emb \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mkey_pos_encoder(kb_k_emb)\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/proshian/Documents/yandex_cup_2023_ml_neuroswipe/src/playground.ipynb#Y166sZmlsZQ%3D%3D?line=212'>213</a>\u001b[0m x \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mcat((x, kb_k_emb), axis \u001b[39m=\u001b[39m \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m--> <a href='vscode-notebook-cell:/c%3A/Users/proshian/Documents/yandex_cup_2023_ml_neuroswipe/src/playground.ipynb#Y166sZmlsZQ%3D%3D?line=213'>214</a>\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mencoder(x, x_pad_mask)\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/proshian/Documents/yandex_cup_2023_ml_neuroswipe/src/playground.ipynb#Y166sZmlsZQ%3D%3D?line=214'>215</a>\u001b[0m y \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mchar_embedding(y)\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/proshian/Documents/yandex_cup_2023_ml_neuroswipe/src/playground.ipynb#Y166sZmlsZQ%3D%3D?line=215'>216</a>\u001b[0m y \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mchar_embedding_dropout(y)\n","File \u001b[1;32mc:\\Users\\proshian\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n","\u001b[1;32mc:\\Users\\proshian\\Documents\\yandex_cup_2023_ml_neuroswipe\\src\\playground.ipynb Cell 103\u001b[0m line \u001b[0;36m6\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/proshian/Documents/yandex_cup_2023_ml_neuroswipe/src/playground.ipynb#Y166sZmlsZQ%3D%3D?line=61'>62</a>\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mliner(x)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/proshian/Documents/yandex_cup_2023_ml_neuroswipe/src/playground.ipynb#Y166sZmlsZQ%3D%3D?line=62'>63</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtransformer_encoder:\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/proshian/Documents/yandex_cup_2023_ml_neuroswipe/src/playground.ipynb#Y166sZmlsZQ%3D%3D?line=63'>64</a>\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtransformer_encoder(x, src_key_padding_mask\u001b[39m=\u001b[39;49mpad_mask)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/proshian/Documents/yandex_cup_2023_ml_neuroswipe/src/playground.ipynb#Y166sZmlsZQ%3D%3D?line=64'>65</a>\u001b[0m \u001b[39mreturn\u001b[39;00m x\n","File \u001b[1;32mc:\\Users\\proshian\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n","File \u001b[1;32mc:\\Users\\proshian\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:315\u001b[0m, in \u001b[0;36mTransformerEncoder.forward\u001b[1;34m(self, src, mask, src_key_padding_mask, is_causal)\u001b[0m\n\u001b[0;32m    312\u001b[0m is_causal \u001b[39m=\u001b[39m make_causal\n\u001b[0;32m    314\u001b[0m \u001b[39mfor\u001b[39;00m mod \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlayers:\n\u001b[1;32m--> 315\u001b[0m     output \u001b[39m=\u001b[39m mod(output, src_mask\u001b[39m=\u001b[39;49mmask, is_causal\u001b[39m=\u001b[39;49mis_causal, src_key_padding_mask\u001b[39m=\u001b[39;49msrc_key_padding_mask_for_layers)\n\u001b[0;32m    317\u001b[0m \u001b[39mif\u001b[39;00m convert_to_nested:\n\u001b[0;32m    318\u001b[0m     output \u001b[39m=\u001b[39m output\u001b[39m.\u001b[39mto_padded_tensor(\u001b[39m0.\u001b[39m)\n","File \u001b[1;32mc:\\Users\\proshian\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n","File \u001b[1;32mc:\\Users\\proshian\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:591\u001b[0m, in \u001b[0;36mTransformerEncoderLayer.forward\u001b[1;34m(self, src, src_mask, src_key_padding_mask, is_causal)\u001b[0m\n\u001b[0;32m    589\u001b[0m     x \u001b[39m=\u001b[39m x \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_ff_block(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnorm2(x))\n\u001b[0;32m    590\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 591\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnorm1(x \u001b[39m+\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sa_block(x, src_mask, src_key_padding_mask, is_causal\u001b[39m=\u001b[39;49mis_causal))\n\u001b[0;32m    592\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnorm2(x \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_ff_block(x))\n\u001b[0;32m    594\u001b[0m \u001b[39mreturn\u001b[39;00m x\n","File \u001b[1;32mc:\\Users\\proshian\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:599\u001b[0m, in \u001b[0;36mTransformerEncoderLayer._sa_block\u001b[1;34m(self, x, attn_mask, key_padding_mask, is_causal)\u001b[0m\n\u001b[0;32m    597\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_sa_block\u001b[39m(\u001b[39mself\u001b[39m, x: Tensor,\n\u001b[0;32m    598\u001b[0m               attn_mask: Optional[Tensor], key_padding_mask: Optional[Tensor], is_causal: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[1;32m--> 599\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mself_attn(x, x, x,\n\u001b[0;32m    600\u001b[0m                        attn_mask\u001b[39m=\u001b[39;49mattn_mask,\n\u001b[0;32m    601\u001b[0m                        key_padding_mask\u001b[39m=\u001b[39;49mkey_padding_mask,\n\u001b[0;32m    602\u001b[0m                        need_weights\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m, is_causal\u001b[39m=\u001b[39;49mis_causal)[\u001b[39m0\u001b[39m]\n\u001b[0;32m    603\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdropout1(x)\n","File \u001b[1;32mc:\\Users\\proshian\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n","File \u001b[1;32mc:\\Users\\proshian\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\activation.py:1205\u001b[0m, in \u001b[0;36mMultiheadAttention.forward\u001b[1;34m(self, query, key, value, key_padding_mask, need_weights, attn_mask, average_attn_weights, is_causal)\u001b[0m\n\u001b[0;32m   1191\u001b[0m     attn_output, attn_output_weights \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39mmulti_head_attention_forward(\n\u001b[0;32m   1192\u001b[0m         query, key, value, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39membed_dim, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_heads,\n\u001b[0;32m   1193\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39min_proj_weight, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39min_proj_bias,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1202\u001b[0m         average_attn_weights\u001b[39m=\u001b[39maverage_attn_weights,\n\u001b[0;32m   1203\u001b[0m         is_causal\u001b[39m=\u001b[39mis_causal)\n\u001b[0;32m   1204\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 1205\u001b[0m     attn_output, attn_output_weights \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39;49mmulti_head_attention_forward(\n\u001b[0;32m   1206\u001b[0m         query, key, value, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49membed_dim, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnum_heads,\n\u001b[0;32m   1207\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49min_proj_weight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49min_proj_bias,\n\u001b[0;32m   1208\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias_k, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias_v, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49madd_zero_attn,\n\u001b[0;32m   1209\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdropout, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mout_proj\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mout_proj\u001b[39m.\u001b[39;49mbias,\n\u001b[0;32m   1210\u001b[0m         training\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtraining,\n\u001b[0;32m   1211\u001b[0m         key_padding_mask\u001b[39m=\u001b[39;49mkey_padding_mask,\n\u001b[0;32m   1212\u001b[0m         need_weights\u001b[39m=\u001b[39;49mneed_weights,\n\u001b[0;32m   1213\u001b[0m         attn_mask\u001b[39m=\u001b[39;49mattn_mask,\n\u001b[0;32m   1214\u001b[0m         average_attn_weights\u001b[39m=\u001b[39;49maverage_attn_weights,\n\u001b[0;32m   1215\u001b[0m         is_causal\u001b[39m=\u001b[39;49mis_causal)\n\u001b[0;32m   1216\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbatch_first \u001b[39mand\u001b[39;00m is_batched:\n\u001b[0;32m   1217\u001b[0m     \u001b[39mreturn\u001b[39;00m attn_output\u001b[39m.\u001b[39mtranspose(\u001b[39m1\u001b[39m, \u001b[39m0\u001b[39m), attn_output_weights\n","File \u001b[1;32mc:\\Users\\proshian\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\functional.py:5373\u001b[0m, in \u001b[0;36mmulti_head_attention_forward\u001b[1;34m(query, key, value, embed_dim_to_check, num_heads, in_proj_weight, in_proj_bias, bias_k, bias_v, add_zero_attn, dropout_p, out_proj_weight, out_proj_bias, training, key_padding_mask, need_weights, attn_mask, use_separate_proj_weight, q_proj_weight, k_proj_weight, v_proj_weight, static_k, static_v, average_attn_weights, is_causal)\u001b[0m\n\u001b[0;32m   5370\u001b[0m k \u001b[39m=\u001b[39m k\u001b[39m.\u001b[39mview(bsz, num_heads, src_len, head_dim)\n\u001b[0;32m   5371\u001b[0m v \u001b[39m=\u001b[39m v\u001b[39m.\u001b[39mview(bsz, num_heads, src_len, head_dim)\n\u001b[1;32m-> 5373\u001b[0m attn_output \u001b[39m=\u001b[39m scaled_dot_product_attention(q, k, v, attn_mask, dropout_p, is_causal)\n\u001b[0;32m   5374\u001b[0m attn_output \u001b[39m=\u001b[39m attn_output\u001b[39m.\u001b[39mpermute(\u001b[39m2\u001b[39m, \u001b[39m0\u001b[39m, \u001b[39m1\u001b[39m, \u001b[39m3\u001b[39m)\u001b[39m.\u001b[39mcontiguous()\u001b[39m.\u001b[39mview(bsz \u001b[39m*\u001b[39m tgt_len, embed_dim)\n\u001b[0;32m   5376\u001b[0m attn_output \u001b[39m=\u001b[39m linear(attn_output, out_proj_weight, out_proj_bias)\n","\u001b[1;31mKeyboardInterrupt\u001b[0m: "]}],"source":["create_submission_greedy(\n","    test_dataset,\n","    grid_name_to_greedy_generator,\n","    baseline_preds_path = \"../data/submissions/sample_submission.csv\",\n","    out_path = \"greedy_submionvdrp.csv\",\n","    vocab_set = vocab_set\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def remove_duplicates(preds):\n","    new_preds = []\n","    met_preds = {}\n","    for pred in preds:\n","        if pred in met_preds:\n","            continue\n","        met_preds.add(pred)\n","        new_preds.append(pred)\n","    return new_preds\n","\n","def get_metric(preds_list, ref):\n","    # Works properly if has duplicates or n_line_preds < 4\n","\n","    MMR = 0\n","    \n","    for preds, target in zip(preds_list, ref):\n","        preds = remove_duplicates(preds)\n","\n","        weights = [1, 0.1, 0.09, 0.08]\n","\n","        line_MRR = sum(weights[i]*pred for i, pred in enumerate(preds))\n","\n","        MMR += line_MRR\n","    \n","    MMR /= len(preds_list)\n","\n","    return MMR"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"}},"nbformat":4,"nbformat_minor":4}
