{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import copy\n",
    "from multiprocessing import cpu_count\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, IterableDataset\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "\n",
    "from model import SwipeCurveTransformer, get_m1_model\n",
    "from tokenizers import CharLevelTokenizerv2, KeyboardTokenizerv1\n",
    "from dataset import NeuroSwipeDatasetv2\n",
    "from word_generators import GreedyGenerator\n",
    "from word_generation_v2 import predict_greedy_raw_multiproc, predict_greedy_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "IN_KAGGLE = False\n",
    "\n",
    "if IN_KAGGLE:\n",
    "    DATA_ROOT = \"/kaggle/input/yandex-cup-playground\"\n",
    "    MODELS_DIR = \"\"\n",
    "else:\n",
    "    DATA_ROOT = \"../data/data_separated_grid\"\n",
    "    MODELS_ROOT = \"../data/trained_models\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_grid(grid_name: str, grids_path: str) -> dict:\n",
    "    with open(grids_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        return json.load(f)[grid_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:00<00:00, 10075.54it/s]\n",
      "100%|██████████| 10000/10000 [00:01<00:00, 9818.58it/s]\n"
     ]
    }
   ],
   "source": [
    "MAX_TRAJ_LEN = 299\n",
    "\n",
    "grid_name_to_grid_path = os.path.join(DATA_ROOT, \"gridname_to_grid.json\")\n",
    "grid_name_to_grid = {grid_name: get_grid(grid_name, grid_name_to_grid_path) for grid_name in (\"default\", \"extra\")}\n",
    "\n",
    "\n",
    "kb_tokenizer = KeyboardTokenizerv1()\n",
    "word_char_tokenizer = CharLevelTokenizerv2(os.path.join(DATA_ROOT, \"voc.txt\"))\n",
    "keyboard_selection_set = set(kb_tokenizer.i2t)\n",
    "\n",
    "\n",
    "val_path = os.path.join(DATA_ROOT, \"valid__in_train_format.jsonl\")\n",
    "\n",
    "\n",
    "val_dataset = NeuroSwipeDatasetv2(\n",
    "    data_path = val_path,\n",
    "    gridname_to_grid = grid_name_to_grid,\n",
    "    kb_tokenizer = kb_tokenizer,\n",
    "    max_traj_len = MAX_TRAJ_LEN,\n",
    "    word_tokenizer = word_char_tokenizer,\n",
    "    include_time = False,\n",
    "    include_velocities = True,\n",
    "    include_accelerations = True,\n",
    "    has_target=True,\n",
    "    has_one_grid_only=False,\n",
    "    include_grid_name=True,\n",
    "    keyboard_selection_set=keyboard_selection_set,\n",
    "    total = 10_000\n",
    ")\n",
    "\n",
    "test_path = os.path.join(DATA_ROOT, \"test.jsonl\")\n",
    "\n",
    "\n",
    "test_dataset = NeuroSwipeDatasetv2(\n",
    "    data_path = test_path,\n",
    "    gridname_to_grid = grid_name_to_grid,\n",
    "    kb_tokenizer = kb_tokenizer,\n",
    "    max_traj_len = MAX_TRAJ_LEN,\n",
    "    word_tokenizer = word_char_tokenizer,\n",
    "    include_time = False,\n",
    "    include_velocities = True,\n",
    "    include_accelerations = True,\n",
    "    has_target=False,\n",
    "    has_one_grid_only=False,\n",
    "    include_grid_name=True,\n",
    "    keyboard_selection_set=keyboard_selection_set,\n",
    "    total = 10_000\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "class NeuroSwipeGridSubset(Dataset):\n",
    "    def __init__(self, dataset: Dataset, grid_name: str):\n",
    "        self.dataset = dataset\n",
    "        self.grid_name = grid_name\n",
    "        self.grid_name_idxs = self._get_grid_name_idxs()\n",
    "        \n",
    "            \n",
    "    def _get_grid_name_idxs(self):\n",
    "        grid_name_idxs: list[int] = []\n",
    "        for i, ((_, _, _, _, _), _, grid_name) in enumerate(self.dataset):\n",
    "            if grid_name == self.grid_name:\n",
    "                grid_name_idxs.append(i)\n",
    "        return grid_name_idxs\n",
    "\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.grid_name_idxs)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.dataset[self.grid_name_idxs[idx]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_default_dataset = NeuroSwipeGridSubset(val_dataset, \"default\")\n",
    "val_extra_dataset = NeuroSwipeGridSubset(val_dataset, \"extra\")\n",
    "\n",
    "test_default_dataset = NeuroSwipeGridSubset(test_dataset, \"default\")\n",
    "test_extra_dataset = NeuroSwipeGridSubset(test_dataset, \"extra\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_duplicates(preds):\n",
    "    new_preds = []\n",
    "    met_preds = set()\n",
    "    for pred in preds:\n",
    "        if pred in met_preds:\n",
    "            continue\n",
    "        met_preds.add(pred)\n",
    "        new_preds.append(pred)\n",
    "    return new_preds\n",
    "\n",
    "\n",
    "def get_metric(preds_list, ref):\n",
    "    # Works properly if has duplicates or n_line_preds < 4\n",
    "\n",
    "    MMR = 0\n",
    "    \n",
    "    for preds, target in zip(preds_list, ref):\n",
    "        preds = remove_duplicates(preds)\n",
    "\n",
    "        weights = [1, 0.1, 0.09, 0.08]\n",
    "\n",
    "        line_MRR = sum(weights[i]* (pred == target) for i, pred in enumerate(preds))\n",
    "\n",
    "        MMR += line_MRR\n",
    "    \n",
    "    MMR /= len(preds_list)\n",
    "\n",
    "    return MMR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Callable, Dict, List\n",
    "\n",
    "\n",
    "def get_targets(dataset: NeuroSwipeDatasetv2) -> List[str]:\n",
    "    targets = []\n",
    "    for (_, _, _, _, word_pad_mask), target_tokens, _ in dataset:\n",
    "        target_len = int(torch.sum(~word_pad_mask)) - 1\n",
    "        target = word_char_tokenizer.decode(target_tokens[:target_len])\n",
    "        targets.append(target)\n",
    "    return targets\n",
    "\n",
    "def evaluate_model_greedy(val_dataset: NeuroSwipeDatasetv2,\n",
    "                          model: nn.Module,\n",
    "                          grid_name: str,\n",
    "                          targets: List[str],\n",
    "                          word_char_tokenizer: CharLevelTokenizerv2,\n",
    "                          device: torch.device):\n",
    "    \"\"\"\n",
    "    Evaluates model on validation dataset using greedy generation.\n",
    "    \"\"\"\n",
    "    assert grid_name in (\"extra\", \"default\")\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "    generator = GreedyGenerator(model, word_char_tokenizer, device)\n",
    "    grid_name_to_greedy_generator = {grid_name:  generator}\n",
    "    preds = predict_greedy_raw(val_dataset,\n",
    "                                grid_name_to_greedy_generator)\n",
    "    MMR = get_metric(preds, targets)\n",
    "    return MMR, preds\n",
    "\n",
    "\n",
    "def evaluate_weights_greedy(val_dataset: NeuroSwipeDatasetv2,\n",
    "                            model_getter: Callable,\n",
    "                            weights_path: str,\n",
    "                            grid_name: str,\n",
    "                            targets: List[str],\n",
    "                            word_char_tokenizer: CharLevelTokenizerv2,\n",
    "                            device: torch.device):\n",
    "    \n",
    "    model = model_getter(device, weights_path)\n",
    "    MMR, preds = evaluate_model_greedy(val_dataset,\n",
    "                                       model,\n",
    "                                       grid_name,\n",
    "                                       targets,\n",
    "                                       word_char_tokenizer,\n",
    "                                       device)\n",
    "    return MMR, preds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_i_to_grid_name(dataset: NeuroSwipeDatasetv2):\n",
    "#     i_to_grid_name = []\n",
    "#     for i, data in tqdm(enumerate(dataset), total=len(dataset)):\n",
    "#         (_, _, _, _, _), _, grid_name = data\n",
    "#         i_to_grid_name.append(grid_name)\n",
    "#     return i_to_grid_name\n",
    "\n",
    "\n",
    "# def combine_preds(i_to_grid_name, default_preds, extra_preds):\n",
    "#     preds = []\n",
    "#     default_i = 0\n",
    "#     extra_i = 0\n",
    "#     for i, grid_name in enumerate(i_to_grid_name):\n",
    "#         if grid_name == \"default\":\n",
    "#             preds.append(default_preds[default_i])\n",
    "#             default_i += 1\n",
    "#         elif grid_name == \"extra\":\n",
    "#             preds.append(extra_preds[extra_i])\n",
    "#             extra_i += 1\n",
    "#         else:\n",
    "#             raise ValueError(f\"Unknown grid_name: {grid_name}\")\n",
    "        \n",
    "#     return preds\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_preds(default_preds,\n",
    "                extra_preds,\n",
    "                default_idxs,\n",
    "                extra_idxs):\n",
    "    preds = [None] * (len(default_preds) + len(extra_preds))\n",
    "\n",
    "    for i, val in zip(default_idxs, default_preds):\n",
    "        preds[i] = val\n",
    "    for i, val in zip(extra_idxs, extra_preds):\n",
    "        preds[i] = val\n",
    "\n",
    "    return preds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cpu')\n",
    "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_name = \"default\"\n",
    "model_getter = get_m1_model\n",
    "weights_path = os.path.join(MODELS_ROOT, \"m1/best_model__2023_11_04__18_31_37__0.02530_default_switch_2.pt\")\n",
    "model = model_getter(device, weights_path)\n",
    "grid_name_to_greedy_generator = {grid_name: GreedyGenerator(model, word_char_tokenizer, device)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target               prediction          \n",
      "-------------------------------\n",
      "на                   на                  \n",
      "все                  фай                 \n",
      "добрый               было                \n",
      "девочка              будут               \n",
      "сказала              сейчаск             \n",
      "скинь                фий                 \n",
      "геев                 груз                \n",
      "тобой                бой                 \n",
      "была                 был                 \n",
      "да                   да                  \n",
      "муж                  муй                 \n",
      "щас                  хотя                \n",
      "она                  она                 \n",
      "проблема             пубей               \n",
      "билайн               бы                  \n",
      "уже                  же                  \n",
      "раньше               буду                \n",
      "рам                  ты                  \n",
      "щас                  ты                  \n",
      "купил                куйду               \n",
      "ты                   ты                  \n",
      "зовут                хэту                \n",
      "короче               корочей             \n",
      "размыто              тумуту              \n",
      "давай                бы                  \n",
      "отдать               эту                 \n",
      "привет               туту                \n",
      "не                   не                  \n",
      "да                   ты                  \n",
      "будете               буду                \n",
      "связи                сайзиц              \n",
      "колывань             былай               \n",
      "меня                 меня                \n",
      "напиши               байду               \n",
      "знаю                 эйду                \n",
      "мамой                таблый              \n",
      "не                   же                  \n",
      "ты                   ты                  \n",
      "только               тобой               \n",
      "они                  тебе                \n",
      "свинг                сай                 \n"
     ]
    }
   ],
   "source": [
    "greedy_generator = GreedyGenerator(model, word_char_tokenizer, device)\n",
    "\n",
    "\n",
    "print(\"{:<20} {:<20}\".format(\"target\", \"prediction\"))\n",
    "print(\"-\"*31)\n",
    "\n",
    "n_examples = 40\n",
    "\n",
    "for i, data in enumerate(val_default_dataset):\n",
    "\n",
    "    (xyt, kb_tokens, dec_in_char_seq, traj_pad_mask, word_pad_mask), target, grid_name = data\n",
    "\n",
    "    pred = greedy_generator(xyt, kb_tokens, traj_pad_mask)\n",
    "\n",
    "    # strip работвет только потому что в настоящих словах нет этих символов\n",
    "    pred = pred\n",
    "    target_len = int(torch.sum(~word_pad_mask)) - 1\n",
    "    target = word_char_tokenizer.decode(target[:target_len])\n",
    "    print(\"{:<20} {:<20}\".format(target, pred))\n",
    "\n",
    "    if i >= n_examples:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_default_targets = get_targets(val_default_dataset)\n",
    "val_extra_targets = get_targets(val_extra_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▏         | 140/9416 [00:06<06:50, 22.62it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32md:\\neuroswipe\\yandex_cup_2023_ml_neuroswipe\\src\\word_generation_v2.ipynb Cell 18\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/neuroswipe/yandex_cup_2023_ml_neuroswipe/src/word_generation_v2.ipynb#Y121sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m mmr, preds \u001b[39m=\u001b[39m evaluate_model_greedy(val_default_dataset,\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/neuroswipe/yandex_cup_2023_ml_neuroswipe/src/word_generation_v2.ipynb#Y121sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m                                     model,\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/neuroswipe/yandex_cup_2023_ml_neuroswipe/src/word_generation_v2.ipynb#Y121sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m                                     grid_name,\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/neuroswipe/yandex_cup_2023_ml_neuroswipe/src/word_generation_v2.ipynb#Y121sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m                                     val_default_targets,\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/neuroswipe/yandex_cup_2023_ml_neuroswipe/src/word_generation_v2.ipynb#Y121sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m                                     word_char_tokenizer,\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/neuroswipe/yandex_cup_2023_ml_neuroswipe/src/word_generation_v2.ipynb#Y121sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m                                     device)\n",
      "\u001b[1;32md:\\neuroswipe\\yandex_cup_2023_ml_neuroswipe\\src\\word_generation_v2.ipynb Cell 18\u001b[0m line \u001b[0;36m2\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/neuroswipe/yandex_cup_2023_ml_neuroswipe/src/word_generation_v2.ipynb#Y121sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m generator \u001b[39m=\u001b[39m GreedyGenerator(model, word_char_tokenizer, device)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/neuroswipe/yandex_cup_2023_ml_neuroswipe/src/word_generation_v2.ipynb#Y121sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m grid_name_to_greedy_generator \u001b[39m=\u001b[39m {grid_name:  generator}\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/neuroswipe/yandex_cup_2023_ml_neuroswipe/src/word_generation_v2.ipynb#Y121sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m preds \u001b[39m=\u001b[39m predict_greedy_raw(val_dataset,\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/neuroswipe/yandex_cup_2023_ml_neuroswipe/src/word_generation_v2.ipynb#Y121sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m                             grid_name_to_greedy_generator)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/neuroswipe/yandex_cup_2023_ml_neuroswipe/src/word_generation_v2.ipynb#Y121sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m MMR \u001b[39m=\u001b[39m get_metric(preds, targets)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/neuroswipe/yandex_cup_2023_ml_neuroswipe/src/word_generation_v2.ipynb#Y121sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m \u001b[39mreturn\u001b[39;00m MMR, preds\n",
      "File \u001b[1;32md:\\neuroswipe\\yandex_cup_2023_ml_neuroswipe\\src\\word_generation_v2.py:81\u001b[0m, in \u001b[0;36mpredict_greedy_raw\u001b[1;34m(dataset, grid_name_to_greedy_generator)\u001b[0m\n\u001b[0;32m     79\u001b[0m \u001b[39mfor\u001b[39;00m data \u001b[39min\u001b[39;00m tqdm(\u001b[39menumerate\u001b[39m(dataset), total\u001b[39m=\u001b[39m\u001b[39mlen\u001b[39m(dataset)):\n\u001b[0;32m     80\u001b[0m     i, ((xyt, kb_tokens, _, traj_pad_mask, _), _, grid_name) \u001b[39m=\u001b[39m data\n\u001b[1;32m---> 81\u001b[0m     pred \u001b[39m=\u001b[39m grid_name_to_greedy_generator[grid_name](xyt, kb_tokens, traj_pad_mask)\n\u001b[0;32m     82\u001b[0m     pred \u001b[39m=\u001b[39m pred\u001b[39m.\u001b[39mremoveprefix(\u001b[39m\"\u001b[39m\u001b[39m<sos>\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     83\u001b[0m     preds[i] \u001b[39m=\u001b[39m [pred]\n",
      "File \u001b[1;32md:\\neuroswipe\\yandex_cup_2023_ml_neuroswipe\\src\\word_generators.py:38\u001b[0m, in \u001b[0;36mGreedyGenerator.__call__\u001b[1;34m(self, xyt, kb_tokens, traj_pad_mask, max_steps_n)\u001b[0m\n\u001b[0;32m     36\u001b[0m x \u001b[39m=\u001b[39m [xyt, kb_tokens, dec_in_char_seq, traj_pad_mask, word_pad_mask]\n\u001b[0;32m     37\u001b[0m x \u001b[39m=\u001b[39m [el\u001b[39m.\u001b[39munsqueeze(\u001b[39m0\u001b[39m) \u001b[39mfor\u001b[39;00m el \u001b[39min\u001b[39;00m x]\n\u001b[1;32m---> 38\u001b[0m next_tokens_logits \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel\u001b[39m.\u001b[39;49mdecode(encoded, dec_in_char_seq, traj_pad_mask, word_pad_mask)\u001b[39m.\u001b[39mtranspose_(\u001b[39m0\u001b[39m, \u001b[39m1\u001b[39m)[\u001b[39m0\u001b[39m, \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\n\u001b[0;32m     39\u001b[0m best_next_token \u001b[39m=\u001b[39m next_tokens_logits\u001b[39m.\u001b[39margmax()  \u001b[39m# batch_i = 0, decoder_out_onehot_vector_seq_i = -1 \u001b[39;00m\n\u001b[0;32m     40\u001b[0m \u001b[39mif\u001b[39;00m best_next_token \u001b[39m==\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39meos_token_id:\n",
      "File \u001b[1;32md:\\neuroswipe\\yandex_cup_2023_ml_neuroswipe\\src\\model.py:221\u001b[0m, in \u001b[0;36mSwipeCurveTransformer.decode\u001b[1;34m(self, x_encoded, y, x_pad_mask, y_pad_mask)\u001b[0m\n\u001b[0;32m    219\u001b[0m y \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mchar_pos_encoder(y)\n\u001b[0;32m    220\u001b[0m mask \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_mask(\u001b[39mlen\u001b[39m(y))\u001b[39m.\u001b[39mto(device\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdevice)\n\u001b[1;32m--> 221\u001b[0m y \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdecoder(y, x_encoded, mask, x_pad_mask, y_pad_mask)\n\u001b[0;32m    222\u001b[0m \u001b[39mreturn\u001b[39;00m y\n",
      "File \u001b[1;32mc:\\Users\\SystemPoint\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1186\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1187\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1188\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1189\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1190\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1191\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32md:\\neuroswipe\\yandex_cup_2023_ml_neuroswipe\\src\\model.py:95\u001b[0m, in \u001b[0;36mSwipeCurveTransformerDecoderv1.forward\u001b[1;34m(self, x, memory, tgt_mask, memory_key_padding_mask, tgt_key_padding_mask)\u001b[0m\n\u001b[0;32m     94\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x, memory, tgt_mask, memory_key_padding_mask, tgt_key_padding_mask):\n\u001b[1;32m---> 95\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtransformer_decoder(x,\n\u001b[0;32m     96\u001b[0m                                  memory,\n\u001b[0;32m     97\u001b[0m                                  tgt_mask\u001b[39m=\u001b[39;49mtgt_mask,\n\u001b[0;32m     98\u001b[0m                                  memory_key_padding_mask\u001b[39m=\u001b[39;49mmemory_key_padding_mask,\n\u001b[0;32m     99\u001b[0m                                  tgt_key_padding_mask\u001b[39m=\u001b[39;49mtgt_key_padding_mask)\n\u001b[0;32m    100\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mout(x)\n\u001b[0;32m    101\u001b[0m     \u001b[39mreturn\u001b[39;00m x\n",
      "File \u001b[1;32mc:\\Users\\SystemPoint\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1186\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1187\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1188\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1189\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1190\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1191\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\SystemPoint\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:333\u001b[0m, in \u001b[0;36mTransformerDecoder.forward\u001b[1;34m(self, tgt, memory, tgt_mask, memory_mask, tgt_key_padding_mask, memory_key_padding_mask)\u001b[0m\n\u001b[0;32m    330\u001b[0m output \u001b[39m=\u001b[39m tgt\n\u001b[0;32m    332\u001b[0m \u001b[39mfor\u001b[39;00m mod \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlayers:\n\u001b[1;32m--> 333\u001b[0m     output \u001b[39m=\u001b[39m mod(output, memory, tgt_mask\u001b[39m=\u001b[39;49mtgt_mask,\n\u001b[0;32m    334\u001b[0m                  memory_mask\u001b[39m=\u001b[39;49mmemory_mask,\n\u001b[0;32m    335\u001b[0m                  tgt_key_padding_mask\u001b[39m=\u001b[39;49mtgt_key_padding_mask,\n\u001b[0;32m    336\u001b[0m                  memory_key_padding_mask\u001b[39m=\u001b[39;49mmemory_key_padding_mask)\n\u001b[0;32m    338\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnorm \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    339\u001b[0m     output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnorm(output)\n",
      "File \u001b[1;32mc:\\Users\\SystemPoint\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1186\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1187\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1188\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1189\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1190\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1191\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\SystemPoint\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:652\u001b[0m, in \u001b[0;36mTransformerDecoderLayer.forward\u001b[1;34m(self, tgt, memory, tgt_mask, memory_mask, tgt_key_padding_mask, memory_key_padding_mask)\u001b[0m\n\u001b[0;32m    650\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    651\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnorm1(x \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sa_block(x, tgt_mask, tgt_key_padding_mask))\n\u001b[1;32m--> 652\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnorm2(x \u001b[39m+\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_mha_block(x, memory, memory_mask, memory_key_padding_mask))\n\u001b[0;32m    653\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnorm3(x \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_ff_block(x))\n\u001b[0;32m    655\u001b[0m \u001b[39mreturn\u001b[39;00m x\n",
      "File \u001b[1;32mc:\\Users\\SystemPoint\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:669\u001b[0m, in \u001b[0;36mTransformerDecoderLayer._mha_block\u001b[1;34m(self, x, mem, attn_mask, key_padding_mask)\u001b[0m\n\u001b[0;32m    667\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_mha_block\u001b[39m(\u001b[39mself\u001b[39m, x: Tensor, mem: Tensor,\n\u001b[0;32m    668\u001b[0m                attn_mask: Optional[Tensor], key_padding_mask: Optional[Tensor]) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[1;32m--> 669\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmultihead_attn(x, mem, mem,\n\u001b[0;32m    670\u001b[0m                             attn_mask\u001b[39m=\u001b[39;49mattn_mask,\n\u001b[0;32m    671\u001b[0m                             key_padding_mask\u001b[39m=\u001b[39;49mkey_padding_mask,\n\u001b[0;32m    672\u001b[0m                             need_weights\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)[\u001b[39m0\u001b[39m]\n\u001b[0;32m    673\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdropout2(x)\n",
      "File \u001b[1;32mc:\\Users\\SystemPoint\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1186\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1187\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1188\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1189\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1190\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1191\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\SystemPoint\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\activation.py:1167\u001b[0m, in \u001b[0;36mMultiheadAttention.forward\u001b[1;34m(self, query, key, value, key_padding_mask, need_weights, attn_mask, average_attn_weights)\u001b[0m\n\u001b[0;32m   1156\u001b[0m     attn_output, attn_output_weights \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39mmulti_head_attention_forward(\n\u001b[0;32m   1157\u001b[0m         query, key, value, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39membed_dim, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_heads,\n\u001b[0;32m   1158\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39min_proj_weight, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39min_proj_bias,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1164\u001b[0m         q_proj_weight\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mq_proj_weight, k_proj_weight\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mk_proj_weight,\n\u001b[0;32m   1165\u001b[0m         v_proj_weight\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mv_proj_weight, average_attn_weights\u001b[39m=\u001b[39maverage_attn_weights)\n\u001b[0;32m   1166\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 1167\u001b[0m     attn_output, attn_output_weights \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39;49mmulti_head_attention_forward(\n\u001b[0;32m   1168\u001b[0m         query, key, value, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49membed_dim, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnum_heads,\n\u001b[0;32m   1169\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49min_proj_weight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49min_proj_bias,\n\u001b[0;32m   1170\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias_k, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias_v, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49madd_zero_attn,\n\u001b[0;32m   1171\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdropout, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mout_proj\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mout_proj\u001b[39m.\u001b[39;49mbias,\n\u001b[0;32m   1172\u001b[0m         training\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtraining,\n\u001b[0;32m   1173\u001b[0m         key_padding_mask\u001b[39m=\u001b[39;49mkey_padding_mask, need_weights\u001b[39m=\u001b[39;49mneed_weights,\n\u001b[0;32m   1174\u001b[0m         attn_mask\u001b[39m=\u001b[39;49mattn_mask, average_attn_weights\u001b[39m=\u001b[39;49maverage_attn_weights)\n\u001b[0;32m   1175\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbatch_first \u001b[39mand\u001b[39;00m is_batched:\n\u001b[0;32m   1176\u001b[0m     \u001b[39mreturn\u001b[39;00m attn_output\u001b[39m.\u001b[39mtranspose(\u001b[39m1\u001b[39m, \u001b[39m0\u001b[39m), attn_output_weights\n",
      "File \u001b[1;32mc:\\Users\\SystemPoint\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\functional.py:5106\u001b[0m, in \u001b[0;36mmulti_head_attention_forward\u001b[1;34m(query, key, value, embed_dim_to_check, num_heads, in_proj_weight, in_proj_bias, bias_k, bias_v, add_zero_attn, dropout_p, out_proj_weight, out_proj_bias, training, key_padding_mask, need_weights, attn_mask, use_separate_proj_weight, q_proj_weight, k_proj_weight, v_proj_weight, static_k, static_v, average_attn_weights)\u001b[0m\n\u001b[0;32m   5104\u001b[0m     k \u001b[39m=\u001b[39m static_k\n\u001b[0;32m   5105\u001b[0m \u001b[39mif\u001b[39;00m static_v \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m-> 5106\u001b[0m     v \u001b[39m=\u001b[39m v\u001b[39m.\u001b[39;49mcontiguous()\u001b[39m.\u001b[39;49mview(v\u001b[39m.\u001b[39;49mshape[\u001b[39m0\u001b[39;49m], bsz \u001b[39m*\u001b[39;49m num_heads, head_dim)\u001b[39m.\u001b[39mtranspose(\u001b[39m0\u001b[39m, \u001b[39m1\u001b[39m)\n\u001b[0;32m   5107\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   5108\u001b[0m     \u001b[39m# TODO finish disentangling control flow so we don't do in-projections when statics are passed\u001b[39;00m\n\u001b[0;32m   5109\u001b[0m     \u001b[39massert\u001b[39;00m static_v\u001b[39m.\u001b[39msize(\u001b[39m0\u001b[39m) \u001b[39m==\u001b[39m bsz \u001b[39m*\u001b[39m num_heads, \\\n\u001b[0;32m   5110\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mexpecting static_v.size(0) of \u001b[39m\u001b[39m{\u001b[39;00mbsz \u001b[39m*\u001b[39m num_heads\u001b[39m}\u001b[39;00m\u001b[39m, but got \u001b[39m\u001b[39m{\u001b[39;00mstatic_v\u001b[39m.\u001b[39msize(\u001b[39m0\u001b[39m)\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "mmr, preds = evaluate_model_greedy(val_default_dataset,\n",
    "                                    model,\n",
    "                                    grid_name,\n",
    "                                    val_default_targets,\n",
    "                                    word_char_tokenizer,\n",
    "                                    device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mmr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['скинь'], ['мазора'], ['то'], ['анюта'], ['звони'], ['лесник'], ['минут'], ['забрала'], ['на'], ['обуд'], ['завтра'], ['такими'], ['давай'], ['посади'], ['бон'], ['даже'], ['перчатка'], ['работа'], ['никого'], ['отресли'], ['не'], ['раз'], ['блин'], ['пока'], ['ну'], ['тогда'], ['башка'], ['был'], ['продал'], ['хочу'], ['хорошая'], ['кофе'], ['быть'], ['ты'], ['стиревем'], ['мойкой'], ['мы'], ['но'], ['мо'], ['нету'], ['ну'], ['так'], ['ты'], ['закрой'], ['сейчас'], ['пойми'], ['что'], ['поровну'], ['это'], ['не']]\n"
     ]
    }
   ],
   "source": [
    "print(preds[200:250])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'m1_v2/best_model__2023_11_09__10_36_02__0.14229_default_switch_2_try_2.pt': 0.8512107051826678}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{\"m1_v2/best_model__2023_11_09__10_36_02__0.14229_default_switch_2_try_2.pt\": 0.8512107051826678,\n",
    " \"m1_bigger/m1_bigger_v2__2023_11_10__13_38_32__0.50552_default_l2_5e-05_ls0.045_switch_0.pt\": 0.810429056924384,\n",
    " \"m1_bigger/m1_bigger_v2__2023_11_10__16_36_38__0.49848_default_l2_5e-05_ls0.045_switch_0.pt\": 0.818500424808836}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    }
   ],
   "source": [
    "print(cpu_count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/9416 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "predictions = predict_greedy_raw_multiproc(val_default_dataset,\n",
    "                                           grid_name_to_greedy_generator,\n",
    "                                           num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 56/9416 [00:02<06:41, 23.30it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32md:\\neuroswipe\\yandex_cup_2023_ml_neuroswipe\\src\\word_generation_v2.ipynb Cell 27\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/neuroswipe/yandex_cup_2023_ml_neuroswipe/src/word_generation_v2.ipynb#Y135sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m predictions \u001b[39m=\u001b[39m predict_greedy_raw(val_default_dataset,\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/neuroswipe/yandex_cup_2023_ml_neuroswipe/src/word_generation_v2.ipynb#Y135sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m                                 grid_name_to_greedy_generator)\n",
      "File \u001b[1;32md:\\neuroswipe\\yandex_cup_2023_ml_neuroswipe\\src\\word_generation_v2.py:81\u001b[0m, in \u001b[0;36mpredict_greedy_raw\u001b[1;34m(dataset, grid_name_to_greedy_generator)\u001b[0m\n\u001b[0;32m     79\u001b[0m \u001b[39mfor\u001b[39;00m data \u001b[39min\u001b[39;00m tqdm(\u001b[39menumerate\u001b[39m(dataset), total\u001b[39m=\u001b[39m\u001b[39mlen\u001b[39m(dataset)):\n\u001b[0;32m     80\u001b[0m     i, ((xyt, kb_tokens, _, traj_pad_mask, _), _, grid_name) \u001b[39m=\u001b[39m data\n\u001b[1;32m---> 81\u001b[0m     pred \u001b[39m=\u001b[39m grid_name_to_greedy_generator[grid_name](xyt, kb_tokens, traj_pad_mask)\n\u001b[0;32m     82\u001b[0m     pred \u001b[39m=\u001b[39m pred\u001b[39m.\u001b[39mremoveprefix(\u001b[39m\"\u001b[39m\u001b[39m<sos>\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     83\u001b[0m     preds[i] \u001b[39m=\u001b[39m [pred]\n",
      "File \u001b[1;32md:\\neuroswipe\\yandex_cup_2023_ml_neuroswipe\\src\\word_generators.py:26\u001b[0m, in \u001b[0;36mGreedyGenerator.__call__\u001b[1;34m(self, xyt, kb_tokens, traj_pad_mask, max_steps_n)\u001b[0m\n\u001b[0;32m     22\u001b[0m xyt, kb_tokens, traj_pad_mask \u001b[39m=\u001b[39m (el\u001b[39m.\u001b[39mto(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdevice) \u001b[39mfor\u001b[39;00m el \u001b[39min\u001b[39;00m (xyt, kb_tokens, traj_pad_mask))\n\u001b[0;32m     23\u001b[0m xyt, kb_tokens \u001b[39m=\u001b[39m (el\u001b[39m.\u001b[39mtranspose(\u001b[39m0\u001b[39m, \u001b[39m1\u001b[39m) \u001b[39mfor\u001b[39;00m el \u001b[39min\u001b[39;00m (xyt, kb_tokens))\n\u001b[1;32m---> 26\u001b[0m encoded \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel\u001b[39m.\u001b[39;49mencode(xyt, kb_tokens, traj_pad_mask)\n\u001b[0;32m     29\u001b[0m \u001b[39mfor\u001b[39;00m _ \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(max_steps_n):\n\u001b[0;32m     31\u001b[0m     dec_in_char_seq \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mtensor(tokens)\u001b[39m.\u001b[39munsqueeze(\u001b[39m0\u001b[39m)\u001b[39m.\u001b[39mto(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdevice)\n",
      "File \u001b[1;32md:\\neuroswipe\\yandex_cup_2023_ml_neuroswipe\\src\\model.py:213\u001b[0m, in \u001b[0;36mSwipeCurveTransformer.encode\u001b[1;34m(self, x, kb_tokens, x_pad_mask)\u001b[0m\n\u001b[0;32m    211\u001b[0m kb_k_emb \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mkey_pos_encoder(kb_k_emb)\n\u001b[0;32m    212\u001b[0m x \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mcat((x, kb_k_emb), axis \u001b[39m=\u001b[39m \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m--> 213\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mencoder(x, x_pad_mask)\n\u001b[0;32m    214\u001b[0m \u001b[39mreturn\u001b[39;00m x\n",
      "File \u001b[1;32mc:\\Users\\SystemPoint\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1186\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1187\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1188\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1189\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1190\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1191\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32md:\\neuroswipe\\yandex_cup_2023_ml_neuroswipe\\src\\model.py:64\u001b[0m, in \u001b[0;36mSwipeCurveTransformerEncoderv1.forward\u001b[1;34m(self, x, pad_mask)\u001b[0m\n\u001b[0;32m     62\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mliner(x)\n\u001b[0;32m     63\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtransformer_encoder:\n\u001b[1;32m---> 64\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtransformer_encoder(x, src_key_padding_mask\u001b[39m=\u001b[39;49mpad_mask)\n\u001b[0;32m     65\u001b[0m \u001b[39mreturn\u001b[39;00m x\n",
      "File \u001b[1;32mc:\\Users\\SystemPoint\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1186\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1187\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1188\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1189\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1190\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1191\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\SystemPoint\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:280\u001b[0m, in \u001b[0;36mTransformerEncoder.forward\u001b[1;34m(self, src, mask, src_key_padding_mask)\u001b[0m\n\u001b[0;32m    277\u001b[0m         src_key_padding_mask_for_layers \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    279\u001b[0m \u001b[39mfor\u001b[39;00m mod \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlayers:\n\u001b[1;32m--> 280\u001b[0m     output \u001b[39m=\u001b[39m mod(output, src_mask\u001b[39m=\u001b[39;49mmask, src_key_padding_mask\u001b[39m=\u001b[39;49msrc_key_padding_mask_for_layers)\n\u001b[0;32m    282\u001b[0m \u001b[39mif\u001b[39;00m convert_to_nested:\n\u001b[0;32m    283\u001b[0m     output \u001b[39m=\u001b[39m output\u001b[39m.\u001b[39mto_padded_tensor(\u001b[39m0.\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\SystemPoint\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1186\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1187\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1188\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1189\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1190\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1191\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\SystemPoint\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:538\u001b[0m, in \u001b[0;36mTransformerEncoderLayer.forward\u001b[1;34m(self, src, src_mask, src_key_padding_mask)\u001b[0m\n\u001b[0;32m    536\u001b[0m     x \u001b[39m=\u001b[39m x \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_ff_block(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnorm2(x))\n\u001b[0;32m    537\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 538\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnorm1(x \u001b[39m+\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sa_block(x, src_mask, src_key_padding_mask))\n\u001b[0;32m    539\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnorm2(x \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_ff_block(x))\n\u001b[0;32m    541\u001b[0m \u001b[39mreturn\u001b[39;00m x\n",
      "File \u001b[1;32mc:\\Users\\SystemPoint\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:546\u001b[0m, in \u001b[0;36mTransformerEncoderLayer._sa_block\u001b[1;34m(self, x, attn_mask, key_padding_mask)\u001b[0m\n\u001b[0;32m    544\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_sa_block\u001b[39m(\u001b[39mself\u001b[39m, x: Tensor,\n\u001b[0;32m    545\u001b[0m               attn_mask: Optional[Tensor], key_padding_mask: Optional[Tensor]) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[1;32m--> 546\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mself_attn(x, x, x,\n\u001b[0;32m    547\u001b[0m                        attn_mask\u001b[39m=\u001b[39;49mattn_mask,\n\u001b[0;32m    548\u001b[0m                        key_padding_mask\u001b[39m=\u001b[39;49mkey_padding_mask,\n\u001b[0;32m    549\u001b[0m                        need_weights\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)[\u001b[39m0\u001b[39m]\n\u001b[0;32m    550\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdropout1(x)\n",
      "File \u001b[1;32mc:\\Users\\SystemPoint\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1186\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1187\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1188\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1189\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1190\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1191\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\SystemPoint\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\activation.py:1167\u001b[0m, in \u001b[0;36mMultiheadAttention.forward\u001b[1;34m(self, query, key, value, key_padding_mask, need_weights, attn_mask, average_attn_weights)\u001b[0m\n\u001b[0;32m   1156\u001b[0m     attn_output, attn_output_weights \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39mmulti_head_attention_forward(\n\u001b[0;32m   1157\u001b[0m         query, key, value, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39membed_dim, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_heads,\n\u001b[0;32m   1158\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39min_proj_weight, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39min_proj_bias,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1164\u001b[0m         q_proj_weight\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mq_proj_weight, k_proj_weight\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mk_proj_weight,\n\u001b[0;32m   1165\u001b[0m         v_proj_weight\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mv_proj_weight, average_attn_weights\u001b[39m=\u001b[39maverage_attn_weights)\n\u001b[0;32m   1166\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 1167\u001b[0m     attn_output, attn_output_weights \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39;49mmulti_head_attention_forward(\n\u001b[0;32m   1168\u001b[0m         query, key, value, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49membed_dim, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnum_heads,\n\u001b[0;32m   1169\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49min_proj_weight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49min_proj_bias,\n\u001b[0;32m   1170\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias_k, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias_v, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49madd_zero_attn,\n\u001b[0;32m   1171\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdropout, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mout_proj\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mout_proj\u001b[39m.\u001b[39;49mbias,\n\u001b[0;32m   1172\u001b[0m         training\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtraining,\n\u001b[0;32m   1173\u001b[0m         key_padding_mask\u001b[39m=\u001b[39;49mkey_padding_mask, need_weights\u001b[39m=\u001b[39;49mneed_weights,\n\u001b[0;32m   1174\u001b[0m         attn_mask\u001b[39m=\u001b[39;49mattn_mask, average_attn_weights\u001b[39m=\u001b[39;49maverage_attn_weights)\n\u001b[0;32m   1175\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbatch_first \u001b[39mand\u001b[39;00m is_batched:\n\u001b[0;32m   1176\u001b[0m     \u001b[39mreturn\u001b[39;00m attn_output\u001b[39m.\u001b[39mtranspose(\u001b[39m1\u001b[39m, \u001b[39m0\u001b[39m), attn_output_weights\n",
      "File \u001b[1;32mc:\\Users\\SystemPoint\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\functional.py:5158\u001b[0m, in \u001b[0;36mmulti_head_attention_forward\u001b[1;34m(query, key, value, embed_dim_to_check, num_heads, in_proj_weight, in_proj_bias, bias_k, bias_v, add_zero_attn, dropout_p, out_proj_weight, out_proj_bias, training, key_padding_mask, need_weights, attn_mask, use_separate_proj_weight, q_proj_weight, k_proj_weight, v_proj_weight, static_k, static_v, average_attn_weights)\u001b[0m\n\u001b[0;32m   5156\u001b[0m q_scaled \u001b[39m=\u001b[39m q \u001b[39m/\u001b[39m math\u001b[39m.\u001b[39msqrt(E)\n\u001b[0;32m   5157\u001b[0m \u001b[39mif\u001b[39;00m attn_mask \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m-> 5158\u001b[0m     attn_output_weights \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mbaddbmm(attn_mask, q_scaled, k\u001b[39m.\u001b[39;49mtranspose(\u001b[39m-\u001b[39;49m\u001b[39m2\u001b[39;49m, \u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m))\n\u001b[0;32m   5159\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   5160\u001b[0m     attn_output_weights \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mbmm(q_scaled, k\u001b[39m.\u001b[39mtranspose(\u001b[39m-\u001b[39m\u001b[39m2\u001b[39m, \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m))\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "predictions = predict_greedy_raw(val_default_dataset,\n",
    "                                grid_name_to_greedy_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate models separately and as a pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_default_targets = get_targets(val_default_dataset)\n",
    "val_extra_targets = get_targets(val_extra_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_name = \"default\"\n",
    "model_getter = get_m1_model\n",
    "weights_path = os.path.join(MODELS_ROOT, \"m1_v2/m1_v2__2023_11_09__10_36_02__0.14229_default_switch_0.pt\")\n",
    "model = model_getter(device, weights_path)\n",
    "grid_name_to_greedy_generator = {grid_name: GreedyGenerator(model, word_char_tokenizer, device)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9416/9416 [04:47<00:00, 32.76it/s]\n"
     ]
    }
   ],
   "source": [
    "default_predictions = predict_greedy_raw_multiproc(val_default_dataset,\n",
    "                                                    grid_name_to_greedy_generator,\n",
    "                                                    num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8512107051826678"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "default_MMR =  get_metric(default_predictions, val_default_targets)\n",
    "default_MMR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_name = \"extra\"\n",
    "model_getter = get_m1_model\n",
    "weights_path = os.path.join(MODELS_ROOT, \"m1_v2/m1_v2__2023_11_09__17_47_40__0.14301_extra_l2_1e-05_switch_0.pt\")\n",
    "model = model_getter(device, weights_path)\n",
    "grid_name_to_greedy_generator = {grid_name: GreedyGenerator(model, word_char_tokenizer, device)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 584/584 [00:18<00:00, 31.60it/s]\n"
     ]
    }
   ],
   "source": [
    "extra_predictions = predict_greedy_raw_multiproc(val_extra_dataset,\n",
    "                                                 grid_name_to_greedy_generator,\n",
    "                                                 num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.851027397260274"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extra_MMR = get_metric(extra_predictions, val_extra_targets)\n",
    "extra_MMR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_preds = merge_preds(default_predictions, extra_predictions, val_default_dataset.grid_name_idxs, val_extra_dataset.grid_name_idxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_targets = None\n",
    "with open(os.path.join(DATA_ROOT, \"valid.ref\"), 'r', encoding='utf-8') as f:\n",
    "    all_targets = f.read().splitlines() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8512"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_MMR = get_metric(all_preds, all_targets)\n",
    "full_MMR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's create a greedy submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Set, List, Tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def separate_invalid_preds_beam(preds: List[List[Tuple[float, str]]],\n",
    "                                vocab_set: Set[str]) -> Tuple[List[List[str]], Dict[int, List[str]]]:\n",
    "    \"\"\"\n",
    "    Arguments:\n",
    "    ----------\n",
    "    preds: List[List[Tuple[float, str]]]\n",
    "        preds[i] stores raw output of a word generator corresponding\n",
    "        to the i-th curve. The raw output is a list of tuples, where\n",
    "        each tuple is (-log_probability, word). The list is sorted\n",
    "        by -log_probability in ascending order.\n",
    "    vocab_set: Set[str]\n",
    "        A set of all possible words.\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    all_real_word_preds: List[List[str]]\n",
    "        all_real_word_preds stores 4 lists of real words sorted by\n",
    "        -log_probability in ascending order.\n",
    "    all_errorous_word_preds: Dict[int, List[str]]\n",
    "        all_errorous_word_preds[i] stores a list of errorous words\n",
    "        sorted by -log_probability in ascending order if all_real_word_preds[i]\n",
    "        has less than 4 words. Otherwise, all_errorous_word_preds does not\n",
    "        have the key i.\n",
    "    \"\"\"\n",
    "\n",
    "    all_real_word_preds = []\n",
    "    all_errorous_word_preds = {}\n",
    "\n",
    "    for i, pred in enumerate(preds):\n",
    "        real_word_preds = []\n",
    "        errorous_word_preds = []\n",
    "        for _, word in pred:\n",
    "            if word in vocab_set:\n",
    "                real_word_preds.append(word)\n",
    "                if len(real_word_preds) == 4:\n",
    "                    break\n",
    "            else:\n",
    "                errorous_word_preds.append(word)\n",
    "        \n",
    "        all_real_word_preds.append(real_word_preds)\n",
    "        if len(real_word_preds) < 4:\n",
    "            all_errorous_word_preds[i] = errorous_word_preds\n",
    "\n",
    "    return all_real_word_preds, all_errorous_word_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def separate_invalid_preds_greedy(preds: List[List[str]],\n",
    "                                vocab_set: Set[str]) -> Tuple[List[List[str]], Dict[int, List[str]]]:\n",
    "\n",
    "    all_real_word_preds = []\n",
    "    all_errorous_word_preds = {}\n",
    "\n",
    "    for i, pred in enumerate(preds):\n",
    "        real_word_preds = []\n",
    "        errorous_word_preds = []\n",
    "        for word in pred:\n",
    "            if word in vocab_set:\n",
    "                real_word_preds.append(word)\n",
    "                if len(real_word_preds) == 4:\n",
    "                    break\n",
    "            else:\n",
    "                errorous_word_preds.append(word)\n",
    "        \n",
    "        all_real_word_preds.append(real_word_preds)\n",
    "        if len(real_word_preds) < 4:\n",
    "            all_errorous_word_preds[i] = errorous_word_preds\n",
    "\n",
    "    return all_real_word_preds, all_errorous_word_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment_predictions(preds, augment_list):\n",
    "    augmented_preds = copy.deepcopy(preds)\n",
    "    for pred, aug in zip(augmented_preds, augment_list):\n",
    "        for aug_el in aug:\n",
    "            if len(pred) >= 4:\n",
    "                break\n",
    "            pred.append(aug_el)\n",
    "    return augmented_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_submission(preds_list, out_path) -> None:\n",
    "    if os.path.exists(out_path):\n",
    "        raise ValueError(f\"File {out_path} already exists\")\n",
    "    \n",
    "    with open(out_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        for preds in preds_list:\n",
    "            pred_str = \",\".join(preds)\n",
    "            f.write(pred_str + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vocab_set(vocab_path: str):\n",
    "    with open(vocab_path, 'r', encoding = \"utf-8\") as f:\n",
    "        return set(f.read().splitlines())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9373/9373 [05:08<00:00, 30.40it/s]\n"
     ]
    }
   ],
   "source": [
    "grid_name = \"default\"\n",
    "model_getter = get_m1_model\n",
    "weights_path = os.path.join(MODELS_ROOT, \"m1_v2/m1_v2__2023_11_09__10_36_02__0.14229_default_switch_0.pt\")\n",
    "model = model_getter(device, weights_path)\n",
    "grid_name_to_greedy_generator = {grid_name: GreedyGenerator(model, word_char_tokenizer, device)}\n",
    "default_test_predictions = predict_greedy_raw_multiproc(test_default_dataset,\n",
    "                                                        grid_name_to_greedy_generator,\n",
    "                                                        num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 627/627 [00:22<00:00, 27.47it/s]\n"
     ]
    }
   ],
   "source": [
    "grid_name = \"extra\"\n",
    "model_getter = get_m1_model\n",
    "weights_path = os.path.join(MODELS_ROOT, \"m1_v2/m1_v2__2023_11_09__17_47_40__0.14301_extra_l2_1e-05_switch_0.pt\")\n",
    "model = model_getter(device, weights_path)\n",
    "grid_name_to_greedy_generator = {grid_name: GreedyGenerator(model, word_char_tokenizer, device)}\n",
    "extra_test_predictions = predict_greedy_raw_multiproc(test_extra_dataset,\n",
    "                                                 grid_name_to_greedy_generator,\n",
    "                                                 num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_test_preds = merge_preds(default_test_predictions, extra_test_predictions, test_default_dataset.grid_name_idxs, test_extra_dataset.grid_name_idxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_set = get_vocab_set(os.path.join(DATA_ROOT, \"voc.txt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_test_preds, invalid_test_preds = separate_invalid_preds_greedy(all_test_preds, vocab_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['на'],\n",
       " ['что'],\n",
       " ['опоздания'],\n",
       " ['сколько'],\n",
       " [],\n",
       " ['не'],\n",
       " ['как'],\n",
       " ['садовод'],\n",
       " ['заметил'],\n",
       " ['ваги']]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_test_preds[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "augment_list = None\n",
    "with open(r\"..\\data\\submissions\\sample_submission.csv\", 'r', encoding = 'utf-8') as f:\n",
    "    augment_lines = f.read().splitlines()\n",
    "augment_list = [line.split(\",\") for line in augment_lines]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "augmented_test_preds = augment_predictions(clean_test_preds, augment_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['на'],\n",
       " ['что'],\n",
       " ['опоздания'],\n",
       " ['сколько'],\n",
       " [],\n",
       " ['не'],\n",
       " ['как'],\n",
       " ['садовод'],\n",
       " ['заметил'],\n",
       " ['ваги']]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "augmented_test_preds[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_name = \"m1_v2__0.14229_deault__0.14301_extra__greedy.csv\"\n",
    "out_path = rf\"..\\data\\submissions\\{submission_name}\"\n",
    "create_submission(augmented_test_preds, out_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
