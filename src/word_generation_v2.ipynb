{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, IterableDataset\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "\n",
    "from model import SwipeCurveTransformer, get_m1_model\n",
    "from tokenizers import CharLevelTokenizerv2, KeyboardTokenizerv1\n",
    "from dataset import NeuroSwipeDatasetv2\n",
    "from word_generators import GreedyGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "IN_KAGGLE = False\n",
    "\n",
    "if IN_KAGGLE:\n",
    "    DATA_ROOT = \"/kaggle/input/yandex-cup-playground\"\n",
    "    MODELS_DIR = \"\"\n",
    "else:\n",
    "    DATA_ROOT = \"../data/data_separated_grid\"\n",
    "    # MODELS_DIR = \"../data/trained_models/m1\"\n",
    "    MODELS_ROOT = \"../data/trained_models\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_grid(grid_name: str, grids_path: str) -> dict:\n",
    "    with open(grids_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        return json.load(f)[grid_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:01<00:00, 6920.25it/s]\n",
      "100%|██████████| 10000/10000 [00:02<00:00, 4257.13it/s]\n"
     ]
    }
   ],
   "source": [
    "MAX_TRAJ_LEN = 299\n",
    "\n",
    "grid_name_to_grid_path = os.path.join(DATA_ROOT, \"gridname_to_grid.json\")\n",
    "grid_name_to_grid = {grid_name: get_grid(grid_name, grid_name_to_grid_path) for grid_name in (\"default\", \"extra\")}\n",
    "\n",
    "\n",
    "kb_tokenizer = KeyboardTokenizerv1()\n",
    "word_char_tokenizer = CharLevelTokenizerv2(os.path.join(DATA_ROOT, \"voc.txt\"))\n",
    "keyboard_selection_set = set(kb_tokenizer.i2t)\n",
    "\n",
    "\n",
    "val_path = os.path.join(DATA_ROOT, \"valid__in_train_format.jsonl\")\n",
    "\n",
    "\n",
    "val_dataset = NeuroSwipeDatasetv2(\n",
    "    data_path = val_path,\n",
    "    gridname_to_grid = grid_name_to_grid,\n",
    "    kb_tokenizer = kb_tokenizer,\n",
    "    max_traj_len = MAX_TRAJ_LEN,\n",
    "    word_tokenizer = word_char_tokenizer,\n",
    "    include_time = False,\n",
    "    include_velocities = True,\n",
    "    include_accelerations = True,\n",
    "    has_target=True,\n",
    "    has_one_grid_only=False,\n",
    "    include_grid_name=True,\n",
    "    keyboard_selection_set=keyboard_selection_set,\n",
    "    total = 10_000\n",
    ")\n",
    "\n",
    "test_path = os.path.join(DATA_ROOT, \"test.jsonl\")\n",
    "\n",
    "\n",
    "test_dataset = NeuroSwipeDatasetv2(\n",
    "    data_path = test_path,\n",
    "    gridname_to_grid = grid_name_to_grid,\n",
    "    kb_tokenizer = kb_tokenizer,\n",
    "    max_traj_len = MAX_TRAJ_LEN,\n",
    "    word_tokenizer = word_char_tokenizer,\n",
    "    include_time = False,\n",
    "    include_velocities = True,\n",
    "    include_accelerations = True,\n",
    "    has_target=False,\n",
    "    has_one_grid_only=False,\n",
    "    include_grid_name=True,\n",
    "    keyboard_selection_set=keyboard_selection_set,\n",
    "    total = 10_000\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "class NeuroSwipeGridSubset(Dataset):\n",
    "    def __init__(self, dataset: Dataset, grid_name: str):\n",
    "        self.dataset = dataset\n",
    "        self.grid_name = grid_name\n",
    "        self.grid_name_idxs = self._get_grid_name_idxs()\n",
    "        \n",
    "            \n",
    "    def _get_grid_name_idxs(self):\n",
    "        grid_name_idxs: list[int] = []\n",
    "        for i, ((_, _, _, _, _), _, grid_name) in enumerate(self.dataset):\n",
    "            if grid_name == self.grid_name:\n",
    "                grid_name_idxs.append(i)\n",
    "        return grid_name_idxs\n",
    "\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.grid_name_idxs)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.dataset[self.grid_name_idxs[idx]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_default_dataset = NeuroSwipeGridSubset(val_dataset, \"default\")\n",
    "val_extra_dataset = NeuroSwipeGridSubset(val_dataset, \"extra\")\n",
    "\n",
    "test_default_dataset = NeuroSwipeGridSubset(test_dataset, \"default\")\n",
    "test_extra_dataset = NeuroSwipeGridSubset(test_dataset, \"extra\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:02<00:00,  3.41it/s]\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from typing import List\n",
    "\n",
    "\n",
    "# def predict_greedy_raw(dataset: NeuroSwipeDatasetv2,\n",
    "#                         grid_name_to_greedy_generator,\n",
    "#                         grid_names_to_use: List[str],\n",
    "#                         ) -> List[List[str]]:\n",
    "#     \"\"\"\n",
    "#     Creates predictions using greedy generation.\n",
    "    \n",
    "#     Arguments:\n",
    "#     ----------\n",
    "#     dataset: NeuroSwipeDatasetv2\n",
    "#     grid_name_to_greedy_generator: dict\n",
    "#         Dict mapping grid names to GreedyGenerator objects.\n",
    "#     grid_names_to_use : List[str]\n",
    "#         Dataset examples with grid names not in this list will be skipped.\n",
    "#         Usefull when evaluating a single model trained on a single grid\n",
    "#         (or maybe a subset of grids).\n",
    "#     \"\"\"\n",
    "#     preds = []\n",
    "\n",
    "#     for i, data in tqdm(enumerate(dataset), total=len(dataset)):\n",
    "#         try:\n",
    "#             (xyt, kb_tokens, _, traj_pad_mask, word_mask), target, grid_name = data\n",
    "#             if grid_name not in grid_names_to_use:\n",
    "#                 continue\n",
    "#             pred = grid_name_to_greedy_generator[grid_name](xyt, kb_tokens, traj_pad_mask)\n",
    "#             pred = pred.removeprefix(\"<sos>\") \n",
    "#             # Even though greedy generation creates only one prediction,\n",
    "#             # we need to wrap it in a list to be consistent with other\n",
    "#             # prediction generation methods.\n",
    "#             preds.append([pred])\n",
    "#         except KeyboardInterrupt:\n",
    "#             print('Досрочно остановлено пользователем')\n",
    "#             break\n",
    "#     return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_duplicates(preds):\n",
    "    new_preds = []\n",
    "    met_preds = set()\n",
    "    for pred in preds:\n",
    "        if pred in met_preds:\n",
    "            continue\n",
    "        met_preds.add(pred)\n",
    "        new_preds.append(pred)\n",
    "    return new_preds\n",
    "\n",
    "\n",
    "def get_metric(preds_list, ref):\n",
    "    # Works properly if has duplicates or n_line_preds < 4\n",
    "\n",
    "    MMR = 0\n",
    "    \n",
    "    for preds, target in zip(preds_list, ref):\n",
    "        preds = remove_duplicates(preds)\n",
    "\n",
    "        weights = [1, 0.1, 0.09, 0.08]\n",
    "\n",
    "        line_MRR = sum(weights[i]* (pred == target) for i, pred in enumerate(preds))\n",
    "\n",
    "        MMR += line_MRR\n",
    "    \n",
    "    MMR /= len(preds_list)\n",
    "\n",
    "    return MMR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Callable, Dict, List\n",
    "\n",
    "\n",
    "def get_grid_name_to_target_list(dataset: NeuroSwipeDatasetv2):\n",
    "    GRID_NAMES = (\"default\", \"extra\")\n",
    "\n",
    "    grid_name_to_target_list = {grid_name: [] for grid_name in GRID_NAMES}\n",
    "\n",
    "    for i, data in tqdm(enumerate(dataset), total=len(dataset)):\n",
    "        (_, _, _, _, word_mask), target, grid_name = data\n",
    "        target_len = torch.sum(~word_mask)\n",
    "        target = word_char_tokenizer.decode(target[:target_len - 1])\n",
    "        # NeuroSwipeDatasetv2 masks all tokens after <eos>.\n",
    "        # So the line below is not needed. However, \n",
    "        # the current version of NeuroSwipeDatasetv1 is\n",
    "        # errorous and does not mask the first <pad> token.\n",
    "        # So the line below is needed for NeuroSwipeDatasetv1.\n",
    "        target = target.removesuffix('<pad>').removesuffix('<eos>')\n",
    "        grid_name_to_target_list[grid_name].append(target)\n",
    "    return grid_name_to_target_list\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def evaluate_model_greedy(val_dataset: NeuroSwipeDatasetv2,\n",
    "                          model: nn.Module,\n",
    "                          grid_name: str,\n",
    "                          grid_name_to_target_list: Dict[str, List[str]],\n",
    "                          word_char_tokenizer: CharLevelTokenizerv2,\n",
    "                          device: torch.device):\n",
    "    \"\"\"\n",
    "    Evaluates model on validation dataset using greedy generation.\n",
    "    \"\"\"\n",
    "    assert grid_name in (\"extra\", \"default\")\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "    generator = GreedyGenerator(model, word_char_tokenizer, device)\n",
    "    grid_name_to_greedy_generator = {grid_name:  generator}\n",
    "    preds = predict_greedy_raw(val_dataset,\n",
    "                                grid_name_to_greedy_generator,\n",
    "                                grid_names_to_use=[grid_name])\n",
    "    targets = grid_name_to_target_list[grid_name]\n",
    "    MMR = get_metric(preds, targets)\n",
    "    return MMR, preds\n",
    "\n",
    "\n",
    "def evaluate_weights_greedy(val_dataset: NeuroSwipeDatasetv2,\n",
    "                            model_getter: Callable,\n",
    "                            weights_path: str,\n",
    "                            grid_name: str,\n",
    "                            grid_name_to_target_list: Dict[str, List[str]],\n",
    "                            word_char_tokenizer: CharLevelTokenizerv2,\n",
    "                            device: torch.device):\n",
    "    \n",
    "    model = model_getter(device, weights_path)\n",
    "    MMR, preds = evaluate_model_greedy(val_dataset,\n",
    "                                model,\n",
    "                                grid_name,\n",
    "                                grid_name_to_target_list,\n",
    "                                word_char_tokenizer,\n",
    "                                device)\n",
    "    return MMR, preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_i_to_grid_name(dataset: NeuroSwipeDatasetv2):\n",
    "    i_to_grid_name = []\n",
    "    for i, data in tqdm(enumerate(dataset), total=len(dataset)):\n",
    "        (_, _, _, _, _), _, grid_name = data\n",
    "        i_to_grid_name.append(grid_name)\n",
    "    return i_to_grid_name\n",
    "\n",
    "def combine_preds(i_to_grid_name, default_preds, extra_preds):\n",
    "    preds = []\n",
    "    default_i = 0\n",
    "    extra_i = 0\n",
    "    for i, grid_name in enumerate(i_to_grid_name):\n",
    "        if grid_name == \"default\":\n",
    "            preds.append(default_preds[default_i])\n",
    "            default_i += 1\n",
    "        elif grid_name == \"extra\":\n",
    "            preds.append(extra_preds[extra_i])\n",
    "            extra_i += 1\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown grid_name: {grid_name}\")\n",
    "        \n",
    "    return preds\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:12<00:00, 796.11it/s]\n"
     ]
    }
   ],
   "source": [
    "grid_name_to_val_targets = get_grid_name_to_target_list(val_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_name = \"default\"\n",
    "model_getter = get_m1_model\n",
    "weights_path = os.path.join(MODELS_ROOT, \"m1_v2\", \"m1_v2__2023_11_09__10_36_02__0.14229_default_switch_0.pt\")\n",
    "grid_name_to_greedy_generator = {grid_name:  GreedyGenerator(model_getter(weights_path = weights_path, device = device), word_char_tokenizer, device)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_m1_model(device, weights_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target               prediction          \n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\proshian\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "на                   на                  \n",
      "все                  все                 \n",
      "этом                 этом                \n",
      "добрый               добрый              \n",
      "девочка              девочка             \n",
      "сказала              сказала             \n",
      "скинь                скинь               \n",
      "геев                 геев                \n",
      "тобой                тобой               \n",
      "была                 быстра              \n",
      "есть                 есть                \n",
      "да                   да                  \n",
      "муж                  маж                 \n",
      "щас                  щас                 \n",
      "она                  она                 \n",
      "проблема             проблема            \n",
      "билайн               билайн              \n",
      "уже                  уже                 \n",
      "раньше               раньше              \n",
      "рам                  нам                 \n",
      "щас                  щас                 \n",
      "купил                купил               \n",
      "ты                   ты                  \n",
      "зовут                зовут               \n",
      "короче               короче              \n",
      "лучше                лучше               \n",
      "приедем              приедем             \n",
      "размыто              размыто             \n",
      "давай                давай               \n",
      "ты                   ты                  \n",
      "отдать               отдать              \n",
      "привет               привет              \n",
      "не                   не                  \n",
      "да                   да                  \n",
      "будете               будете              \n",
      "связи                связи               \n",
      "колывань             кровываю            \n",
      "меня                 меня                \n",
      "напиши               напиши              \n",
      "знаю                 знаю                \n",
      "мамой                мамой               \n"
     ]
    }
   ],
   "source": [
    "greedy_generator = GreedyGenerator(model, word_char_tokenizer, device)\n",
    "\n",
    "\n",
    "print(\"{:<20} {:<20}\".format(\"target\", \"prediction\"))\n",
    "print(\"-\"*31)\n",
    "\n",
    "n_examples = 40\n",
    "\n",
    "for i, data in enumerate(val_dataset):\n",
    "\n",
    "    (xyt, kb_tokens, dec_in_char_seq, traj_pad_mask, word_pad_mask), target, grid_name = data\n",
    "\n",
    "    pred = greedy_generator(xyt, kb_tokens, traj_pad_mask)\n",
    "\n",
    "    # strip работвет только потому что в настоящих словах нет этих символов\n",
    "    pred = pred\n",
    "    target = word_char_tokenizer.decode(target).strip(\"<eos><pad>\")\n",
    "    print(\"{:<20} {:<20}\".format(target, pred))\n",
    "\n",
    "    if i >= n_examples:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|█▉        | 1967/10000 [03:08<12:51, 10.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Досрочно остановлено пользователем\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "mmr, preds = evaluate_model_greedy(val_dataset,\n",
    "                                    model,\n",
    "                                    grid_name,\n",
    "                                    grid_name_to_val_targets,\n",
    "                                    word_char_tokenizer,\n",
    "                                    device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mmr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['скинь'], ['мазора'], ['то'], ['анюта'], ['звони'], ['лесник'], ['минут'], ['забрала'], ['на'], ['обуд'], ['завтра'], ['такими'], ['давай'], ['посади'], ['бон'], ['даже'], ['перчатка'], ['работа'], ['никого'], ['отресли'], ['не'], ['раз'], ['блин'], ['пока'], ['ну'], ['тогда'], ['башка'], ['был'], ['продал'], ['хочу'], ['хорошая'], ['кофе'], ['быть'], ['ты'], ['стиревем'], ['мойкой'], ['мы'], ['но'], ['мо'], ['нету'], ['ну'], ['так'], ['ты'], ['закрой'], ['сейчас'], ['пойми'], ['что'], ['поровну'], ['это'], ['не']]\n"
     ]
    }
   ],
   "source": [
    "print(preds[200:250])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'m1_v2/best_model__2023_11_09__10_36_02__0.14229_default_switch_2_try_2.pt': 0.8512107051826678}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{\"m1_v2/best_model__2023_11_09__10_36_02__0.14229_default_switch_2_try_2.pt\": 0.8512107051826678,\n",
    " \"m1_bigger/m1_bigger_v2__2023_11_10__13_38_32__0.50552_default_l2_5e-05_ls0.045_switch_0.pt\": 0.810429056924384,\n",
    " \"m1_bigger/m1_bigger_v2__2023_11_10__16_36_38__0.49848_default_l2_5e-05_ls0.045_switch_0.pt\": 0.818500424808836}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_name = \"default\"\n",
    "weights_path = os.path.join(MODELS_ROOT, \"m1_v2\", \"m1_v2__2023_11_09__10_36_02__0.14229_default_switch_0.pt\")\n",
    "model = get_m1_model(weights_path = weights_path, device = device)\n",
    "grid_name_to_greedy_generator = {grid_name:  GreedyGenerator(model, word_char_tokenizer, device)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from word_generation_v2 import predict_greedy_raw_multiproc\n",
    "\n",
    "predictions = predict_greedy_raw_multiproc(val_default_dataset,\n",
    "                                           grid_name_to_greedy_generator,\n",
    "                                           num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's create a submission"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
