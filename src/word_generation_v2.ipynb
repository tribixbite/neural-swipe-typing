{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, IterableDataset\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "\n",
    "from model import SwipeCurveTransformer, get_m1_model\n",
    "from tokenizers import CharLevelTokenizerv2, KeyboardTokenizerv1\n",
    "from dataset import NeuroSwipeDatasetv2\n",
    "from word_generators import GreedyGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "IN_KAGGLE = False\n",
    "\n",
    "if IN_KAGGLE:\n",
    "    DATA_ROOT = \"/kaggle/input/yandex-cup-playground\"\n",
    "    MODELS_DIR = \"\"\n",
    "else:\n",
    "    DATA_ROOT = \"../data/data_separated_grid\"\n",
    "    MODELS_DIR = \"../data/trained_models/m1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_grid(grid_name: str, grids_path: str) -> dict:\n",
    "    with open(grids_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        return json.load(f)[grid_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:01<00:00, 5943.39it/s]\n"
     ]
    }
   ],
   "source": [
    "MAX_TRAJ_LEN = 299\n",
    "\n",
    "grid_name_to_grid_path = os.path.join(DATA_ROOT, \"gridname_to_grid.json\")\n",
    "grid_name_to_grid = {grid_name: get_grid(grid_name, grid_name_to_grid_path) for grid_name in (\"default\", \"extra\")}\n",
    "\n",
    "\n",
    "kb_tokenizer = KeyboardTokenizerv1()\n",
    "word_char_tokenizer = CharLevelTokenizerv2(os.path.join(DATA_ROOT, \"voc.txt\"))\n",
    "keyboard_selection_set = set(kb_tokenizer.i2t)\n",
    "\n",
    "\n",
    "val_path = os.path.join(DATA_ROOT, \"valid__in_train_format.jsonl\")\n",
    "\n",
    "\n",
    "val_dataset = NeuroSwipeDatasetv2(\n",
    "    data_path = val_path,\n",
    "    gridname_to_grid = grid_name_to_grid,\n",
    "    kb_tokenizer = kb_tokenizer,\n",
    "    max_traj_len = MAX_TRAJ_LEN,\n",
    "    word_tokenizer = word_char_tokenizer,\n",
    "    include_time = False,\n",
    "    include_velocities = True,\n",
    "    include_accelerations = True,\n",
    "    has_target=True,\n",
    "    has_one_grid_only=False,\n",
    "    include_grid_name=True,\n",
    "    keyboard_selection_set=keyboard_selection_set,\n",
    "    total = 10_000\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_raw_pred_list_greedy(dataset,\n",
    "                                grid_name_to_greedy_generator,\n",
    "                                skip_grid_name = None):\n",
    "    \"\"\"\n",
    "    Creates submission file generating words greedily.\n",
    "\n",
    "    If prediction is not in the vocabulary \n",
    "    \"\"\"\n",
    "\n",
    "    preds = []\n",
    "    targets = []\n",
    "\n",
    "    for i, data in tqdm(enumerate(dataset), total=len(dataset)):\n",
    "        try:\n",
    "            (xyt, kb_tokens, _, traj_pad_mask, word_mask), target, grid_name = data\n",
    "            if grid_name == skip_grid_name:\n",
    "                continue\n",
    "            pred = grid_name_to_greedy_generator[grid_name](xyt, kb_tokens, traj_pad_mask)\n",
    "            pred = pred.removeprefix(\"<sos>\") \n",
    "            target_len = torch.sum(~word_mask)\n",
    "            target = word_char_tokenizer.decode(target[:target_len]).removesuffix('<pad>').removesuffix('<eos>')\n",
    "            preds.append([pred])\n",
    "            targets.append(target)\n",
    "        except KeyboardInterrupt:\n",
    "            print('Досрочно остановлено пользователем')\n",
    "            break\n",
    "    return preds, targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_duplicates(preds):\n",
    "    new_preds = []\n",
    "    met_preds = set()\n",
    "    for pred in preds:\n",
    "        if pred in met_preds:\n",
    "            continue\n",
    "        met_preds.add(pred)\n",
    "        new_preds.append(pred)\n",
    "    return new_preds\n",
    "\n",
    "\n",
    "def get_metric(preds_list, ref):\n",
    "    # Works properly if has duplicates or n_line_preds < 4\n",
    "\n",
    "    MMR = 0\n",
    "    \n",
    "    for preds, target in zip(preds_list, ref):\n",
    "        preds = remove_duplicates(preds)\n",
    "\n",
    "        weights = [1, 0.1, 0.09, 0.08]\n",
    "\n",
    "        line_MRR = sum(weights[i]* (pred == target) for i, pred in enumerate(preds))\n",
    "\n",
    "        MMR += line_MRR\n",
    "    \n",
    "    MMR /= len(preds_list)\n",
    "\n",
    "    return MMR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_weights(val_dataset,\n",
    "                     model_getter,\n",
    "                     grid_name,\n",
    "                     weights_path,\n",
    "                     device):\n",
    "    assert grid_name in (\"extra\", \"default\")\n",
    "    grid_name_to_greedy_generator = {grid_name:  GreedyGenerator(model_getter(device, weights_path), word_char_tokenizer, device)}\n",
    "    skip_grid_name = \"default\" if grid_name == \"extra\" else \"extra\"\n",
    "    preds, targets = create_raw_pred_list_greedy(val_dataset, grid_name_to_greedy_generator, skip_grid_name=skip_grid_name)\n",
    "    mrr = get_metric(preds, targets)\n",
    "    return mrr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_name = \"default\"\n",
    "model_getter = get_m1_model\n",
    "weights_path = r\"..\\data\\trained_models\\m1_1\\best_model__2023_11_09__10_36_02__0.14229_default_switch_2_try_2.pt\"\n",
    "grid_name_to_greedy_generator = {grid_name:  GreedyGenerator(model_getter(weights_path = weights_path, device = device), word_char_tokenizer, device)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<word_generators.GreedyGenerator at 0x18ad4671d50>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_name_to_greedy_generator['default']()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_m1_model(device, weights_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "greedy_generator = GreedyGenerator(model, word_char_tokenizer, device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target               prediction          \n",
      "-------------------------------\n",
      "на                   на                  \n",
      "все                  все                 \n",
      "этом                 этом                \n",
      "добрый               добрый              \n",
      "девочка              девочка             \n",
      "сказала              сказала             \n",
      "скинь                скинь               \n",
      "геев                 геев                \n",
      "тобой                тобой               \n",
      "была                 быстра              \n",
      "есть                 есть                \n",
      "да                   да                  \n",
      "муж                  маж                 \n",
      "щас                  щас                 \n",
      "она                  она                 \n",
      "проблема             проблема            \n",
      "билайн               билайн              \n",
      "уже                  уже                 \n",
      "раньше               раньше              \n",
      "рам                  нам                 \n",
      "щас                  щас                 \n",
      "купил                купил               \n",
      "ты                   ты                  \n",
      "зовут                зовут               \n",
      "короче               короче              \n",
      "лучше                лучше               \n",
      "приедем              приедем             \n",
      "размыто              размыто             \n",
      "давай                давай               \n",
      "ты                   ты                  \n",
      "отдать               отдать              \n",
      "привет               привет              \n",
      "не                   не                  \n",
      "да                   да                  \n",
      "будете               будете              \n",
      "связи                связи               \n",
      "колывань             кровываю            \n",
      "меня                 меня                \n",
      "напиши               напиши              \n",
      "знаю                 знаю                \n",
      "мамой                мамой               \n"
     ]
    }
   ],
   "source": [
    "greedy_generator = GreedyGenerator(model, word_char_tokenizer, device)\n",
    "\n",
    "\n",
    "print(\"{:<20} {:<20}\".format(\"target\", \"prediction\"))\n",
    "print(\"-\"*31)\n",
    "\n",
    "n_examples = 40\n",
    "\n",
    "for i, data in enumerate(val_dataset):\n",
    "\n",
    "    (xyt, kb_tokens, dec_in_char_seq, traj_pad_mask, word_pad_mask), target, grid_name = data\n",
    "\n",
    "    pred = greedy_generator(xyt, kb_tokens, traj_pad_mask)\n",
    "\n",
    "    # strip работвет только потому что в настоящих словах нет этих символов\n",
    "    pred = pred.strip(\"<eos><pad>\") \n",
    "    target = word_char_tokenizer.decode(target).strip(\"<eos><pad>\")\n",
    "    print(\"{:<20} {:<20}\".format(target, pred))\n",
    "\n",
    "    if i >= n_examples:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [14:40<00:00, 11.36it/s] \n"
     ]
    }
   ],
   "source": [
    "mmr = evaluate_weights(\n",
    "    val_dataset = val_dataset,\n",
    "    model_getter = get_m1_model,\n",
    "    grid_name = \"default\",\n",
    "    weights_path = weights_path,\n",
    "    device = device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8512107051826678\n"
     ]
    }
   ],
   "source": [
    "print(mmr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'m1_v2/best_model__2023_11_09__10_36_02__0.14229_default_switch_2_try_2.pt': 0.8512107051826678}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{\"m1_v2/best_model__2023_11_09__10_36_02__0.14229_default_switch_2_try_2.pt\": 0.8512107051826678}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's create a submission"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
