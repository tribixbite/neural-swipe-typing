{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, IterableDataset\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "\n",
    "from model import SwipeCurveTransformer, get_m1_model\n",
    "from tokenizers import CharLevelTokenizerv2, KeyboardTokenizerv1\n",
    "from dataset import NeuroSwipeDatasetv2\n",
    "from word_generators import GreedyGenerator\n",
    "from word_generation_v2 import predict_greedy_raw_multiproc, predict_greedy_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "IN_KAGGLE = False\n",
    "\n",
    "if IN_KAGGLE:\n",
    "    DATA_ROOT = \"/kaggle/input/yandex-cup-playground\"\n",
    "    MODELS_DIR = \"\"\n",
    "else:\n",
    "    DATA_ROOT = \"../data/data_separated_grid\"\n",
    "    # MODELS_DIR = \"../data/trained_models/m1\"\n",
    "    MODELS_ROOT = \"../data/trained_models\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_grid(grid_name: str, grids_path: str) -> dict:\n",
    "    with open(grids_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        return json.load(f)[grid_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:01<00:00, 6920.25it/s]\n",
      "100%|██████████| 10000/10000 [00:02<00:00, 4257.13it/s]\n"
     ]
    }
   ],
   "source": [
    "MAX_TRAJ_LEN = 299\n",
    "\n",
    "grid_name_to_grid_path = os.path.join(DATA_ROOT, \"gridname_to_grid.json\")\n",
    "grid_name_to_grid = {grid_name: get_grid(grid_name, grid_name_to_grid_path) for grid_name in (\"default\", \"extra\")}\n",
    "\n",
    "\n",
    "kb_tokenizer = KeyboardTokenizerv1()\n",
    "word_char_tokenizer = CharLevelTokenizerv2(os.path.join(DATA_ROOT, \"voc.txt\"))\n",
    "keyboard_selection_set = set(kb_tokenizer.i2t)\n",
    "\n",
    "\n",
    "val_path = os.path.join(DATA_ROOT, \"valid__in_train_format.jsonl\")\n",
    "\n",
    "\n",
    "val_dataset = NeuroSwipeDatasetv2(\n",
    "    data_path = val_path,\n",
    "    gridname_to_grid = grid_name_to_grid,\n",
    "    kb_tokenizer = kb_tokenizer,\n",
    "    max_traj_len = MAX_TRAJ_LEN,\n",
    "    word_tokenizer = word_char_tokenizer,\n",
    "    include_time = False,\n",
    "    include_velocities = True,\n",
    "    include_accelerations = True,\n",
    "    has_target=True,\n",
    "    has_one_grid_only=False,\n",
    "    include_grid_name=True,\n",
    "    keyboard_selection_set=keyboard_selection_set,\n",
    "    total = 10_000\n",
    ")\n",
    "\n",
    "test_path = os.path.join(DATA_ROOT, \"test.jsonl\")\n",
    "\n",
    "\n",
    "test_dataset = NeuroSwipeDatasetv2(\n",
    "    data_path = test_path,\n",
    "    gridname_to_grid = grid_name_to_grid,\n",
    "    kb_tokenizer = kb_tokenizer,\n",
    "    max_traj_len = MAX_TRAJ_LEN,\n",
    "    word_tokenizer = word_char_tokenizer,\n",
    "    include_time = False,\n",
    "    include_velocities = True,\n",
    "    include_accelerations = True,\n",
    "    has_target=False,\n",
    "    has_one_grid_only=False,\n",
    "    include_grid_name=True,\n",
    "    keyboard_selection_set=keyboard_selection_set,\n",
    "    total = 10_000\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "class NeuroSwipeGridSubset(Dataset):\n",
    "    def __init__(self, dataset: Dataset, grid_name: str):\n",
    "        self.dataset = dataset\n",
    "        self.grid_name = grid_name\n",
    "        self.grid_name_idxs = self._get_grid_name_idxs()\n",
    "        \n",
    "            \n",
    "    def _get_grid_name_idxs(self):\n",
    "        grid_name_idxs: list[int] = []\n",
    "        for i, ((_, _, _, _, _), _, grid_name) in enumerate(self.dataset):\n",
    "            if grid_name == self.grid_name:\n",
    "                grid_name_idxs.append(i)\n",
    "        return grid_name_idxs\n",
    "\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.grid_name_idxs)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.dataset[self.grid_name_idxs[idx]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_default_dataset = NeuroSwipeGridSubset(val_dataset, \"default\")\n",
    "val_extra_dataset = NeuroSwipeGridSubset(val_dataset, \"extra\")\n",
    "\n",
    "test_default_dataset = NeuroSwipeGridSubset(test_dataset, \"default\")\n",
    "test_extra_dataset = NeuroSwipeGridSubset(test_dataset, \"extra\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_duplicates(preds):\n",
    "    new_preds = []\n",
    "    met_preds = set()\n",
    "    for pred in preds:\n",
    "        if pred in met_preds:\n",
    "            continue\n",
    "        met_preds.add(pred)\n",
    "        new_preds.append(pred)\n",
    "    return new_preds\n",
    "\n",
    "\n",
    "def get_metric(preds_list, ref):\n",
    "    # Works properly if has duplicates or n_line_preds < 4\n",
    "\n",
    "    MMR = 0\n",
    "    \n",
    "    for preds, target in zip(preds_list, ref):\n",
    "        preds = remove_duplicates(preds)\n",
    "\n",
    "        weights = [1, 0.1, 0.09, 0.08]\n",
    "\n",
    "        line_MRR = sum(weights[i]* (pred == target) for i, pred in enumerate(preds))\n",
    "\n",
    "        MMR += line_MRR\n",
    "    \n",
    "    MMR /= len(preds_list)\n",
    "\n",
    "    return MMR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Callable, Dict, List\n",
    "\n",
    "\n",
    "def get_targets(dataset: NeuroSwipeDatasetv2) -> List[str]:\n",
    "    targets = []\n",
    "    for (_, _, _, _, _), target, _ in dataset:\n",
    "        targets.append(target)\n",
    "    return targets\n",
    "\n",
    "def evaluate_model_greedy(val_dataset: NeuroSwipeDatasetv2,\n",
    "                          model: nn.Module,\n",
    "                          grid_name: str,\n",
    "                          targets: List[str],\n",
    "                          word_char_tokenizer: CharLevelTokenizerv2,\n",
    "                          device: torch.device):\n",
    "    \"\"\"\n",
    "    Evaluates model on validation dataset using greedy generation.\n",
    "    \"\"\"\n",
    "    assert grid_name in (\"extra\", \"default\")\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "    generator = GreedyGenerator(model, word_char_tokenizer, device)\n",
    "    grid_name_to_greedy_generator = {grid_name:  generator}\n",
    "    preds = predict_greedy_raw(val_dataset,\n",
    "                                grid_name_to_greedy_generator)\n",
    "    MMR = get_metric(preds, targets)\n",
    "    return MMR, preds\n",
    "\n",
    "\n",
    "def evaluate_weights_greedy(val_dataset: NeuroSwipeDatasetv2,\n",
    "                            model_getter: Callable,\n",
    "                            weights_path: str,\n",
    "                            grid_name: str,\n",
    "                            targets: List[str],\n",
    "                            word_char_tokenizer: CharLevelTokenizerv2,\n",
    "                            device: torch.device):\n",
    "    \n",
    "    model = model_getter(device, weights_path)\n",
    "    MMR, preds = evaluate_model_greedy(val_dataset,\n",
    "                                       model,\n",
    "                                       grid_name,\n",
    "                                       targets,\n",
    "                                       word_char_tokenizer,\n",
    "                                       device)\n",
    "    return MMR, preds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_i_to_grid_name(dataset: NeuroSwipeDatasetv2):\n",
    "#     i_to_grid_name = []\n",
    "#     for i, data in tqdm(enumerate(dataset), total=len(dataset)):\n",
    "#         (_, _, _, _, _), _, grid_name = data\n",
    "#         i_to_grid_name.append(grid_name)\n",
    "#     return i_to_grid_name\n",
    "\n",
    "\n",
    "# def combine_preds(i_to_grid_name, default_preds, extra_preds):\n",
    "#     preds = []\n",
    "#     default_i = 0\n",
    "#     extra_i = 0\n",
    "#     for i, grid_name in enumerate(i_to_grid_name):\n",
    "#         if grid_name == \"default\":\n",
    "#             preds.append(default_preds[default_i])\n",
    "#             default_i += 1\n",
    "#         elif grid_name == \"extra\":\n",
    "#             preds.append(extra_preds[extra_i])\n",
    "#             extra_i += 1\n",
    "#         else:\n",
    "#             raise ValueError(f\"Unknown grid_name: {grid_name}\")\n",
    "        \n",
    "#     return preds\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_preds(default_preds,\n",
    "                  extra_preds,\n",
    "                  default_idxs,\n",
    "                    extra_idxs):\n",
    "    preds = [None] * (len(default_preds) + len(extra_preds))\n",
    "\n",
    "    for i in default_idxs:\n",
    "        preds[i] = default_preds[i]\n",
    "    for i in extra_idxs:\n",
    "        preds[i] = extra_preds[i]\n",
    "\n",
    "    return preds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_name = \"default\"\n",
    "model_getter = get_m1_model\n",
    "weights_path = os.path.join(MODELS_ROOT, \"m1_v2\", \"m1_v2__2023_11_09__10_36_02__0.14229_default_switch_0.pt\")\n",
    "model = model_getter(device, weights_path)\n",
    "grid_name_to_greedy_generator = {grid_name: GreedyGenerator(model, word_char_tokenizer, device)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target               prediction          \n",
      "-------------------------------\n",
      "на                   на                  \n",
      "все                  все                 \n",
      "добрый               добрый              \n",
      "девочка              девочка             \n",
      "сказала              сказала             \n",
      "скинь                скинь               \n",
      "геев                 геев                \n",
      "тобой                тобой               \n",
      "была                 быстра              \n",
      "да                   да                  \n",
      "муж                  маж                 \n",
      "щас                  щас                 \n",
      "она                  она                 \n",
      "проблема             проблема            \n",
      "билайн               билайн              \n",
      "уже                  уже                 \n",
      "раньше               раньше              \n",
      "рам                  нам                 \n",
      "щас                  щас                 \n",
      "купил                купил               \n",
      "ты                   ты                  \n",
      "зовут                зовут               \n",
      "короче               короче              \n",
      "размыто              размыто             \n",
      "давай                давай               \n",
      "отдать               отдать              \n",
      "привет               привет              \n",
      "не                   не                  \n",
      "да                   да                  \n",
      "будете               будете              \n",
      "связи                связи               \n",
      "колывань             кровываю            \n",
      "меня                 меня                \n",
      "напиши               напиши              \n",
      "знаю                 знаю                \n",
      "мамой                мамой               \n",
      "не                   не                  \n",
      "ты                   ты                  \n",
      "только               только              \n",
      "они                  они                 \n",
      "свинг                свинг               \n"
     ]
    }
   ],
   "source": [
    "greedy_generator = GreedyGenerator(model, word_char_tokenizer, device)\n",
    "\n",
    "\n",
    "print(\"{:<20} {:<20}\".format(\"target\", \"prediction\"))\n",
    "print(\"-\"*31)\n",
    "\n",
    "n_examples = 40\n",
    "\n",
    "for i, data in enumerate(val_default_dataset):\n",
    "\n",
    "    (xyt, kb_tokens, dec_in_char_seq, traj_pad_mask, word_pad_mask), target, grid_name = data\n",
    "\n",
    "    pred = greedy_generator(xyt, kb_tokens, traj_pad_mask)\n",
    "\n",
    "    # strip работвет только потому что в настоящих словах нет этих символов\n",
    "    pred = pred\n",
    "    target_len = int(torch.sum(~word_pad_mask)) - 1\n",
    "    target = word_char_tokenizer.decode(target[:target_len])\n",
    "    print(\"{:<20} {:<20}\".format(target, pred))\n",
    "\n",
    "    if i >= n_examples:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_default_targets = get_targets(val_default_dataset)\n",
    "val_extra_targets = get_targets(val_extra_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/9416 [00:00<?, ?it/s]c:\\Users\\proshian\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.\n",
      "  warnings.warn(\n",
      "  2%|▏         | 187/9416 [00:18<15:21, 10.02it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\proshian\\Documents\\yandex_cup_2023_ml_neuroswipe\\src\\word_generation_v2.ipynb Cell 18\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/proshian/Documents/yandex_cup_2023_ml_neuroswipe/src/word_generation_v2.ipynb#X22sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m mmr, preds \u001b[39m=\u001b[39m evaluate_model_greedy(val_default_dataset,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/proshian/Documents/yandex_cup_2023_ml_neuroswipe/src/word_generation_v2.ipynb#X22sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m                                     model,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/proshian/Documents/yandex_cup_2023_ml_neuroswipe/src/word_generation_v2.ipynb#X22sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m                                     grid_name,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/proshian/Documents/yandex_cup_2023_ml_neuroswipe/src/word_generation_v2.ipynb#X22sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m                                     val_default_targets,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/proshian/Documents/yandex_cup_2023_ml_neuroswipe/src/word_generation_v2.ipynb#X22sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m                                     word_char_tokenizer,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/proshian/Documents/yandex_cup_2023_ml_neuroswipe/src/word_generation_v2.ipynb#X22sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m                                     device)\n",
      "\u001b[1;32mc:\\Users\\proshian\\Documents\\yandex_cup_2023_ml_neuroswipe\\src\\word_generation_v2.ipynb Cell 18\u001b[0m line \u001b[0;36m2\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/proshian/Documents/yandex_cup_2023_ml_neuroswipe/src/word_generation_v2.ipynb#X22sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m generator \u001b[39m=\u001b[39m GreedyGenerator(model, word_char_tokenizer, device)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/proshian/Documents/yandex_cup_2023_ml_neuroswipe/src/word_generation_v2.ipynb#X22sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m grid_name_to_greedy_generator \u001b[39m=\u001b[39m {grid_name:  generator}\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/proshian/Documents/yandex_cup_2023_ml_neuroswipe/src/word_generation_v2.ipynb#X22sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m preds \u001b[39m=\u001b[39m predict_greedy_raw(val_dataset,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/proshian/Documents/yandex_cup_2023_ml_neuroswipe/src/word_generation_v2.ipynb#X22sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m                             grid_name_to_greedy_generator)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/proshian/Documents/yandex_cup_2023_ml_neuroswipe/src/word_generation_v2.ipynb#X22sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m MMR \u001b[39m=\u001b[39m get_metric(preds, targets)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/proshian/Documents/yandex_cup_2023_ml_neuroswipe/src/word_generation_v2.ipynb#X22sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m \u001b[39mreturn\u001b[39;00m MMR, preds\n",
      "File \u001b[1;32mc:\\Users\\proshian\\Documents\\yandex_cup_2023_ml_neuroswipe\\src\\word_generation_v2.py:81\u001b[0m, in \u001b[0;36mpredict_greedy_raw\u001b[1;34m(dataset, grid_name_to_greedy_generator)\u001b[0m\n\u001b[0;32m     79\u001b[0m \u001b[39mfor\u001b[39;00m data \u001b[39min\u001b[39;00m tqdm(\u001b[39menumerate\u001b[39m(dataset), total\u001b[39m=\u001b[39m\u001b[39mlen\u001b[39m(dataset)):\n\u001b[0;32m     80\u001b[0m     i, ((xyt, kb_tokens, _, traj_pad_mask, _), _, grid_name) \u001b[39m=\u001b[39m data\n\u001b[1;32m---> 81\u001b[0m     pred \u001b[39m=\u001b[39m grid_name_to_greedy_generator[grid_name](xyt, kb_tokens, traj_pad_mask)\n\u001b[0;32m     82\u001b[0m     pred \u001b[39m=\u001b[39m pred\u001b[39m.\u001b[39mremoveprefix(\u001b[39m\"\u001b[39m\u001b[39m<sos>\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     83\u001b[0m     preds[i] \u001b[39m=\u001b[39m [pred]\n",
      "File \u001b[1;32mc:\\Users\\proshian\\Documents\\yandex_cup_2023_ml_neuroswipe\\src\\word_generators.py:26\u001b[0m, in \u001b[0;36mGreedyGenerator.__call__\u001b[1;34m(self, xyt, kb_tokens, traj_pad_mask, max_steps_n)\u001b[0m\n\u001b[0;32m     22\u001b[0m xyt, kb_tokens, traj_pad_mask \u001b[39m=\u001b[39m (el\u001b[39m.\u001b[39mto(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdevice) \u001b[39mfor\u001b[39;00m el \u001b[39min\u001b[39;00m (xyt, kb_tokens, traj_pad_mask))\n\u001b[0;32m     23\u001b[0m xyt, kb_tokens \u001b[39m=\u001b[39m (el\u001b[39m.\u001b[39mtranspose(\u001b[39m0\u001b[39m, \u001b[39m1\u001b[39m) \u001b[39mfor\u001b[39;00m el \u001b[39min\u001b[39;00m (xyt, kb_tokens))\n\u001b[1;32m---> 26\u001b[0m encoded \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel\u001b[39m.\u001b[39;49mencode(xyt, kb_tokens, traj_pad_mask)\n\u001b[0;32m     29\u001b[0m \u001b[39mfor\u001b[39;00m _ \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(max_steps_n):\n\u001b[0;32m     31\u001b[0m     dec_in_char_seq \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mtensor(tokens)\u001b[39m.\u001b[39munsqueeze(\u001b[39m0\u001b[39m)\u001b[39m.\u001b[39mto(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdevice)\n",
      "File \u001b[1;32mc:\\Users\\proshian\\Documents\\yandex_cup_2023_ml_neuroswipe\\src\\model.py:213\u001b[0m, in \u001b[0;36mSwipeCurveTransformer.encode\u001b[1;34m(self, x, kb_tokens, x_pad_mask)\u001b[0m\n\u001b[0;32m    211\u001b[0m kb_k_emb \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mkey_pos_encoder(kb_k_emb)\n\u001b[0;32m    212\u001b[0m x \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mcat((x, kb_k_emb), axis \u001b[39m=\u001b[39m \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m--> 213\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mencoder(x, x_pad_mask)\n\u001b[0;32m    214\u001b[0m \u001b[39mreturn\u001b[39;00m x\n",
      "File \u001b[1;32mc:\\Users\\proshian\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\proshian\\Documents\\yandex_cup_2023_ml_neuroswipe\\src\\model.py:64\u001b[0m, in \u001b[0;36mSwipeCurveTransformerEncoderv1.forward\u001b[1;34m(self, x, pad_mask)\u001b[0m\n\u001b[0;32m     62\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mliner(x)\n\u001b[0;32m     63\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtransformer_encoder:\n\u001b[1;32m---> 64\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtransformer_encoder(x, src_key_padding_mask\u001b[39m=\u001b[39;49mpad_mask)\n\u001b[0;32m     65\u001b[0m \u001b[39mreturn\u001b[39;00m x\n",
      "File \u001b[1;32mc:\\Users\\proshian\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\proshian\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:315\u001b[0m, in \u001b[0;36mTransformerEncoder.forward\u001b[1;34m(self, src, mask, src_key_padding_mask, is_causal)\u001b[0m\n\u001b[0;32m    312\u001b[0m is_causal \u001b[39m=\u001b[39m make_causal\n\u001b[0;32m    314\u001b[0m \u001b[39mfor\u001b[39;00m mod \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlayers:\n\u001b[1;32m--> 315\u001b[0m     output \u001b[39m=\u001b[39m mod(output, src_mask\u001b[39m=\u001b[39;49mmask, is_causal\u001b[39m=\u001b[39;49mis_causal, src_key_padding_mask\u001b[39m=\u001b[39;49msrc_key_padding_mask_for_layers)\n\u001b[0;32m    317\u001b[0m \u001b[39mif\u001b[39;00m convert_to_nested:\n\u001b[0;32m    318\u001b[0m     output \u001b[39m=\u001b[39m output\u001b[39m.\u001b[39mto_padded_tensor(\u001b[39m0.\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\proshian\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\proshian\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:592\u001b[0m, in \u001b[0;36mTransformerEncoderLayer.forward\u001b[1;34m(self, src, src_mask, src_key_padding_mask, is_causal)\u001b[0m\n\u001b[0;32m    590\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    591\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnorm1(x \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sa_block(x, src_mask, src_key_padding_mask, is_causal\u001b[39m=\u001b[39mis_causal))\n\u001b[1;32m--> 592\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnorm2(x \u001b[39m+\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_ff_block(x))\n\u001b[0;32m    594\u001b[0m \u001b[39mreturn\u001b[39;00m x\n",
      "File \u001b[1;32mc:\\Users\\proshian\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:607\u001b[0m, in \u001b[0;36mTransformerEncoderLayer._ff_block\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    606\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_ff_block\u001b[39m(\u001b[39mself\u001b[39m, x: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[1;32m--> 607\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlinear2(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdropout(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mactivation(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlinear1(x))))\n\u001b[0;32m    608\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdropout2(x)\n",
      "File \u001b[1;32mc:\\Users\\proshian\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\proshian\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    113\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[1;32m--> 114\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mlinear(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "mmr, preds = evaluate_model_greedy(val_default_dataset,\n",
    "                                    model,\n",
    "                                    grid_name,\n",
    "                                    val_default_targets,\n",
    "                                    word_char_tokenizer,\n",
    "                                    device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mmr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['скинь'], ['мазора'], ['то'], ['анюта'], ['звони'], ['лесник'], ['минут'], ['забрала'], ['на'], ['обуд'], ['завтра'], ['такими'], ['давай'], ['посади'], ['бон'], ['даже'], ['перчатка'], ['работа'], ['никого'], ['отресли'], ['не'], ['раз'], ['блин'], ['пока'], ['ну'], ['тогда'], ['башка'], ['был'], ['продал'], ['хочу'], ['хорошая'], ['кофе'], ['быть'], ['ты'], ['стиревем'], ['мойкой'], ['мы'], ['но'], ['мо'], ['нету'], ['ну'], ['так'], ['ты'], ['закрой'], ['сейчас'], ['пойми'], ['что'], ['поровну'], ['это'], ['не']]\n"
     ]
    }
   ],
   "source": [
    "print(preds[200:250])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'m1_v2/best_model__2023_11_09__10_36_02__0.14229_default_switch_2_try_2.pt': 0.8512107051826678}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{\"m1_v2/best_model__2023_11_09__10_36_02__0.14229_default_switch_2_try_2.pt\": 0.8512107051826678,\n",
    " \"m1_bigger/m1_bigger_v2__2023_11_10__13_38_32__0.50552_default_l2_5e-05_ls0.045_switch_0.pt\": 0.810429056924384,\n",
    " \"m1_bigger/m1_bigger_v2__2023_11_10__16_36_38__0.49848_default_l2_5e-05_ls0.045_switch_0.pt\": 0.818500424808836}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_name = \"default\"\n",
    "weights_path = os.path.join(MODELS_ROOT, \"m1_v2\", \"m1_v2__2023_11_09__10_36_02__0.14229_default_switch_0.pt\")\n",
    "model = get_m1_model(weights_path = weights_path, device = device)\n",
    "grid_name_to_greedy_generator = {grid_name:  GreedyGenerator(model, word_char_tokenizer, device)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9416/9416 [11:31<00:00, 13.61it/s]\n"
     ]
    }
   ],
   "source": [
    "predictions = predict_greedy_raw_multiproc(val_default_dataset,\n",
    "                                           grid_name_to_greedy_generator,\n",
    "                                           num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 68/9416 [00:07<17:22,  8.97it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\proshian\\Documents\\yandex_cup_2023_ml_neuroswipe\\src\\word_generation_v2.ipynb Cell 32\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/proshian/Documents/yandex_cup_2023_ml_neuroswipe/src/word_generation_v2.ipynb#X56sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m predictions \u001b[39m=\u001b[39m predict_greedy_raw(val_default_dataset,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/proshian/Documents/yandex_cup_2023_ml_neuroswipe/src/word_generation_v2.ipynb#X56sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m                                 grid_name_to_greedy_generator)\n",
      "File \u001b[1;32mc:\\Users\\proshian\\Documents\\yandex_cup_2023_ml_neuroswipe\\src\\word_generation_v2.py:82\u001b[0m, in \u001b[0;36mpredict_greedy_raw\u001b[1;34m(dataset, grid_name_to_greedy_generator, num_workers)\u001b[0m\n\u001b[0;32m     80\u001b[0m \u001b[39mfor\u001b[39;00m data \u001b[39min\u001b[39;00m tqdm(\u001b[39menumerate\u001b[39m(dataset), total\u001b[39m=\u001b[39m\u001b[39mlen\u001b[39m(dataset)):\n\u001b[0;32m     81\u001b[0m     i, ((xyt, kb_tokens, _, traj_pad_mask, _), _, grid_name) \u001b[39m=\u001b[39m data\n\u001b[1;32m---> 82\u001b[0m     pred \u001b[39m=\u001b[39m grid_name_to_greedy_generator[grid_name](xyt, kb_tokens, traj_pad_mask)\n\u001b[0;32m     83\u001b[0m     pred \u001b[39m=\u001b[39m pred\u001b[39m.\u001b[39mremoveprefix(\u001b[39m\"\u001b[39m\u001b[39m<sos>\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     84\u001b[0m     preds[i] \u001b[39m=\u001b[39m [pred]\n",
      "File \u001b[1;32mc:\\Users\\proshian\\Documents\\yandex_cup_2023_ml_neuroswipe\\src\\word_generators.py:38\u001b[0m, in \u001b[0;36mGreedyGenerator.__call__\u001b[1;34m(self, xyt, kb_tokens, traj_pad_mask, max_steps_n)\u001b[0m\n\u001b[0;32m     36\u001b[0m x \u001b[39m=\u001b[39m [xyt, kb_tokens, dec_in_char_seq, traj_pad_mask, word_pad_mask]\n\u001b[0;32m     37\u001b[0m x \u001b[39m=\u001b[39m [el\u001b[39m.\u001b[39munsqueeze(\u001b[39m0\u001b[39m) \u001b[39mfor\u001b[39;00m el \u001b[39min\u001b[39;00m x]\n\u001b[1;32m---> 38\u001b[0m next_tokens_logits \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel\u001b[39m.\u001b[39;49mdecode(encoded, dec_in_char_seq, traj_pad_mask, word_pad_mask)\u001b[39m.\u001b[39mtranspose_(\u001b[39m0\u001b[39m, \u001b[39m1\u001b[39m)[\u001b[39m0\u001b[39m, \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\n\u001b[0;32m     39\u001b[0m best_next_token \u001b[39m=\u001b[39m next_tokens_logits\u001b[39m.\u001b[39margmax()  \u001b[39m# batch_i = 0, decoder_out_onehot_vector_seq_i = -1 \u001b[39;00m\n\u001b[0;32m     40\u001b[0m \u001b[39mif\u001b[39;00m best_next_token \u001b[39m==\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39meos_token_id:\n",
      "File \u001b[1;32mc:\\Users\\proshian\\Documents\\yandex_cup_2023_ml_neuroswipe\\src\\model.py:221\u001b[0m, in \u001b[0;36mSwipeCurveTransformer.decode\u001b[1;34m(self, x_encoded, y, x_pad_mask, y_pad_mask)\u001b[0m\n\u001b[0;32m    219\u001b[0m y \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mchar_pos_encoder(y)\n\u001b[0;32m    220\u001b[0m mask \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_mask(\u001b[39mlen\u001b[39m(y))\u001b[39m.\u001b[39mto(device\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdevice)\n\u001b[1;32m--> 221\u001b[0m y \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdecoder(y, x_encoded, mask, x_pad_mask, y_pad_mask)\n\u001b[0;32m    222\u001b[0m \u001b[39mreturn\u001b[39;00m y\n",
      "File \u001b[1;32mc:\\Users\\proshian\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\proshian\\Documents\\yandex_cup_2023_ml_neuroswipe\\src\\model.py:95\u001b[0m, in \u001b[0;36mSwipeCurveTransformerDecoderv1.forward\u001b[1;34m(self, x, memory, tgt_mask, memory_key_padding_mask, tgt_key_padding_mask)\u001b[0m\n\u001b[0;32m     94\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x, memory, tgt_mask, memory_key_padding_mask, tgt_key_padding_mask):\n\u001b[1;32m---> 95\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtransformer_decoder(x,\n\u001b[0;32m     96\u001b[0m                                  memory,\n\u001b[0;32m     97\u001b[0m                                  tgt_mask\u001b[39m=\u001b[39;49mtgt_mask,\n\u001b[0;32m     98\u001b[0m                                  memory_key_padding_mask\u001b[39m=\u001b[39;49mmemory_key_padding_mask,\n\u001b[0;32m     99\u001b[0m                                  tgt_key_padding_mask\u001b[39m=\u001b[39;49mtgt_key_padding_mask)\n\u001b[0;32m    100\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mout(x)\n\u001b[0;32m    101\u001b[0m     \u001b[39mreturn\u001b[39;00m x\n",
      "File \u001b[1;32mc:\\Users\\proshian\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\proshian\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:369\u001b[0m, in \u001b[0;36mTransformerDecoder.forward\u001b[1;34m(self, tgt, memory, tgt_mask, memory_mask, tgt_key_padding_mask, memory_key_padding_mask)\u001b[0m\n\u001b[0;32m    366\u001b[0m output \u001b[39m=\u001b[39m tgt\n\u001b[0;32m    368\u001b[0m \u001b[39mfor\u001b[39;00m mod \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlayers:\n\u001b[1;32m--> 369\u001b[0m     output \u001b[39m=\u001b[39m mod(output, memory, tgt_mask\u001b[39m=\u001b[39;49mtgt_mask,\n\u001b[0;32m    370\u001b[0m                  memory_mask\u001b[39m=\u001b[39;49mmemory_mask,\n\u001b[0;32m    371\u001b[0m                  tgt_key_padding_mask\u001b[39m=\u001b[39;49mtgt_key_padding_mask,\n\u001b[0;32m    372\u001b[0m                  memory_key_padding_mask\u001b[39m=\u001b[39;49mmemory_key_padding_mask)\n\u001b[0;32m    374\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnorm \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    375\u001b[0m     output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnorm(output)\n",
      "File \u001b[1;32mc:\\Users\\proshian\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\proshian\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:718\u001b[0m, in \u001b[0;36mTransformerDecoderLayer.forward\u001b[1;34m(self, tgt, memory, tgt_mask, memory_mask, tgt_key_padding_mask, memory_key_padding_mask, tgt_is_causal, memory_is_causal)\u001b[0m\n\u001b[0;32m    716\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnorm1(x \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sa_block(x, tgt_mask, tgt_key_padding_mask, tgt_is_causal))\n\u001b[0;32m    717\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnorm2(x \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_mha_block(x, memory, memory_mask, memory_key_padding_mask, memory_is_causal))\n\u001b[1;32m--> 718\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnorm3(x \u001b[39m+\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_ff_block(x))\n\u001b[0;32m    720\u001b[0m \u001b[39mreturn\u001b[39;00m x\n",
      "File \u001b[1;32mc:\\Users\\proshian\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:744\u001b[0m, in \u001b[0;36mTransformerDecoderLayer._ff_block\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    743\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_ff_block\u001b[39m(\u001b[39mself\u001b[39m, x: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[1;32m--> 744\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlinear2(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdropout(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mactivation(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlinear1(x))))\n\u001b[0;32m    745\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdropout3(x)\n",
      "File \u001b[1;32mc:\\Users\\proshian\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\functional.py:1457\u001b[0m, in \u001b[0;36mrelu\u001b[1;34m(input, inplace)\u001b[0m\n\u001b[0;32m   1455\u001b[0m     result \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mrelu_(\u001b[39minput\u001b[39m)\n\u001b[0;32m   1456\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 1457\u001b[0m     result \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mrelu(\u001b[39minput\u001b[39;49m)\n\u001b[0;32m   1458\u001b[0m \u001b[39mreturn\u001b[39;00m result\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "predictions = predict_greedy_raw(val_default_dataset,\n",
    "                                grid_name_to_greedy_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's create a submission"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
