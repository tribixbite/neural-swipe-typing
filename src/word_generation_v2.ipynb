{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, IterableDataset\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "\n",
    "from model import SwipeCurveTransformer, get_m1_model\n",
    "from tokenizers import CharLevelTokenizerv2, KeyboardTokenizerv1\n",
    "from dataset import NeuroSwipeDatasetv2\n",
    "from word_generators import GreedyGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "IN_KAGGLE = False\n",
    "\n",
    "if IN_KAGGLE:\n",
    "    DATA_ROOT = \"/kaggle/input/yandex-cup-playground\"\n",
    "    MODELS_DIR = \"\"\n",
    "else:\n",
    "    DATA_ROOT = \"../data/data_separated_grid\"\n",
    "    MODELS_DIR = \"../data/trained_models/m1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_grid(grid_name: str, grids_path: str) -> dict:\n",
    "    with open(grids_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        return json.load(f)[grid_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:01<00:00, 6752.40it/s]\n",
      "100%|██████████| 10000/10000 [00:01<00:00, 6165.24it/s]\n"
     ]
    }
   ],
   "source": [
    "MAX_TRAJ_LEN = 299\n",
    "\n",
    "grid_name_to_grid_path = os.path.join(DATA_ROOT, \"gridname_to_grid.json\")\n",
    "grid_name_to_grid = {grid_name: get_grid(grid_name, grid_name_to_grid_path) for grid_name in (\"default\", \"extra\")}\n",
    "\n",
    "\n",
    "kb_tokenizer = KeyboardTokenizerv1()\n",
    "word_char_tokenizer = CharLevelTokenizerv2(os.path.join(DATA_ROOT, \"voc.txt\"))\n",
    "keyboard_selection_set = set(kb_tokenizer.i2t)\n",
    "\n",
    "\n",
    "val_path = os.path.join(DATA_ROOT, \"valid__in_train_format.jsonl\")\n",
    "\n",
    "\n",
    "val_dataset = NeuroSwipeDatasetv2(\n",
    "    data_path = val_path,\n",
    "    gridname_to_grid = grid_name_to_grid,\n",
    "    kb_tokenizer = kb_tokenizer,\n",
    "    max_traj_len = MAX_TRAJ_LEN,\n",
    "    word_tokenizer = word_char_tokenizer,\n",
    "    include_time = False,\n",
    "    include_velocities = True,\n",
    "    include_accelerations = True,\n",
    "    has_target=True,\n",
    "    has_one_grid_only=False,\n",
    "    include_grid_name=True,\n",
    "    keyboard_selection_set=keyboard_selection_set,\n",
    "    total = 10_000\n",
    ")\n",
    "\n",
    "test_path = os.path.join(DATA_ROOT, \"test.jsonl\")\n",
    "\n",
    "\n",
    "test_dataset = NeuroSwipeDatasetv2(\n",
    "    data_path = test_path,\n",
    "    gridname_to_grid = grid_name_to_grid,\n",
    "    kb_tokenizer = kb_tokenizer,\n",
    "    max_traj_len = MAX_TRAJ_LEN,\n",
    "    word_tokenizer = word_char_tokenizer,\n",
    "    include_time = False,\n",
    "    include_velocities = True,\n",
    "    include_accelerations = True,\n",
    "    has_target=False,\n",
    "    has_one_grid_only=False,\n",
    "    include_grid_name=True,\n",
    "    keyboard_selection_set=keyboard_selection_set,\n",
    "    total = 10_000\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_raw_pred_list_greedy(dataset: NeuroSwipeDatasetv2,\n",
    "                                grid_name_to_greedy_generator,\n",
    "                                skip_grid_name = None):\n",
    "    \"\"\"\n",
    "    Creates submission file generating words greedily.\n",
    "\n",
    "    Arguments:\n",
    "    ----------\n",
    "    dataset: NeuroSwipeDatasetv2\n",
    "    grid_name_to_greedy_generator: dict\n",
    "        Dict mapping grid names to GreedyGenerator objects.\n",
    "    skip_grid_name: str\n",
    "    \"\"\"\n",
    "\n",
    "    preds = []\n",
    "\n",
    "    for i, data in tqdm(enumerate(dataset), total=len(dataset)):\n",
    "        try:\n",
    "            (xyt, kb_tokens, _, traj_pad_mask, word_mask), target, grid_name = data\n",
    "            if grid_name == skip_grid_name:\n",
    "                continue\n",
    "            pred = grid_name_to_greedy_generator[grid_name](xyt, kb_tokens, traj_pad_mask)\n",
    "            pred = pred.removeprefix(\"<sos>\") \n",
    "            preds.append([pred])\n",
    "        except KeyboardInterrupt:\n",
    "            print('Досрочно остановлено пользователем')\n",
    "            break\n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_duplicates(preds):\n",
    "    new_preds = []\n",
    "    met_preds = set()\n",
    "    for pred in preds:\n",
    "        if pred in met_preds:\n",
    "            continue\n",
    "        met_preds.add(pred)\n",
    "        new_preds.append(pred)\n",
    "    return new_preds\n",
    "\n",
    "\n",
    "def get_metric(preds_list, ref):\n",
    "    # Works properly if has duplicates or n_line_preds < 4\n",
    "\n",
    "    MMR = 0\n",
    "    \n",
    "    for preds, target in zip(preds_list, ref):\n",
    "        preds = remove_duplicates(preds)\n",
    "\n",
    "        weights = [1, 0.1, 0.09, 0.08]\n",
    "\n",
    "        line_MRR = sum(weights[i]* (pred == target) for i, pred in enumerate(preds))\n",
    "\n",
    "        MMR += line_MRR\n",
    "    \n",
    "    MMR /= len(preds_list)\n",
    "\n",
    "    return MMR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Callable, Dict, List\n",
    "\n",
    "\n",
    "def get_grid_name_to_target_list(dataset: NeuroSwipeDatasetv2):\n",
    "    GRID_NAMES = (\"default\", \"extra\")\n",
    "\n",
    "    grid_name_to_target_list = {grid_name: [] for grid_name in GRID_NAMES}\n",
    "\n",
    "    for i, data in tqdm(enumerate(dataset), total=len(dataset)):\n",
    "        (_, _, _, _, word_mask), target, grid_name = data\n",
    "        target_len = torch.sum(~word_mask)\n",
    "        target = word_char_tokenizer.decode(target[:target_len - 1])\n",
    "        # NeuroSwipeDatasetv2 masks all tokens after <eos>.\n",
    "        # So the line below is not needed. However, \n",
    "        # the current version of NeuroSwipeDatasetv1 is\n",
    "        # errorous and does not mask the first <pad> token.\n",
    "        # So the line below is needed for NeuroSwipeDatasetv1.\n",
    "        target = target.removesuffix('<pad>').removesuffix('<eos>')\n",
    "        grid_name_to_target_list[grid_name].append(target)\n",
    "    return grid_name_to_target_list\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def evaluate_model_greedy(val_dataset: NeuroSwipeDatasetv2,\n",
    "                          model: nn.Module,\n",
    "                          grid_name: str,\n",
    "                          grid_name_to_target_list: Dict[str, List[str]],\n",
    "                          word_char_tokenizer: CharLevelTokenizerv2,\n",
    "                          device: torch.device):\n",
    "    \"\"\"\n",
    "    Evaluates model on validation dataset using greedy generation.\n",
    "    \"\"\"\n",
    "    assert grid_name in (\"extra\", \"default\")\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "    generator = GreedyGenerator(model, word_char_tokenizer, device)\n",
    "    grid_name_to_greedy_generator = {grid_name:  generator}\n",
    "    skip_grid_name = \"default\" if grid_name == \"extra\" else \"extra\"\n",
    "    preds = create_raw_pred_list_greedy(val_dataset,\n",
    "                                        grid_name_to_greedy_generator,\n",
    "                                        skip_grid_name=skip_grid_name)\n",
    "    targets = grid_name_to_target_list[grid_name]\n",
    "    MMR = get_metric(preds, targets)\n",
    "    return MMR\n",
    "\n",
    "\n",
    "def evaluate_weights_greedy(val_dataset: NeuroSwipeDatasetv2,\n",
    "                            model_getter: Callable,\n",
    "                            weights_path: str,\n",
    "                            grid_name: str,\n",
    "                            grid_name_to_target_list: Dict[str, List[str]],\n",
    "                            word_char_tokenizer: CharLevelTokenizerv2,\n",
    "                            device: torch.device):\n",
    "    \n",
    "    model = model_getter(device, weights_path)\n",
    "    MMR = evaluate_model_greedy(val_dataset,\n",
    "                                model,\n",
    "                                grid_name,\n",
    "                                grid_name_to_target_list,\n",
    "                                word_char_tokenizer,\n",
    "                                device)\n",
    "    return MMR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_name = \"default\"\n",
    "model_getter = get_m1_model\n",
    "weights_path = r\"..\\data\\trained_models\\m1_1\\best_model__2023_11_09__10_36_02__0.14229_default_switch_2_try_2.pt\"\n",
    "grid_name_to_greedy_generator = {grid_name:  GreedyGenerator(model_getter(weights_path = weights_path, device = device), word_char_tokenizer, device)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<word_generators.GreedyGenerator at 0x18ad4671d50>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_name_to_greedy_generator['default']()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_m1_model(device, weights_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "greedy_generator = GreedyGenerator(model, word_char_tokenizer, device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target               prediction          \n",
      "-------------------------------\n",
      "на                   на                  \n",
      "все                  все                 \n",
      "этом                 этом                \n",
      "добрый               добрый              \n",
      "девочка              девочка             \n",
      "сказала              сказала             \n",
      "скинь                скинь               \n",
      "геев                 геев                \n",
      "тобой                тобой               \n",
      "была                 быстра              \n",
      "есть                 есть                \n",
      "да                   да                  \n",
      "муж                  маж                 \n",
      "щас                  щас                 \n",
      "она                  она                 \n",
      "проблема             проблема            \n",
      "билайн               билайн              \n",
      "уже                  уже                 \n",
      "раньше               раньше              \n",
      "рам                  нам                 \n",
      "щас                  щас                 \n",
      "купил                купил               \n",
      "ты                   ты                  \n",
      "зовут                зовут               \n",
      "короче               короче              \n",
      "лучше                лучше               \n",
      "приедем              приедем             \n",
      "размыто              размыто             \n",
      "давай                давай               \n",
      "ты                   ты                  \n",
      "отдать               отдать              \n",
      "привет               привет              \n",
      "не                   не                  \n",
      "да                   да                  \n",
      "будете               будете              \n",
      "связи                связи               \n",
      "колывань             кровываю            \n",
      "меня                 меня                \n",
      "напиши               напиши              \n",
      "знаю                 знаю                \n",
      "мамой                мамой               \n"
     ]
    }
   ],
   "source": [
    "greedy_generator = GreedyGenerator(model, word_char_tokenizer, device)\n",
    "\n",
    "\n",
    "print(\"{:<20} {:<20}\".format(\"target\", \"prediction\"))\n",
    "print(\"-\"*31)\n",
    "\n",
    "n_examples = 40\n",
    "\n",
    "for i, data in enumerate(val_dataset):\n",
    "\n",
    "    (xyt, kb_tokens, dec_in_char_seq, traj_pad_mask, word_pad_mask), target, grid_name = data\n",
    "\n",
    "    pred = greedy_generator(xyt, kb_tokens, traj_pad_mask)\n",
    "\n",
    "    # strip работвет только потому что в настоящих словах нет этих символов\n",
    "    pred = pred\n",
    "    target = word_char_tokenizer.decode(target).strip(\"<eos><pad>\")\n",
    "    print(\"{:<20} {:<20}\".format(target, pred))\n",
    "\n",
    "    if i >= n_examples:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [14:40<00:00, 11.36it/s] \n"
     ]
    }
   ],
   "source": [
    "mmr = evaluate_weights(\n",
    "    val_dataset = val_dataset,\n",
    "    model_getter = get_m1_model,\n",
    "    grid_name = \"default\",\n",
    "    weights_path = weights_path,\n",
    "    device = device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8512107051826678\n"
     ]
    }
   ],
   "source": [
    "print(mmr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'m1_v2/best_model__2023_11_09__10_36_02__0.14229_default_switch_2_try_2.pt': 0.8512107051826678}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{\"m1_v2/best_model__2023_11_09__10_36_02__0.14229_default_switch_2_try_2.pt\": 0.8512107051826678}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's create a submission"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
