{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import copy\n",
    "from multiprocessing import cpu_count\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, IterableDataset\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "\n",
    "from model import SwipeCurveTransformer, get_m1_model, get_m1_bigger_model, get_m1_smaller_model\n",
    "from tokenizers import CharLevelTokenizerv2, KeyboardTokenizerv1\n",
    "from dataset import NeuroSwipeDatasetv2\n",
    "from word_generators import GreedyGenerator, BeamGenerator\n",
    "from word_generation_v2 import predict_greedy_raw, predict_raw_mp  #  , predict_greedy_raw_multiproc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "IN_KAGGLE = False\n",
    "\n",
    "if IN_KAGGLE:\n",
    "    DATA_ROOT = \"/kaggle/input/yandex-cup-playground\"\n",
    "    MODELS_DIR = \"\"\n",
    "else:\n",
    "    DATA_ROOT = \"../data/data_separated_grid\"\n",
    "    MODELS_ROOT = \"../data/trained_models\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_grid(grid_name: str, grids_path: str) -> dict:\n",
    "    with open(grids_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        return json.load(f)[grid_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:01<00:00, 9313.98it/s]\n",
      "100%|██████████| 10000/10000 [00:00<00:00, 10859.10it/s]\n"
     ]
    }
   ],
   "source": [
    "MAX_TRAJ_LEN = 299\n",
    "\n",
    "grid_name_to_grid_path = os.path.join(DATA_ROOT, \"gridname_to_grid.json\")\n",
    "grid_name_to_grid = {grid_name: get_grid(grid_name, grid_name_to_grid_path) for grid_name in (\"default\", \"extra\")}\n",
    "\n",
    "\n",
    "kb_tokenizer = KeyboardTokenizerv1()\n",
    "word_char_tokenizer = CharLevelTokenizerv2(os.path.join(DATA_ROOT, \"voc.txt\"))\n",
    "keyboard_selection_set = set(kb_tokenizer.i2t)\n",
    "\n",
    "\n",
    "val_path = os.path.join(DATA_ROOT, \"valid__in_train_format.jsonl\")\n",
    "\n",
    "\n",
    "val_dataset = NeuroSwipeDatasetv2(\n",
    "    data_path = val_path,\n",
    "    gridname_to_grid = grid_name_to_grid,\n",
    "    kb_tokenizer = kb_tokenizer,\n",
    "    max_traj_len = MAX_TRAJ_LEN,\n",
    "    word_tokenizer = word_char_tokenizer,\n",
    "    include_time = False,\n",
    "    include_velocities = True,\n",
    "    include_accelerations = True,\n",
    "    has_target=True,\n",
    "    has_one_grid_only=False,\n",
    "    include_grid_name=True,\n",
    "    keyboard_selection_set=keyboard_selection_set,\n",
    "    total = 10_000\n",
    ")\n",
    "\n",
    "test_path = os.path.join(DATA_ROOT, \"test.jsonl\")\n",
    "\n",
    "\n",
    "test_dataset = NeuroSwipeDatasetv2(\n",
    "    data_path = test_path,\n",
    "    gridname_to_grid = grid_name_to_grid,\n",
    "    kb_tokenizer = kb_tokenizer,\n",
    "    max_traj_len = MAX_TRAJ_LEN,\n",
    "    word_tokenizer = word_char_tokenizer,\n",
    "    include_time = False,\n",
    "    include_velocities = True,\n",
    "    include_accelerations = True,\n",
    "    has_target=False,\n",
    "    has_one_grid_only=False,\n",
    "    include_grid_name=True,\n",
    "    keyboard_selection_set=keyboard_selection_set,\n",
    "    total = 10_000\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "class NeuroSwipeGridSubset(Dataset):\n",
    "    def __init__(self, dataset: Dataset, grid_name: str):\n",
    "        self.dataset = dataset\n",
    "        self.grid_name = grid_name\n",
    "        self.grid_name_idxs = self._get_grid_name_idxs()\n",
    "        \n",
    "            \n",
    "    def _get_grid_name_idxs(self):\n",
    "        grid_name_idxs: list[int] = []\n",
    "        for i, ((_, _, _, _, _), _, grid_name) in enumerate(self.dataset):\n",
    "            if grid_name == self.grid_name:\n",
    "                grid_name_idxs.append(i)\n",
    "        return grid_name_idxs\n",
    "\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.grid_name_idxs)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.dataset[self.grid_name_idxs[idx]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_default_dataset = NeuroSwipeGridSubset(val_dataset, \"default\")\n",
    "val_extra_dataset = NeuroSwipeGridSubset(val_dataset, \"extra\")\n",
    "\n",
    "test_default_dataset = NeuroSwipeGridSubset(test_dataset, \"default\")\n",
    "test_extra_dataset = NeuroSwipeGridSubset(test_dataset, \"extra\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_duplicates(preds):\n",
    "    new_preds = []\n",
    "    met_preds = set()\n",
    "    for pred in preds:\n",
    "        if pred in met_preds:\n",
    "            continue\n",
    "        met_preds.add(pred)\n",
    "        new_preds.append(pred)\n",
    "    return new_preds\n",
    "\n",
    "\n",
    "def get_metric(preds_list, ref):\n",
    "    # Works properly if has duplicates or n_line_preds < 4\n",
    "\n",
    "    MMR = 0\n",
    "    \n",
    "    for preds, target in zip(preds_list, ref):\n",
    "        preds = remove_duplicates(preds)\n",
    "\n",
    "        weights = [1, 0.1, 0.09, 0.08]\n",
    "\n",
    "        line_MRR = sum(weights[i]* (pred == target) for i, pred in enumerate(preds))\n",
    "\n",
    "        MMR += line_MRR\n",
    "    \n",
    "    MMR /= len(preds_list)\n",
    "\n",
    "    return MMR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Callable, Dict, List\n",
    "\n",
    "\n",
    "def get_targets(dataset: NeuroSwipeDatasetv2) -> List[str]:\n",
    "    targets = []\n",
    "    for (_, _, _, _, word_pad_mask), target_tokens, _ in dataset:\n",
    "        target_len = int(torch.sum(~word_pad_mask)) - 1\n",
    "        target = word_char_tokenizer.decode(target_tokens[:target_len])\n",
    "        targets.append(target)\n",
    "    return targets\n",
    "\n",
    "def evaluate_model_greedy(val_dataset: NeuroSwipeDatasetv2,\n",
    "                          model: nn.Module,\n",
    "                          grid_name: str,\n",
    "                          targets: List[str],\n",
    "                          word_char_tokenizer: CharLevelTokenizerv2,\n",
    "                          device: torch.device):\n",
    "    \"\"\"\n",
    "    Evaluates model on validation dataset using greedy generation.\n",
    "    \"\"\"\n",
    "    assert grid_name in (\"extra\", \"default\")\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "    generator = GreedyGenerator(model, word_char_tokenizer, device)\n",
    "    grid_name_to_greedy_generator = {grid_name:  generator}\n",
    "    preds = predict_greedy_raw(val_dataset,\n",
    "                                grid_name_to_greedy_generator)\n",
    "    MMR = get_metric(preds, targets)\n",
    "    return MMR, preds\n",
    "\n",
    "\n",
    "def evaluate_weights_greedy(val_dataset: NeuroSwipeDatasetv2,\n",
    "                            model_getter: Callable,\n",
    "                            weights_path: str,\n",
    "                            grid_name: str,\n",
    "                            targets: List[str],\n",
    "                            word_char_tokenizer: CharLevelTokenizerv2,\n",
    "                            device: torch.device):\n",
    "    \n",
    "    model = model_getter(device, weights_path)\n",
    "    MMR, preds = evaluate_model_greedy(val_dataset,\n",
    "                                       model,\n",
    "                                       grid_name,\n",
    "                                       targets,\n",
    "                                       word_char_tokenizer,\n",
    "                                       device)\n",
    "    return MMR, preds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_i_to_grid_name(dataset: NeuroSwipeDatasetv2):\n",
    "#     i_to_grid_name = []\n",
    "#     for i, data in tqdm(enumerate(dataset), total=len(dataset)):\n",
    "#         (_, _, _, _, _), _, grid_name = data\n",
    "#         i_to_grid_name.append(grid_name)\n",
    "#     return i_to_grid_name\n",
    "\n",
    "\n",
    "# def combine_preds(i_to_grid_name, default_preds, extra_preds):\n",
    "#     preds = []\n",
    "#     default_i = 0\n",
    "#     extra_i = 0\n",
    "#     for i, grid_name in enumerate(i_to_grid_name):\n",
    "#         if grid_name == \"default\":\n",
    "#             preds.append(default_preds[default_i])\n",
    "#             default_i += 1\n",
    "#         elif grid_name == \"extra\":\n",
    "#             preds.append(extra_preds[extra_i])\n",
    "#             extra_i += 1\n",
    "#         else:\n",
    "#             raise ValueError(f\"Unknown grid_name: {grid_name}\")\n",
    "        \n",
    "#     return preds\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_preds(default_preds,\n",
    "                extra_preds,\n",
    "                default_idxs,\n",
    "                extra_idxs):\n",
    "    preds = [None] * (len(default_preds) + len(extra_preds))\n",
    "\n",
    "    for i, val in zip(default_idxs, default_preds):\n",
    "        preds[i] = copy.deepcopy(val)\n",
    "    for i, val in zip(extra_idxs, extra_preds):\n",
    "        preds[i] = copy.deepcopy(val)\n",
    "\n",
    "    return preds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cpu')\n",
    "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_name = \"default\"\n",
    "model_getter = get_m1_smaller_model\n",
    "weights_path = os.path.join(MODELS_ROOT, \"m1_smaller/m1_smaller_v2_2023_11_11_17_43_35_0_33179_default_l2_1e_05_ls0_02.pt\")\n",
    "model = model_getter(device, weights_path)\n",
    "grid_name_to_greedy_generator = {grid_name: GreedyGenerator(model, word_char_tokenizer, device)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target               prediction          \n",
      "-------------------------------\n",
      "на                   на                  \n",
      "все                  все                 \n",
      "добрый               добрый              \n",
      "девочка              девочка             \n",
      "сказала              сказала             \n",
      "скинь                скинь               \n",
      "геев                 гееев               \n",
      "тобой                тобой               \n",
      "была                 быса                \n",
      "да                   да                  \n",
      "муж                  мад                 \n",
      "щас                  щас                 \n",
      "она                  она                 \n",
      "проблема             проблема            \n",
      "билайн               билайн              \n",
      "уже                  уже                 \n",
      "раньше               раньше              \n",
      "рам                  рам                 \n",
      "щас                  щас                 \n",
      "купил                купил               \n",
      "ты                   ты                  \n",
      "зовут                зовут               \n",
      "короче               короче              \n",
      "размыто              размыто             \n",
      "давай                давай               \n",
      "отдать               отдать              \n",
      "привет               привет              \n",
      "не                   не                  \n",
      "да                   да                  \n",
      "будете               будете              \n",
      "связи                связи               \n",
      "колывань             колываешь           \n",
      "меня                 меня                \n",
      "напиши               напиши              \n",
      "знаю                 знаю                \n",
      "мамой                мамой               \n",
      "не                   не                  \n",
      "ты                   ты                  \n",
      "только               только              \n",
      "они                  они                 \n",
      "свинг                свинг               \n"
     ]
    }
   ],
   "source": [
    "greedy_generator = GreedyGenerator(model, word_char_tokenizer, device)\n",
    "\n",
    "\n",
    "print(\"{:<20} {:<20}\".format(\"target\", \"prediction\"))\n",
    "print(\"-\"*31)\n",
    "\n",
    "n_examples = 40\n",
    "\n",
    "for i, data in enumerate(val_default_dataset):\n",
    "\n",
    "    (xyt, kb_tokens, dec_in_char_seq, traj_pad_mask, word_pad_mask), target, grid_name = data\n",
    "\n",
    "    pred = greedy_generator(xyt, kb_tokens, traj_pad_mask)\n",
    "\n",
    "    # strip работвет только потому что в настоящих словах нет этих символов\n",
    "    pred = pred\n",
    "    target_len = int(torch.sum(~word_pad_mask)) - 1\n",
    "    target = word_char_tokenizer.decode(target[:target_len])\n",
    "    print(\"{:<20} {:<20}\".format(target, pred))\n",
    "\n",
    "    if i >= n_examples:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_default_targets = get_targets(val_default_dataset)\n",
    "val_extra_targets = get_targets(val_extra_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mmr, preds = evaluate_model_greedy(val_default_dataset,\n",
    "#                                     model,\n",
    "#                                     grid_name,\n",
    "#                                     val_default_targets,\n",
    "#                                     word_char_tokenizer,\n",
    "#                                     device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(mmr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['скинь'], ['мазора'], ['то'], ['анюта'], ['звони'], ['лесник'], ['минут'], ['забрала'], ['на'], ['обуд'], ['завтра'], ['такими'], ['давай'], ['посади'], ['бон'], ['даже'], ['перчатка'], ['работа'], ['никого'], ['отресли'], ['не'], ['раз'], ['блин'], ['пока'], ['ну'], ['тогда'], ['башка'], ['был'], ['продал'], ['хочу'], ['хорошая'], ['кофе'], ['быть'], ['ты'], ['стиревем'], ['мойкой'], ['мы'], ['но'], ['мо'], ['нету'], ['ну'], ['так'], ['ты'], ['закрой'], ['сейчас'], ['пойми'], ['что'], ['поровну'], ['это'], ['не']]\n"
     ]
    }
   ],
   "source": [
    "# print(preds[200:250])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictions = predict_greedy_raw_multiproc(val_default_dataset,\n",
    "#                                            grid_name_to_greedy_generator,\n",
    "#                                            num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictions = predict_greedy_raw(val_default_dataset,\n",
    "#                                 grid_name_to_greedy_generator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate models separately and as a pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Callable\n",
    "\n",
    "def weights_to_raw_predictions(grid_name: str,\n",
    "                                model_getter: Callable,\n",
    "                                weights_path: str,\n",
    "                                word_char_tokenizer: CharLevelTokenizerv2,\n",
    "                                dataset: Dataset,\n",
    "                                generator_ctor,\n",
    "                                n_workers: int = 4,\n",
    "                                generator_kwargs = None\n",
    "                           ):\n",
    "     DEVICE = torch.device('cpu')  # Avoid multiprocessing with GPU\n",
    "     if generator_kwargs is None:\n",
    "          generator_kwargs = {}\n",
    "\n",
    "     model = model_getter(DEVICE, weights_path)\n",
    "     grid_name_to_greedy_generator = {grid_name: generator_ctor(model, word_char_tokenizer, DEVICE)}\n",
    "     raw_predictions = predict_raw_mp(dataset,\n",
    "                                        grid_name_to_greedy_generator,\n",
    "                                        num_workers=n_workers,\n",
    "                                        generator_kwargs=generator_kwargs)\n",
    "     return raw_predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    }
   ],
   "source": [
    "print(cpu_count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_default_targets = get_targets(val_default_dataset)\n",
    "val_extra_targets = get_targets(val_extra_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'get_m1_smaller_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32md:\\neuroswipe\\yandex_cup_2023_ml_neuroswipe\\src\\word_generation_v2.ipynb Cell 28\u001b[0m line \u001b[0;36m3\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/neuroswipe/yandex_cup_2023_ml_neuroswipe/src/word_generation_v2.ipynb#Y342sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m default_predictions \u001b[39m=\u001b[39m weights_to_raw_predictions(\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/neuroswipe/yandex_cup_2023_ml_neuroswipe/src/word_generation_v2.ipynb#Y342sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m     grid_name \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mdefault\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/neuroswipe/yandex_cup_2023_ml_neuroswipe/src/word_generation_v2.ipynb#Y342sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     model_getter\u001b[39m=\u001b[39mget_m1_smaller_model,\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/neuroswipe/yandex_cup_2023_ml_neuroswipe/src/word_generation_v2.ipynb#Y342sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     weights_path \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(MODELS_ROOT, \u001b[39m\"\u001b[39m\u001b[39mm1_smaller/m1_smaller_v2_2023_11_11_17_43_35_0_33179_default_l2_1e_05_ls0_02.pt\u001b[39m\u001b[39m\"\u001b[39m),\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/neuroswipe/yandex_cup_2023_ml_neuroswipe/src/word_generation_v2.ipynb#Y342sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     word_char_tokenizer\u001b[39m=\u001b[39mword_char_tokenizer,\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/neuroswipe/yandex_cup_2023_ml_neuroswipe/src/word_generation_v2.ipynb#Y342sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     dataset\u001b[39m=\u001b[39mval_default_dataset,\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/neuroswipe/yandex_cup_2023_ml_neuroswipe/src/word_generation_v2.ipynb#Y342sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     generator_ctor\u001b[39m=\u001b[39mGreedyGenerator,\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/neuroswipe/yandex_cup_2023_ml_neuroswipe/src/word_generation_v2.ipynb#Y342sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m     n_workers\u001b[39m=\u001b[39m\u001b[39m4\u001b[39m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/neuroswipe/yandex_cup_2023_ml_neuroswipe/src/word_generation_v2.ipynb#Y342sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m )\n",
      "\u001b[1;31mNameError\u001b[0m: name 'get_m1_smaller_model' is not defined"
     ]
    }
   ],
   "source": [
    "default_predictions = weights_to_raw_predictions(\n",
    "    grid_name = \"default\",\n",
    "    model_getter=get_m1_bigger_model,\n",
    "    weights_path = os.path.join(MODELS_ROOT, \"m1_bigger/m1_bigger_v2__2023_11_11__13_17_50__0.13845_default_l2_0_ls0_switch_0.pt\"),\n",
    "    word_char_tokenizer=word_char_tokenizer,\n",
    "    dataset=val_default_dataset,\n",
    "    generator_ctor=GreedyGenerator,\n",
    "    n_workers=4\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8531223449447749"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "default_MMR =  get_metric(default_predictions, val_default_targets)\n",
    "default_MMR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "default_predictions_best_bigger = default_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "default_predictions_best_bigger_clean, _ = separate_invalid_preds_greedy(default_predictions_best_bigger, vocab_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8784"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(bool(el) for el in default_predictions_best_bigger_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9416/9416 [04:08<00:00, 37.90it/s]\n"
     ]
    }
   ],
   "source": [
    "default_predictions = weights_to_raw_predictions(\n",
    "    grid_name = \"default\",\n",
    "    model_getter=get_m1_smaller_model,\n",
    "    weights_path = os.path.join(MODELS_ROOT, \"m1_smaller/m1_smaller_v2_2023_11_11_17_43_35_0_33179_default_l2_1e_05_ls0_02.pt\"),\n",
    "    word_char_tokenizer=word_char_tokenizer,\n",
    "    dataset=val_default_dataset,\n",
    "    generator_ctor=GreedyGenerator,\n",
    "    n_workers=4\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "default_predictions_clean, _ = separate_invalid_preds_greedy(default_predictions, vocab_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8449"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(bool(el) for el in default_predictions_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8221112999150383"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "default_MMR =  get_metric(default_predictions, val_default_targets)\n",
    "default_MMR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grid_name = \"default\"\n",
    "# model_getter = get_m1_bigger_model\n",
    "# weights_path = os.path.join(MODELS_ROOT, \"m1_bigger/m1_bigger_v2__2023_11_11__13_17_50__0.13845_default_l2_0_ls0_switch_0.pt\")\n",
    "# model = model_getter(device, weights_path)\n",
    "# grid_name_to_greedy_generator = {grid_name: GreedyGenerator(model, word_char_tokenizer, device)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9416/9416 [05:02<00:00, 31.10it/s]\n"
     ]
    }
   ],
   "source": [
    "# default_predictions = predict_greedy_raw_multiproc(val_default_dataset,\n",
    "#                                                     grid_name_to_greedy_generator,\n",
    "#                                                     num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_name = \"extra\"\n",
    "model_getter = get_m1_model\n",
    "weights_path = os.path.join(MODELS_ROOT, \"m1_v2/m1_v2__2023_11_09__17_47_40__0.14301_extra_l2_1e-05_switch_0.pt\")\n",
    "model = model_getter(device, weights_path)\n",
    "grid_name_to_greedy_generator = {grid_name: GreedyGenerator(model, word_char_tokenizer, device)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 584/584 [00:18<00:00, 31.60it/s]\n"
     ]
    }
   ],
   "source": [
    "extra_predictions = predict_greedy_raw_multiproc(val_extra_dataset,\n",
    "                                                 grid_name_to_greedy_generator,\n",
    "                                                 num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.851027397260274"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extra_MMR = get_metric(extra_predictions, val_extra_targets)\n",
    "extra_MMR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_preds = merge_preds(default_predictions, extra_predictions, val_default_dataset.grid_name_idxs, val_extra_dataset.grid_name_idxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_targets = None\n",
    "with open(os.path.join(DATA_ROOT, \"valid.ref\"), 'r', encoding='utf-8') as f:\n",
    "    all_targets = f.read().splitlines() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8512"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_MMR = get_metric(all_preds, all_targets)\n",
    "full_MMR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "{\"m1_v2/best_model__2023_11_09__10_36_02__0.14229_default_switch_2_try_2.pt\": 0.8512107051826678,\n",
    " \"m1_v2/m1_v2__2023_11_09__17_47_40__0.14301_extra_l2_1e-05_switch_0.pt\": 0.851027397260274,\n",
    " \n",
    " \"m1_bigger/m1_bigger_v2__2023_11_10__13_38_32__0.50552_default_l2_5e-05_ls0.045_switch_0.pt\": 0.810429056924384,\n",
    " \"m1_bigger/m1_bigger_v2__2023_11_10__16_36_38__0.49848_default_l2_5e-05_ls0.045_switch_0.pt\": 0.818500424808836,\n",
    " \"m1_bigger/m1_bigger_v2__2023_11_10__21_51_01__0.49382_default_l2_5e-05_ls0.045_switch_0.pt\": 0.8210492778249787,\n",
    " \n",
    " \"m1_bigger/m1_bigger_v2__2023_11_11__13_17_50__0.13845_default_l2_0_ls0_switch_0.pt\": 0.8512107051826678,\n",
    " \"m1_bigger/m1_bigger_v2__2023_11_11__14_29_37__0.13679_default_l2_0_ls0_switch_0.pt\": 0.8531223449447749,\n",
    " \n",
    " \"m1_smaller/m1_smaller_v2_2023_11_11_17_43_35_0_33179_default_l2_1e_05_ls0_02.pt\": 0.8221112999150383}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's create a greedy submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Set, List, Tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def separate_invalid_preds_beam(preds: List[List[Tuple[float, str]]],\n",
    "#                                 vocab_set: Set[str]) -> Tuple[List[List[str]], Dict[int, List[str]]]:\n",
    "#     \"\"\"\n",
    "#     Arguments:\n",
    "#     ----------\n",
    "#     preds: List[List[Tuple[float, str]]]\n",
    "#         preds[i] stores raw output of a word generator corresponding\n",
    "#         to the i-th curve. The raw output is a list of tuples, where\n",
    "#         each tuple is (-log_probability, word). The list is sorted\n",
    "#         by -log_probability in ascending order.\n",
    "#     vocab_set: Set[str]\n",
    "#         A set of all possible words.\n",
    "\n",
    "#     Returns:\n",
    "#     --------\n",
    "#     all_real_word_preds: List[List[str]]\n",
    "#         all_real_word_preds stores 4 lists of real words sorted by\n",
    "#         -log_probability in ascending order.\n",
    "#     all_errorous_word_preds: Dict[int, List[str]]\n",
    "#         all_errorous_word_preds[i] stores a list of errorous words\n",
    "#         sorted by -log_probability in ascending order if all_real_word_preds[i]\n",
    "#         has less than 4 words. Otherwise, all_errorous_word_preds does not\n",
    "#         have the key i.\n",
    "#     \"\"\"\n",
    "\n",
    "#     all_real_word_preds = []\n",
    "#     all_errorous_word_preds = {}\n",
    "\n",
    "#     for i, pred in enumerate(preds):\n",
    "#         real_word_preds = []\n",
    "#         errorous_word_preds = []\n",
    "#         for _, word in pred:\n",
    "#             if word in vocab_set:\n",
    "#                 real_word_preds.append(word)\n",
    "#                 if len(real_word_preds) == 4:\n",
    "#                     break\n",
    "#             else:\n",
    "#                 errorous_word_preds.append(word)\n",
    "        \n",
    "#         all_real_word_preds.append(real_word_preds)\n",
    "#         if len(real_word_preds) < 4:\n",
    "#             all_errorous_word_preds[i] = errorous_word_preds\n",
    "\n",
    "#     return all_real_word_preds, all_errorous_word_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def separate_invalid_preds_greedy(preds: List[List[str]],\n",
    "                                vocab_set: Set[str]) -> Tuple[List[List[str]], Dict[int, List[str]]]:\n",
    "\n",
    "    all_real_word_preds = []\n",
    "    all_errorous_word_preds = {}\n",
    "\n",
    "    for i, pred in enumerate(preds):\n",
    "        real_word_preds = []\n",
    "        errorous_word_preds = []\n",
    "        for word in pred:\n",
    "            if word in vocab_set:\n",
    "                real_word_preds.append(word)\n",
    "                if len(real_word_preds) == 4:\n",
    "                    break\n",
    "            else:\n",
    "                errorous_word_preds.append(word)\n",
    "        \n",
    "        all_real_word_preds.append(real_word_preds)\n",
    "        if len(real_word_preds) < 4:\n",
    "            all_errorous_word_preds[i] = errorous_word_preds\n",
    "\n",
    "    return all_real_word_preds, all_errorous_word_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def augment_predictions(preds, augment_list):\n",
    "#     augmented_preds = copy.deepcopy(preds)\n",
    "#     for pred, aug in zip(augmented_preds, augment_list):\n",
    "#         for aug_el in aug:\n",
    "#             if len(pred) >= 4:\n",
    "#                 break\n",
    "#             pred.append(aug_el)\n",
    "#     return augmented_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment_predictions(preds:List[List[str]], augment_list: List[List[str]]):\n",
    "    augmented_preds = copy.deepcopy(preds)\n",
    "    for pred_line, aug_l_line in zip(augmented_preds, augment_list):\n",
    "        for aug_el in aug_l_line:\n",
    "            if len(pred_line) >= 4:\n",
    "                break\n",
    "            if not aug_el in pred_line:\n",
    "                pred_line.append(aug_el)\n",
    "    return augmented_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_submission(preds_list, out_path) -> None:\n",
    "    if os.path.exists(out_path):\n",
    "        raise ValueError(f\"File {out_path} already exists\")\n",
    "    \n",
    "    with open(out_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        for preds in preds_list:\n",
    "            pred_str = \",\".join(preds)\n",
    "            f.write(pred_str + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vocab_set(vocab_path: str):\n",
    "    with open(vocab_path, 'r', encoding = \"utf-8\") as f:\n",
    "        return set(f.read().splitlines())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 117/9373 [00:04<05:26, 28.34it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32md:\\neuroswipe\\yandex_cup_2023_ml_neuroswipe\\src\\word_generation_v2.ipynb Cell 48\u001b[0m line \u001b[0;36m6\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/neuroswipe/yandex_cup_2023_ml_neuroswipe/src/word_generation_v2.ipynb#Y216sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m model \u001b[39m=\u001b[39m model_getter(device, weights_path)\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/neuroswipe/yandex_cup_2023_ml_neuroswipe/src/word_generation_v2.ipynb#Y216sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m grid_name_to_greedy_generator \u001b[39m=\u001b[39m {grid_name: GreedyGenerator(model, word_char_tokenizer, device)}\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/neuroswipe/yandex_cup_2023_ml_neuroswipe/src/word_generation_v2.ipynb#Y216sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m default_test_predictions \u001b[39m=\u001b[39m predict_raw_mp(test_default_dataset,\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/neuroswipe/yandex_cup_2023_ml_neuroswipe/src/word_generation_v2.ipynb#Y216sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m                                           grid_name_to_greedy_generator,\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/neuroswipe/yandex_cup_2023_ml_neuroswipe/src/word_generation_v2.ipynb#Y216sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m                                           num_workers\u001b[39m=\u001b[39;49m\u001b[39m3\u001b[39;49m)\n",
      "File \u001b[1;32md:\\neuroswipe\\yandex_cup_2023_ml_neuroswipe\\src\\word_generation_v2.py:94\u001b[0m, in \u001b[0;36mpredict_raw_mp\u001b[1;34m(dataset, grid_name_to_greedy_generator, num_workers, generator_kwargs)\u001b[0m\n\u001b[0;32m     91\u001b[0m process_example_ \u001b[39m=\u001b[39m partial(process_example, generator_kwargs\u001b[39m=\u001b[39mgenerator_kwargs)\n\u001b[0;32m     93\u001b[0m \u001b[39mwith\u001b[39;00m ProcessPoolExecutor(num_workers) \u001b[39mas\u001b[39;00m executor:\n\u001b[1;32m---> 94\u001b[0m     \u001b[39mfor\u001b[39;00m i, pred \u001b[39min\u001b[39;00m tqdm(executor\u001b[39m.\u001b[39mmap(process_example_, data), total\u001b[39m=\u001b[39m\u001b[39mlen\u001b[39m(dataset)):\n\u001b[0;32m     95\u001b[0m         preds[i] \u001b[39m=\u001b[39m [pred]\n\u001b[0;32m     97\u001b[0m \u001b[39mreturn\u001b[39;00m preds\n",
      "File \u001b[1;32mc:\\Users\\SystemPoint\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tqdm\\std.py:1195\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1192\u001b[0m time \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_time\n\u001b[0;32m   1194\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 1195\u001b[0m     \u001b[39mfor\u001b[39;00m obj \u001b[39min\u001b[39;00m iterable:\n\u001b[0;32m   1196\u001b[0m         \u001b[39myield\u001b[39;00m obj\n\u001b[0;32m   1197\u001b[0m         \u001b[39m# Update and possibly print the progressbar.\u001b[39;00m\n\u001b[0;32m   1198\u001b[0m         \u001b[39m# Note: does not call self.update(1) for speed optimisation.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\SystemPoint\\AppData\\Local\\Programs\\Python\\Python310\\lib\\concurrent\\futures\\process.py:567\u001b[0m, in \u001b[0;36m_chain_from_iterable_of_lists\u001b[1;34m(iterable)\u001b[0m\n\u001b[0;32m    561\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_chain_from_iterable_of_lists\u001b[39m(iterable):\n\u001b[0;32m    562\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    563\u001b[0m \u001b[39m    Specialized implementation of itertools.chain.from_iterable.\u001b[39;00m\n\u001b[0;32m    564\u001b[0m \u001b[39m    Each item in *iterable* should be a list.  This function is\u001b[39;00m\n\u001b[0;32m    565\u001b[0m \u001b[39m    careful not to keep references to yielded objects.\u001b[39;00m\n\u001b[0;32m    566\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 567\u001b[0m     \u001b[39mfor\u001b[39;00m element \u001b[39min\u001b[39;00m iterable:\n\u001b[0;32m    568\u001b[0m         element\u001b[39m.\u001b[39mreverse()\n\u001b[0;32m    569\u001b[0m         \u001b[39mwhile\u001b[39;00m element:\n",
      "File \u001b[1;32mc:\\Users\\SystemPoint\\AppData\\Local\\Programs\\Python\\Python310\\lib\\concurrent\\futures\\_base.py:609\u001b[0m, in \u001b[0;36mExecutor.map.<locals>.result_iterator\u001b[1;34m()\u001b[0m\n\u001b[0;32m    606\u001b[0m \u001b[39mwhile\u001b[39;00m fs:\n\u001b[0;32m    607\u001b[0m     \u001b[39m# Careful not to keep a reference to the popped future\u001b[39;00m\n\u001b[0;32m    608\u001b[0m     \u001b[39mif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 609\u001b[0m         \u001b[39myield\u001b[39;00m fs\u001b[39m.\u001b[39;49mpop()\u001b[39m.\u001b[39;49mresult()\n\u001b[0;32m    610\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    611\u001b[0m         \u001b[39myield\u001b[39;00m fs\u001b[39m.\u001b[39mpop()\u001b[39m.\u001b[39mresult(end_time \u001b[39m-\u001b[39m time\u001b[39m.\u001b[39mmonotonic())\n",
      "File \u001b[1;32mc:\\Users\\SystemPoint\\AppData\\Local\\Programs\\Python\\Python310\\lib\\concurrent\\futures\\_base.py:441\u001b[0m, in \u001b[0;36mFuture.result\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    438\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state \u001b[39m==\u001b[39m FINISHED:\n\u001b[0;32m    439\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__get_result()\n\u001b[1;32m--> 441\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_condition\u001b[39m.\u001b[39;49mwait(timeout)\n\u001b[0;32m    443\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state \u001b[39min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n\u001b[0;32m    444\u001b[0m     \u001b[39mraise\u001b[39;00m CancelledError()\n",
      "File \u001b[1;32mc:\\Users\\SystemPoint\\AppData\\Local\\Programs\\Python\\Python310\\lib\\threading.py:320\u001b[0m, in \u001b[0;36mCondition.wait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    318\u001b[0m \u001b[39mtry\u001b[39;00m:    \u001b[39m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[0;32m    319\u001b[0m     \u001b[39mif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 320\u001b[0m         waiter\u001b[39m.\u001b[39;49macquire()\n\u001b[0;32m    321\u001b[0m         gotit \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m    322\u001b[0m     \u001b[39melse\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "grid_name = \"default\"\n",
    "model_getter = get_m1_model\n",
    "weights_path = os.path.join(MODELS_ROOT, \"m1_v2/m1_v2__2023_11_09__10_36_02__0.14229_default_switch_0.pt\")\n",
    "model = model_getter(device, weights_path)\n",
    "grid_name_to_greedy_generator = {grid_name: GreedyGenerator(model, word_char_tokenizer, device)}\n",
    "default_test_predictions = predict_raw_mp(test_default_dataset,\n",
    "                                          grid_name_to_greedy_generator,\n",
    "                                          num_workers=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 627/627 [00:20<00:00, 30.18it/s]\n"
     ]
    }
   ],
   "source": [
    "grid_name = \"extra\"\n",
    "model_getter = get_m1_model\n",
    "weights_path = os.path.join(MODELS_ROOT, \"m1_v2/m1_v2__2023_11_09__17_47_40__0.14301_extra_l2_1e-05_switch_0.pt\")\n",
    "model = model_getter(device, weights_path)\n",
    "grid_name_to_greedy_generator = {grid_name: GreedyGenerator(model, word_char_tokenizer, device)}\n",
    "extra_test_predictions = predict_raw_mp(test_extra_dataset,\n",
    "                                        grid_name_to_greedy_generator,\n",
    "                                        num_workers=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_test_preds = merge_preds(default_test_predictions, extra_test_predictions, test_default_dataset.grid_name_idxs, test_extra_dataset.grid_name_idxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_set = get_vocab_set(os.path.join(DATA_ROOT, \"voc.txt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_test_preds, invalid_test_preds = separate_invalid_preds_greedy(all_test_preds, vocab_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['на'],\n",
       " ['что'],\n",
       " ['опоздания'],\n",
       " ['сколько'],\n",
       " [],\n",
       " ['не'],\n",
       " ['как'],\n",
       " ['садовод'],\n",
       " ['заметил'],\n",
       " ['ваги']]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_test_preds[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "augment_list = None\n",
    "with open(r\"..\\data\\submissions\\sample_submission.csv\", 'r', encoding = 'utf-8') as f:\n",
    "    augment_lines = f.read().splitlines()\n",
    "augment_list = [line.split(\",\") for line in augment_lines]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "augmented_test_preds = augment_predictions(clean_test_preds, augment_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['на', 'неа', 'на', 'ненка'],\n",
       " ['что', 'часто', 'частого', 'чисто'],\n",
       " ['опоздания', 'опоздания', 'опозданиям', 'оприходования'],\n",
       " ['сколько', 'сколько', 'сокольского', 'свердловского'],\n",
       " ['дремать', 'дописать', 'донимать', 'дюрренматт'],\n",
       " ['не', 'неук', 'нк', 'ненка'],\n",
       " ['как', 'как', 'капак', 'капе'],\n",
       " ['садовод', 'спародировал', 'садовод', 'сурдоперевод'],\n",
       " ['заметил', 'знаменито', 'знаменитого', 'замерил'],\n",
       " ['ваги', 'ваенги', 'венгрии', 'ванги']]"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "augmented_test_preds[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_name = \"m1_v2__0.14229_deault__0.14301_extra__greedy.csv\"\n",
    "out_path = rf\"..\\data\\submissions\\{submission_name}\"\n",
    "create_submission(augmented_test_preds, out_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation via beamsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BeamSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator_kwargs = {\n",
    "    'max_steps_n': 35,\n",
    "    'return_hypotheses_n': 7,\n",
    "    'beamsize': 6,\n",
    "    'normalization_factor': 0.5,\n",
    "    'verbose': False\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9373/9373 [1:28:45<00:00,  1.76it/s]\n"
     ]
    }
   ],
   "source": [
    "weights_f_name = \"m1_bigger/m1_bigger_v2__2023_11_11__14_29_37__0.13679_default_l2_0_ls0_switch_0.pt\"\n",
    "\n",
    "default_test_predictions = weights_to_raw_predictions(\n",
    "    grid_name = \"default\",\n",
    "    model_getter=get_m1_bigger_model,\n",
    "    weights_path = os.path.join(MODELS_ROOT, weights_f_name),\n",
    "    word_char_tokenizer=word_char_tokenizer,\n",
    "    dataset=test_default_dataset,\n",
    "    generator_ctor=BeamGenerator,\n",
    "    n_workers=4,\n",
    "    generator_kwargs=generator_kwargs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_f_name = \"m1_bigger/m1_bigger_v2__2023_11_11__14_29_37__0.13679_default_l2_0_ls0_switch_0.pt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9373/9373 [1:12:28<00:00,  2.16it/s]\n"
     ]
    }
   ],
   "source": [
    "# grid_name = \"default\"\n",
    "# model_getter = get_m1_bigger_model\n",
    "# weights_f_name = \"m1_v2/m1_v2__2023_11_09__10_36_02__0.14229_default_switch_0.pt\"\n",
    "# weights_path = os.path.join(MODELS_ROOT, weights_f_name)\n",
    "# model = model_getter(device, weights_path)\n",
    "# grid_name_to_beam_generator = {grid_name: BeamGenerator(model, word_char_tokenizer, device)}\n",
    "# default_test_predictions = predict_raw_mp(test_default_dataset,\n",
    "#                                           grid_name_to_beam_generator,\n",
    "#                                           num_workers=5,\n",
    "#                                           generator_kwargs=generator_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "default_test_preds_path = os.path.join(\"../data/saved_beamsearch_results/\",\n",
    "                                       f\"{weights_f_name.replace('/', '__')}.pkl\")\n",
    "\n",
    "with open(default_test_preds_path, 'wb') as f:\n",
    "    pickle.dump(default_test_predictions, f, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(default_test_preds_path, 'rb') as f:\n",
    "    check_default_test_predictions = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True, False)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_default_test_predictions == default_test_predictions, check_default_test_predictions is default_test_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 627/627 [04:45<00:00,  2.19it/s]\n"
     ]
    }
   ],
   "source": [
    "grid_name = \"extra\"\n",
    "model_getter = get_m1_model\n",
    "weights_f_name = \"m1_v2/m1_v2__2023_11_09__17_47_40__0.14301_extra_l2_1e-05_switch_0.pt\"\n",
    "weights_path = os.path.join(MODELS_ROOT, weights_f_name)\n",
    "model = model_getter(device, weights_path)\n",
    "grid_name_to_beam_generator = {grid_name: BeamGenerator(model, word_char_tokenizer, device)}\n",
    "extra_test_predictions = predict_raw_mp(test_extra_dataset,\n",
    "                                        grid_name_to_beam_generator,\n",
    "                                        num_workers=5,\n",
    "                                        generator_kwargs=generator_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[[(0.0007509778079111129, 'на'),\n",
       "   (3.309941194903711, 'не-а-а-а'),\n",
       "   (3.3550884596756756, 'неа'),\n",
       "   (3.890410980826455, 'нас'),\n",
       "   (4.074969764595153, 'не'),\n",
       "   (4.373856262813206, 'ну'),\n",
       "   (4.41572101401283, 'не-а-а-а-а')]],\n",
       " [[(0.4908975681421362, 'рядов'),\n",
       "   (0.6450710900287799, 'рядомы'),\n",
       "   (0.7488804344352544, 'рядом'),\n",
       "   (0.958582528002698, 'рядовы'),\n",
       "   (1.2750473936050235, 'ряды'),\n",
       "   (1.2825134230126898, 'рядым'),\n",
       "   (1.3310995005909219, 'рядова')]]]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extra_test_predictions[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "extra_test_preds_path = os.path.join(\"../data/saved_beamsearch_results/\",\n",
    "                                       f\"{weights_f_name.replace('/', '__')}.pkl\")\n",
    "\n",
    "with open(extra_test_preds_path, 'wb') as f:\n",
    "    pickle.dump(extra_test_predictions, f, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_f_name = \"m1_v2/m1_v2__2023_11_09__17_47_40__0.14301_extra_l2_1e-05_switch_0.pt\"\n",
    "extra_test_preds_path = os.path.join(\"../data/saved_beamsearch_results/\",\n",
    "                                       f\"{weights_f_name.replace('/', '__')}.pkl\")\n",
    "\n",
    "with open(extra_test_preds_path, 'rb') as f:\n",
    "    extra_test_predictions = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_f_name = \"m1_v2/m1_v2__2023_11_09__10_36_02__0.14229_default_switch_0.pt\"\n",
    "default_test_preds_path_m1_v2_14229 = os.path.join(\"../data/saved_beamsearch_results/\",\n",
    "                                       f\"{weights_f_name.replace('/', '__')}.pkl\")\n",
    "\n",
    "with open(default_test_preds_path_m1_v2_14229, 'rb') as f:\n",
    "    default_test_preds_m1_v2_14229 = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_test_predictions = [el[0] for el in default_test_predictions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_test_preds_m1_v2_14229 = [el[0] for el in default_test_preds_m1_v2_14229]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extra_test_predictions = [el[0] for el in extra_test_predictions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple, List\n",
    "def remove_beamsearch_probs(preds: List[List[Tuple[float, str]]]) -> List[List[str]]:\n",
    "    new_preds = []\n",
    "    for pred_line in preds:\n",
    "        new_preds_line = []\n",
    "        for _, word in pred_line:\n",
    "            new_preds_line.append(word)\n",
    "        new_preds.append(new_preds_line)\n",
    "    return new_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "default_test_predictions = remove_beamsearch_probs(default_test_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "default_test_preds_m1_v2_14229 = remove_beamsearch_probs(default_test_preds_m1_v2_14229)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "extra_test_predictions = remove_beamsearch_probs(extra_test_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_default_test_predictions, _ = separate_invalid_preds_greedy(default_test_predictions, vocab_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9373, 9193)"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(clean_default_test_predictions), sum(bool(el) for el in clean_default_test_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_default_test_preds_m1_v2_14229, _ = separate_invalid_preds_greedy(default_test_preds_m1_v2_14229, vocab_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9373, 9185)"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(clean_default_test_preds_m1_v2_14229), sum(bool(el) for el in clean_default_test_preds_m1_v2_14229)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_default_predictions = augment_predictions(clean_default_test_predictions, clean_default_test_preds_m1_v2_14229)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9373, 9244)"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_default_predictions), sum(bool(el) for el in all_default_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_test_predictions = merge_preds(all_default_predictions, extra_test_predictions, test_default_dataset.grid_name_idxs, test_extra_dataset.grid_name_idxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(not el for el in full_test_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_set = get_vocab_set(os.path.join(DATA_ROOT, \"voc.txt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_test_predictions, invalid_test_predictions =  separate_invalid_preds_greedy(full_test_predictions, vocab_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "147"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(not el for el in clean_test_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(<class 'int'>, {4: 7404, 3: 1032, 2: 840, 1: 577, 0: 147})\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "n_preds_in_line_dict = defaultdict(int)\n",
    "\n",
    "for line in clean_test_predictions:\n",
    "    n_preds_in_line_dict[len(line)] += 1\n",
    "\n",
    "print(n_preds_in_line_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_test_baseline_augmented = augment_predictions(clean_test_predictions, augment_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(not el for el in clean_test_baseline_augmented)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_name = \"m1_v2__0.14229_deault__0.14301_extra__beam.csv\"\n",
    "out_path = rf\"..\\data\\submissions\\{submission_name}\"\n",
    "create_submission(clean_test_baseline_augmented, out_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "old_preds_path = os.path.join(DATA_ROOT, \"test_raw_pred___best_model__2023_11_04__18_31_37__0.02530_default_switch_2.pt__best_model__2023_11_05__07_55_13__0.02516_extra_switch_2__with_pad_cutting.pt.pkl\")\n",
    "with open(old_preds_path, 'rb') as f:\n",
    "    old_preds_list = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "old_preds_list = remove_beamsearch_probs(old_preds_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "old_preds_list_valid, old_preds_list_invalid = separate_invalid_preds_greedy(old_preds_list, vocab_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_test_old_preds_augmented = augment_predictions(clean_test_predictions, old_preds_list_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(<class 'int'>, {4: 7981, 2: 657, 3: 776, 0: 126, 1: 460})\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "n_preds_in_line_dict = defaultdict(int)\n",
    "\n",
    "for line in clean_test_old_preds_augmented:\n",
    "    n_preds_in_line_dict[len(line)] += 1\n",
    "\n",
    "print(n_preds_in_line_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_test_old_preds_baseline_augmented = augment_predictions(clean_test_old_preds_augmented, augment_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_name = \"default__m1_bigger_13679__m1_v2__14229___extra__14301___with_baseline__beam.csv\"\n",
    "out_path = rf\"..\\data\\submissions\\{submission_name}\"\n",
    "create_submission(clean_test_baseline_augmented, out_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_name_to_ranged_bs_model_preds_paths = {\n",
    "    'default': [\"m1_bigger__m1_bigger_v2__2023_11_11__14_29_37__0.13679_default_l2_0_ls0_switch_0.pt.pkl\",\n",
    "                \"m1_v2__m1_v2__2023_11_09__10_36_02__0.14229_default_switch_0.pt.pkl\"],\n",
    "    'extra': [\"m1_v2__m1_v2__2023_11_09__17_47_40__0.14301_extra_l2_1e-05_switch_0.pt.pkl\"]\n",
    "}\n",
    "\n",
    "# должны ранжироваться по качесту beamsearch на валидации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [],
   "source": [
    "def patch_wrong_prediction_shape(prediciton):\n",
    "    return [pred_el[0] for pred_el in prediciton]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [],
   "source": [
    "default_idxs = test_default_dataset.grid_name_idxs\n",
    "extra_idxs = test_extra_dataset.grid_name_idxs \n",
    "\n",
    "grid_name_to_augmented_preds = {}\n",
    "\n",
    "for grid_name in ('default', 'extra'):\n",
    "    bs_pred_list = []\n",
    "\n",
    "    for f_name in grid_name_to_ranged_bs_model_preds_paths[grid_name]:\n",
    "        f_path = os.path.join(\"../data/saved_beamsearch_results/\", f_name)\n",
    "        with open(f_path, 'rb') as f:\n",
    "            bs_pred_list.append(pickle.load(f))\n",
    "        \n",
    "    bs_pred_list = [patch_wrong_prediction_shape(bs_preds) for bs_preds in bs_pred_list] \n",
    "    bs_pred_list = [remove_beamsearch_probs(bs_preds) for bs_preds in bs_pred_list]\n",
    "    bs_pred_list = [separate_invalid_preds_greedy(bs_preds, vocab_set)[0] for bs_preds in bs_pred_list]\n",
    "\n",
    "\n",
    "    augmented_preds = bs_pred_list.pop(0)\n",
    "\n",
    "    while bs_pred_list:\n",
    "        augmented_preds = augment_predictions(augmented_preds, bs_pred_list.pop(0))\n",
    "\n",
    "    grid_name_to_augmented_preds[grid_name] = augmented_preds\n",
    "\n",
    "\n",
    "full_preds = merge_preds(\n",
    "    grid_name_to_augmented_preds['default'],\n",
    "    grid_name_to_augmented_preds['extra'],\n",
    "    default_idxs,\n",
    "    extra_idxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(<class 'int'>, {4: 7404, 3: 1032, 2: 840, 1: 577, 0: 147})\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "n_preds_in_line_dict = defaultdict(int)\n",
    "\n",
    "for line in full_preds:\n",
    "    n_preds_in_line_dict[len(line)] += 1\n",
    "\n",
    "print(n_preds_in_line_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_preds_augmentations = [\n",
    "    \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(*full_preds, sep = '\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
