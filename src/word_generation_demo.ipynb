{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from typing import List, Tuple, Callable\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "# from model import get_m1_model, get_m1_bigger_model, get_m1_smaller_model\n",
    "from model import MODEL_GETTERS_DICT\n",
    "from ns_tokenizers import CharLevelTokenizerv2, KeyboardTokenizerv1\n",
    "from dataset import CurveDataset, CurveDatasetSubset\n",
    "from word_generators_v2 import GreedyGenerator, BeamGenerator, WordGenerator\n",
    "from metrics import get_mmr\n",
    "from feature_extraction.feature_extractors import weights_function_v1\n",
    "from feature_extraction.feature_extractors import get_val_transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "IN_KAGGLE = False\n",
    "\n",
    "if IN_KAGGLE:\n",
    "    DATA_ROOT = \"/kaggle/input/yandex-cup-playground\"\n",
    "    MODELS_DIR = \"\"\n",
    "else:\n",
    "    DATA_ROOT = \"../data/data_separated_grid\"\n",
    "    MODELS_ROOT = \"../data/trained_models_for_final_submit\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "VAL_PATH = os.path.join(DATA_ROOT, \"valid__in_train_format.jsonl\")\n",
    "TEST_PATH = os.path.join(DATA_ROOT, \"test.jsonl\")\n",
    "\n",
    "VOCAB_PATH = os.path.join(DATA_ROOT, \"voc.txt\")\n",
    "GRID_NAME_TO_GRID_PATH = os.path.join(DATA_ROOT, \"gridname_to_grid.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accumulating out-of-bounds coordinates...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7eb65bf3e4f24a53bff23c49020e7140",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84478de6ec944201986e95301d48e69e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "augmenting gname_to_out_of_bounds\n"
     ]
    }
   ],
   "source": [
    "kb_tokenizer = KeyboardTokenizerv1()\n",
    "char_tokenizer = CharLevelTokenizerv2(VOCAB_PATH)\n",
    "\n",
    "data_paths = [VAL_PATH, TEST_PATH]\n",
    "\n",
    "# takes almost no time\n",
    "dist_transform_v1 = get_val_transform(\n",
    "    gridname_to_grid_path=GRID_NAME_TO_GRID_PATH,\n",
    "    grid_names=('default', 'extra'),\n",
    "    transform_name=\"traj_feats_and_distance_weights\",\n",
    "    char_tokenizer=char_tokenizer,\n",
    "    dist_weights_func=weights_function_v1,\n",
    "    include_time=False,\n",
    "    include_velocities=True,\n",
    "    include_accelerations=True\n",
    ")\n",
    "\n",
    "# takes a lot of time\n",
    "kb_transform = get_val_transform(\n",
    "    gridname_to_grid_path=GRID_NAME_TO_GRID_PATH,\n",
    "    grid_names=('default', 'extra'),\n",
    "    transform_name=\"traj_feats_and_nearest_key\",\n",
    "    char_tokenizer=char_tokenizer,\n",
    "    uniform_noise_range=0,\n",
    "    ds_paths_list=data_paths,\n",
    "    totals = [10_000, 10_000],\n",
    "    include_time=False,\n",
    "    include_velocities=True,\n",
    "    include_accelerations=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10000it [00:00, 19441.20it/s]\n",
      "10000it [00:00, 19562.92it/s]\n"
     ]
    }
   ],
   "source": [
    "val_dataset = CurveDataset(\n",
    "    data_path=VAL_PATH,\n",
    "    store_gnames=True,\n",
    "    init_transform=None,\n",
    "    # get_item_transform=kb_transform,\n",
    "    get_item_transform=dist_transform_v1,\n",
    ")\n",
    "\n",
    "test_dataset = CurveDataset(\n",
    "    data_path=TEST_PATH,\n",
    "    store_gnames=True,\n",
    "    init_transform=None,\n",
    "    # get_item_transform=kb_transform,\n",
    "    get_item_transform=dist_transform_v1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_default_dataset = CurveDatasetSubset(val_dataset, \"default\")\n",
    "val_extra_dataset = CurveDatasetSubset(val_dataset, \"extra\")\n",
    "\n",
    "test_default_dataset = CurveDatasetSubset(test_dataset, \"default\")\n",
    "test_extra_dataset = CurveDatasetSubset(test_dataset, \"extra\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_targets(dataset: CurveDataset, \n",
    "                char_tokenizer: CharLevelTokenizerv2) -> List[str]:\n",
    "    targets = []\n",
    "    for _, target_tokens in dataset:\n",
    "        target = char_tokenizer.decode(target_tokens[:-1])\n",
    "        targets.append(target)\n",
    "    return targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vocab_set(vocab_path: str):\n",
    "    with open(vocab_path, 'r', encoding = \"utf-8\") as f:\n",
    "        return set(f.read().splitlines())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_set = get_vocab_set(os.path.join(DATA_ROOT, \"voc.txt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['v3_weighted_and_traj_transformer_bigger', 'v3_nearest_and_traj_transformer_bigger', 'v3_nearest_only_transformer_bigger', 'v3_trainable_gaussian_weights_and_traj_transformer_bigger', 'm1', 'm1_bigger', 'm1_smaller'])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MODEL_GETTERS_DICT.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_default_targets = get_targets(val_default_dataset, char_tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_name = \"default\"\n",
    "model_getter = MODEL_GETTERS_DICT['v3_weighted_and_traj_transformer_bigger']\n",
    "weights_path = r\"../results/models_for_debug/weighted_transformer_bigger-default--epoch=60-val_loss=0.442-val_word_level_accuracy=0.875.pt\"\n",
    "\n",
    "# model_getter = MODEL_GETTERS_DICT['v3_nearest_and_traj_transformer_bigger']\n",
    "# weights_path = r\"..\\results\\models_for_debug\\my_features_1\\v3_nearest_and_traj_transformer_bigger-default--epoch=32-val_loss=0.441-val_word_level_accuracy=0.864.pt\"\n",
    "\n",
    "model = model_getter(device, weights_path).eval()\n",
    "grid_name_to_greedy_generator = {grid_name: GreedyGenerator(model, char_tokenizer, device)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_suffix(s: str, suffix: str) -> str:\n",
    "    if s.endswith(suffix):\n",
    "        return s[:-len(suffix)]\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_classes = 35\n",
    "\n",
    "greedy_generator__no_vocab = GreedyGenerator(model, char_tokenizer, device)\n",
    "beam_generator__no_vocab = BeamGenerator(model, char_tokenizer, device)\n",
    "\n",
    "greedy_generator_with_vocab = GreedyGenerator(model, char_tokenizer, device, vocab_set, max_token_id=n_classes-1)\n",
    "beam_generator__with_vocab = BeamGenerator(model, char_tokenizer, device, vocab=vocab_set, max_token_id=n_classes-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def denormalize_beamsearch(score, pred_len, normalization_factor):\n",
    "    return score * (pred_len + 1)**normalization_factor\n",
    "\n",
    "def beamsearch_score_to_prob(score, pred_len, normalization_factor):   \n",
    "    return np.exp(denormalize_beamsearch(-score, pred_len, normalization_factor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_WORD_LEN = 35\n",
    "\n",
    "def predict(word_generator: WordGenerator, dataset, n_hypotheses, scores_to_prob: Callable, \n",
    "            max_steps_n: int = MAX_WORD_LEN, verbose = True, \n",
    "            n_examples = None, generator_call_kwargs = None, ) -> List[List[Tuple[str, float]]]:\n",
    "    \n",
    "    curve_id_to_hypotheses = []\n",
    "\n",
    "    n_examples = n_examples or len(dataset)\n",
    "    generator_call_kwargs = {} if generator_call_kwargs is None else generator_call_kwargs\n",
    "    \n",
    "\n",
    "    if verbose:\n",
    "        print((\"{:<22}\" + \"{:<29}\" * n_hypotheses).format(\"target\", *[f\"pred{i}\" for i in range(1, n_hypotheses+1)]))\n",
    "        print(\"-\"*(15+30*n_hypotheses))\n",
    "\n",
    "    for i, data in enumerate(val_default_dataset):\n",
    "        if i >= n_examples:\n",
    "            return curve_id_to_hypotheses\n",
    "\n",
    "        (encoder_in, dec_in), target = data\n",
    "\n",
    "        scores_and_preds_full = word_generator(encoder_in, max_steps_n = max_steps_n, \n",
    "            **generator_call_kwargs)\n",
    "\n",
    "        preds_and_probs_full = [(pred, scores_to_prob(pred, score)) \n",
    "                                for score, pred in scores_and_preds_full]\n",
    "\n",
    "        curve_id_to_hypotheses.append(preds_and_probs_full)\n",
    "\n",
    "        true_label = char_tokenizer.decode(target[:-1])\n",
    "\n",
    "        flat_preds_and_scores = (item for pair in preds_and_probs_full[:n_hypotheses] for item in pair)\n",
    "        if verbose:\n",
    "            print((\"{:<15}   |   \" + \"{:<16}{:.4f}   |   \" *n_hypotheses ).format(true_label, *flat_preds_and_scores))\n",
    "    \n",
    "    return curve_id_to_hypotheses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_scores_from_results(swipe_id_to_hypotheses_lst: list) -> list:\n",
    "    return [[pred for pred, score in item_hypothses_lst] for item_hypothses_lst in swipe_id_to_hypotheses_lst]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_EXAMPLES = 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target                pred1                        \n",
      "---------------------------------------------\n",
      "на                |   на              0.8950   |   \n",
      "все               |   все             0.8705   |   \n",
      "добрый            |   добрый          0.8608   |   \n",
      "девочка           |   девочка         0.8550   |   \n",
      "сказала           |   сказала         0.8633   |   \n",
      "скинь             |   скинь           0.8786   |   \n",
      "геев              |   геев            0.8842   |   \n",
      "тобой             |   тобой           0.8880   |   \n",
      "была              |   баса            0.4085   |   \n",
      "да                |   да              0.8957   |   \n",
      "муж               |   муж             0.8350   |   \n",
      "щас               |   щас             0.9516   |   \n",
      "она               |   она             0.9011   |   \n",
      "проблема          |   проблема        0.8468   |   \n",
      "билайн            |   билайн          0.8468   |   \n",
      "уже               |   уже             0.9064   |   \n",
      "раньше            |   раньше          0.8657   |   \n",
      "рам               |   нам             0.7396   |   \n",
      "щас               |   щас             0.9419   |   \n",
      "купил             |   купил           0.7817   |   \n",
      "ты                |   ты              0.9104   |   \n",
      "зовут             |   зовут           0.8996   |   \n",
      "короче            |   короче          0.8362   |   \n",
      "размыто           |   размыто         0.2740   |   \n",
      "давай             |   давай           0.8700   |   \n",
      "отдать            |   отдать          0.5606   |   \n",
      "привет            |   привет          0.8450   |   \n",
      "не                |   не              0.8842   |   \n",
      "да                |   да              0.8947   |   \n",
      "будете            |   будете          0.8685   |   \n",
      "связи             |   связи           0.8859   |   \n",
      "колывань          |   колывани        0.5530   |   \n",
      "меня              |   меня            0.8577   |   \n",
      "напиши            |   напиши          0.8690   |   \n",
      "знаю              |   знаю            0.9134   |   \n",
      "мамой             |   мамой           0.8660   |   \n",
      "не                |   не              0.8892   |   \n",
      "ты                |   ты              0.9095   |   \n",
      "только            |   только          0.8676   |   \n",
      "они               |   они             0.8998   |   \n"
     ]
    }
   ],
   "source": [
    "curve_id_to_hypotheses = predict(\n",
    "    greedy_generator_with_vocab, val_dataset, n_hypotheses=1, \n",
    "    scores_to_prob=lambda pred, score: np.exp(-score), n_examples=N_EXAMPLES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.925"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_mmr(\n",
    "    remove_scores_from_results(curve_id_to_hypotheses), \n",
    "    val_default_targets[:N_EXAMPLES])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target                pred1                        \n",
      "---------------------------------------------\n",
      "на                |   на              0.8729   |   \n",
      "все               |   все             0.8297   |   \n",
      "добрый            |   добрый          0.7269   |   \n",
      "девочка           |   девочка         0.6857   |   \n",
      "сказала           |   сказала         0.7000   |   \n",
      "скинь             |   скинь           0.7596   |   \n",
      "геев              |   геев            0.7808   |   \n",
      "тобой             |   тобой           0.7647   |   \n",
      "была              |   баса            0.3738   |   \n",
      "да                |   да              0.8705   |   \n",
      "муж               |   муж             0.7908   |   \n",
      "щас               |   щас             0.8447   |   \n",
      "она               |   она             0.8367   |   \n",
      "проблема          |   проблема        0.6630   |   \n",
      "билайн            |   билайн          0.7044   |   \n",
      "уже               |   уже             0.8313   |   \n",
      "раньше            |   раньше          0.7320   |   \n",
      "рам               |   нам             0.7039   |   \n",
      "щас               |   щас             0.8326   |   \n",
      "купил             |   купил           0.6966   |   \n",
      "ты                |   ты              0.8728   |   \n",
      "зовут             |   зовут           0.7649   |   \n",
      "короче            |   короче          0.7234   |   \n",
      "размыто           |   размыто         0.1835   |   \n",
      "давай             |   давай           0.7630   |   \n",
      "отдать            |   отдать          0.4711   |   \n",
      "привет            |   привет          0.7301   |   \n",
      "не                |   не              0.8619   |   \n",
      "да                |   да              0.8694   |   \n",
      "будете            |   будете          0.7364   |   \n",
      "связи             |   связи           0.7597   |   \n",
      "колывань          |   колываешь       0.1670   |   \n",
      "меня              |   меня            0.7948   |   \n",
      "напиши            |   напиши          0.7292   |   \n",
      "знаю              |   знаю            0.7961   |   \n",
      "мамой             |   мамой           0.7615   |   \n",
      "не                |   не              0.8673   |   \n",
      "ты                |   ты              0.8716   |   \n",
      "только            |   только          0.7333   |   \n",
      "они               |   они             0.8335   |   \n"
     ]
    }
   ],
   "source": [
    "curve_id_to_hypotheses = predict(\n",
    "    greedy_generator__no_vocab, val_dataset, n_hypotheses=1, \n",
    "    scores_to_prob=lambda pred, score: np.exp(-score), n_examples=N_EXAMPLES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.925"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_mmr(\n",
    "    remove_scores_from_results(curve_id_to_hypotheses), \n",
    "    val_default_targets[:N_EXAMPLES])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target                pred1                        pred2                        pred3                        pred4                        \n",
      "---------------------------------------------------------------------------------------------------------------------------------------\n",
      "на                |   на              0.8950   |   нан             0.0014   |   нам             0.0013   |   нас             0.0013   |   \n",
      "все               |   все             0.8705   |   всенародная     0.0002   |   всенародно      0.0001   |   всенародную     0.0001   |   \n",
      "добрый            |   добрый          0.8608   |   добрый-добрый   0.0011   |   добрым          0.0039   |   добрые          0.0019   |   \n",
      "девочка           |   девочка         0.8550   |   девочка-волшебница0.0002   |   девочки         0.0029   |   девочку         0.0025   |   \n",
      "сказала           |   сказала         0.8633   |   сказал-сделал   0.0008   |   сказал          0.0037   |   сказали         0.0026   |   \n",
      "скинь             |   скинь           0.8786   |   скиньте         0.0025   |   скинь-ка        0.0012   |   скинься         0.0011   |   \n",
      "геев              |   геев            0.8842   |   генеалог        0.0017   |   генетическая    0.0004   |   генетическую    0.0002   |   \n",
      "тобой             |   тобой           0.8880   |   тобой-то        0.0011   |   тобоган         0.0012   |   тобрекс         0.0006   |   \n",
      "была              |   баса            0.4085   |   бычатся         0.1309   |   бычачий         0.0969   |   бычка           0.0666   |   \n",
      "да                |   да              0.8957   |   даяна           0.0011   |   дак             0.0013   |   дар             0.0013   |   \n",
      "муж               |   муж             0.8350   |   мудехар         0.0059   |   мудр            0.0120   |   мал             0.0106   |   \n",
      "щас               |   щас             0.9516   |   щаденко         0.0004   |   щаного          0.0005   |   щавель          0.0004   |   \n",
      "она               |   она             0.9011   |   онассис         0.0013   |   оная            0.0013   |   онам            0.0012   |   \n",
      "проблема          |   проблема        0.8468   |   проблемы        0.0031   |   проблема-то     0.0011   |   проблемам       0.0014   |   \n",
      "билайн            |   билайн          0.8468   |   биоразнообразие 0.0006   |   библа           0.0072   |   биоразнообразия 0.0003   |   \n",
      "уже               |   уже             0.9064   |   ужеобразные     0.0014   |   уже-уже         0.0012   |   ужей            0.0012   |   \n",
      "раньше            |   раньше          0.8657   |   ранешенько      0.0014   |   ранишь          0.0042   |   раньше-то       0.0012   |   \n",
      "рам               |   нам             0.7396   |   нас             0.0760   |   рам             0.0335   |   наматрасник     0.0001   |   \n",
      "щас               |   щас             0.9419   |   щажение         0.0013   |   щаного          0.0006   |   щаденко         0.0004   |   \n",
      "купил             |   купил           0.7817   |   купили          0.0354   |   купила          0.0165   |   купить          0.0128   |   \n",
      "ты                |   ты              0.9104   |   ты-таки         0.0007   |   трын-трава      0.0002   |   ты-то           0.0006   |   \n",
      "зовут             |   зовут           0.8996   |   зовут-то        0.0012   |   зовутся         0.0012   |   зовусь          0.0013   |   \n",
      "короче            |   короче          0.8362   |   коромысел       0.0014   |   короед          0.0027   |   корочу          0.0019   |   \n",
      "размыто           |   размыто         0.2740   |   размыть         0.1901   |   размыла         0.1489   |   размыл          0.0867   |   \n",
      "давай             |   давай           0.8700   |   давай-давай     0.0003   |   давайся         0.0013   |   давайте         0.0011   |   \n",
      "отдать            |   отдать          0.5606   |   отжать          0.2723   |   отжал           0.0127   |   отдавать        0.0017   |   \n",
      "привет            |   привет          0.8450   |   привет-пока     0.0008   |   привет-привет   0.0004   |   приветик        0.0012   |   \n",
      "не                |   не              0.8842   |   нее             0.0107   |   нехемия         0.0003   |   нехарактерен    0.0000   |   \n",
      "да                |   да              0.8947   |   дам             0.0014   |   дан             0.0014   |   дак             0.0014   |   \n",
      "будете            |   будете          0.8685   |   будет-то        0.0010   |   будем           0.0027   |   будешь-то       0.0005   |   \n",
      "связи             |   связи           0.8859   |   связочного      0.0005   |   свяжи           0.0026   |   связист         0.0011   |   \n",
      "колывань          |   колывани        0.5530   |   колыванов       0.0507   |   колывань        0.0457   |   кровать         0.0214   |   \n",
      "меня              |   меня            0.8577   |   меннонитов      0.0008   |   меннониты       0.0007   |   меняя           0.0024   |   \n",
      "напиши            |   напиши          0.8690   |   напиши-ка       0.0012   |   напишите        0.0015   |   напишу          0.0026   |   \n",
      "знаю              |   знаю            0.9134   |   знаю-знаю       0.0012   |   знать           0.0036   |   знают           0.0032   |   \n",
      "мамой             |   мамой           0.8660   |   мамору          0.0017   |   маторин         0.0011   |   мамочку         0.0010   |   \n",
      "не                |   не              0.8892   |   нее             0.0055   |   нехирургические 0.0000   |   нехирургическое 0.0000   |   \n",
      "ты                |   ты              0.9095   |   ты-таки         0.0007   |   ты-то           0.0005   |   тык             0.0013   |   \n",
      "только            |   только          0.8676   |   только-то       0.0012   |   тольятти        0.0011   |   толбухин        0.0010   |   \n",
      "они               |   они             0.8998   |   онищенко        0.0012   |   онигири         0.0013   |   они-то          0.0013   |   \n"
     ]
    }
   ],
   "source": [
    "n_examples = N_EXAMPLES\n",
    "normalization_factor = 0.5\n",
    "beamsize = 6\n",
    "\n",
    "curve_id_to_hypotheses = predict(\n",
    "    beam_generator__with_vocab, val_dataset, n_hypotheses=4, n_examples=n_examples,\n",
    "    generator_call_kwargs={'normalization_factor': normalization_factor, 'beamsize': beamsize}, \n",
    "    scores_to_prob =lambda pred, score: beamsearch_score_to_prob(score, len(pred) + 1, normalization_factor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9295"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_mmr(\n",
    "    remove_scores_from_results(curve_id_to_hypotheses), \n",
    "    val_default_targets[:N_EXAMPLES])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target                pred1                        pred2                        pred3                        pred4                        \n",
      "---------------------------------------------------------------------------------------------------------------------------------------\n",
      "на                |   на              0.8729   |   нан             0.0014   |   нак             0.0013   |   наз             0.0012   |   \n",
      "все               |   все             0.8297   |   всем            0.0015   |   вссе            0.0012   |   всен            0.0012   |   \n",
      "добрый            |   добрый          0.7269   |   добрым          0.0032   |   добрыйо         0.0011   |   добрыйи         0.0010   |   \n",
      "девочка           |   девочка         0.6857   |   девочки         0.0023   |   девочку         0.0020   |   девочкам        0.0013   |   \n",
      "сказала           |   сказала         0.7000   |   сказал          0.0031   |   сказали         0.0021   |   сказалась       0.0009   |   \n",
      "скинь             |   скинь           0.7596   |   скиньт          0.0020   |   скиньно         0.0010   |   скиньль         0.0008   |   \n",
      "геев              |   геев            0.7808   |   генев           0.0082   |   геева           0.0042   |   гееев           0.0037   |   \n",
      "тобой             |   тобой           0.7647   |   тобойой         0.0010   |   тобойа          0.0011   |   тобойе          0.0011   |   \n",
      "была              |   баса            0.3738   |   быча            0.1813   |   бычка           0.0504   |   быса            0.0366   |   \n",
      "да                |   да              0.8705   |   дар             0.0013   |   дан             0.0013   |   дак             0.0013   |   \n",
      "муж               |   муж             0.7908   |   мал             0.0101   |   мудд            0.0049   |   мудл            0.0038   |   \n",
      "щас               |   щас             0.8447   |   щаса            0.0015   |   щасе            0.0013   |   щасб            0.0013   |   \n",
      "она               |   она             0.8367   |   онат            0.0012   |   онас            0.0012   |   онао            0.0012   |   \n",
      "проблема          |   проблема        0.6630   |   проблемы        0.0024   |   проблемам       0.0011   |   проблеман       0.0010   |   \n",
      "билайн            |   билайн          0.7044   |   билайк          0.0064   |   билайне         0.0023   |   билайна         0.0015   |   \n",
      "уже               |   уже             0.8313   |   ужеи            0.0013   |   ужео            0.0012   |   ужеб            0.0012   |   \n",
      "раньше            |   раньше          0.7320   |   раньшее         0.0013   |   ранье           0.0027   |   раньшей         0.0012   |   \n",
      "рам               |   нам             0.7039   |   нас             0.0730   |   рам             0.0318   |   наи             0.0028   |   \n",
      "щас               |   щас             0.8326   |   щаса            0.0012   |   щаси            0.0012   |   щасб            0.0012   |   \n",
      "купил             |   купил           0.6966   |   купили          0.0302   |   купила          0.0141   |   купить          0.0108   |   \n",
      "ты                |   ты              0.8728   |   тыб             0.0012   |   тыи             0.0012   |   тыф             0.0012   |   \n",
      "зовут             |   зовут           0.7649   |   зовута          0.0014   |   зовуть          0.0011   |   зовуты          0.0011   |   \n",
      "короче            |   короче          0.7234   |   корочей         0.0019   |   корочее         0.0012   |   корочу          0.0017   |   \n",
      "размыто           |   размыто         0.1835   |   размыть         0.1296   |   размыла         0.1043   |   размымил        0.0524   |   \n",
      "давай             |   давай           0.7630   |   давайе          0.0011   |   давайс          0.0011   |   давайь          0.0010   |   \n",
      "отдать            |   отдать          0.4711   |   отжать          0.2082   |   отжасть         0.0122   |   отжаль          0.0125   |   \n",
      "привет            |   привет          0.7301   |   приветик        0.0009   |   привете         0.0012   |   привета         0.0011   |   \n",
      "не                |   не              0.8619   |   нее             0.0100   |   нео             0.0014   |   нес             0.0013   |   \n",
      "да                |   да              0.8694   |   дан             0.0014   |   дам             0.0014   |   дак             0.0013   |   \n",
      "будете            |   будете          0.7364   |   будетеле        0.0010   |   будетем         0.0012   |   будетей         0.0012   |   \n",
      "связи             |   связи           0.7597   |   связин          0.0032   |   связит          0.0024   |   связил          0.0018   |   \n",
      "колывань          |   колываешь       0.1670   |   колывать        0.1306   |   колывает        0.0731   |   колывают        0.0191   |   \n",
      "меня              |   меня            0.7948   |   меняя           0.0021   |   менял           0.0012   |   меням           0.0012   |   \n",
      "напиши            |   напиши          0.7292   |   напишин         0.0016   |   напишу          0.0022   |   напишит         0.0012   |   \n",
      "знаю              |   знаю            0.7961   |   знать           0.0030   |   знают           0.0027   |   знаюл           0.0011   |   \n",
      "мамой             |   мамой           0.7615   |   мамтой          0.0025   |   мамойа          0.0012   |   мамойж          0.0011   |   \n",
      "не                |   не              0.8673   |   нее             0.0052   |   ну              0.0036   |   нег             0.0013   |   \n",
      "ты                |   ты              0.8716   |   тыб             0.0012   |   тык             0.0012   |   тыд             0.0012   |   \n",
      "только            |   только          0.7333   |   толькое         0.0011   |   толькоь         0.0010   |   толькоб         0.0010   |   \n",
      "они               |   они             0.8335   |   оние            0.0015   |   онии            0.0015   |   онир            0.0013   |   \n"
     ]
    }
   ],
   "source": [
    "n_examples = N_EXAMPLES\n",
    "normalization_factor = 0.5\n",
    "\n",
    "curve_id_to_hypotheses = predict(\n",
    "    beam_generator__no_vocab, val_dataset, n_hypotheses=4, n_examples=n_examples,\n",
    "    generator_call_kwargs={'normalization_factor': normalization_factor, 'beamsize': beamsize}, \n",
    "    scores_to_prob =lambda pred, score: beamsearch_score_to_prob(score, len(pred) + 1, normalization_factor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9272500000000001"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_mmr(\n",
    "    remove_scores_from_results(curve_id_to_hypotheses), \n",
    "    val_default_targets[:N_EXAMPLES])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('на', 0.8729091854152667), ('нан', 0.0013687703829175547), ('нак', 0.0012917311480830328), ('наз', 0.001240692764716203), ('нас', 0.0012353012520421001), ('нам', 0.0012299431799445055)]\n",
      "\n",
      "[('все', 0.8296965372726712), ('всем', 0.0014837087743218484), ('вссе', 0.001230527051960393), ('всен', 0.001221845670644851), ('всел', 0.0011628419218424532), ('всев', 0.0011594028348149632)]\n"
     ]
    }
   ],
   "source": [
    "print(curve_id_to_hypotheses[0][:6])\n",
    "print()\n",
    "print(curve_id_to_hypotheses[1][:6])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------\n",
    "Как и ожидается, после денормализации бимсерча вероятности не такие же как в greedy\n",
    "\n",
    "Нужно отметить, что в общем случае должно быть так:\n",
    "* greedy_search_no_vocab__results == beamsearch__no_vocab__results\n",
    "* greedy_search_with_voc__results == beamsearch__with_voc__results\n",
    "* greedy_search_with_voc__results != beamsearch__no_vocab__results\n",
    "* greedy_search__no_vocab__results != beamsearch__with_voc__results\n",
    "\n",
    "\n",
    "\n",
    "Некоторые заметки:\n",
    "1. Иногда вероятность оказывается немонотонной. Это именно из-за того, что мы убрали нормализацию бимсерча. То есть убрали штраф за краткость, а при ранжировании он был\n",
    "2. Даже если beamsize = n_classes, beamsearch не оценивает явно вероятность всех слов, потому что из-за over confidence вероятности некоторых возможных токенов оказываются нулевыми и эта ветка обрывается\n",
    "---------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extra: Batched Greedy Search example\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Batched greedy search Pros:\n",
    "* produces the same results as unbatched variant (make sure to compare with no_vocab version)\n",
    "* works faster\n",
    "Batched greedy search Cons:\n",
    "* doesn't support vocab masking yet\n",
    "* has a different interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from dataset import CollateFnV2\n",
    "from word_generators_v2 import GreedyGeneratorBatched"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "collate_fn = CollateFnV2(batch_first=False, word_pad_idx=char_tokenizer.char_to_idx['<pad>'])\n",
    "val_default_dataloader = DataLoader(val_default_dataset, batch_size=N_EXAMPLES, shuffle=False, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "greedy_generator_batched__no_vocab = GreedyGeneratorBatched(model, char_tokenizer, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_WORD_LEN = 35\n",
    "\n",
    "\n",
    "def remove_tokens(tensor, tokens_to_remove):\n",
    "    return tensor[~torch.isin(tensor, torch.tensor(tokens_to_remove))]\n",
    "\n",
    "def predict_batched(word_generator: WordGenerator, dataloader, max_steps: int = MAX_WORD_LEN, \n",
    "                    verbose: bool = True, n_batches: int = None, generator_call_kwargs = None, \n",
    "                    ):\n",
    "    n_hypotheses = 1\n",
    "\n",
    "    generator_call_kwargs = {} if generator_call_kwargs is None else generator_call_kwargs\n",
    "\n",
    "    pad_token_id = word_generator.tokenizer.char_to_idx['<pad>']\n",
    "    eos_token_id = word_generator.tokenizer.char_to_idx['<eos>']\n",
    "    sos_token_id = word_generator.tokenizer.char_to_idx['<sos>']\n",
    "\n",
    "\n",
    "\n",
    "    if verbose:\n",
    "        print((\"{:<22}\" + \"{:<29}\" * n_hypotheses).format(\"target\", *[f\"pred{i}\" for i in range(1, n_hypotheses+1)]))\n",
    "        print(\"-\"*(15+30*n_hypotheses))\n",
    "\n",
    "    for i, ((encoder_in, _, encoder_pad_mask, _), target) in enumerate(dataloader):\n",
    "        target = target.T\n",
    "        if n_batches is not None and i >= n_batches:\n",
    "            break\n",
    "\n",
    "        with torch.no_grad():\n",
    "            char_token_ids, log_probs = word_generator(encoder_in, encoder_pad_mask, max_steps, **generator_call_kwargs)\n",
    "            char_token_ids = char_token_ids.T\n",
    "\n",
    "            pred_words = [char_tokenizer.decode(remove_tokens(char_token_ids[i], [pad_token_id, eos_token_id, sos_token_id])) \n",
    "                          for i in range(char_token_ids.size(0))]\n",
    "            target_words = [char_tokenizer.decode(remove_tokens(target[i], [pad_token_id, eos_token_id, sos_token_id]))\n",
    "                            for i in range(target.size(0))]\n",
    "            log_probs = log_probs.cpu().numpy()\n",
    "            probs = np.exp(log_probs)\n",
    "\n",
    "            if verbose:\n",
    "                for true_label, pred_word, log_prob in zip(target_words, pred_words, probs):\n",
    "                    print((\"{:<15}   |   \" + \"{:<16}{:.4f}   |   \" *n_hypotheses ).format(true_label, pred_word, log_prob))\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target                pred1                        \n",
      "---------------------------------------------\n",
      "на                |   на              0.8729   |   \n",
      "все               |   все             0.8297   |   \n",
      "добрый            |   добрый          0.7269   |   \n",
      "девочка           |   девочка         0.6857   |   \n",
      "сказала           |   сказала         0.7000   |   \n",
      "скинь             |   скинь           0.7596   |   \n",
      "геев              |   геев            0.7808   |   \n",
      "тобой             |   тобой           0.7647   |   \n",
      "была              |   баса            0.3738   |   \n",
      "да                |   да              0.8705   |   \n",
      "муж               |   муж             0.7908   |   \n",
      "щас               |   щас             0.8447   |   \n",
      "она               |   она             0.8367   |   \n",
      "проблема          |   проблема        0.6630   |   \n",
      "билайн            |   билайн          0.7044   |   \n",
      "уже               |   уже             0.8313   |   \n",
      "раньше            |   раньше          0.7320   |   \n",
      "рам               |   нам             0.7039   |   \n",
      "щас               |   щас             0.8326   |   \n",
      "купил             |   купил           0.6966   |   \n",
      "ты                |   ты              0.8728   |   \n",
      "зовут             |   зовут           0.7649   |   \n",
      "короче            |   короче          0.7234   |   \n",
      "размыто           |   размыто         0.1835   |   \n",
      "давай             |   давай           0.7630   |   \n",
      "отдать            |   отдать          0.4711   |   \n",
      "привет            |   привет          0.7301   |   \n",
      "не                |   не              0.8619   |   \n",
      "да                |   да              0.8694   |   \n",
      "будете            |   будете          0.7364   |   \n",
      "связи             |   связи           0.7597   |   \n",
      "колывань          |   колываешь       0.1670   |   \n",
      "меня              |   меня            0.7948   |   \n",
      "напиши            |   напиши          0.7292   |   \n",
      "знаю              |   знаю            0.7961   |   \n",
      "мамой             |   мамой           0.7615   |   \n",
      "не                |   не              0.8673   |   \n",
      "ты                |   ты              0.8716   |   \n",
      "только            |   только          0.7333   |   \n",
      "они               |   они             0.8335   |   \n"
     ]
    }
   ],
   "source": [
    "predict_batched(greedy_generator_batched__no_vocab, val_default_dataloader, n_batches=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
