Модель - практически обычной четырехслойный трансформер. Единственное отличие - эмбеддинги на входе первого слоя энкодера имеют меньшую размерность, чем у всех других слоев.


Предобработка (фильтрация датасета):
Удалял ошибочные данные из обучающего датасета, как в старой гугловской статье Modeling Gesture-Typing Movements:
* Если расстояние от точки кривой до центра ближайшей клавиши больше, чем расстояние между центрами клавиш 'ц' и 'ф', выбрасываем обучающий пример
* Использовал алгоритм из той же статьи, который относит каждую точку кривой обучающего датасета к букве таргета. Если оказывается, что к какой-то букве относится меньше двух точек, удаляем такой пример.
* Удалил все пример, где время не монотонно возрастает

Таким образом я отфильтровал 7% обучающего датасета




Создание сабмита:
AppendAgregator:
Модели ранжируются по mmr@4 на валидационной выборке, в качестве финальных предсказаний для каждой кривой кривой записываются сначала все валидные предсказания первой по mmr модели, затем второй и тд.
Такая аггрегация исопльзовалась в финальном сабмите. Для default клавиатуры было исопльзовано 5 чекпойнтов модели m1_bigger и 1 чекпойнт модели m1, на extra - 1 m1_bigger, 1 m1. В конце я дополнял мое решение результатами работы бейзлайна.
Такой чекпойнт дал 0.8936 на валидационной выборке, 0,8919 на публичной тестовой и 0,8963 на приаватной тестовой

m1 - трансформер с 4-я слоями энкодера и 3-я слоями декодера,  m1_bigger - это трансформер с 4-я слоями энкодера и 4-я слоями декодера.

WeightedAgregator:
Каждой модели назначаются веса. Все уверенности модели умножаются на назначенный ей вес. В качестве финальных предсказаний для каждой кривой предсказания отдельных моделей сливаются в один список с поддержанием сортировки по уверенности.
Этот способ ансамблирования был реализован после соревнования и с теми же моделями дал 0.8995 на валидационной выборке. Будет интересно посмотреть, какой mmr на тестовой выборке.



Что не сработало:
Пробовал для каждого сгенерированного слова не принадлежащего словарю находить слово из словаря с минимальным расстояним редактирвоания, сортировать исправленные слова по расстоянию редактирования и расширять ими список предсказаний с валидными словами. В конце, как и в случае с удалением невалидных слов, предсказания дополняются результатами бейзлайна. К сожалению, это давало более низкий mmr, чем дополнение предсказаний с валидными словами результатами работы бейзлайна без использования исправленных невалиных слов. Поэтому этот эксперимент остался только в очень захламленном блокноте playground в разделе min dist algo



Что придумал на соревновании, но не успел:
1. Обучить отдельную энкодер-декодер модель исправлять опечатки (слова не из словаря). Для этого планировал сделать датасет из "опечаток" модели и настоящих слов. Также можно было зафайнтюнить предобученные модели, решающие задачу spelling correction c hugging face. 

2. Обучить сиамскую сеть. Для этого сначала получим кривые: если слово есть в обучающей выборке возьмем кривую оттуда, если нет, в качестве синтетических данных проведем кривую, у которой минимальный рывок (третья производная координаты по времени). Такой выбор синтетических данных объясняется в статье от Гугл (правда, кажется, 2016 года) Modeling Gesture-Typing Movements. В качестве фич будем использовать выход энкодера из моего решения. Построим сиамскую сееть и обучим с триплет лоссом мерить косинусное расстояние между энккодингом данной кривой и энкодингами кривых, полученных из каждого слова словаря.

3. Зафайнтюнить Bert, добавив ему токены для отдельных букв, без использования информации о траектории: преобразование одной последовательности клавиш в другую. Так предполагалось обучаться на всех данных, включая дополнительные

4. Ансамблирование с помощью взвешивания сделал только после соревнования. Сейчас веса подбираются вручную, планируется использовать генетический алгоритм.